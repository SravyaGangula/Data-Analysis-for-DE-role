Job_title,Company,Job_posted_date,Link,Matching_percentage,Logo,Location,Job_description,Salary_range,Category
Junior Data Engineer (US),Fitness Matrix Inc,12/25/2023,https://www.linkedin.com/jobs/view/3793120666,0,https://media.licdn.com/dms/image/D4E0BAQGmk8ZefBUxLg/company-logo_100_100/0/1698352894604/fitness_matrix_inc_logo?e=2147483647&v=beta&t=72cgj7Ot5k670-7oCMGX7QoHQoicVzzbGuWzPstPuXw,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Junior Data Engineer (US) - Onsite<br/><br/></strong><strong>Full-time<br/><br/></strong><strong>$66K - $77K per annum<br/><br/></strong><strong>1+ Year Experience Required<br/><br/></strong><strong>Introduction:<br/><br/></strong>FitnessMatrixInc is a unique approach to health and wellness that is based on the principle of bio-individuality. This means that we believe that everyone is different and has their own unique needs and challenges. We will work with you to understand your biochemistry and develop a personalized plan that is right for you.<br/><br/><strong>Position Summary<br/><br/></strong>Join the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.<br/><br/><strong>Key Responsibilities include:<br/><br/></strong><ul><li>Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. </li><li>Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency </li><li>Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency </li><li>Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data </li><li>Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently </li><li>Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation </li><li>Create/maintain documentation for data processes, data flows, and system configurations </li><li>Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness <br/><br/></li></ul><strong>Characteristics of this role:<br/><br/></strong><ul><li>Team Player: Willing to teach, share knowledge, and work with others to make the team successful. </li><li>Communication: Exceptional verbal, written, organizational, presentation, and communication skills. </li><li>Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. </li><li>Attention to detail: Systematically and accurately research future solutions and current problems. </li><li>Strong work ethic: The innate drive to do work extremely well. </li><li>Passion: A drive to deliver better products and services than expected to customers. <br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><ul><li>2+ years of programming experience in languages such as Python, Java, SQL </li><li>2+ years of experience with ETL tools and database management (relational, non-relational) </li><li>2+ years of experience in data modeling techniques and tools to design efficient scalable data structures </li><li>Skills in data quality assessment, data cleansing, and data validation <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Knowledge of big data technologies and cloud platforms </li><li>Experience with technologies like PySpark, Databricks, and Azure Synapse. <br/><br/></li></ul><strong>Education<br/><br/></strong>Bachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience<br/><br/><strong>Why should we work with Fitness Matrix?<br/><br/></strong>Fitness Matrix Inc is the leading provider of holistic and multidimensional health and wellness services. We offer a comprehensive approach to health and wellness. We take into account all aspects of your life, from your physical fitness and nutrition to your mental, emotional, and spiritual well-being. We use the latest science and technology to develop our programs and services. We are constantly innovating and finding new ways to help our clients achieve their goals. We offer a variety of programs and services to meet your needs and budget.<br/><br/>
</div>",$66- $77,Data Engineer
Data Engineer (DE),Zortech Solutions,12/24/2023,https://www.linkedin.com/jobs/view/3787251275,0,https://media.licdn.com/dms/image/C4E0BAQFLYN9bJoNeQg/company-logo_100_100/0/1630602268967?e=2147483647&v=beta&t=VbFirFeWDqzftzmA-xuL4-Rh3UkhihCRtFcB66Ze6Cg,"Paradise Valley, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Role: Data Engineer (DE)<br/><br/></strong><strong>Location: Scottsdale AZ (day 1 onsite)<br/><br/></strong><strong>Duration: Fulltime <br/><br/></strong><strong>Must have skill set: Java , Scala , S3, Glue, Redshift<br/><br/></strong><ul><li>You have 6-8 years of relevant software development experience. </li><li>You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is critical. </li><li>Highly analytical and data oriented. </li><li>Experience in SQL, NoSql Database </li><li>Data masking of on prem PII data. </li><li>Develop API calls with using secure data transfer. </li><li>Take standard output data to lower environments for pre prod testing! </li><li>Enable secured channels for data models and data science activities. </li><li>Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 mins </li><li>You have experience with development tools and agile methodologies.</li></ul>
</div>",No Salary Info Found,Data Engineer
Data Engineer,Sophinea Corporation,12/19/2023,https://www.linkedin.com/jobs/view/3790308997,0,https://media.licdn.com/dms/image/C4E0BAQHKGcS2SVjMMw/company-logo_100_100/0/1630602935929?e=2147483647&v=beta&t=n6S3niAlq2wKPznT1N5AljnE-ih5chfyLz6xcSmYBBk,United States,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Sophinea, a leading computer software company, is seeking a highly skilled and motivated Data Engineer to join our dynamic team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure. You will ensure the accuracy, availability, and security of our data, providing critical insights to drive the company's success.<br/><br/>In this role, you will collaborate with cross-functional teams to identify and implement data solutions that align with our business objectives. You will be responsible for optimizing data pipelines, ensuring efficient data extraction, transformation, and loading processes. Additionally, you will contribute to the development and implementation of data governance policies, ensuring compliance and data integrity.<br/><br/>If you have a passion for data engineering, possess strong analytical and problem-solving skills, and excel in a collaborative environment, we would love to hear from you. Join our innovative team and be part of shaping the future of our data-driven company.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Design, develop, and maintain data pipelines for ETL (Extract, Transform, Load) processes</li><li>Collaborate with cross-functional teams to identify data requirements and implement effective data solutions</li><li>Optimize data models and improve the performance of data stores</li><li>Monitor data quality and implement data validation techniques to ensure accuracy and consistency</li><li>Implement effective data security measures and maintain data privacy standards</li><li>Develop and maintain data governance policies and procedures</li><li>Troubleshoot and resolve data-related issues in a timely manner<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li>Bachelor's degree in Computer Science, Information Systems, or a related field</li><li>Proven experience as a Data Engineer or in a similar role</li><li>Strong knowledge of SQL and data modeling techniques</li><li>Proficiency in at least one programming language, such as Python or Java</li><li>Experience with ETL and data integration tools, such as Apache Kafka or Informatica</li><li>Familiarity with cloud-based data platforms, such as AWS or GCP</li><li>Excellent problem-solving and analytical skills</li><li>Strong communication and collaboration abilities</li><li>Ability to work in a fast-paced and dynamic environment</li><li>Attention to detail and commitment to data accuracy and integrity<br/><br/></li></ul><strong>Benefits<br/><br/></strong><ul><li>Health Care Plan (Medical, Dental &amp; Vision)</li><li>Retirement Plan (401k, IRA)</li><li>Life Insurance (Basic, Voluntary &amp; AD&amp;D)</li><li>Paid Time Off (Vacation, Sick &amp; Public Holidays)</li><li>Short Term &amp; Long Term Disability</li><li>Training &amp; Development</li><li>Work From Home</li></ul>
</div>",No Salary Info Found,Data Engineer
Data Engineer,Accroid Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788129009,0,https://media.licdn.com/dms/image/D4D0BAQGz_di1atu9CQ/company-logo_100_100/0/1683292700129/accroid_inc_logo?e=2147483647&v=beta&t=OvupgW0oZWw8oodQiV4pXMO4DTI0u9OdLiuevK1eX9s,"Ankeny, IA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Onsite<br/><br/></strong><strong>Data Engineer <br/><br/></strong><ul><li>Build and maintain data pipelines utilizing Databricks and ADLS.</li><li>Collaborate with cross-functional teams to understand and fulfill data requirements.</li><li>Deliver outputs that align with defined specifications and meet business objectives.</li><li>Provide expertise in data engineering and contribute to the overall success of data-related projects.</li></ul>
</div>",No Salary Info Found,Data Engineer
ETL Data Engineer,Zortech Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3788124368,0,https://media.licdn.com/dms/image/C4E0BAQFLYN9bJoNeQg/company-logo_100_100/0/1630602268967?e=2147483647&v=beta&t=VbFirFeWDqzftzmA-xuL4-Rh3UkhihCRtFcB66Ze6Cg,"Georgia, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Note for full time candidates: (Visa Independent Only for FTE)<br/><br/></strong><strong>Role: ETL Data Engineer<br/><br/></strong><strong>Location: Augusta GA (100% Onsite)<br/><br/></strong><strong>Duration: C2C/Fulltime<br/><br/></strong><strong>Job Description<br/><br/></strong><ul><li>Strong hands-on coding experience with 6 to 8 years of experience in ETL </li><li>Hands on exp. on SQL/PL SQL </li><li>Strong hands-on Experience using Azure cloud </li><li>Hands on exp. on Data cloud platforms like Snowflake </li><li>Ability to plan and own the work packets and with minimal supervision or direction is highly desired</li></ul>
</div>",No Salary Info Found,Data Engineer
Data and Analytics Engineer,Jetty,12/19/2023,https://www.linkedin.com/jobs/view/3788131758,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,PA Consulting,12/19/2023,https://www.linkedin.com/jobs/view/3752017186,0,https://media.licdn.com/dms/image/D4E0BAQGzMvnsrZOkxA/company-logo_100_100/0/1688328174598/pa_consulting_logo?e=2147483647&v=beta&t=Ec8QVvRnf_DVjk0c5JfZAs23urJGlPyEs7bqBhsMsWM,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>We believe in the power of ingenuity to build a positive human future.<br/><br/>As strategies, technologies and innovation collide, we create opportunity from complexity.<br/><br/>Our diverse teams of experts combine innovative thinking and breakthrough use of technologies to progress further, faster. Our clients adapt and transform, and together we achieve enduring results.<br/><br/>An innovation and transformation consultancy, we are over 4000 specialists in consumer and manufacturing, defence and security, energy and utilities, financial services, government and public services, health and life sciences, and transport. Our people are strategists, innovators, designers, consultants, digital experts, scientists, engineers and technologists. We operate globally from offices across the UK, US, Netherlands and Nordics.<br/><br/>PA. Bringing Ingenuity to Life<br/><br/><strong>Job Description<br/><br/></strong><strong>Your day to day <br/><br/></strong>We’re an innovation and transformation consultancy that believes in the power of ingenuity to build a positive-human future in a technology-driven world. Our diverse teams of experts combine innovative thinking with breakthrough-technologies to progress further, faster.<br/><br/>Are you ready to harness the power of data to drive advancements in healthcare? Are you passionate about designing, building, and maintaining data infrastructure that plays a pivotal role in improving patient outcomes and shaping the future of medicine? If you're seeking a rewarding career at the intersection of healthcare and technology, we invite you to be part of our dynamic team. This is a unique, multi-year, project-based opportunity to build and grow a clinical data registry platform over many years working with a dedicated team of collaborators and customers. As a Data Engineer for our cutting-edge medical data registry, you'll be at the forefront of managing, optimizing, and expanding our data infrastructure, enabling critical insights that can positively impact patient outcomes. If you're excited about leveraging your data engineering skills to make a difference in the world of healthcare, we want to hear from you.<br/><br/><strong>Qualifications<br/><br/></strong>Minimum qualifications:<br/><br/><br/><ul><li>Advanced SQL and Python</li><li>Expertise in the design and construction of Big Data Lakes and Data Warehouses capable of ingesting, standardizing, and serving billions of data rows spanning diverse datasets ranging from tens to hundreds</li><li>Experience building dynamic, metadata driven pipelines and analyses</li><li>Building and managing fully automated data pipelines (ETL, ELT, ELTL) including:</li><ul><li>Designing and building data interfaces to source systems</li><li>Combining and transforming data into the appropriate format for storage</li><li>Developing data sets for analytics purposes</li><li>Developing pipelines that can handle common issues/errors in a robust and automated way</li></ul><li>Cloud experience in Azure, AWS or GCP<br/><br/></li></ul>Preferred qualifications:<br/><br/><br/><ul><li>Spark / PySpark experience highly preferable</li><li>Working in Agile and DevOps environments</li><li>Basic Python, Bash, or PowerShell for automation</li><li>Data modelling – Kimball, Data Vault, Star/Snowflake schema, Query-first etc.</li><li>Data visualisation in Power BI, Tableau, Qlik or similar</li><li>Architecting Data Platforms - designing BI/MI/Analytics solutions using Big Data, Relational or Streaming technologies</li><li>One or more of the following certifications:</li><ul><li>Microsoft Certified: Azure Data Engineer Associate</li><li>AWS Certified Data Analytics - Specialty</li><li>GCP Professional Data Engineers<br/><br/><br/></li></ul></ul><strong>Additional Information<br/><br/></strong>Life At PA encompasses our peoples' experience at PA. It's about how we enrich peoples’ working lives by giving them access to unique people and growth opportunities and purpose led meaningful work.<br/><br/>We believe diversity fuels ingenuity. Diversity of thought brings exciting perspectives; diversity of experience brings a wealth of knowledge, and diversity of skills brings the tools we need. When we bring people together with diverse backgrounds, identities, and minds, embracing that difference through an inclusive culture where our people thrive; we unleash the power of diversity – bringing ingenuity to life. We are dedicated to supporting the physical, emotional, social and financial well-being of our people.<br/><br/>The Salary for this role is between $90,000 - $110,000
      </div>",$90000- $110000,Data Engineer
Software Engineer -Entry Level,Lockheed Martin,12/19/2023,https://www.linkedin.com/jobs/view/3790017200,0,https://media.licdn.com/dms/image/C4E0BAQHF1YKEZdN4LA/company-logo_100_100/0/1668532986109/lockheed_martin_logo?e=2147483647&v=beta&t=MAt3FDVkp1mxAnqi-7a-mmVAi8Lcd_S1_XvT0Y_Z40s,"King of Prussia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Lockheed Martin Rotary and Mission Systems, we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and visionary thinking, everything is within our reach – and yours as a Lockheed Martin employee. Lockheed Martin values your skills, training and education. Come and experience your future!<br/><br/>Within the RMS C6ISR Division, we are seeking a motivated and experienced Software Engineer to join our team. The successful candidate will join the Weapons Platform Integration (WPI) portfolio to make an immediate impact on the PIErS project team.<br/><br/>The qualified candidate will have experience developing software in an Agile development environment as part of a scrum team. These roles are largely team based and successful engineers in our organization are able to work and communicate to not only their scrum teams, but cross-team, and to project leadership. The candidate should be comfortable presenting and demonstrating capabilities to both internal leadership and external Customers.
      </div>",No Salary Info Found,Data Engineer
Data Engineer,ASCENDING Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3790307654,0,https://media.licdn.com/dms/image/C4D0BAQG4H6mBuWVGQw/company-logo_100_100/0/1631372273839/ascendingllc_logo?e=2147483647&v=beta&t=HqSlWBYB2Htxq8mAj5GFZEzDCI-FyaW7xdBt4yqDPEo,"Fairfax, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Full-time, 100% Remote<br/><br/>Available for W-2 or 1099 Individual. <br/><br/></strong>Our client, one of the largest Amazon Web Services (AWS) partners for data services, is looking for a true Mid level Big Data Engineer to contribute to join their team of technologists to build and contribute to large-scale, innovative projects. Technological and career growth opportunities are a natural and every day part of the working environment.<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Analyze system requirements and design responsive algorithms and solutions.</li><li>Use big data and cloud technologies to produce production quality code.</li><li>Engage in performance tuning and scalability engineering.</li><li>Work with team, peers and management to identify objectives and set priorities.</li><li>Perform related SDLC engineering activities like sprint planning and estimation.</li><li>Work effectively in small agile teams.</li><li>Provide creative solutions to problems.</li><li>Identify opportunities for improvement and execute.<br/><br/></li></ul><strong>Requirements:<br/><br/></strong><ul><li>Minimum 4 years of proven professional experience working in the IT industry.</li><li>Bachelor's in Computer Science or related domain.</li><li>Experience with cloud based Big Data technologies.</li><li>Experience with big data technologies like Hadoop, Spark and Hive.</li><li>AWS experience (S3 and EMR).</li><li>Proficiency in Hive / Spark SQL / SQL. Experience with Spark.</li><li>Experience with one or more programming languages like Scala &amp; Python &amp; Java.</li><li>Ability to push the frontier of technology and independently pursue better alternatives.<br/><br/></li></ul>Thanks for applying!<br/><br/>Powered by JazzHR<br/><br/>Hv70rUP3Sg
      </div>",No Salary Info Found,Data Engineer
Data Engineer,AddSource,12/20/2023,https://www.linkedin.com/jobs/view/3789020143,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791621839,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,Proven Recruiting,12/21/2023,https://www.linkedin.com/jobs/view/3760795548,0,https://media.licdn.com/dms/image/C560BAQG1WSkkWHu85g/company-logo_100_100/0/1657560807678/proven_recruiting_logo?e=2147483647&v=beta&t=6BYTJvA8GhqtC21wPu2OfbNK4TVrc0ttTFTHBB3vmLQ,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Sr. Data Engineer<br/><br/></strong><strong>What you'll do:<br/><br/></strong><ul><li>Redesign data architecture to support new data initiatives </li><li>Gather requirements from the business enterprise wide to address business requirements </li><li>Make data more reliable and accessible to stakeholders </li><li>Design and craft modern data and analytics platforms <br/><br/><br/></li></ul><strong>Requirements:<br/><br/></strong><ul><li>7+ years of experience as Data Engineer </li><li>Experience deploying production systems into the cloud </li><li>Experience with Airflow, AWS, Astronomer, Domo, DBT <br/><br/><br/></li></ul>#IND3<br/><br/><strong>What does this position pay?<br/><br/></strong>Compensation is determined by several factors which may include skillset, experience level, and geographic location.<br/><br/>The expected range for this role is $135,000 to $145,000 per year. Please note this range is an estimate and actual pay may vary based on qualifications and experience.<br/><br/>
</div>",$135000- $145000,Data Engineer
"Software Engineer, Python- Firefly",Adobe,12/19/2023,https://www.linkedin.com/jobs/view/3788123694,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Senior Software Engineer (BlackLocus),The Home Depot,12/19/2023,https://www.linkedin.com/jobs/view/3789844811,0,https://media.licdn.com/dms/image/C4E0BAQHzR2llYqUBtg/company-logo_100_100/0/1630656428961/the_home_depot_logo?e=2147483647&v=beta&t=NH5wv1AXmlH4oUpVAOaSorm4nU1y-uttFDDEbY5Veps,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Position Purpose<br/><br/></strong>BlackLocus is building cloud-based analytic tools to optimize and automate retail merchandising decisions such as pricing, assortment, space and fulfillment. By applying machine learning and revenue management techniques, the BlackLocus platform enables intelligent retail software to identify opportunities for competitive advantage. The company was a venture-funded startup, founded by Carnegie Mellon alumni and entrepreneurs with a passion for creative deployment of new technology. Acquired by The Home Depot in December of 2012, we operate with autonomy as a remote product lab.<br/><br/><strong>Job Summary<br/><br/></strong>BlackLocus is seeking creative, thoughtful coders to join our development team. Our people solve interesting, challenging problems while working closely with data scientists and business analysts. We build tools to make business actions simple even from large data sets. Our data mining and machine learning pipeline, as well as our user-facing applications, are built primarily in Java, Python, and JavaScript. Our services and tools are entirely cloud-deployed.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>80% Delivery &amp; Execution: Write clean, maintainable, high-quality code; Establish best practices across development projects; Help take new products from prototype to deployment; Solve problems with production systems and automate operations as much as possible</li><li>Stay current with advancements in technology and advocate for the appropriate use of those advancements in our own stack; End to end responsibility on projects of increasing complexity</li><li>20% Mentoring: Mentor other engineers via design and code review<br/><br/></li></ul><strong>Direct Manager/Direct Reports<br/><br/></strong><ul><li>This role reports to the Director of Engineering BlackLocus.</li><li>This role has no direct reports.<br/><br/></li></ul><strong>Travel Requirements<br/><br/></strong><ul><li>Typically requires overnight travel less than 10% of the time.<br/><br/></li></ul><strong>Physical Requirements<br/><br/></strong><ul><li>Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.<br/><br/></li></ul><strong>Working Conditions<br/><br/></strong><ul><li>Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>Must be eighteen years of age or older.</li><li>Must be legally permitted to work in the United States.</li><li>Experience writing quality code in any language appropriate to the problem</li><li>Experience collaborating with a diverse group of people.</li><li>Knowledge in algorithms, data structures, and complexity analysis</li><li>Experience with technical design and can speak to reasoned design decisions and tradeoffs</li><li>Experience with persistent data stores and their query languages</li><li>Bachelor's of Science in Computer Science or equivalent experience and self-education<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Experience with either Java or Python as your preferred language.</li><li>Experience developing creative solutions to challenging problems in a self-directed, lean environment.<br/><br/></li></ul><strong>Minimum Education<br/><br/></strong><ul><li>The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.<br/><br/></li></ul><strong>Preferred Education<br/><br/></strong><ul><li>No additional education<br/><br/></li></ul><strong>Minimum Years Of Work Experience<br/><br/></strong><ul><li>4<br/><br/></li></ul><strong>Preferred Years Of Work Experience<br/><br/></strong><ul><li>No additional years of experience<br/><br/></li></ul><strong>Minimum Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Preferred Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Certifications<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Competencies<br/><br/></strong><ul><li>Ability to identify and document business requirements</li><li>Ability to communicate to a wide variety of audiences, both business and technical</li><li>Ability to understand existing business processes and assist with efforts to (re-)engineer processes</li><li>Strong project management skills, including strong process orientation, ability to work and lead cross functional teams, strategic thinking and creative problem solving skills.</li><li>Ability to establish priorities and procedures for accomplishing work within established deadlines; ability to lead multiple projects and manage toward deadlines and deliverables</li><li>Strong communication skills both written and verbal</li></ul>
</div>",No Salary Info Found,Data Engineer
"Staff Streaming Data Engineer, Data Science Platform",NVIDIA,12/19/2023,https://www.linkedin.com/jobs/view/3789796216,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,Visa,12/19/2023,https://www.linkedin.com/jobs/view/3790090038,0,https://media.licdn.com/dms/image/C560BAQEP8_eM4zW8bw/company-logo_100_100/0/1630663392691/visa_logo?e=2147483647&v=beta&t=TzxC8Eby4Etg1Y4aK9Ul8pUVAccJ4Do5GJP4uVtlOBY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.<br/><br/>When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.<br/><br/><strong>Join Visa: A Network Working for Everyone.<br/><br/></strong><strong>Job Description<br/><br/></strong>Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area.<br/><br/>Visa AI as a Service (VAIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, VAIaS automates the updates to data, models, and applications. Combined with strong AI governance, VAIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!<br/><br/>This position is for a Data Engineer with solid development experience who will focus on creating new capabilities for Visa AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.<br/><br/>You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.<br/><br/>This position will be based in Austin, TX. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li> Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions</li><li> Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards</li><li> Responsibilities span all phases of solution development including:</li><li> Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved</li><li> Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner<br/><br/></li></ul>This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.<br/><br/><strong>Qualifications<br/><br/></strong>Basic Qualifications:<br/><br/><ul><li> Bachelors degree, OR 3+ years of relevant work experience<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li> 2 or more years of work experience</li><li> Exposure to leading-edge areas such as Machine Learning, Big Data, Distributed Systems or SRE. </li><li> Experience in at least one of the following: Golang, Java, or C/C++, Spark</li><li> Familiarity with web service standards and related patterns (REST, gRPC)</li><li> Experience implementing solutions for low-latency, distributed services using open standard technologies. <br/><br/></li></ul><strong>Additional Information<br/><br/></strong><strong>Work Hours:</strong> Varies upon the needs of the department.<br/><br/><strong>Travel Requirements:</strong> This position requires travel 5-10% of the time.<br/><br/><strong>Mental/Physical Requirements:</strong> This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.<br/><br/>Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.<br/><br/>Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.<br/><br/><strong>U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 89,600.00 to 114,300.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.</strong>
</div>",No Salary Info Found,Data Engineer
Data Engineer,Braintrust,12/19/2023,https://www.linkedin.com/jobs/view/3789766635,0,https://media.licdn.com/dms/image/C560BAQHbQYFSQsK__A/company-logo_100_100/0/1630511738029/usebraintrust_logo?e=2147483647&v=beta&t=KwbYjG0MdxQVYAijRBYsSuBn-w2onHZNpCmM31LViso,"Austin, Texas Metropolitan Area","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality.<br/><br/><strong>About The Hiring Process<br/><br/></strong>The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match.<br/><br/>Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies.<br/><br/><strong>JOB TYPE:</strong> Direct Hire/ FTE Position (no agencies/C2C - see notes below)<br/><br/><strong>LOCATION:</strong> Work from anywhere - Anytime | No timezone overlap required<br/><br/><strong>SALARY RANGE</strong> $110,000 – $130,000 /yr<br/><br/><strong>ESTIMATED DURATION:</strong> 40/week - long term<br/><br/><strong>EXPERIENCE:</strong> 3-4 years<br/><br/><strong>BRAINTRUST JOB ID:</strong> 11526<br/><br/>The Opportunity<br/><br/><strong>Required Skills<br/><br/></strong><ul><li> T-SQL (DDL, Stored Proces, Views, CTEs, etc) </li><li> VCS (Git, SVN, etc) <br/><br/></li></ul><strong>Bonus Skills<br/><br/></strong><ul><li> Candidates with a CPA/CFA or other financial services background are preferred. </li><li> Candidates who understand web technologies and can program in other languages in addition to SQL will be preferred. JavaScript/ES6/NodeJS preferred. </li><li> VS Code, SSMS, and other IDEs. </li><li> CI/CD experience with integrating database changes into deployment models. <br/><br/></li></ul>What You'll Be Working On<br/><br/><ul><li>This is a FTE position and is only open to US-based candidates**<br/><br/></li></ul>InvestEdge is seeking a database specialist with expert knowledge in relational data modeling, querying, and data analysis.<br/><br/>This role requires expert knowledge of working with MSSQL and Postgres databases, and can write complex queries, stored procedures, and views.<br/><br/><strong>The Candidate<br/><br/></strong><ul><li> has likely worked as a senior data developer or data architect role, and also understands database administration concepts such as indexing strategies, backup and fault-tolerance strategies, and how to organize and secure data at rest. </li><li> have a background in financial services and understand how financial markets work. </li><li> Has a CPA/CFA with the ability to write advanced SQL should be a shoe-in. <br/><br/></li></ul>This role will work with InvestEdge's senior data architect to implement new solutions as well as improve existing ones. Also, the role will be working with large data sets and large database footprints and should understand concepts such as performance tuning, SQL Injection, and data security best practices.<br/><br/>In addition to an emphasis on data manipulation and storage, the candidate will also work on other aspects of the application including UX and middle-tier concerns relating to the presentation, use, and manipulation of data. The ideal candidate is a well-rounded developer that is comfortable in any layer of the application, even as their focus is data and the persistence of that data.<br/><br/><strong>Roles And Responsibilities<br/><br/></strong><ul><li> Work with the senior data architect to implement data routines in a financial services environment. </li><li> Create new queries, views, and stored procedures for a large existing relational data set. </li><li> Debug and troubleshoot logical issues in database code. </li><li> Debug and troubleshoot performance issues in database code. </li><li> Serve as a subject matter expert on a large in-house enterprise database model. </li><li> Understand the business domain of the application. </li><li> Work in an Agile environment on a cross-functional team. <br/><br/></li></ul><strong>Apply Now!<br/><br/></strong><strong>Notes<br/><br/></strong>Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.<br/><br/>Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
      </div>",$110000- $130000,Data Engineer
Associate Analytics Engineer,NexusLeap,12/19/2023,https://www.linkedin.com/jobs/view/3784428116,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789086619,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $130,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$130000- $173000,Data Engineer
Data Engineer,AtkinsRéalis,12/20/2023,https://www.linkedin.com/jobs/view/3785085485,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer - Hedge Fund - NYC (PW),MRINetwork,12/25/2023,https://www.linkedin.com/jobs/view/3793411752,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791628110,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Join our growing Engineering team!<br/><br/></strong>This Jobot Job is hosted by Mike Duffy<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $100,000 - $140,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>We are rapidly growing equipment finance company with over 25 years in business!<br/><br/>The Data Engineer will be responsible for building data-driven analytics tools that are used across the entire organization to improve decision making.<br/><br/>The Data Engineer should have 3+ years of experience with Python, ETL, and SQL<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Excellent pay &amp; benefits!</li><li> 100% remote flexibility!</li><li> Room for growth!</li><li> Outstanding company culture!<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.</li><li> Has demonstrated proficiency in designing and developing data marts in Snowflake schema.</li><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL Server, NoSQL, Kafka using AWS or AZURE Big Data technologies.</li><li> Use troubleshooting skills to identify and correct root cause of workflow failures based on error log outputs and environmental conditions.</li><li> Use SQL to examine, filter, and aggregate data in Microsoft SQL Server.</li><li> Experience working with data transformation processing.</li><li> Anticipate, identify, and solve issues concerning data management to improve data quality.</li><li> Experience working with Microsoft BI and Microsoft SQL server.</li><li> Perform POCs on new technology, architecture patterns.</li><li> Must have Experience with at least one Columnar MPP Cloud data warehouse (Snowflake /Azure Synapse / Redshift)</li><li> Design of complex physical data models, projects and cloud-based data lake constructs including SQL/NoSQL database systems. Leads the creation of integrated data views based on business or analytics requirements.</li><li> Design, implement, and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems and business requirements.</li><li> Experience in ETL tools like DBT is nice to have.</li><li> Experience with version control and DevOps platforms such as AZURE DevOps, GitHub, GitLab</li><li> Experience with CI/CD Pipelines and SDLC best practices.</li><li> Experience using Agile methods and project management tools like Jira preferred.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Software Engineering, Information Technology, or a related field.</li><li> Minimum of 3 years of experience in a data engineer or similar role.</li><li> Strong knowledge of Python, ETL, SQL, data integration, and data pipelines.</li><li> Experience with data architecture, data modeling, schema design, and software development.</li><li> Proficiency in data migration, transformation, and scripting.</li><li> Familiarity with machine learning models and their data needs.</li><li> Understanding of distributed systems as it pertains to data storage and computing.</li><li> Strong project management and organizational skills.</li><li> Ability to analyze problems and strategize for better solutions.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$100000- $140000,Data Engineer
"Data Engineer, Technical Lead (Python, LLM's)",McGregor Boyall,12/19/2023,https://www.linkedin.com/jobs/view/3790303994,0,https://media.licdn.com/dms/image/C560BAQGO939jAMuxSA/company-logo_100_100/0/1631300963839?e=2147483647&v=beta&t=wvxlzhXn-VazqLNArp93vINVZ16ckjtnm-GiYJMVXIY,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Data Engineer, Technical Lead (Python, LLM's)</strong></p><p>One of the market's leading Insurance providers requires a data engineer and technical lead to help the growth of their fintech-style venture in New York City. The successful candidate will work on Greenfield initiatives that utilise Python, Pyspark, SQL, LLM's and other Gen AI tools to build the latest tools for the Insurance technology domain.</p><p>The candidate will play an active role in developing the codebase, as well as leading a small team of data engineers, data scientists and web engineers. The team leverages modern technology tools within a Python eco-system, and other tools include Azure cloud, modern DevOps tooling, data pipelines and machine learning algorithms.</p><p>The successful candidate can look to receive between $170,000 and $200,000 base salary, including a competitive bonus and benefits package.</p><p><strong>Key Requirements summary:</strong></p><ul><li>Experience coding in Python using SQL</li><li>Experience developing LLM's and other Gen AI tools (exploratory phase is acceptable</li><li>Experience leading small teams is desired, but not essential</li><li>Partnering with multiple business units in an agile environment, including working directly with Product teams</li><li>Some experience of working in a Data Science/AI/Data Analysis function</li></ul><p>This role is hybrid onsite in New York City</p><p> </p><p> <br/></p><p> </p><br/><p>McGregor Boyall is an equal opportunity employer and do not discriminate on any grounds.</p>
</div>",$170000- $200000,Data Engineer
Data Engineer IT,JetBlue,12/19/2023,https://www.linkedin.com/jobs/view/3732582931,0,https://media.licdn.com/dms/image/D4E0BAQG7WW9ALUsLog/company-logo_100_100/0/1696016819906?e=2147483647&v=beta&t=L7PqtwBmL8gLdGKgw93szjr4QtfAyWOEjlsnQbr6X7I,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Position Summary<br/><br/>The Data Engineer is responsible for integrating and modeling data in JetBlue’s modern data stack to support analysts, business intelligence users, data scientists, and decision-makers across the company. The Data Engineer must have a deep understanding of Structured Query Language (SQL) and be familiar with Snowflake, dbt (data build tool), and git version control. In this role, the Data Engineer collaborates with stakeholders across the company to understand and address their needs. The Data Engineer must enjoy working with others and be comfortable expressing ideas in a public setting. The Data Engineer reports to the Manager of IT Data Engineering.<br/><br/>Essential Responsibilities:<br/><br/><ul><li>Work with business stakeholders to understand problems and data sources, playing the pivotal role of architecting data models to address Crewmember needs</li><li>Gather requirements, build roadmaps, and write great documentation for data sources that need to be modeled</li><li>Build Extract, Load, Transform (ELT) jobs based on jointly defined requirements</li><li>Perform end-to-end unit testing &amp; code reviews to promote data integrity across a variety of products built by the development team</li><li>Support bug fixing and performance analysis along the data pipeline, including writing tests &amp; coordinating with Quality Assurance teams</li><li>Be comfortable presenting to large groups &amp; expressing ideas in public settings with high visibility</li><li>Be a strong advocate for a culture of process and data quality across development teams</li><li>Follow an agile development methodology</li><li>Other duties as assigned<br/><br/><br/></li></ul>Minimum Experience and Qualifications:<br/><br/><ul><li>Bachelor Degree in Mathematics, Operations Research, Statistics, Computer Science, Engineering, or Physics; OR demonstrated capability to perform job responsibilities with a High School Diploma/GED and at least four (4) years of previous relevant work experience</li><li>Three (3) years of relevant experience in a data role working with data warehouses and business intelligence tools</li><li>Proven experience with dbt (data build tool) &amp; Snowflake</li><li>Strong SQL skills</li><li>Experience with modern ELT orchestration tools like Azure Data Factory or Airflow</li><li>Experience with git and git-based workflows</li><li>Available for occasional overnight travel (10%)</li><li>Must pass a pre-employment drug test</li><li>Must be legally eligible to work in the country in which the position is located</li><li>Authorization to work in the US is required. This position is not eligible for visa sponsorship <br/><br/><br/></li></ul>Preferred Experience and Qualifications:<br/><br/><ul><li>Experience implementing best-practices for data modelling, especially with regards to dimensional modelling for business intelligence</li><li>Basic Python skills</li><li>Proven track record of successfully contributing to a project that transitioned a large enterprise to a new cloud data warehouse, like Snowflake</li><li>Prior airline experience<br/><br/><br/></li></ul>Crewmember Expectations:<br/><br/><ul><li>Regular attendance and punctuality </li><li>Potential need to work flexible hours (including nights &amp; weekends) and be available to respond on short-notice</li><li>Able to maintain a professional appearance</li><li>When working or traveling on JetBlue flights, and if time permits, all capable Crewmembers are asked to assist with light cleaning of the aircraft</li><li>Must be an appropriate organizational fit for the JetBlue culture, that is, exhibit the JetBlue values of Safety, Caring, Integrity, Passion and Fun</li><li>Promote JetBlue’s #1 value of safety as a Safety Ambassador, supporting JetBlue’s Safety Management System (SMS) components, Safety Policy and behavioral standards</li><li>Identify safety and/or security concerns, issues, incidents or hazards that should be reported and report them whenever possible and by any means necessary including JetBlue’s confidential reporting systems (Aviation Safety Action Program (ASAP) or Safety Action Report (SAR))<br/><br/><br/></li></ul>Equipment:<br/><br/><ul><li>Computer and other office equipment<br/><br/><br/></li></ul>Work Environment:<br/><br/><ul><li>Traditional office environment<br/><br/><br/></li></ul>Physical Effort:<br/><br/><ul><li>Generally not required, or up to 10 pounds occasionally, 0 pounds frequently. (Sedentary)<br/><br/><br/></li></ul>Compensation:<br/><br/><ul><li>The base pay range for this position is between $100,000.00 and $128,600.00 per year. Base pay is one component of JetBlue’s total compensation package, which may also include access to healthcare benefits, a 401(k) plan and company match, crewmember stock purchase plan, short-term and long-term disability coverage, basic life insurance, free space available travel on JetBlue, and more.<br/><br/><br/></li></ul>
</div>",$100000.00- $128600.00,Data Engineer
"Staff Data Engineer, Data Products (Contract)",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3759870591,0,https://media.licdn.com/dms/image/C560BAQH0xjWQVXJr6w/company-logo_100_100/0/1630660955481/sofi_logo?e=2147483647&v=beta&t=FVZG0dNVAhdZ-W3Op_NDxjxwWCaIzunudLIIydaqJQI,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Employee Applicant Privacy Notice<br/><br/></strong><strong>Who we are:<br/><br/></strong>Shape a brighter financial future with us.<br/><br/>Together with our members, we’re changing the way people think about and interact with personal finance.<br/><br/>We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. <strong>Join us to invest in yourself, your career, and the financial world.<br/><br/></strong><strong>Team: <br/><br/></strong>SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.<br/><br/><strong>Role:<br/><br/></strong>A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.<br/><br/><strong>What you’ll do:<br/><br/><br/></strong><ul><li>Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.</li><li>Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,</li><li>Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.<br/><br/><br/></li></ul><strong>What you’ll need:<br/><br/><br/></strong><ul><li>A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;</li><li>Over 8 years of experience in data engineering and analytics technical strategy. </li><li>Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..</li><li>Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP</li><li>Strong in Python and/or another data centric language. </li><li>Thorough knowledge of data modeling, database design, data architecture principles, and data operations.</li><li>Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.</li><li>Experience in the Fintech industry is advantageous.<br/><br/><br/></li></ul><em><strong>Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.<br/><br/></strong></em><strong>Compensation And Benefits<br/><br/></strong>The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.<br/><br/>To view all of our comprehensive and competitive benefits, visit our <strong>Benefits at SoFi </strong>page!<br/><br/>SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.<br/><br/>The Company hires the best qualified candidate for the job, without regard to protected characteristics.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.<br/><br/>New York applicants: Notice of Employee Rights<br/><br/>SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.<br/><br/>Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.<br/><br/><strong>Internal Employees<br/><br/></strong>If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.
      </div>",No Salary Info Found,Data Engineer
Cloud Data Engineer,Talener,12/19/2023,https://www.linkedin.com/jobs/view/3748836564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,BeaconFire Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3788691831,0,https://media.licdn.com/dms/image/C560BAQEgZyD0JY8dTA/company-logo_100_100/0/1630645938186?e=2147483647&v=beta&t=_1a4H3IIfyJigHbi_NPBI4P5Hj_Unz3cwiUADDdNxy8,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Qualifications:</strong></p><p>• Passion for data and a deep desire to learn.</p><p>• Bachelor’s Degree in Computer Science/Information Technology, Data Analytics/Data Science, or related</p><p>discipline.</p><p>• Intermediate Python. Experience in data processing is a plus. (Numpy, Pandas, etc)</p><p>• Strong written and verbal communication skills.</p><p>• Ability to work both independently and as part of a team.</p><p><br/></p><p><strong>Responsibilities:</strong></p><p>• Collaborate with analytics team to find reliable data solutions to meet the business needs.</p><p>• Design and implement scalable ETL or ELT processes to support the business demand for data.</p><p>• Perform data extraction, manipulation, and production from database tables.</p><p>• Build utilities, user-defined functions, and frameworks to better enable data flow patterns.</p><p>• Build and incorporate automated unit tests, participate in integration testing efforts.</p><p>• Work with teams to resolve operational &amp; performance issues.</p><p>• Work with architecture/engineering leads and other teams to ensure quality solutions are implemented, and engineering best practices are defined and adhered to.</p><p><br/></p><p>Location: Remote to start</p><p><br/></p><p>Salary: $65,000.00 to $80,000.00 /year</p><p><br/></p><p>BeaconFire is an e-verified company, and we provide H1B visa sponsorship to all qualified internationalcandidates.</p>
</div>",$65000.00- $80000.00,Data Engineer
"Data Engineer, Product Analytics",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3790554161,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Sr Data Developer,Synechron,12/20/2023,https://www.linkedin.com/jobs/view/3788674633,0,https://media.licdn.com/dms/image/C4D0BAQF-kdmTYpOKFg/company-logo_100_100/0/1663673608492/synechron_logo?e=2147483647&v=beta&t=srG-HyAPgRmdiRELy-32e05tZFPYByEm48tZ92tcIg4,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Overview</strong></p><p>As a Data Developer, you will be responsible for supporting business intelligence and reporting initiatives. You will use your engineering skills and experience with ETL concepts to create data structures for reporting systems and develop data exchanges and integrations between various platforms. You should also be able to optimize existing and new data processes. While not required, experience within the Capital Markets/Investment Banking domain is preferred.</p><p><strong>JOB: Data Developer</strong></p><p><strong>Location: NYC NY</strong></p><p><br/></p><p><strong>Additional Information – New York Only* </strong></p><p><strong>The base salary for this position will vary based on geography and other factors. </strong></p><p><strong>In accordance with New York law, the base salary for this role if filled within New York is $125k-$145k/year &amp; benefits (see below). </strong></p><p><br/></p><p><strong>Responsibilities</strong></p><ul><li>Participate in all phases of the data solutions development lifecycle</li><li>Engage with the core data team in the design of efficient processes to load and manage data, data quality assessments to ensure that the quality of the source data will meet the information requirements, and development of business rules, data mappings, and transformation rules</li></ul><p><strong>Requirements</strong></p><p>You are:</p><ul><li>Bringing 8+ years of experience to the team (a must!)</li><li>Highly experienced in ETL concepts, data mapping &amp; transformation rules, and developing real-time, API-based data ingestion and integration solutions using leading iPaaS offerings</li><li>An expert in developing scheduled batch processes for data integration using leading ETL tools</li><li>Experienced in MDM (Master Data Management) / EDL (Enterprise Data Lake)</li><li>Very knowledgeable in SQL</li><li>Well-versed in MS SQL Server platform</li><li>Highly understanding of RDBMS concepts</li><li>Experience in developing stored procedures, functions, and scripts</li><li>Experienced in database/query performance optimization (indexing, query tuning, troubleshooting performance problems)</li><li>Experienced in data modeling/database design</li></ul><p>It would be great if you also had:</p><ul><li>Experience working with BIG data and unstructured data sources (AWS)</li><li>Experience with Databricks and Airflow</li><li>Experience with both iPaaS and on-prem ETL platforms like Mulesoft, Informatica</li><li>Familiarity with Salesforce</li><li>Experience within the Capital Markets/Investment Banking domains</li></ul><p><strong>We Can Offer You</strong></p><ul><li>A highly competitive compensation and benefits package</li><li>A multinational organization with 45 offices in 19 countries and the possibility to work abroad</li><li>Laptop and a mobile phone</li><li>10 days of paid annual leave (plus sick leave and national holidays)</li><li>Maternity &amp; Paternity leave plans</li><li>A comprehensive insurance plan including: medical, dental, vision, life insurance, and long-/short-term disability (plans vary by region)</li><li>Retirement savings plans</li><li>A higher education certification policy</li><li>Commuter benefits (varies by region)</li><li>Extensive training opportunities, focused on skills, substantive knowledge, and personal development</li><li>On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses </li><li>Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups </li><li>Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms</li><li>A flat and approachable organization</li><li>A truly diverse, fun-loving and global work culture</li></ul><p><br/></p><p><br/></p><p><strong>Diversity &amp; Inclusion</strong> are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs.</p><p>All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.</p>
</div>",$125- $145,Data Engineer
Python Data Engineer,Synechron,12/20/2023,https://www.linkedin.com/jobs/view/3788676786,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
"Software Engineer: Intern Opportunities, CTJ",Microsoft,12/24/2023,https://www.linkedin.com/jobs/view/3708145695,0,https://media.licdn.com/dms/image/C560BAQE88xCsONDULQ/company-logo_100_100/0/1630652622688/microsoft_logo?e=2147483647&v=beta&t=4ft1hh_UdO2TMuqRWlFPHTTr2B3BN0E2LmTE6tEYwJI,"Redmond, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Come build community, explore your passions and do your best work at Microsoft with thousands of students from every corner of the world. This opportunity will allow you to bring your aspirations, talent, potential—and excitement for the journey ahead.   <br/><br/>Software engineers (SWEs) work with teammates to solve problems and build innovative software solutions. You are passionate about customers and product quality, and you provide technical guidance to Technical Program Managers and Product Managers they consider user needs and product requirements. You will also be expected to demonstrate an ability to learn and adopt relevant new technologies, tools, methods and processes to leverage in your solutions.  As a SWE, you are dedicated to design, development and testing of next-generation software which will empower every person and organization on the planet to achieve more.   <br/><br/>At Microsoft, Interns work on real-world projects in collaboration with teams across the world, while having fun along the way. You’ll be empowered to build community, explore your passions and achieve your goals. This is your chance to bring your solutions and ideas to life while working on cutting-edge technology.<br/><br/>Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Applies engineering principles to solve complex problems through sound and creative engineering.  </li><li>Quickly learns new engineering methods and incorporates them into work processes.  </li><li>Seeks feedback and applies internal or industry best practices to improve technical solutions.  </li><li>Demonstrates skill in time management and completing software projects in a cooperative team environment. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><strong>Required/Minimum Qualifications<br/><br/></strong><ul><li>Currently enrolled in a bachelor's or master's degree in engineering, computer science or related field. </li><li>Must have at least one additional quarter/semester of school remaining following the completion of the internship. </li><li>One year of programming experience in an object-oriented language. <br/><br/></li></ul><strong>Other Requirements<br/><br/></strong>Must Have: Security Clearance Requirements: Candidates must be able to meet Microsoft, customer and/or government security screening requirements required for this role.<br/><br/>These requirements include, but are not limited to the following specialized security screenings:<br/><br/><ul><li>Candidates must have a minimum Active Top Secret (TS) clearance and be willing and eligible to up-level to TS/SCI with Full Scope Poly (FSP). This role will require candidates to maintain the TS/SCI with FSP.</li><li>Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter.<br/><br/></li></ul><strong>Additional Or Preferred Qualifications<br/><br/></strong><ul><li>1+ year(s) experience in software engineering, network engineering, or systems administration</li><li>1+ year(s) experience reading and/or writing code (e.g., sample documentation, product demos).</li><li>Ability to demonstrate an understanding of computer science fundamentals, including data structures and algorithms. <br/><br/></li></ul><em>The base pay range for this internship is USD $5,090 - $10,120 per month. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $6,690 - $11,030 per month.<br/><br/></em>Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-intern-pay<br/><br/>Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
      </div>",$5090- $10120,Data Engineer
Software Development Engineer I,Moderna,12/23/2023,https://www.linkedin.com/jobs/view/3744581968,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
"Software Engineer, Data Platform",Lyft,12/19/2023,https://www.linkedin.com/jobs/view/3716407381,0,https://media.licdn.com/dms/image/C560BAQFoMDej0VdZVA/company-logo_100_100/0/1630565402130/lyft_logo?e=2147483647&v=beta&t=ZP-NFPxZPUKGL-odxJYvJwUPGQa3FfeKeCwD-pTgP6k,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.<br/><br/>The Data Orchestration team within Data Platform is responsible for managing orchestration engines including Airflow and Flyte, which power and accelerate data pipelines and machine learning processes at the scale required by Lyft products. These components support a variety of use cases, including but not limited to Core Dataset, Financial Infra, Pricing, Estimated Time of Arrivals (ETA), and Mapping. The team's clusters host and serve thousands of workflows and over 100,000 executions on a daily basis.<br/><br/>As a Software Engineer, with your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance the platform offerings. Your work will have a major impact on several areas of the business.<br/><br/>We are looking for candidates who are self starters and have a proven track record of delivering software solutions that can solve critical business needs. The candidate should be able to dive deep into any problems with lots of ambiguity and build a technical solution to solve it. They should be willing to take ownership of a project or a feature and be able to drive it from design to implementation.<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Design, develop, deploy, monitor, operate and maintain existing or new elements of our platform</li><li>Help establish roadmap and architecture based on technology and our needs</li><li>Write well-crafted, well-tested, readable, maintainable code</li><li>Analyze our internal systems and processes and locate areas for improvement/automation</li><li>Collaborate with product org stakeholders to address and prioritize custom edge cases</li><li>Help lead large projects from inception to positive execution</li><li>Unblock, support and communicate with internal partners to achieve results<br/><br/></li></ul><strong>Experience:<br/><br/></strong><ul><li>3+ years of software engineering industry experience and with data structures/algorithms</li><li>2+ years of experience building and developing large-scale infrastructure, distributed systems or networks, and/or experience with data infrastructure</li><li>Experience working with kubernetes and container technologies (e.g. Docker, cri-o, etc)</li><li>Familiar with a cloud-based environments such as AWS/GCP/Azure<br/><br/></li></ul><strong>Benefits:<br/><br/></strong><ul><li>Great medical, dental, and vision insurance options</li><li>Mental health benefits</li><li>Family building benefits</li><li>In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off</li><li>401(k) plan to help save for your future</li><li>18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible</li><li>Pre-tax commuter benefits</li><li>Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program<br/><br/></li></ul><em>Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. <br/><br/></em><em>Starting in September 2023, this role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year.<br/><br/></em><em>Candidates for this role must be based in the Seattle metro area.<br/><br/></em><em>The expected range of pay for this position in the Seattle area is $103,785 - $165,600. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.</em>
</div>",$103785- $165600,Data Engineer
Data Engineer,PitchBook,12/19/2023,https://www.linkedin.com/jobs/view/3721103987,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
"Data Engineer, Data Platform - US Tech Services Team",TikTok,12/19/2023,https://www.linkedin.com/jobs/view/3646525311,0,https://media.licdn.com/dms/image/C510BAQGCdThXIss7UQ/company-logo_100_100/0/1630606162248/tiktok_logo?e=2147483647&v=beta&t=139uJTX7-HNeX1_kJsHK-Ztmj2K9yb9XfIIGQoNOW3c,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong> About Tiktok<br/>TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul and Tokyo. <br/><br/>Why Join Us<br/>At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.<br/><br/>About USDS<br/>At TikTok, we're committed to a process of continuous innovation and improvement in our user experience and safety controls. We're proud to be able to serve a global community of more than a billion people who use TikTok to creatively express themselves and be entertained, and we're dedicated to giving them a platform that builds opportunity and fosters connection. We also take our responsibility to safeguard our community seriously, both in how we address potentially harmful content and how we protect against unauthorized access to user data.<br/><br/>U.S. Data Security (“USDS”) is a standalone department of TikTok in the U.S. This new security-first division was created to bring heightened focus and governance to our data protection policies and content assurance protocols to keep U.S. users safe. Our focus is on providing oversight and protection of the TikTok platform and user data in the U.S., so millions of Americans can continue turning to TikTok to learn something new, earn a living, express themselves creatively, or be entertained. The teams within USDS that deliver on this commitment daily span Trust &amp; Safety, Security &amp; Privacy, Engineering, User &amp; Product Ops, Corporate Functions and more.<br/><br/>As a data engineer in the data platform team area, you will have the opportunity to build, optimize and grow one of the largest data platforms in the world that directly supports the TikTok app. You'll have the opportunity to gain hands-on experience on all kinds of systems in the data platform ecosystem. Your work will have a direct and huge impact on the company's core products as well as hundreds of millions of users.<br/><br/>• Design, build and maintain data transformations efficiently and reliably for different purposes (e.g. reporting, growth analysis, multi-dimensional analysis)<br/>• Design, implement and maintain reliable, scalable, robust and extensible big data systems that support core products and business<br/>• Establish solid design and best engineering practice for engineers as well as non-technical people <br/><br/><strong>Qualifications<br/><br/></strong> • Bachelor's degree in Computer Science, a related technical field involving software or systems engineering, or equivalent practical experience<br/>• Experience in performing data analysis, data ingestion and ETL(Extraction, Transformation &amp; Loading)<br/>• Experience with the Big Data technologies is a plus (Hadoop, M/R, Hive, Spark, Metastore, Presto, Flume, Kafka, ClickHouse, Flink etc)<br/><br/>TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.<br/><br/>TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at usds.accommodations@tiktok.com <br/><br/><strong>Job Information:<br/><br/></strong>【For Pay Transparency】Compensation Description (annually) <p>The base salary range for this position in the selected city is $177688 - $341734 annually.<span>​</span></p><p>Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.<span>​</span></p><p>Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: <span>​</span></p><p>We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&amp;D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. <span>​</span></p><p>Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. <span>​</span></p><p>We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.<span>​</span></p>
</div>",$177688- $341734,Data Engineer
Data Engineer II,The Pokémon Company International,12/20/2023,https://www.linkedin.com/jobs/view/3774999827,0,https://media.licdn.com/dms/image/C4E0BAQEH1-l_RgwF3A/company-logo_100_100/0/1646325210472/pokemon_logo?e=2147483647&v=beta&t=Oe28Lc38w305caI5gYviqmBOc7OFu4sMH1IucxnlGmY,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><strong>Get to know The Pokémon Company International <br/><br/></strong></strong>The Pokémon Company International, a subsidiary of The Pokémon Company in Japan, manages the property outside of Asia and is responsible for brand management, licensing, marketing, the Pokémon Trading Card Game, the animated TV series, home entertainment, and the official Pokémon website. Pokémon was launched in Japan in 1996 and today is one of the most popular children's entertainment properties in the world.<br/><br/>Learn more online at Corporate.Pokemon.com and Pokemon.com . And check out Twitter ( twitter.com/Pokemon ), LinkedIn ( linkedin.com/company/Pokémon ), Youtube ( youtube.com/pokemon ), and Instagram ( instagram.com/pokemon ).<br/><br/><strong><strong> Get to know the role <br/><br/></strong></strong><ul><li>Job Title: Data Engineer</li><li>Job Summary: Designs, builds and oversees the deployment and operation of technology architecture, solutions and software to capture, manage, store and utilize structured and unstructured data from internal and external sources.</li><li>FLSA Classification (US Only): Exempt</li><li>People Manager: No<br/><br/></li></ul><strong><strong> What you’ll do <br/><br/></strong></strong><ul><li>Establish and build processes and structures based on business and technical requirements to channel data from multiple inputs, route appropriately and store using a combination of distributed (cloud) structures, local databases, and other applicable storage forms as required.</li><li>Develops technical tools and programming that leverage available technologies (e.g., artificial intelligence, machine learning and big-data techniques) to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis.</li><li>Create and establish documentation, design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements.</li><li>Reviews internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.</li><li>Participate in data migration and data onboarding efforts to consolidate data locations and promote consistency, security and accessibility to enable our engineering and business partners to make data-informed decisions. <br/><br/></li></ul><strong><strong> What you’ll bring <br/><br/></strong></strong><ul><li>Three (3) to four (4) years of relevant professional experience or a demonstrated equivalent level of expertise.</li><li>Bachelor's degree in a related field or a demonstrated equivalent level of applicable experience.</li><li>Experience in data architecture.</li><li>Experience in cloud data engineering (S3, RDS, Redshift).</li><li>Demonstrated strength in SQL, data modeling, ETL development, and data warehousing.</li><li>Coding proficiency in at least one modern programming language (Python, Scala, Spark, Java, etc.).</li><li>Communication and leadership experience, with experience initiating and driving projects.</li><li>Experience leading data driven discussions and designing scalable data platforms.</li><li>Knowledge of industry best practices and the ability to evaluate the applicability of new processes and technologies.</li><li>Analytical and mathematical mind, capable of evaluating and solving various complex problems.</li><li> Proficiency with Databricks, Terraform, Data Streaming, DBT, RBAC (Role Based Access Control) a strong plus. </li><li> Prior DBA experience a strong plus. <br/><br/></li></ul><strong><strong> How you’ll be successful <br/><br/></strong></strong><ul><li>Passion for Pokémon: Develops an understanding of the Pokémon brand, the impact it has on our people, culture, business, fans, and communities, and applying that knowledge and passion to everything you do.</li><li>Challenging the Expected: Approaches challenges with curiosity and creativity, embracing the possibility of failure as an opportunity to learn something new, develop innovative ideas, solve complex problems and identify unique opportunities. </li><li>Integrity and Respect: Demonstrates integrity and respect by leading with empathy, listening to others, seeking out different perspectives, and taking personal responsibility for decisions, actions, and results.</li><li>Dedicated to Quality: Takes ownership to maintain and promote high standards, looks for new ways to learn and improve, and embraces a growth mindset to seek and apply feedback from others in an effort to continuously improve. </li><li>Building Relationships: Develops and strengthens relationships, adopting a “team first” mentality and working collaboratively to solve problems and meet shared goals. </li><li>Delighting Customers: Listens and understands the interests and needs of our customers and stakeholders, making them feel heard and important, and embracing these learnings to continue delivering a unique Pokémon experience.<br/><br/></li></ul><strong><strong> What to expect <br/><br/></strong></strong><ul><li>An employee first culture</li><li>Company events that celebrate the spirit of Pokémon</li><li>Competitive cash-based compensation programs</li><li>Base salary range: For this role, new hires generally start between $102,000 - $121,600 . The full range is $102,000 - $154,000. This range is applicable for the labor market where the role is intended to be hired. Final base salary is directly related to each candidates' qualifications and professional experience uniquely.</li><li>100% employer-paid healthcare premiums for you</li><li>Generous paid family leave</li><li>Employer-paid life insurance</li><li>Employer-paid long and short-term income protection insurance</li><li>US Employees: 401k Employer Matching</li><li>UK/IRE Employees: Pension Employer Contributions</li><li>Fitness reimbursement</li><li>Commuter benefit</li><li>LinkedIn learning</li><li>Comprehensive relocation package</li><li>Hybrid work environment<br/><br/></li></ul>The above statements are intended to describe the general nature and level of work being performed by people assigned to this role. They are not to be construed as an exhaustive list of all responsibilities, duties, and skills required. Employees may be required to perform duties outside of their normal responsibilities from time to time, as needed. For roles in the United Kingdom, candidates will need the right to work. In some cases, and for some roles, the Company may be able to arrange a visa. For roles in Ireland, this role requires candidates to have the right to live and work in the Republic of Ireland. However, we welcome applications from all nationalities and may consider supporting an employment permit application, in appropriate and suitable cases.<br/><br/>
</div>",$102000- $121600,Data Engineer
"Data Engineer , Amazon Pharmacy",Amazon,12/20/2023,https://www.linkedin.com/jobs/view/3768741058,0,https://media.licdn.com/dms/image/C560BAQHTvZwCx4p2Qg/company-logo_100_100/0/1630640869849/amazon_logo?e=2147483647&v=beta&t=ckUoyDcKb4OtrPrnkiepZRIH4rOREd9cewh-TTrMVJE,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Are you looking for a role that allows you to shape the future of how customers access healthcare and essential medication? At Amazon Pharmacy, we are committed to building the world’s most customer-centric pharmacy experience. We do this by delivering a convenient, shoppable pharmacy experience, allowing customers to compare prices and purchase medications for home delivery, all in one place. Join our team and help create the future of medicine.<br/><br/>As a Data Engineer in Pharmacy team, you will partner with Software Engineers, Business Intelligence Engineers and product managers. In close collaboration with the Senior DE on the team, you will design, implement, and maintain next generation BI solutions for large scale, highly secure and complex data structures to ensure the data is auditable, available and accessible. You will gain a deep understanding of our services and the data they produce, and become our resident expert in how to transform that data into a format that is useful for analytics and business intelligence. You will proactively help to identify new data for integration with our platform, and propose and implement new technologies to help us better understand our data.<br/><br/>Key job responsibilities<br/><br/>Key job responsibilities<br/><br/>Design, implement, maintain and support a secure and robust data lake in native AWS with 300+ datasets which contain both PII and PHI data.<br/><br/>Implement ingestion routines both real time and batch using best practices in modeling, ETL/ELT processes by leveraging AWS technologies and big data tools.<br/><br/>Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL, Python and AWS big data technologies.<br/><br/>Gather business and functional requirements and translate into secure, robust, scalable, operable solutions with a flexible and adaptable architecture.<br/><br/>Collaborate with engineers to help adopt best practices in system creation, integrity, test design, analysis, validation, and documentation.<br/><br/>Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service tools for customers.<br/><br/>Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency.<br/><br/>We are open to hiring candidates to work out of one of the following locations:<br/><br/>Seattle, WA, USA<br/><br/><strong>Basic Qualifications<br/><br/></strong><ul><li> 2+ years of data engineering experience</li><li> Experience with data modeling, warehousing and building ETL pipelines</li><li> Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)</li><li> Experience with one or more scripting language (e.g., Python, KornShell)<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li> Experience with big data technologies such as: Hadoop, Hive, Spark, EMR</li><li> Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.<br/><br/></li></ul>Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.<br/><br/>Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.<br/><br/><br/><strong>Company</strong> - Amazon.com Services LLC<br/><br/>Job ID: A2504745
      </div>",$81000- $185000,Data Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083989,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $140,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$140000- $173000,Data Engineer
Data Engineer,Meta,12/20/2023,https://www.linkedin.com/jobs/view/3703435524,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Meta, we have many opportunities to work with data each and every day. In this role as a Data Engineer on the Meta Data Center’s Data Science team, your primary responsibility will be to partner with key stakeholders, data scientists and software engineers to support and enable the continued growth critical to Meta's Data Center organization. You will be responsible for creating the technology and data architecture that moves and translates data used to inform our most critical strategic and real-time decisions. You will also help translate business needs into requirements and identify efficiency opportunities. In addition to extracting and transforming data, you will be expected to use your expertise to build extensible data models, provide meaningful recommendations and actionable strategies to partnering data scientist for performance enhancements and development of best practices, including streamlining of data sources and related programmatic initiatives. The ideal candidate will have a passion for working in white space and creating impact from the ground up in a fast-paced environment. This position is part of the Infrastructure Data Center team.<br/><br/>Data Engineer Responsibilities:<br/><br/><ul><li>Partner with leadership, engineers, program managers and data scientists to understand data needs</li><li>Apply proven expertise and build high-performance scalable data warehouses</li><li>Design, build and launch efficient &amp; reliable data pipelines to move and transform data (both large and small amounts)</li><li>Securely source external data from numerous partners</li><li>Intelligently design data models for optimal storage and retrieval</li><li>Deploy inclusive data quality checks to ensure high quality of data</li><li>Optimize existing pipelines and maintain of all domain-related data pipelines</li><li>Ownership of the end-to-end data engineering component of the solution</li><li>Support on-call shift as needed to support the team</li><li>Design and develop new systems in partnership with software engineers to enable quick and easy consumption of data<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>BS/MS in Computer Science or a related technical field</li><li>5+ years of Python or other modern programming language development experience</li><li>5+ years of SQL and relational databases experience</li><li>5+ years experience in custom ETL design, implementation and maintenance</li><li>3+ years of experience with workflow management engines (i.e. Airflow, Luigi, Prefect, Dagster, Digdag, Google Cloud Composer, AWS Step Functions, Azure Data Factory, UC4, Control-M)</li><li>3+ years experience with Data Modeling</li><li>Experience working with cloud or on-premises Big Data/MPP analytics platform (i.e. Netezza, Teradata, AWS Redshift, Google BigQuery, Azure Data Warehouse, or similar)</li><li>2+ years experience working with enterprise DE tools and experience learning in-house DE tools</li><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Experience with more than one coding language</li><li>Experience designing and implementing real-time pipelines</li><li>Experience with data quality and validation</li><li>Experience with SQL performance tuning and end-to-end process optimization</li><li>Experience with anomaly/outlier detection</li><li>Experience with notebook-based Data Science workflow</li><li>Experience with Airflow</li><li>Experience querying massive datasets using Spark, Presto, Hive, Impala, etc.<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data Engineer
data engineer sr,Starbucks,12/20/2023,https://www.linkedin.com/jobs/view/3760908330,0,https://media.licdn.com/dms/image/C4D0BAQEQxk9y2rk7Hw/company-logo_100_100/0/1631316692276?e=2147483647&v=beta&t=_fQHVDrrgPekvhAMO1vrJ4oE1EjD5wQkh5eg7vgDM6Q,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Summary And Mission<br/><br/></strong>This position contributes to Starbucks success by building enterprise data services for analytic solutions. This position is responsible for design, development, testing and support for data pipelines to enable continuous data processing for data exploration, data preparation and real-time business analytics. Models and acts in accordance with Starbucks guiding principles.<br/><br/><strong>Summary Of Key Responsibilities<br/><br/></strong>Responsibilities and essential job functions include but are not limited to the following:<br/><br/><ul><li> Work with data engineering and data science teams to support and optimize non-interactive (batch, distributed) &amp; real-time, highly available data, data pipeline and technology capabilities</li><li> Translate business requirements into technical requirements to ensure solutions meet business needs</li><li> Work with infrastructure provisioning &amp; configuration tools to develop scripts to automate deployment of physical and virtual environments; to develop tools to monitor usage of virtual resources.</li><li> Define &amp; implement data retention policies and procedures</li><li> Define &amp; implement data governance policies and procedures</li><li> Identify improvements in team coding standards and help in implementation of the improvements.</li><li> Leverage subject matter expertise to coordinate issue resolution efforts across peer support groups, technical support teams, and vendors</li><li> Develop and maintain documentation relating to all assigned systems and projects</li><li> Perform systems and applications performance characterization and trade-off studies through analysis and simulation</li><li> Perform root cause analysis to identify permanent resolutions to software or business process issues<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><ul><li> Education (minimum education level, degree or certification necessary): Bachelor’s degree in computer science, management information systems, or related discipline</li><li> 4+ years of professional industry experience with software development<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong>Skills (minimum skills required):<br/><br/><ul><li>3+ years Hadoop, Hive, Spark</li><li>3+ years Python or Scala</li><li>2+ years SQL Platform </li><li> 2+ years Data platform implementation on Azure or AWS </li><li> 2+ years CI/CD experience </li><li> 2+ years implementing data governance solutions</li><li>1+ Exposure to MPP solutions is a plus </li><li> Ability to apply knowledge of multidisciplinary business principles and practices to achieve successful outcomes in cross-functional projects and activities</li><li> Effective communication skills</li><li> Excel at problem solving</li><li> Strong working knowledge of Python or Scala</li><li> Strong working knowledge of SQL and No-SQL Platforms</li><li> Proficiency in debugging, troubleshooting, performance tuning and relevant tooling</li><li> Strong working knowledge of Hadoop, YARN, MapReduce, Hive, Spark</li><li> Proven ability to productionalize big data implementations</li><li> Experience using one of the public cloud (AWS or Azure preferred) for data applications</li><li> Proficiency in shell scripting</li><li> Solid understanding of data design patterns and best practices</li><li> Proficiency in CI/CD tools</li><li> Proficiency in logging and monitoring tools, patterns &amp; implementations</li><li> Understanding of enterprise security, REST / SOAP services, best practices around enterprise deployments</li><li> Proven ability and desire to mentor others in a team environment</li><li> Working knowledge of data visualization tools such as Tableau is a plus</li><li> Practice agile and DevOps<br/><br/></li></ul>Job Attribute<br/><br/>Job Number: 50025625<br/><br/>Job Group: Professional<br/><br/>Job Family: Technology<br/><br/>Job Subfamily: Business Intelligence<br/><br/>Job Location: United States<br/><br/>FLSA Status: Exempt<br/><br/><em>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.<br/><br/>We are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.<br/><br/>Qualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at applicantaccommodation@starbucks.com.</em>
</div>",No Salary Info Found,Data Engineer
Senior Data Engineer,CareerAddict,12/25/2023,https://www.linkedin.com/jobs/view/3791672621,0,https://media.licdn.com/dms/image/C4E0BAQHQUo3YFS080Q/company-logo_100_100/0/1630594573373/career_addict_logo?e=2147483647&v=beta&t=hlZnAyyIVBvbBfiOiJmKLhmpwyazTzU_0eCdWkhqD1E,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        NO SPONSORSHIP<br/><br/>Senior Data Engineer<br/><br/>Salary - 155K - 175K + Bonus<br/><br/>You will drive the data integration solutions in terms of design, build and deployment, DevOps with best-in-class data models, data quality and data architecture standards<br/><br/>Possesses strong data capabilities in terms of data analysis, data models, and hands on expertise in crafting and deploying data pipes usingAzuredata platform and tools, as well as enterprise ETL tool Talend, leveraging its DQ, DI and Data Catalogue features.<br/><br/>Accountable for the technical leadership regarding the data integration solutions and delivery. Ensuring a sound and best in class design, with enterprise implementation, deployment and operational meets the technical quality standards<br/><br/>Responsible for planning and coordinating in carving out the needed dev/test environments, as well as defining and managing code branching/config strategies supporting concurrent releases<br/><br/>Works with Data and Enterprise architecture team to define the data integration design/coding/deployment/operational standards and technology stack<br/><br/>Responsible for data operations, in terms of scheduling, successful execution, and reconciliation of the data pipes in production<br/><br/><strong>Qualifications&amp; Requirements<br/><br/></strong>Bachelor's degree in data, computer science or relevant discipline.<br/><br/>8+ years of experience in ETL, ELT and data engineering<br/><br/>At least 3+ years of working experience on Azure data platforms<br/><br/>Experience working in agile delivery, Jira usage and other agile delivery best practices<br/><br/>Data architecture, Data Modeling, and data visualization experience is a plus<br/><br/>Ability to interact with business, other teams to create data mapping documents, ETL architecture/design artifacts, performance improvements, improve delivery&amp; operational excellence.<br/><br/>Technologies/Software<br/><br/>8+ years of end-to-end implementation experience of deploying enterprise data warehouse, data mart and data lake solutions<br/><br/>3+ years of working experience with Azure data solutions including but not limited to ADLS, Data Bricks, ADF, Synapse etc<br/><br/>Azure ADLS/Databricks administration experience<br/><br/>5+ years of Implementation and maintenance experience with Talend DI, DQ capabilities<br/><br/>Demonstrable understanding of Data Governance, and enabling technical tools and technologies<br/><br/>SELLING POINTS: Data analysis data models azure data platform etl tool talend end-to-end implementation deploying enterprise data warehouse data mart data lake solutions azure data solutions ADLS data bricks ADF synapse azure ADLS data bricks administration talend DIDQ understand of data governance.
      </div>",No Salary Info Found,Data Engineer
"Information Engineer - Analytics, Full-time, Days",Northwestern Memorial Hospital,12/23/2023,https://www.linkedin.com/jobs/view/3791999885,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Senior Data Engineer,Singleton Group,12/19/2023,https://www.linkedin.com/jobs/view/3790329724,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
"Software Engineer, Growth Data Engineering",Stripe,12/19/2023,https://www.linkedin.com/jobs/view/3790401364,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Sr. Data Engineer II,RED SKY Consulting,12/19/2023,https://www.linkedin.com/jobs/view/3790402405,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Senior Enterprise Data Engineer,UScellular,12/19/2023,https://www.linkedin.com/jobs/view/3770790363,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Staff Data Engineer,Kin Insurance,12/19/2023,https://www.linkedin.com/jobs/view/3763328086,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Lead Data Engineer,Burtch Works,12/19/2023,https://www.linkedin.com/jobs/view/3740458573,0,https://media.licdn.com/dms/image/D560BAQGI80kVo4t7hg/company-logo_100_100/0/1698938235961/burtch_works_logo?e=2147483647&v=beta&t=LxsQJgb0mJ-H9yqdcajlHGKjF2bVmSqlKjUQ61OHZE0,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Our client, a leader in the hospitality industry, is looking for a <strong>Lead Data Engineer</strong> to provide technical expertise and leadership in delivering end to end data pipelines. This role will impact the teams advanced analytics capabilities and drive innovation and decision-making across the organization.</p><p><br/></p><p><strong>Responsibilities:</strong></p><ul><li>Build and maintain real-time data pipelines</li><li>Collaborate with the greater analytics organization to prepare data for modeling</li><li>Lead a team of Data Engineers and delegate tasks</li><li>Architect, implement, and maintain data warehouse and database systems for efficient data storage, retrieval, and analysis using Snowflake.</li><li>Act as a subject matter expert on data-related projects and communicate effectively with non-technical stakeholders.</li></ul><p><br/></p><p><strong>Qualifications:</strong></p><ul><li>Bachelors degree in a STEM field preferred (Masters is a plus)</li><li>5+ Years experience in Data Engineering, 2+ years with leadership responsibilities a plus</li><li>Experience working with Snowflake as well as ETL tools like Matillion or DBT</li><li>Proven experience working with Cloud Architectures (Azure is a plus)</li><li>Expertise with Python and SQL</li></ul><p><br/></p><p>Work Environment: Hybrid Tuesday-Thursday</p><p><br/></p><p>Compensation: $130,000-$150,000</p><p><br/></p><p><strong><em>KeyWords: </em></strong><em>Matillion, DBT, Snowflake, Data Engineer, Azure, AWS, Cloud, SQL, Python, ETL</em></p>
</div>",$130000- $150000,Data Engineer
Sr. Data Engineer,Alliant Credit Union,12/19/2023,https://www.linkedin.com/jobs/view/3772773871,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Senior Data Warehouse Engineer (Hybrid),Enova International,12/20/2023,https://www.linkedin.com/jobs/view/3759692241,0,https://media.licdn.com/dms/image/C4D0BAQGulVsv9HtBbA/company-logo_100_100/0/1631344411570?e=2147483647&v=beta&t=9nVicROxVM1-lW1ILBL0Zwb5mZ5O6wMf8NfeeGAm124,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas or take over sponsorship at this time.<br/><br/></em><strong>About the role:<br/><br/></strong>The Data Engineering, Warehouse, and Operations Team effectively and sustainably builds data strategy and provides data solutions and tools across the organization. We integrate, transform, and improve volumes of data at the project or enterprise level for streamlined processes, greater efficiencies, and smarter, more informed decision-making. This team is high-energy, dynamic and in a business-critical domain space. This role is an opportunity to make a real difference in the data space, and we need confident, experienced people eager to bring in solutions, with a demonstrated ability to learn fast and make that happen. #BI-Hybrid<br/><br/><strong>Requirements:<br/><br/></strong><em>Experience designing, developing, and working with dimensional models is a must.<br/><br/></em><ul><li>8+ years of strong databases and SQL experience </li><li>Strong experience in data warehousing methodologies</li><li>Experience leading projects/teams from conception to completion, in fast paced dynamic environments</li><li>6+ years of experience in the design and implementation of ETL/ELT frameworks for complex data mart projects</li><li>Hands-on experience in architecting, designing, implementing, and maintaining multi-layered SQL and Python processes</li><li>Experience working with Relational Database Management Systems, including PostgreSQL, MS SQL Server, MySQL, RDS, and Cloud Data Warehouses such as Snowflake and AWS Redshift</li><li>A Bachelor’s or Master’s degree in Engineering, Computer Science, IT or related study is preferred</li><li>Nice to have: AWS and/or Snowflake Certifications<br/><br/><br/></li></ul><strong>Responsibilities:<br/><br/></strong><ul><li>Opportunity to lead technical initiatives by architecting the solution and collaborating with team members and peers to execute the solution</li><li>Act diligently to respond to urgent projects and tasks</li><li>Troubleshooting discrepancies in existing databases, data pipelines, warehouses, and reporting</li><li>Collaborating with principals, peers, leadership, and the business</li><li>Work as a “full stack” Data Engineer contributing to each phase of the SDLC, building a new pipeline between two data sources or working with the business to design and develop a new dashboard</li><li>Advise on best practices and innovative designs/solutions </li><li>Perform other functions as assigned by management to support the operation of the business<br/><br/><br/></li></ul>#BI-Hybrid<br/><br/><strong>Benefits &amp; Perks:<br/><br/></strong><ul><li>Flexible work schedule (In-office T/W/Th and remote M/F for hybrid-eligible roles)</li><li>Health, dental, and vision insurance including mental health benefits</li><li>401(k) matching plus a roth option (U.S. Based employees only)</li><li>PTO &amp; paid holidays off</li><li>Sabbatical program (for eligible roles)</li><li>Summer hours (for eligible roles)</li><li>Paid parental leave</li><li>DEI groups (B.L.A.C.K. @ Enova, HOLA @ Enova, Women @ Enova, Pride @ Enova, South Asians @ Enova, APEX @ Enova, and Parents @ Enova)</li><li>Employee recognition and rewards program</li><li>Charitable matching and a paid volunteer day…Plus so much more!<br/><br/><br/></li></ul><em>Full-Time Employees working 30+ hours per week are eligible for benefits; interns are not eligible.<br/><br/></em><strong>About Enova<br/><br/></strong>Enova International is a leading financial technology company that provides online financial services through our AI and machine learning-powered Colossus™platform. We serve non-prime consumers and businesses alike, while offering world-class technology and services to traditional banks—in order to create accessible credit for millions.<br/><br/>Being a values-driven organization is at the core of Enova’s success. We live our values by listening to our customers, challenging assumptions, thinking big, setting high expectations, and hiring and developing the best. Through our values and our commitment to making Enova an awesome place to work, we maintain an environment of inclusion and culture where our employees can thrive. You can learn more about Enova’s values and culture here.<br/><br/>It is our policy to provide equal employment opportunity for all persons and not discriminate in employment decisions by placing the most qualified person in each job, without regard to any other classification protected by federal, state, or local law. California Applicants: Click here to review our California Privacy Policy for Job Applicants.<br/><br/>
</div>",No Salary Info Found,Data Engineer
"Data Engineer, Data Platform",Grammarly,12/25/2023,https://www.linkedin.com/jobs/view/3656898066,0,https://media.licdn.com/dms/image/C560BAQFroT18wpIblQ/company-logo_100_100/0/1669669290715/grammarly_logo?e=2147483647&v=beta&t=ztA7DBsCxjynNbw6oGlEHqtgqJneLWUJ1rfYbYVi91A,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>Grammarly is excited to offer a </em><em>remote-first hybrid working model</em><em>. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.<br/><br/></em><em>All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków. </em><em>This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.<br/><br/></em><em>Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.<br/><br/></em><strong>The opportunity <br/><br/></strong>Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.<br/><br/>To achieve our ambitious goals, we’re looking for a Data Engineer to join our Data Engineering Platform team. This person will build highly automated, low latency core datasets that will help data engineers and end users across Grammarly to work with analytical data at scale.<br/><br/>Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.<br/><br/><strong>Your impact<br/><br/></strong>As a Data Engineer on our Data Engineering Platform team, you will:<br/><br/><ul><li>Drive improvements to make our analytics effortless by creating and adjusting core data models and storage structures, all while understanding the needs of our users. </li><li>Make analytical data and metrics usable within a few minutes of real world events occuring, and build streaming processes for the output derived events and aggregate data.</li><li>Model structure, storage, and access of data at very high volumes for our data lakehouse.</li><li>Improve developer productivity and self-serve solutions by contributing components to our stream data processing framework(s).</li><li>Own data engineering's infrastructure-as-code for provisioning services that allow our engineers to deploy mature software installations within a few hours.</li><li>Build a world-class process that will allow our systems to scale.</li><li>Mentor other back-end engineers on the team and help them grow.</li><li>Build and contribute to AWS high-scale distributed systems on the back-end.<br/><br/></li></ul><strong>We’re Looking For Someone Who<br/><br/></strong><ul><li>Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.</li><li>Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.</li><li>Is able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub where the team is based.</li><li>Has experience with Python, Scala, or Java.</li><li>Has experience with designing database objects and writing relational queries</li><li>Has experience designing and standing up APIs and services.</li><li>Has experience with system design and building internal tools.</li><li>Has experience handling applications that work with data from data lakes.</li><li>Has at least some experience building internal Admin sites.</li><li>Has good knowledge of and at least some experience with AWS (or, alternatively, has deep expertise in Azure or GCE and is willing to learn AWS in a short time frame).</li><li>Can knowledgeably choose an open source or third-party service to accomplish what they need or, alternatively, can devise a quick and simple solution on their own.<br/><br/></li></ul><strong>Support for you, professionally and personally<br/><br/></strong><ul><li>Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.</li><li>A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs. <br/><br/></li></ul><strong>Compensation And Benefits<br/><br/></strong>Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:<br/><br/><ul><li>Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)</li><li>Disability and life insurance options</li><li>401(k) and RRSP matching </li><li>Paid parental leave</li><li>Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days </li><li>Home office stipends</li><li>Caregiver and pet care stipends</li><li>Wellness stipends</li><li>Admission discounts</li><li>Learning and development opportunities<br/><br/></li></ul>Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.<br/><br/>Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.<br/><br/><strong>United States<br/><br/></strong>Zone 1: $167,000 - $242,000/year (USD)<br/><br/>Zone 2: $150,000 – $218,000/year (USD)<br/><br/>Zone 3: $142,000 – $206,000/year (USD)<br/><br/>Zone 4: $134,000 – $194,000/year (USD)<br/><br/><strong>We encourage you to apply<br/><br/></strong>At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).<br/><br/><em>Please note that EEOC is optional and specific to US-based candidates.<br/><br/></em>#NA<br/><br/><em>All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.<br/><br/></em>
</div>",$167000- $242000,Data Engineer
Data Engineer,IBM,12/23/2023,https://www.linkedin.com/jobs/view/3756686670,0,https://media.licdn.com/dms/image/D560BAQGiz5ecgpCtkA/company-logo_100_100/0/1688684715866/ibm_logo?e=2147483647&v=beta&t=5zkuzxYrW1Iyx8oUa-u7lMSQ9TN1Q9D87M_0ybQf3NQ,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        669931BR<br/><br/><strong>Introduction<br/><br/></strong>At IBM, work is more than a job - it's a calling: To build. To design. To code. To consult. To think along with clients and sell. To make markets. To invent. To collaborate. Not just to do something better, but to attempt things you've never thought possible. Are you ready to lead in this new era of technology and solve some of the world's most challenging problems? If so, lets talk.<br/><br/><strong>Your Role and Responsibilities<br/><br/></strong>Octo, an IBM company, is an industry-leading, award-winning provider of technical solutions for the federal government. At Octo, we specialize in providing agile software engineering, user experience design, cloud services, and digital strategy services that address government's most pressing missions. Octo delivers intelligent solutions and rapid results, yielding lower costs and measurable outcomes.<br/><br/>Our team is what makes Octo great. At Octo you'll work beside some of the smartest and most accomplished staff you'll find in your career. Octo offers fantastic benefits and an amazing workplace culture where you will feel valued while you perform mission critical work for our government. Voted one of the region’s best places to work multiple times, Octo is an employer of choice!<br/><br/>As a <strong>Data Engineer</strong>, you will work closely with architects, engineers, and integrators to assess customer requirements and to design and support our team to unlock insights from the massive amounts of data within the Veterans Affairs ecosystem. You will be tasked with overall onboarding, operationalizing, administration, and maintenance of key big data/data science/machine learning platforms like Databricks and other cutting-edge technologies.<br/><br/>Previous experience with Veterans Affairs and/or health/clinical data is a major plus.<br/><br/><strong>Us...<br/><br/></strong>We were founded as a fresh alternative in the Government Consulting Community and are dedicated to the belief that results are a product of analytical thinking, agile design principles and that solutions are built in collaboration with, not for, our customers. This mantra drives us to succeed and act as true partners in advancing our client’s missions.<br/><br/><strong>Program Mission...<br/><br/></strong>This program supports Veterans Affairs' strategic mission of furthering efforts to modernize its data analytics platform and enhance accessibility to enterprise data and reporting tools.<br/><br/><strong>Responsibilities...<br/><br/><br/></strong><ul><li>Serves as a technical consultant to implement Analytics solutions and produce Data Domain ETL Scripts.</li><li>Uses PowerBI/dashboards to support problem identification and resolution.</li><li>Develops and maintains documentation on various operational and design aspects of the Platform. Assist in troubleshooting issues and resolving them.</li><li>Builds awareness, increases knowledge and drives adoption of modern technologies, sharing user and engineering benefits to gain buy-in.</li><li>Effectively communicates with and influences key stakeholders across the enterprise, at all levels of the organization.</li><li>Operates as a trusted advisor for technology, platform, or capability domain, helping to shape use cases and implementation in a unified manner.<br/><br/><br/></li></ul><strong>Years of Experience: </strong>Must have at least 5 years of experience with Microsoft database and BI technologies, including at least 2-3 years of experience with Azure Data Lake Storage, Azure Data Factory, Azure SQL DW, Azure Synapse, Databricks, Spark, and/or Python<br/><br/><strong>Education: </strong>Bachelor's degree in computer science or related area OR 8 years of additional experience will be considered in lieu of degree.<br/><br/><strong>Location: </strong>Remote within the United States.<br/><br/><strong>Clearance:</strong> Ability to obtain a Public Trust security clearance.<br/><br/><strong>Required Technical and Professional Expertise<br/><br/><br/></strong><ul><li>See below for experience and educational requirements.</li><li>Experience defining and implementing strategies for extracting, transforming, and loading data from multiple data sources into analytic data stores.</li><li>Knowledge of Cloud Data Analytics platforms </li><li>Experience programming in PowerShell, Python, SQL.</li><li>Experience with cloud data storage formats such as Parquet, Avro. </li><li>Experience with data transformation techniques.</li><li>Ability to test data integrity and develop tests and quality checks. </li><li>Experience preparing data for various types of data analysis: descriptive, diagnostic, predictive, prescriptive. </li><li>Performance analysis and tuning experience</li><li>Experience with Data Warehouse or Big Data solutions</li><li>Experience with ML models</li><li>Experience with data modeling and database design</li><li>Strong communication, interpersonal, and collaboration skills working in a team-oriented environment</li><li>Clearance: Ability to obtain a Public Trust security clearance.<br/><br/><br/></li></ul><strong>Preferred Technical And Professional Expertise<br/><br/><br/></strong><ul><li>Experience supporting Department of Veterans Affairs (VA) and/or other federal organizations.</li><li>Advanced SQL, NoSQL query, and scripting. Experience with Python, Java.</li><li>Experience with Azure Data Lake Storage, Azure Data Factory, Azure SQL DW, Azure Synapse, Databricks, Spark, and/or Python</li><li>Experience with relational database systems (i.e., DB2, SQL Server) and non-relational databases such as (Azure SQL, Amazon RDBS, MongoDB, Hadoop tools).</li><li>Understanding of data design concepts (i.e., data modeling, data mapping, OLTP, and OLAP).</li><li>Experience modeling data, message, and service interoperability.</li><li>Azure PowerShell knowledge<br/><br/><br/></li></ul><strong>About Business Unit<br/><br/></strong>IBM Consulting is IBM’s consulting and global professional services business, with market leading capabilities in business and technology transformation. With deep expertise in many industries, we offer strategy, experience, technology, and operations services to many of the most innovative and valuable companies in the world. Our people are focused on accelerating our clients’ businesses through the power of collaboration. We believe in the power of technology responsibly used to help people, partners and the planet.<br/><br/><strong>Your Life @ IBM<br/><br/></strong>In a world where technology never stands still, we understand that, dedication to our clients success, innovation that matters, and trust and personal responsibility in all our relationships, lives in what we do as IBMers as we strive to be the catalyst that makes the world work better.<br/><br/>Being an IBMer means you’ll be able to learn and develop yourself and your career, you’ll be encouraged to be courageous and experiment everyday, all whilst having continuous trust and support in an environment where everyone can thrive whatever their personal or professional background.<br/><br/>Our IBMers are growth minded, always staying curious, open to feedback and learning new information and skills to constantly transform themselves and our company. They are trusted to provide on-going feedback to help other IBMers grow, as well as collaborate with colleagues keeping in mind a team focused approach to include different perspectives to drive exceptional outcomes for our customers. The courage our IBMers have to make critical decisions everyday is essential to IBM becoming the catalyst for progress, always embracing challenges with resources they have to hand, a can-do attitude and always striving for an outcome focused approach within everything that they do.<br/><br/>Are you ready to be an IBMer?<br/><br/><strong>About IBM<br/><br/></strong>IBM’s greatest invention is the IBMer. We believe that through the application of intelligence, reason and science, we can improve business, society and the human condition, bringing the power of an open hybrid cloud and AI strategy to life for our clients and partners around the world.Restlessly reinventing since 1911, we are not only one of the largest corporate organizations in the world, we’re also one of the biggest technology and consulting employers, with many of the Fortune 50 companies relying on the IBM Cloud to run their business. At IBM, we pride ourselves on being an early adopter of artificial intelligence, quantum computing and blockchain. Now it’s time for you to join us on our journey to being a responsible technology innovator and a force for good in the world.<br/><br/><strong>Location Statement<br/><br/></strong>IBM offers a competitive and comprehensive benefits program. Eligible employees may have access to:<br/><br/><br/><ul><li> Healthcare benefits including medical &amp; prescription drug coverage, dental, vision, and mental health &amp; well being</li><li> Financial programs such as 401(k), the IBM Employee Stock Purchase Plan, financial counseling, life insurance, short &amp; long- term disability coverage, and opportunities for performance based salary incentive programs</li><li> Generous paid time off including 12 holidays, minimum 56 hours sick time, 120 hours vacation, 12 weeks parental bonding leave in accordance with IBM Policy, and other Paid Care Leave programs. IBM also offers paid family leave benefits to eligible employees where required by applicable law</li><li> Training and educational resources on our personalized, AI-driven learning platform where IBMers can grow skills and obtain industry-recognized certifications to achieve their career goals</li><li> Diverse and inclusive employee resource groups, giving &amp; volunteer opportunities, and discounts on retail products, services &amp; experiences<br/><br/><br/></li></ul>The compensation range and benefits for this position are based on a full-time schedule for a full calendar year. The salary will vary depending on your job-related skills, experience and location. Pay increment and frequency of pay will be in accordance with employment classification and applicable laws. For part time roles, your compensation and benefits will be adjusted to reflect your hours. Benefits may be pro-rated for those who start working during the calendar year.<br/><br/>We consider qualified applicants with criminal histories, consistent with applicable law.<br/><br/>IBM will not be providing visa sponsorship for this position now or in the future. Therefore, in order to be considered for this position, you must have the ability to work without a need for current or future visa sponsorship.<br/><br/><strong>Being You @ IBM<br/><br/></strong>IBM is committed to creating a diverse environment and is proud to be an equal-opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, gender, gender identity or expression, sexual orientation, national origin, caste, genetics, pregnancy, disability, neurodivergence, age, veteran status, or other characteristics. IBM is also committed to compliance with all fair employment practices regarding citizenship and immigration status.
      </div>",No Salary Info Found,Data Engineer
Data Engineer,Blackstone Talent Group,12/19/2023,https://www.linkedin.com/jobs/view/3790357905,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,Kearney & Company,12/19/2023,https://www.linkedin.com/jobs/view/3790345109,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,AARP,12/19/2023,https://www.linkedin.com/jobs/view/3770536272,0,https://media.licdn.com/dms/image/C4D0BAQGrLdVnDetK2w/company-logo_100_100/0/1630512518306/aarp_logo?e=2147483647&v=beta&t=GPoqu717ZAAEG4LNm6Og7hd8S4ESP2pWTXNvKncT_lk,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>AARP Services, Inc., founded in 1999, is a wholly-owned taxable subsidiary of AARP. AARP Services manages the provider relationships for and performs quality control oversight of the wide range of products and services that carry the AARP name and are made available by independent providers as benefits to AARP’s millions of members. The provider offers currently span health products, financial products, travel and leisure products, and life event services. Specific products include Medicare supplemental insurance; credit cards, auto and home, mobile home and motorcycle insurance, life insurance and annuities; member discounts on rental cars, cruises, vacation packages and lodging; special offers on technology and gifts; pharmacy services and legal services. AARP Services also engages in new product development activities for AARP and provides certain consulting services to outside companies.<br/><br/>As the Data Engineer for the Marketing team with AARP Services, you will administer and oversee systems, tools and technologies for CRM Databases and member advertising platforms. In addition, you will design and implement data architecture including designing data pipelines, creating data models, and ensuring high performance, low latency as well as accuracy, completeness, and consistency of data.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Writes code proficiently to generate answers to analytic inquiries.</li><li>Manages the intake and output process for technical and non-technical internal audiences requesting analytic projects.</li><li>Utilizes data engineering procedures to feature engineer, move data, and produce and/or automate products, especially those including large amounts of data.</li><li>Develops reports and data visualizations to answer a broad range of questions.</li><li>Generates insights to be shared with internal customers.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Bachelor’s degree in a related field or relevant years of experience in lieu of degree</li><li>3+years of related experience; including programming and cloud platforms preferably on data management processes, data engineering, or data analytics</li><li>2+ years on Python, PySpark, Databricks, Snowflake, etc.</li><li>Data analysis experience is required</li><li>Experience with digital audience platforms preferred</li><li>Technical project management and vendor resource management experience preferred</li><li>AWS Architect and/or Cloud certifications preferred<br/><br/></li></ul><strong>Additional Requirements<br/><br/></strong><ul><li>Regular and reliable job attendance</li><li>Effective verbal and written communication skills</li><li>Exhibit respect and understanding of others to maintain professional relationships</li><li>Independent judgement in evaluation options to make sound decisions</li><li>In office/open office environment with the ability to work effectively surrounded by moderate noise<br/><br/></li></ul><strong>Flexible Work Arrangement (FWA)<br/><br/></strong>AARP observes Mondays and Fridays as telecommuting workdays, except for essential functions. Remote work and telecommuting can only be done within the United States and its territories.<br/><br/><strong>Compensation And Benefits<br/><br/></strong>AARP offers a competitive compensation and benefits package including a 401(k); 100% company-funded pension plan; health, dental, and vision plans; life insurance; paid time off to include company and individual holidays, vacation, sick, caregiving, and parental leave; performance-based and peer-based recognition; tuition reimbursement; among others.<br/><br/><strong>Equal Employment Opportunity<br/><br/></strong>AARP is an equal opportunity employer committed to hiring a diverse workforce and sustaining an inclusive culture. AARP does not discriminate on the basis of race, ethnicity, religion, sex, color, national origin, age, sexual orientation, gender identity or expression, mental or physical disability, genetic information, veteran status, or on any other basis prohibited by applicable law.
      </div>",No Salary Info Found,Data Engineer
Data Engineer,Tential Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3771471112,0,https://media.licdn.com/dms/image/C560BAQHnOqVlYhs_Qw/company-logo_100_100/0/1644376641769/tential_logo?e=2147483647&v=beta&t=KGNXyf8sS9RdkjXtqLM2TG9fNnJmesGJvYC4j3btUis,"Vienna, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>Modernize an On-Prem architecture migrating to Azure creating new data pipelines and contributing to architectural decisions. Develop strategies for data acquisition, and database implementation. Responsible for designing, building, integrating data from various resources, and managing big data. Solves highly complex problems; takes a broad perspective to identify solutions. Works independently.<br/><br/><strong>Requirements<br/><br/></strong><ul><li>Must have strong hands-on experience with Azure Data Factory and Databricks.</li><li>3+ years of experience in data engineering.</li><li>Experienced in sourcing, maintaining, and updating data in On-Prem and Cloud environments.</li><li>Strong SQL skills and knowledge of data warehousing and ETL best practices.</li><li>Experience designing, building and monitoring of data pipelines using Azure Data Factory.</li><li>Understands data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage.</li><li>Experience using GIT &amp; Source Control. </li><li>Some experience in developing NO SQL solutions using Azure Cosmos DB.</li><li>Bachelor’s degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience.<br/><br/><br/></li></ul><strong>Responsibilities:<br/><br/></strong><ul><li>Develop high-performance data pipelines.</li><li>Contribute to architectural decisions and system evaluations.</li><li>Build conceptual and logical data models for stakeholders and management.</li><li>Ensure data quality and continuous improvement.</li><li>Familiarity with data warehousing concepts and best practices.</li><li>Perform other duties as assigned.<br/><br/><br/></li></ul><strong>Additional Information:<br/><br/></strong><ul><li>Our client is looking for candidates local to either the VA or Pensacola (but preference is Pensacola) area but are open to Full-time remote within the United States.<br/><br/><br/></li></ul>#Dice<br/><br/>#Remote<br/><br/>
</div>",No Salary Info Found,Data Engineer
Data Engineer,ASCENDING Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3790307654,0,https://media.licdn.com/dms/image/C4D0BAQG4H6mBuWVGQw/company-logo_100_100/0/1631372273839/ascendingllc_logo?e=2147483647&v=beta&t=HqSlWBYB2Htxq8mAj5GFZEzDCI-FyaW7xdBt4yqDPEo,"Fairfax, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Full-time, 100% Remote<br/><br/>Available for W-2 or 1099 Individual. <br/><br/></strong>Our client, one of the largest Amazon Web Services (AWS) partners for data services, is looking for a true Mid level Big Data Engineer to contribute to join their team of technologists to build and contribute to large-scale, innovative projects. Technological and career growth opportunities are a natural and every day part of the working environment.<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Analyze system requirements and design responsive algorithms and solutions.</li><li>Use big data and cloud technologies to produce production quality code.</li><li>Engage in performance tuning and scalability engineering.</li><li>Work with team, peers and management to identify objectives and set priorities.</li><li>Perform related SDLC engineering activities like sprint planning and estimation.</li><li>Work effectively in small agile teams.</li><li>Provide creative solutions to problems.</li><li>Identify opportunities for improvement and execute.<br/><br/></li></ul><strong>Requirements:<br/><br/></strong><ul><li>Minimum 4 years of proven professional experience working in the IT industry.</li><li>Bachelor's in Computer Science or related domain.</li><li>Experience with cloud based Big Data technologies.</li><li>Experience with big data technologies like Hadoop, Spark and Hive.</li><li>AWS experience (S3 and EMR).</li><li>Proficiency in Hive / Spark SQL / SQL. Experience with Spark.</li><li>Experience with one or more programming languages like Scala &amp; Python &amp; Java.</li><li>Ability to push the frontier of technology and independently pursue better alternatives.<br/><br/></li></ul>Thanks for applying!<br/><br/>Powered by JazzHR<br/><br/>Hv70rUP3Sg
      </div>",No Salary Info Found,Data Engineer
"Data Engineer, Product Analytics",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3725765838,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.<br/><br/>Data Engineer, Product Analytics Responsibilities:<br/><br/><ul><li>Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems</li><li>Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve</li><li>Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way</li><li>Define and manage SLA for all data sets in allocated areas of ownership</li><li>Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership</li><li>Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains</li><li>Solve our most challenging data integration problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources</li><li>Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts</li><li>Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts</li><li>Influence product and cross-functional teams to identify data opportunities to drive impact</li><li>Mentor team members by giving/receiving actionable feedback<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.</li><li>4+ years of work experience in data engineering (a minimum of 2+ years with a Ph.D)</li><li>Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Master's or Ph.D degree in a STEM field</li><li>Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy</li><li>Experience working with terabyte to petabyte scale data<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data Engineer
Data Engineer,Deloitte,12/20/2023,https://www.linkedin.com/jobs/view/3752817620,0,https://media.licdn.com/dms/image/C560BAQGNtpblgQpJoQ/company-logo_100_100/0/1662120928214/deloitte_logo?e=2147483647&v=beta&t=KhIfaHWyu1aAgyyImEhYDprMjFP3LaMR0E7NF2MPxMY,"Arlington, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Do you want to build your brand by working for a leading consulting firm that drives eminence in the marketplace? Are you interested in leveraging your analytical skills and strategic ideas to improve mission execution? If so, Deloitte could be the place for you! Our Government and Public Services Strategy and Analytics team brings deep industry expertise, rigorous analytical capabilities and a pragmatic mindset to help solve our client's most complex business problems. Join our team and play a key role in helping to design our clients' roadmap to the future and help transform the Federal marketplace.<br/><br/><strong>Work you'll do<br/><br/></strong>The Data Analytics Architect will have overall responsibility of planning how work within different teams will integrate into one solution. The Data Analytics Architect will also have overall responsibility of being the primary representative on all architecture matters and the leading member of the Architecture Team. The Architect will:<br/><br/><ul><li>Work closely with various software development team(s) to migrate and architect data to meet client needs</li><li>Work directly with clients to validate migrated data</li><li>Work with Agile development teams to understand changes and their impacts towards data migration efforts</li><li>Leading developers, managing database administrators' workload and activities, among other tasks.</li><li>Create and manage schedules for data management (e.g. migration, integration, etc.) efforts</li><li>Build processes and scripts required to transform and stage data necessary to develop products and analyses<br/><br/></li></ul><strong>The team <br/><br/></strong>Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, &amp; local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.<br/><br/>The GPS Analytics and Cognitive (A&amp;C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.<br/><br/><strong>Qualifications<br/><br/></strong>Required:<br/><br/><ul><li>Must have an active Secret clearance</li><li>2+ years of hands-on experience with ETL/data pipeline development experience, leveraging industry-standard tools, ideally Informatica</li><li>2+ years of experience working with relational databases and data lakes, with an emphasis on data warehousing, performance tuning, and analytics use cases</li><li>Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.<br/><br/></li></ul>Preferred:<br/><br/><ul><li>Experience integrating them into custom web applications</li><li>Data modeling and solution design experience</li><li>Familiarity programming in languages commonly used for data management and data science/statistics, such as Python</li><li>A general interest in relevant emerging technologies such as cloud-native services, and a constant thirst to further your own technical abilities</li><li>Experience working in an Agile development environment</li><li>Hands-on experience with full suite of software lifecycle tools (Confluence, Jira, Stash, Jenkins, Artifactory, etc.)</li></ul>
</div>",No Salary Info Found,Data Engineer
Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788692797,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"McLean, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Location: McLean, Virginia, United States of America Job Title: Data Engineer Are you passionate about technology and problem-solving? Do you thrive in a collaborative and inclusive work environment? At Capital One, we believe in diversity, inclusivity, and innovation. We are a team of makers, breakers, and doers who strive to solve real problems and meet the needs of our customers. The Finance Tech team at Capital One is seeking a Senior Associate, Data Engineer who is excited about integrating data with emerging technologies. As a Senior Associate, Data Engineer, you will help pioneer a major transformation at Capital One. What You'll Do: - Actively identify customer needs and collaborate with stakeholders to create effective solutions. - Support the design and development of scalable data architectures and systems for extracting, storing, and processing large amounts of data. - Build and optimize data pipelines for efficient data ingestion, transformation, and loading from various sources, while ensuring data quality and integrity. - Work with Data Scientists, Machine Learning Engineers, Business Analysts, and Product Owners to understand their requirements and provide efficient solutions for data exploration, analysis, and modeling. - Implement testing, validation, and pipeline observability to ensure data pipelines meet customer SLAs. Basic Qualifications: - Bachelor's Degree - Minimum of 2 years of application development experience (Internship experience not applicable) - Minimum of 1 year of experience in big data technologies Preferred Qualifications: - 3+ years of experience developing data pipelines using Python or Scala - 2+ years of experience with distributed computing tools (Spark, EMR, Hadoop) - 2+ years of experience with UNIX/Linux, including basic commands and shell scripting - 1+ years of experience with a public cloud platform (AWS, Microsoft Azure, Google Cloud) - 1+ years of data warehousing experience (Redshift or Snowflake) - 1+ years of experience with Agile engineering practices Please note that Capital One will not sponsor a new applicant for employment authorization for this position. At Capital One, we value the well-being of our employees and offer a comprehensive set of health, financial, and other benefits to support them. Visit our Capital One Careers website to learn more about the benefits we provide. This role will accept applications for a minimum of 5 business days. No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other prohibited basis under applicable law. We also promote a drug-free workplace. Capital One will consider qualified applicants with a criminal history in accordance with applicable laws. If you require an accommodation during the application process, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. Rest assured that any information you provide will be kept confidential and used only to provide necessary reasonable accommodations. For technical support or questions about Capital One's recruiting process, please email Careers@capitalone.com. Please note that Capital One Financial is composed of different entities. Positions posted in Canada are for Capital One Canada, positions in the United Kingdom are for Capital One Europe, and positions in the Philippines are for Capital One Philippines Service Corp. (COPSSC).
      </div>",No Salary Info Found,Data Engineer
"Analytics Engineer, Data Insights",MERU,12/25/2023,https://www.linkedin.com/jobs/view/3599301708,0,https://media.licdn.com/dms/image/C4E0BAQEVuf3UK2EhgQ/company-logo_100_100/0/1631333559352?e=2147483647&v=beta&t=KDydjKATbpF7A3q6-c3kxeDG9KTxggW0DkHeCIqNdcw,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><u>Meet the Company:</u></strong></p><p>We are MERU. A values-driven, impact-oriented team dedicated to fixing companies. We provide advisory services and data analytics support to middle-market companies ($50M - $2B in annual sales), and our clients include private equity firms, credit funds, investment banks, and law firms. We bring deep turnaround experience, a group of veteran operators, and an incentive-aligned approach to any situation. MERU was founded by professionals from Alvarez &amp; Marsal and McKinsey and has seen rapid growth in the five-plus years since its founding.</p><p><br/></p><p><strong><u>The MERU Way &amp; Valuing Our Team:</u></strong></p><p>We're Partners, not consultants. When you join MERU, you will help our clients solve their most pressing problems, supported by a team of people who will challenge you, support you, and inspire you.</p><p><br/></p><p>In order to be Partners, we don't silo people into just one functional area of the business, instead advancing our team's capabilities by providing training for every service that MERU offers. Additionally, we don't just focus on technical skills but also leadership style and soft skills, so MERU team members not only know what it means to manage a client engagement but to lead a team to success. In training team members to be well-rounded individuals, we can deliver an overall higher impact to clients, allowing each individual the ability to gain experience in diligence, turnarounds, interim management, data science, and more.</p><p><br/></p><p>To aid this career advancement and development, MERU provides an internal Coach to each team member in order to guide and maintain their professional development plan goals. Unlike most Firms, we actually focus on the achievement of those goals for each individual team member, providing opportunities that would not usually be offered.</p><p><br/></p><p>Finally, MERU values personal time, only traveling when necessary, in order to celebrate and respect your personal life. We believe that by encouraging and mandating balance, it will lead to happier and longer-tenured team members.</p><p><br/></p><p>When you come to MERU, you come to further your career and maintain your entrepreneurial spirit, never losing sight of the desire to provide meaningful impact, solutions, and value to clients. Learn more about our colleagues’ core characteristics and culture here: https://wearemeru.com/meru-way/</p><p><br/></p><p><strong><u>Responsibilities: </u></strong></p><ul><li>Demonstrates ownership of individual workstreams with minimal supervision from senior team members, with the ability to coach junior team members on the engagement</li><li>Complete ownership for end-to-end process of engaging stakeholders for design sessions and requirements gathering and solution build​</li><li>Produces high quality, production level code, balances on-time delivery with long-term sustainability</li><li>Proactively communicates progress and roadblocks to senior team members on an ongoing basis; proactively develops solutions to the roadblocks</li><li>Contributes to proposal development (i.e., assistance with analysis/presentation, etc.) and proactively identifies ways to improve the proposal quality (i.e., research, package case studies, etc.)</li><li>Assists Partners in preparation for pitches and attends as required</li><li>Proactively identifies ways to improve proposal quality</li><li>Supports in the development of Firm Contribution areas, such as Recruiting, Professional Development, Marketing, etc.</li></ul><p><br/></p><p><strong><u>Qualifications:</u></strong></p><ul><li><strong>3+ years of business intelligence or data analytics experience</strong></li><li><strong>Previous experience in data and analytics consulting or a client-facing role, required</strong></li><li>Bachelor’s degree from a top university, required</li><li>Strong knowledge and delivery experience with Tableau, Power BI, Qlik, or any other data visualization tools</li><li>Working knowledge of ETL tools like Power Query, Azure Data Factory, FiveTran, Stitch, Alteryx, and languages like SQL, Python, or R</li><li>Relevant certifications associated with business intelligence tools, and enthusiasm to learn new tools and technologies and attain certifications</li><li>Experience in mentoring junior analysts and leading cross-functional teams to deliver data products</li><li>Demonstrated ability to interact and work collaboratively with junior and senior team members, senior management, and other stakeholders or professionals</li><li>Experience in independently managing deliverables with little oversight</li><li>Effective communication skills to explain technical concepts to a non-technical audience or senior executives</li><li>“Roll up your sleeves” mentality and willingness to complete any task if needed, no matter the role</li><li>Ability to assist with internal firm initiatives (e.g., marketing, client pitches)</li><li>Willingness to travel up to 20%</li><li>Ability to work full time in an office and remote environment; physically able to sit/stand at a computer and work in front of a computer screen for significant portions of the workday</li><li>Authorization to work in the United States</li><li>Commitment to living MERU’s values and core characteristics</li></ul><p><br/></p><p><strong><u>Overview of MERU Service Offerings: </u></strong></p><p><br/></p><p>Data Insights:</p><p>Work with companies at all stages of their digital transformation journey to automate reporting processes, build scalable data platforms, and leverage predictive analytics to transform data from a liability into an asset. Services include Data Discovery and Analysis, Data Prep and Integration, Self-Service Analytics, Data Visualization and Reporting, Data Science and Advanced Analytics, and Strategy Enablement.</p><p><br/></p><p>Performance Improvement:</p><p>Help companies identify and achieve their full potential by leveraging a value-focused approach to driving sustainable margin expansion impact. Services include MERU 360° Assessment, Transformation Plan Development, Chief Transformation Officer placement, Cash Cycle and Working Capital Optimization, and Implementation Performance Management.</p><p><br/></p><p>Turnaround &amp; Restructuring:</p><p>Partner with clients during uncertain times to help stabilize operations and rapidly triage the causes of financial distress, charting a path back to long-term sustainability. Services include Interim Management, Turnaround Plan Development and Execution, Liquidity Management, Stakeholder Negotiations, Strategic Alternatives Assessment, Bankruptcy, Insolvency, and Case Management.</p><p><br/></p><p>Transaction Services:</p><p>Partner with private equity firms across the investment lifecycle, from due diligence to portfolio value creation and exit planning. Services include Due Diligence, Pre-Close Planning, Post-Close Implementation, and Exit Planning.</p><p><br/></p><p><strong><u>Salary Range:</u></strong><u> </u></p><p>$105,000 – $155,000. In addition to benefits, MERU also offers an extremely competitive bonus program that is based on firm contribution efforts and performance.</p><p><br/></p><p><strong><u>Voluntary Inclusion:</u></strong></p><p>It is MERU’s policy to provide and promote equal opportunity in employment, compensation, and other terms and conditions of employment without discrimination because of race, color, sex, sexual orientation, family medical history or genetic information, political affiliation, military service, pregnancy, marital status, family status, religion, national origin, age or disability or any other non-merit based factor in accordance with all applicable laws and regulations.</p><p><br/></p><p><strong><u>Unsolicited Resumes from Third-Party Recruiters:</u></strong></p><p>Please note that we do not accept unsolicited resumes from third-party recruiters unless such recruiters are engaged to provide candidates for a specified opening. Any employment agency, person, or entity that submits an unsolicited resume does so with the understanding that MERU will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person, or entity.</p>
</div>",$50- $2,Data Engineer
Insights Data Engineer,SCIENTIFIC GAMES,12/21/2023,https://www.linkedin.com/jobs/view/3791523755,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3766608708,0,https://media.licdn.com/dms/image/C4D0BAQFPP1NRP4F5dQ/company-logo_100_100/0/1656657978597/tata_consultancy_services_logo?e=2147483647&v=beta&t=Ao4Ihtw2eg1ymYGPB7E4AEHoNQ83oX6bP1DrQIiqR1s,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<ul><li>The ETL Engineer performs design, development and implementation of integration processes for both the Enterprise Data lake, Data Warehouse and Applications</li><li>Analyzes requirements and existing resources to create efficient database and integration designs that meet company IT standards.</li><li>Works with project and business analyst leads to develop and clarify in-depth technical requirements.</li><li>Participates in all phases of the integration development lifecycle, including unit testing, quality assurance(QA) and ongoing support.</li><li>Helps with Production support as needed</li></ul>
</div>",No Salary Info Found,Data Engineer
AWS Data Engineer,Intellectt Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788188147,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Sr Data Engineer,The Fountain Group,12/19/2023,https://www.linkedin.com/jobs/view/3784094967,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Senior Data Engineer,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3738099369,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,Robert Half,12/19/2023,https://www.linkedin.com/jobs/view/3788193038,0,https://media.licdn.com/dms/image/D560BAQFP6-a3z7Fm8Q/company-logo_100_100/0/1696341221977/robert_half_international_logo?e=2147483647&v=beta&t=bEiN5BCeElOLCcC8_YBaV9u7oNwig23-OSsa-qGORvI,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Are you a data wizard with a passion for transforming raw data into actionable insights? Do you want to work on cutting-edge data engineering projects, leveraging the latest technologies and making a real impact? If you're ready to dive into a world of data-driven innovation, we want YOU to be part of our dynamic team!<br/><br/><strong>🚀 The Role<br/><br/></strong>As a Data Engineer, you'll be the architect of our data infrastructure, responsible for designing and building the foundation upon which our analytics and data-driven insights rely. You'll work in a collaborative and agile environment, alongside a team of experts who are passionate about data and innovation.<br/><br/><strong>📊 What You'll Do<br/><br/></strong><ul><li>Design, develop, and maintain robust data pipelines and ETL processes.</li><li>Optimize and ensure the scalability, reliability, and performance of our data systems.</li><li>Collaborate with data scientists, analysts, and stakeholders to understand data requirements.</li><li>Implement data security and privacy best practices.</li><li>Stay current with emerging data technologies and trends.<br/><br/></li></ul><strong>Requirements<br/><br/></strong>🔑 Requirements:<br/><br/><ul><li>Proficiency in programming languages like Python, Java, or Scala.</li><li>Strong knowledge of SQL and relational databases.</li><li>Experience with big data technologies such as Hadoop, Spark, or Kafka.</li><li>Familiarity with cloud platforms (AWS, GCP, Azure).</li><li>Strong problem-solving and analytical skills.</li><li>Excellent communication and collaboration abilities.<br/><br/></li></ul>Data E<br/><br/>Technology Doesn't Change the World, People Do.®<br/><br/>Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.<br/><br/>Robert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go.<br/><br/>All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance. Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan. Visit<br/><br/>© 2024 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to
      </div>",No Salary Info Found,Data Engineer
Data Center Engineer,Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3732380840,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Big Data Developer,EROS Technologies Inc,12/20/2023,https://www.linkedin.com/jobs/view/3715677211,0,https://media.licdn.com/dms/image/D4D0BAQGRIARVhkjBpA/company-logo_100_100/0/1684167454683/eros_technologies_inc_logo?e=2147483647&v=beta&t=RYJ7eFTjbsMv3Z5KOJoyPIuk-eSao9yz4HmoqQY8rzM,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Hi</strong></p><p><strong>Hope You are doing well</strong></p><p><strong> </strong></p><p><strong>Job Big data engineer</strong></p><p><strong>Location Atlanta GA</strong></p><p><strong>Duration Full time</strong></p><p><strong>Interview Mode Video</strong></p><p><strong> </strong></p><p><strong>JD</strong></p><p><strong>Job Description:</strong></p><p><strong> </strong></p><p><span>Must have Skills: Cloud architecture (Strong), Cloud development (Strong), Python (Strong), Snowflake, AWS Lambda.</span><span> </span></p><p><strong> </strong></p><p><span>We are looking for a strong Data Engineer cum Architect, to create new modern data ingestion pipelines using latest technologies like AWS Athena, Lambdas, Python, Spark.</span><span> </span></p><p><span>You'll be working on data pipelines and tools to provide the underlying data ingestion framework."" </span></p><p><span> </span></p><p><strong>Technical Skills: </strong></p><ul><li>Frontrunner </li><li>Be inclined towards process automations &amp; improvements, Identifying &amp; automating repetitive things. </li><li>Must be able to handle Data engineering operations / enhancement project with a technical consultant bend. </li><li><span>SQL, Python, PySpark , S3, Lambda, EMR, Glue, Athena, EC2, IAM, Redshift, DMS, Airflow, Jenkins, Snowflake. </span></li><li><span>End-to-end data solutions (ingest, storage, integration, processing, access) on AWS. </span></li><li><strong>Migrate data from traditional relational database systems to AWS relational databases such as Amazon RDS, Aurora, and Redshift.  </strong></li><li><strong>12+ years IT experience. Background and experience in data engineering/analytics. </strong></li><li><strong>Should have a very good hands-on experience in Cloud DB platforms (Snowflake is preferable), Building data pipelines &amp; SQL, Python for Data Engineering.  </strong></li><li><strong>Got experience to Perform, Support and Lead all aspects of Data Engineering strategy. </strong></li><li><strong>Excellent root cause analysis skills.  </strong></li><li><strong>Ensure effective data pipeline engineering, deployment, ongoing operations, and continuous improvement. </strong></li><li><strong>Manage and perform data operations and data engineering requirements including automation and optimization. </strong></li><li><strong>Highly motivated, a self-starter, ability to work in a fast faced environment while managing competing priorities. </strong></li><li><strong>Creative problem solver and highly collaborative teammate who is comfortable working as a key contributor. </strong></li><li><strong>Certification in Data Engineering and/or Cloud Platforms are a plus. </strong></li><li><strong>Good written and verbal communication skills, and comfortable presenting findings to Sr. Management.  </strong></li></ul><p><br/></p><p><br/></p><p><strong>Thanks &amp; Regards</strong></p><p><strong> </strong></p><p><strong>Anuj Suman</strong></p><p><strong>Lead Recruter </strong></p><p><strong>Eros Technologies Inc.</strong></p><p><strong>suman.k@erostechnologies.com</strong></p>
</div>",No Salary Info Found,Data Engineer
Data Engineer,Georgia-Pacific LLC,12/21/2023,https://www.linkedin.com/jobs/view/3760170144,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer III - Remote | WFH,Get It Recruit - Information Technology,12/25/2023,https://www.linkedin.com/jobs/view/3787808700,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"La Mesa, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a dynamic and innovative team seeking a skilled Data Engineer III to join us remotely. At our company, we value collaboration, creativity, and a passion for transforming data into meaningful insights. If you thrive in a fast-paced, agile environment and are excited about building solutions that make a real impact, we invite you to explore this opportunity.<br/><br/><strong>Responsibilities<br/><br/></strong>Design and implement features in collaboration with a diverse team of engineers, product owners, data analysts, and business partners using Agile/Scrum methodology.<br/><br/>Develop programs and systems that translate data into meaningful information for analysis.<br/><br/>Build ETL/ELT jobs and workflows to integrate data from various sources.<br/><br/>Install continuous pipelines of filtered information for data analysts/scientists.<br/><br/>Construct data workflows using SQL Server Integration Services (SSIS), Microsoft Azure (Azure Data Factory, Storage Accounts, Synapse), and Databricks.<br/><br/>Collaborate with business stakeholders and product engineering teams to analyze business problems and implement solutions.<br/><br/>Document software architecture, create roadmap plans, and assist in the design, implementation, and maintenance of complex solutions.<br/><br/>Build systems that collect, manage, and convert raw data into usable information for business analysts.<br/><br/>Ensure data accessibility for evaluation and optimization.<br/><br/><strong>Qualifications<br/><br/></strong>Required:<br/><br/>Master's degree in computer science, systems engineering, or a related technical discipline (preferred).<br/><br/>5 years of experience as a Data Engineer/Administrator or in a similar role.<br/><br/>6 additional years of relevant experience may substitute for education.<br/><br/><strong>Preferred<br/><br/></strong>Proficiency in back-end data organization using SQL scripts and SSIS.<br/><br/>Experience with Microsoft Azure, Databricks, and Python or other scripting languages in data pipelines.<br/><br/>Familiarity with Microsoft Power BI.<br/><br/>Ability to work independently and provide technical and non-technical support to multiple users.<br/><br/>Capable of working under pressure, handling multiple tasks simultaneously.<br/><br/>Occasional overtime and weekend availability may be required.<br/><br/><strong>Salary Range<br/><br/></strong>Experience providing services to the federal government is preferred.<br/><br/>Target salary range: $165,001 - $175,000. The estimate displayed represents the typical salary range for this position based on experience and other factors.<br/><br/><strong>COVID Policy<br/><br/></strong>We prioritize the health and safety of our team members. While we do not require COVID-19 vaccinations or boosters, we adhere to customer site vaccination requirements when work is performed at a customer site.<br/><br/>Employment Type: Full-Time
      </div>",$165001- $175000,Data Engineer
"Data Engineer - Data Science Solution, Privacy, and Ethics (JRD)",Johnson & Johnson,12/24/2023,https://www.linkedin.com/jobs/view/3792749486,0,https://media.licdn.com/dms/image/D4E0BAQFuqNYNGYIxzg/company-logo_100_100/0/1694701608948/johnson__johnson_logo?e=2147483647&v=beta&t=rMPpZ5Dp4g-fQnmmnC_FkqYIFuXXr06ODBxaP3Xy9b8,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description:<br/><br/></strong><strong>Johnson &amp; Johnson Innovative Medicine</strong> is recruiting for a Data Engineer in R&amp;D Data Science Solution, Privacy, and Ethics (DSSPE) team, located in San Diego, CA, Spring House, PA, South San Francisco, CA, or Titusville, NJ.<br/><br/>The team applies a diverse set of data and tools, along with platform solutions to answer impactful analytical questions and provide insights to strategy makings, from early stage of drug discovery to clinical programs.<br/><br/>As a member of the Data Platforms team, the Data Analytics Engineer will lead and deliver data integration and analytics solutions to support precision medicine for Janssen’s growing oncology pipeline. This role is responsible for implementing R&amp;D data pipelines as well as develop/deploy innovative technology/solutions that triangulate insights for clinical programs. The role requires solid understanding of data engineering, analytical solutions, and creativity to invent and customize where necessary.<br/><br/><strong>Key Responsibilities:<br/><br/></strong><ul><li>Implement data &amp; analytics engineering strategy for oncology clinical trial data.</li><li>Partner closely with cross functional team including Biomarker &amp; Diagnostic Operations, data scientists and IT for implementation and execution.</li><li>Partner with R&amp;D partners to deliver analytical data pipeline with a focus on oncology biomarker, diagnostic, and sample management.</li><li>Participate in evaluations of algorithms, tools and technologies that enable R&amp;D data science initiative.</li><li>Provides key sophisticated analytical support for clinical programs with a precision medicine focus.</li><li>Creation of high-level biomarker and diagnostic datasets from a variety specialty lab partner(s). The candidate should be comfortable working with a diverse collection of data files, formats and data types depending on the assays/platform used<br/><br/></li></ul><strong>Qualifications:<br/><br/></strong><ul><li>Bachelors Degree in Bioinformatics, Statistics, Computer Science, Information Technology, Operation Research or a related subject area is required.</li><li>3+ years of life science proven experience on data science or data analytics teams required.</li><li>Proficient with one or more programming language such as SQL / Python</li><li>Experience with Data Management and Relational Data Warehouses (such as Redshift).</li><li>Understand requirements and implement data integration strategies including schema mapping, data transformations, and data cleaning.</li><li>Solid understanding of a cloud platform, such as AWS.</li><li>Excellent communication, interpersonal, and written skills.<br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Prior independent or research experiences on projects using data from clinical trials, clinical trial subject operational data, SDTM/ADaM format, etc.</li><li>Demonstrate knowledge of health outcomes databases (claim, EMR/EHR, survey, observation studies) or clinical operations.</li><li>Experience with relevant disease biology in cancer, immunology, neuroscience, cardiovascular, or infectious disease.</li><li>Working experience in data science projects using predictive technologies, data mining and/or text mining of datasets in the clinical or healthcare domain.<br/><br/></li></ul>Expected Base Salary: 104,000 - 145,000<br/><br/>Johnson &amp; Johnson is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, age, national origin, or protected veteran status and will not be discriminated against on the basis of disability.<br/><br/>For more information on how we support the whole health of our employees throughout their wellness, career and life journey, please visit www.careers.jnj.com.<br/><br/>#JRDDS<br/><br/>#JNJDataScience<br/><br/>#JRD<br/><br/>
</div>",No Salary Info Found,Data Engineer
Machine Learning Software Engineer,Sony Interactive Entertainment,12/19/2023,https://www.linkedin.com/jobs/view/3766979811,0,https://media.licdn.com/dms/image/C4D0BAQFJO00VqEb3Vg/company-logo_100_100/0/1630540194089/sony_interactive_entertainment_llc_logo?e=2147483647&v=beta&t=jfycjFelGW7uhdwCfVpNWJM5i608eZ6RciYz-9xMHRA,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Why PlayStation?<br/><br/></strong>PlayStation isn’t just the Best Place to Play — it’s also the Best Place to Work. Today, we’re recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation®5, PlayStation®4, PlayStation®VR, PlayStation®Plus, acclaimed PlayStation software titles from PlayStation Studios, and more.<br/><br/>PlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team.<br/><br/>The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.<br/><br/><strong>ML Software Engineer<br/><br/></strong>Sony Interactive Entertainment’s (SIE) Global Payment, Fraud Management and Decision Science (GPFD) teams are the guardians of both customer trust and purchase success for PlayStation and the PlayStation Network (PSN). We provide innovative solutions to support every element of the network, various platform services, customer service teams, a diverse developer community, and more.<br/><br/>GPFD runs a next generation risk platform and machine learning framework that support the global, fast growing PlayStation Network customer base, world class PlayStation consoles, and network entertainment services such as PlayStation Plus and PlayStation Now. In doing so, the ability to extract information from data and drive action that help achieve business goals is essential. GPFD’s data science team is responsible for evaluating online user activity data for potential fraud and revenue optimization across this platform, and the engineering team empowers them. We are looking for an engineer to join our GPFD team to support this data science platform.<br/><br/>The position is a hands-on engineering role with a wide range of responsibilities to evolve and support a machine learning pipeline. You should be intimately familiar with running applications at scale on modern cloud architectures using containerized and serverless workflows. You must be a self-motivated individual and take pride in delivering high-quality work within a fast-paced, dynamic environment.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Create, deploy, and maintain cloud solutions using AWS</li><li>Build core infrastructure around data streaming and enhancement</li><li>Build and enhance our machine learning pipeline to support development, experimentation, continuous integration, continuous delivery, verification/validation, and monitoring of ML models</li><li>Ensure all work is deployed in an automated, repeatable fashion</li><li>Ensure highest levels of service availability<br/><br/></li></ul>Qualifications and Education Requirements:<br/><br/><ul><li>Bachelor’s degree and 2-5 years of related experience</li><li>Demonstrated experience with Java and Python</li><li>Competency with most common AWS Services - EKS/ECS, Kinesis, Lambda, DynamoDB, SNS, SQS, and more</li><li>Knowledge in systems monitoring, alerting and analytics including using tools such as DataDog, Splunk, New Relic, AWS CloudTrail, etc.</li><li>General knowledge in Linux</li><li>Strong communication abilities to work with cross functional teams</li><li>Experience with orchestration and management of containers using Kubernetes or similar.<br/><br/></li></ul>Preferred Skills:<br/><br/><ul><li>AWS certification</li><li>Basic knowledge of data science and data science workflows</li><li>Experience with streams/queues at internet scale – Kinesis/Kafka/ActiveMQ/SQS</li><li>Experience successfully implementing data pipelines<br/><br/></li></ul><strong> Please refer to our Candidate Privacy Notice for more information about how we process your personal information, and your data protection rights. <br/><br/></strong>At SIE, we consider several factors when setting each role’s base pay range, including the competitive benchmarking data for the market and geographic location.<br/><br/>Please note that the base pay range may vary in line with our hybrid working policy and individual base pay will be determined based on job-related factors which may include knowledge, skills, experience, and location.<br/><br/>In addition, this role is eligible for SIE’s top-tier benefits package that includes medical, dental, vision, matching 401(k), paid time off, wellness program and coveted employee discounts for Sony products. This role also may be eligible for a bonus package. Click <strong>here</strong> to learn more.<br/><br/>The estimated base pay range for this role is listed below.<br/><br/>$127,400 — $191,000 USD<br/><br/><strong>Equal Opportunity Statement:<br/><br/></strong>Sony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to gender (including gender identity, gender expression and gender reassignment), race (including colour, nationality, ethnic or national origin), religion or belief, marital or civil partnership status, disability, age, sexual orientation, pregnancy or maternity, trade union membership or membership in any other legally protected category.<br/><br/>We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.<br/><br/>PlayStation is a Fair Chance employer and qualified applicants with arrest and conviction records will be considered for employment.<br/><br/>
</div>",$127400- $191000,Data Engineer
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789762711,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        A market leader in the analytics space, specifically focusing on analytics for the entertainment space is hiring a Senior Data Engineer to join their team of 5. This role will be a lot of new development and migrations as they are moving their SQL based pipelines over to Python, AWS, and Spark so strong SQL experience is a big plus. This company processes tens of billions of rows of data every year and has almost 20TB of processing data. The main tech stack for this role is SQL, Python, AWS, and Spark experience. This team also uses Glue, Power BI, Anthem, EMR, PySpark, and any experience working with marketing metrics/analysis is a plus. You will be building new capabilities for their analytics teams, integrating big data tools and moving to AWS within their pipelines.<br/><br/>This role is looking for someone to work PST hours. If you are local to Southern California that is a big plus but not required as this role is 100% fully remote. This is a small team so they ideally need someone open to wearing a few different hats who can interact with various teams within the organization so good communication is a must.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>5+ years professional Data Engineering Experience </li><li>Background in DBA/SQL Development </li><li>5 years of experience building ETL pipelines with Python, AWS, and Spark/PySpark </li><li>Experience working with large amounts of data <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Bachelors in STEM field </li><li>Excellent written and verbal communication skills </li><li>Any experience with Glue, Power BI, Anthem, or EMR </li><li>Experience working with marketing metrics data <br/><br/></li></ul>The Offer<br/><br/><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Sick Time </li><li>Paid Time Off </li><li>401(k) with match </li><li>Annual Bonus </li><li>Remote PST time <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Cassi Benson
      </div>",No Salary Info Found,Data Engineer
Senior Backend Software Engineer,Intuit,12/19/2023,https://www.linkedin.com/jobs/view/3739151548,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765472151,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Sr. Software Engineer I (CI/CD),Tandem Diabetes Care,12/19/2023,https://www.linkedin.com/jobs/view/3784070997,0,https://media.licdn.com/dms/image/C560BAQFd1c31xI-BMw/company-logo_100_100/0/1643691665912/tandemdiabetes_logo?e=2147483647&v=beta&t=5t4Trbrf9Z4rkywXrK1zW1IB20lIdWNwaYkKeJN01FE,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>GROW WITH US: </strong></p><p>Tandem Diabetes Care creates new possibilities for people living with diabetes, their loved ones, and their healthcare providers through a positively different experience. We’d love for you to team up with us to “innovate every day,” put “people first,” and take a “no-shortcuts” approach that has propelled us to become a leader in the diabetes technology industry.</p><p><br/></p><p><strong>STAY AWESOME:</strong></p><p>Tandem Diabetes Care is proud to manufacture and sell the t:slim X2 insulin pump with Control-IQ technology. We’re also so much more than that. Our company’s human-centered approach to design, development, and support delivers innovative products and services for people who use insulin. Since many of our own team members live with type 1 diabetes, or have a loved one impacted by diabetes, the work is personal, and we are committed to the cause. Learn more at tandemdiabetes.com.</p><p><br/></p><p><strong>A DAY IN THE LIFE:</strong></p><p>An experienced member of the Software Engineering team with a strong focus on automation, CI/CD pipeline optimization, and enhancing internal tools to drive team efficiency and scalability. This role is responsible for mentoring other team members and may at times lead projects.</p><ul><li>Contributes to the development, maintenance, and improvements of our CI/CD pipeline.</li><li>Collaborates with cross-functional teams to design and develop internal tools and systems.</li><li>Creates and maintains tools to streamline processes and reduce manual work.</li><li>Provides mentorship and guidance to other developers on the team.</li><li>Contributes to web development projects, including the design and implementation.</li><li>Independently designs, develops, modifies, and tests software units per corporate software process documents.</li><li>Independently identifies opportunities in the software process, discusses with peers, and implements proposals to address gaps.</li><li>May manage working interactions with external vendors and resources ensuring that deliverables and timelines are met.</li><li>Responsible for software design specifications, interface descriptions, and other software documentation; may act as documentation owner for projects.</li><li>Translates high-level requirements into software design and implementation.</li><li>Provides estimates of effort and timelines to management.</li><li>Contributes to software architecture.</li><li>Ensures compliance with company policies, including Privacy/HIPAA, and other legal and regulatory requirements.</li></ul><p><br/></p><p><strong>YOU’RE AWESOME AT</strong>:</p><ul><li>Proficient with formal software development and test methodologies.</li><li>Able to work independently and deliver high-quality work products without close supervision.</li><li>Able to articulate work assignments and support the work of other team members.</li><li>Adept at seeing change as an opportunity to improve business performance and campaigning for it when necessary.</li><li>Able to effectively convey information related to work product and lead group discussions.</li><li>Able to assert own ideas and persuade others through effectively consolidating, evaluating, and presenting relevant information.</li><li>Experience in common and industry CI/CD standard platforms such as Bamboo, Jenkins, Travis CI, or GitLab.</li><li>Proficient with scripting and automation using languages like Python, Bash, or similar.</li><li>Skilled in web development languages, including HTML, CSS, JavaScript, and popular web frameworks like React, and Angular.</li><li>Knowledge of Good Documentation Practices (GDP) preferred.</li></ul><p><br/></p><p><strong>EXTRA AWESOME:</strong></p><ul><li>Bachelor’s degree in engineering or computer sciences or related field or equivalent combination of education and applicable job experience.</li><li>Experience in either SQL, C#, C++, or Node.js / JavaScript preferred.</li><li>5 years’ experience in the field of embedded software for medical devices, web application software or in a related area.</li></ul><p><br/></p><p><strong>WHAT’S IN IT FOR YOU?</strong></p><p>In addition to innovative technology, we have a culture that fosters the idea that the happiest people are the most productive people. Not only do we hire forward-thinking achievers to join our workforce; we reward, develop, and retain them too. Just one of the many reasons of how we #StayAwesome! To learn more about our culture and benefits please visit https://www.tandemdiabetes.com/careers.</p><p><br/></p><p><strong>BE YOU, WITH US!</strong></p><p>Tandem is firmly committed to being an equal opportunity employer and maintaining a diverse and inclusive environment. We value and embrace that every single one of us brings value to the table. But sometimes we forget that when we don’t meet 100% of a job description’s criteria – maybe you’re feeling that way right now? We encourage you to apply anyway. Because we want you to be you, with us.</p><p><br/></p><p><strong>COMPENSATION &amp; BENEFITS: </strong></p><p><em>The starting base pay range for this position is $140,000 - $160,000 annually. Base pay will vary based on job-related knowledge, skills, experience and may also fluctuate depending on candidate’s location and the overall job market. In addition to base pay, Tandem offers a competitive compensation package that includes bonus, equity, and a robust benefits package. </em></p><p><em>Tandem offers health care benefits such as medical, dental, vision, health savings accounts and flexible saving accounts. You’ll also receive 11 paid holidays per year, a minimum of 20 days of paid time off (starting in year 1) and have access to a 401k plan with company match. Learn more about Tandem’s benefits here!</em></p><p><br/></p><p><strong>YOU SHOULD KNOW: </strong></p><p>Potential new employees must successfully complete a drug screen (excludes marijuana) and background check which includes criminal search, education certification and employment verification prior to hire.</p><p><br/></p><p><strong>REFERRALS: </strong></p><p>We love a good referral! If you know someone that would be a great fit for this position, please share!</p><p><br/></p><p><strong>If you are applying for this job and live in California, please read Tandem’s CCPA Notice: </strong>https://www.tandemdiabetes.com/careers/california-consumer-privacy-act-notice-for-job-applicants.</p>
</div>",$140000- $160000,Data Engineer
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment Partners LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785064004,0,https://media.licdn.com/dms/image/C4E0BAQGbIGAVD9Ugtg/company-logo_100_100/0/1630587145865/motion_recruitment_partners_llc_logo?e=2147483647&v=beta&t=alBjyOtSVLguJoyqNF0DXJ9Pwg7PtTJhNsISoDSt9QU,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Motion Recruitment Partners, LLC, is seeking the following. Apply via Dice today!<br/><br/>A market leader in the analytics space, specifically focusing on analytics for the entertainment space is hiring a Senior Data Engineer to join their team of 5. This role will be a lot of new development and migrations as they are moving their SQL based pipelines over to Python, AWS, and Spark so strong SQL experience is a big plus. This company processes tens of billions of rows of data every year and has almost 20TB of processing data. The main tech stack for this role is SQL, Python, AWS, and Spark experience. This team also uses Glue, Power BI, Anthem, EMR, PySpark, and any experience working with marketing metrics/analysis is a plus. You will be building new capabilities for their analytics teams, integrating big data tools and moving to AWS within their pipelines.<br/><br/>This role is looking for someone to work PST hours. If you are local to Southern California that is a big plus but not required as this role is 100% fully remote. This is a small team so they ideally need someone open to wearing a few different hats who can interact with various teams within the organization so good communication is a must.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>5+ years professional Data Engineering Experience </li><li>Background in DBA/SQL Development </li><li>5 years of experience building ETL pipelines with Python, AWS, and Spark/PySpark </li><li>Experience working with large amounts of data <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Bachelors in STEM field </li><li>Excellent written and verbal communication skills </li><li>Any experience with Glue, Power BI, Anthem, or EMR </li><li>Experience working with marketing metrics data <br/><br/></li></ul>The Offer<br/><br/><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Sick Time </li><li>Paid Time Off </li><li>401(k) with match </li><li>Annual Bonus </li><li>Remote PST time <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Data Engineer / Background in SQL / Migrate to AWS
      </div>",No Salary Info Found,Data Engineer
Data Visualization Developer,Vaco,12/20/2023,https://www.linkedin.com/jobs/view/3785619035,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer,National Funding,12/20/2023,https://www.linkedin.com/jobs/view/3785066474,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Engineer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791621839,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Join our growing Engineering team!<br/><br/></strong>This Jobot Job is hosted by Mike Duffy<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $100,000 - $140,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>We are rapidly growing equipment finance company with over 25 years in business!<br/><br/>The Data Engineer will be responsible for building data-driven analytics tools that are used across the entire organization to improve decision making.<br/><br/>The Data Engineer should have 3+ years of experience with Python, ETL, and SQL<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Excellent pay &amp; benefits!</li><li> 100% remote flexibility!</li><li> Room for growth!</li><li> Outstanding company culture!<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.</li><li> Has demonstrated proficiency in designing and developing data marts in Snowflake schema.</li><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL Server, NoSQL, Kafka using AWS or AZURE Big Data technologies.</li><li> Use troubleshooting skills to identify and correct root cause of workflow failures based on error log outputs and environmental conditions.</li><li> Use SQL to examine, filter, and aggregate data in Microsoft SQL Server.</li><li> Experience working with data transformation processing.</li><li> Anticipate, identify, and solve issues concerning data management to improve data quality.</li><li> Experience working with Microsoft BI and Microsoft SQL server.</li><li> Perform POCs on new technology, architecture patterns.</li><li> Must have Experience with at least one Columnar MPP Cloud data warehouse (Snowflake /Azure Synapse / Redshift)</li><li> Design of complex physical data models, projects and cloud-based data lake constructs including SQL/NoSQL database systems. Leads the creation of integrated data views based on business or analytics requirements.</li><li> Design, implement, and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems and business requirements.</li><li> Experience in ETL tools like DBT is nice to have.</li><li> Experience with version control and DevOps platforms such as AZURE DevOps, GitHub, GitLab</li><li> Experience with CI/CD Pipelines and SDLC best practices.</li><li> Experience using Agile methods and project management tools like Jira preferred.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Software Engineering, Information Technology, or a related field.</li><li> Minimum of 3 years of experience in a data engineer or similar role.</li><li> Strong knowledge of Python, ETL, SQL, data integration, and data pipelines.</li><li> Experience with data architecture, data modeling, schema design, and software development.</li><li> Proficiency in data migration, transformation, and scripting.</li><li> Familiarity with machine learning models and their data needs.</li><li> Understanding of distributed systems as it pertains to data storage and computing.</li><li> Strong project management and organizational skills.</li><li> Ability to analyze problems and strategize for better solutions.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$100000- $140000,Database Engineer
Database Administrator,Kyriba,12/25/2023,https://www.linkedin.com/jobs/view/3728897082,0,https://media.licdn.com/dms/image/C560BAQF47pI3TnrqjA/company-logo_100_100/0/1630563216998/kyriba_logo?e=2147483647&v=beta&t=lezVorkZCtuAg8UNnBXwBVJCuW_8HkxfvIg4r0ei9WA,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        It's fun to work in a company where people truly BELIEVE in what they're doing!<br/><br/><em>We're committed to bringing passion and customer focus to the business.<br/><br/></em><strong>About The Role<br/><br/></strong>You will be managing, maintaining, and monitoring PostgreSQL, MongoDB and Oracle database systems, ensuring high availability, scalability, and security. You will perform routine database maintenance tasks, including backups, recovery, patching and leading the efforts on optimizing MongoDB and well as troubleshooting and resolving database-related issues in a timely manner.<br/><br/><strong>Essential Duties And Responsibilities<br/><br/></strong><ul><li>Performance Optimization:</li><ul><li>Collaborate with software developers to optimize SQL queries and database code for maximum efficiency and performance.</li><li>Implement best practices and industry standards to improve database performance.</li></ul><li>Code Review:</li><ul><li>Review and assess database-related code written by developers for adherence to best practices, performance, and security standards.</li><li>Provide feedback and recommendations for code improvements, with a focus on enhancing query performance.</li></ul><li>Database Security:</li><ul><li>Implement and maintain database security measures to protect sensitive data.</li><li>Monitor and audit database access and activities to ensure compliance with security policies.</li></ul><li>Backup and Recovery:</li><ul><li>Design and implement database backup and recovery strategies to ensure data integrity and availability.</li><li>Conduct regular disaster recovery testing.</li></ul><li>Documentation:</li><ul><li>Create and maintain comprehensive documentation related to database configurations, procedures, and best practices.</li></ul><li>Collaboration:</li><ul><li>Work closely with cross-functional teams, including developers, system administrators, and network engineers, to ensure seamless integration and optimal performance of database systems.</li></ul><li>AWS Migration:</li><ul><li>Participate in the planning and execution of the migration of our database systems to Amazon Web Services (AWS).</li><li>Work closely with the cloud engineering team to ensure a smooth transition to AWS while maintaining data integrity and performance.<br/></li></ul></ul><strong>Education, Experience And Skills<br/><br/></strong><ul><li>Bachelor's degree in Computer Science, Information Technology, or a related field (Master's degree preferred).</li><li>Minimum of 3+ years of hands-on experience in Oracle Database Administration.</li><li>Proficiency in PostgreSQL and MongoDB</li><li>Extensive experience in performance tuning and query optimization.</li><li>Solid understanding of database security principles and Linux/Centos</li><li>Excellent problem-solving and troubleshooting skills.</li><li>Windows Experience.<br/><br/></li></ul>Base compensation for this role is: $109,500.00 - $138,700.00 annual salary. In addition to the base pay this position includes a variable compensation. The role might also be potentially eligible to long term Incentive. The final package may vary and will be determined by various factors including candidate profile and ideal qualifications as well as specific cost of living circumstances in some specific locations.<br/><br/>Comprehensive benefits package may be found here: www.kyriba.com/company/careers/benefits/<br/><br/>Kyriba believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship, and genetic information. See EEO is the Law.<br/><br/>If reasonable accommodation is needed to participate in the job application or interview process and/or to perform essential job functions, please send an email to HR_NORAM@kyriba.com
      </div>",$109500.00- $138700.00,Database Engineer
Data Engineer,Braintrust,12/19/2023,https://www.linkedin.com/jobs/view/3789766635,0,https://media.licdn.com/dms/image/C560BAQHbQYFSQsK__A/company-logo_100_100/0/1630511738029/usebraintrust_logo?e=2147483647&v=beta&t=KwbYjG0MdxQVYAijRBYsSuBn-w2onHZNpCmM31LViso,"Austin, Texas Metropolitan Area","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality.<br/><br/><strong>About The Hiring Process<br/><br/></strong>The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match.<br/><br/>Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies.<br/><br/><strong>JOB TYPE:</strong> Direct Hire/ FTE Position (no agencies/C2C - see notes below)<br/><br/><strong>LOCATION:</strong> Work from anywhere - Anytime | No timezone overlap required<br/><br/><strong>SALARY RANGE</strong> $110,000 – $130,000 /yr<br/><br/><strong>ESTIMATED DURATION:</strong> 40/week - long term<br/><br/><strong>EXPERIENCE:</strong> 3-4 years<br/><br/><strong>BRAINTRUST JOB ID:</strong> 11526<br/><br/>The Opportunity<br/><br/><strong>Required Skills<br/><br/></strong><ul><li> T-SQL (DDL, Stored Proces, Views, CTEs, etc) </li><li> VCS (Git, SVN, etc) <br/><br/></li></ul><strong>Bonus Skills<br/><br/></strong><ul><li> Candidates with a CPA/CFA or other financial services background are preferred. </li><li> Candidates who understand web technologies and can program in other languages in addition to SQL will be preferred. JavaScript/ES6/NodeJS preferred. </li><li> VS Code, SSMS, and other IDEs. </li><li> CI/CD experience with integrating database changes into deployment models. <br/><br/></li></ul>What You'll Be Working On<br/><br/><ul><li>This is a FTE position and is only open to US-based candidates**<br/><br/></li></ul>InvestEdge is seeking a database specialist with expert knowledge in relational data modeling, querying, and data analysis.<br/><br/>This role requires expert knowledge of working with MSSQL and Postgres databases, and can write complex queries, stored procedures, and views.<br/><br/><strong>The Candidate<br/><br/></strong><ul><li> has likely worked as a senior data developer or data architect role, and also understands database administration concepts such as indexing strategies, backup and fault-tolerance strategies, and how to organize and secure data at rest. </li><li> have a background in financial services and understand how financial markets work. </li><li> Has a CPA/CFA with the ability to write advanced SQL should be a shoe-in. <br/><br/></li></ul>This role will work with InvestEdge's senior data architect to implement new solutions as well as improve existing ones. Also, the role will be working with large data sets and large database footprints and should understand concepts such as performance tuning, SQL Injection, and data security best practices.<br/><br/>In addition to an emphasis on data manipulation and storage, the candidate will also work on other aspects of the application including UX and middle-tier concerns relating to the presentation, use, and manipulation of data. The ideal candidate is a well-rounded developer that is comfortable in any layer of the application, even as their focus is data and the persistence of that data.<br/><br/><strong>Roles And Responsibilities<br/><br/></strong><ul><li> Work with the senior data architect to implement data routines in a financial services environment. </li><li> Create new queries, views, and stored procedures for a large existing relational data set. </li><li> Debug and troubleshoot logical issues in database code. </li><li> Debug and troubleshoot performance issues in database code. </li><li> Serve as a subject matter expert on a large in-house enterprise database model. </li><li> Understand the business domain of the application. </li><li> Work in an Agile environment on a cross-functional team. <br/><br/></li></ul><strong>Apply Now!<br/><br/></strong><strong>Notes<br/><br/></strong>Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.<br/><br/>Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
      </div>",$110000- $130000,Database Engineer
Sr. Data Engineer,Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3768582691,0,https://media.licdn.com/dms/image/C4D0BAQFPP1NRP4F5dQ/company-logo_100_100/0/1656657978597/tata_consultancy_services_logo?e=2147483647&v=beta&t=Ao4Ihtw2eg1ymYGPB7E4AEHoNQ83oX6bP1DrQIiqR1s,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Key Qualifications<br/><br/></strong><ul><li> Fluency in Advanced SQL (complex joins, stored procedures, subqueries, window functions, performance optimization, etc.), Snowflake, Python.</li><li> Provide analytical reporting and analytics to the operations team and external partners.</li><li> Ability to operate in a fast paced, rapidly changing environment.</li><li> Ability to rapidly learn and adapt to business changes.</li><li> Excellent communication, project management, and presentation skills</li><li> Create and maintain reports, create and manage data models, leverage data across complex hierarchies using multiple data sources.</li><li> Leverage process improvement techniques to drive improvements in data quality.<br/><br/></li></ul>Perform testing to support system implementations and upgrades
      </div>",No Salary Info Found,Database Engineer
Data Engineer,Visa,12/19/2023,https://www.linkedin.com/jobs/view/3790090038,0,https://media.licdn.com/dms/image/C560BAQEP8_eM4zW8bw/company-logo_100_100/0/1630663392691/visa_logo?e=2147483647&v=beta&t=TzxC8Eby4Etg1Y4aK9Ul8pUVAccJ4Do5GJP4uVtlOBY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.<br/><br/>When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.<br/><br/><strong>Join Visa: A Network Working for Everyone.<br/><br/></strong><strong>Job Description<br/><br/></strong>Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area.<br/><br/>Visa AI as a Service (VAIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, VAIaS automates the updates to data, models, and applications. Combined with strong AI governance, VAIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!<br/><br/>This position is for a Data Engineer with solid development experience who will focus on creating new capabilities for Visa AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.<br/><br/>You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.<br/><br/>This position will be based in Austin, TX. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li> Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions</li><li> Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards</li><li> Responsibilities span all phases of solution development including:</li><li> Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved</li><li> Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner<br/><br/></li></ul>This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.<br/><br/><strong>Qualifications<br/><br/></strong>Basic Qualifications:<br/><br/><ul><li> Bachelors degree, OR 3+ years of relevant work experience<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li> 2 or more years of work experience</li><li> Exposure to leading-edge areas such as Machine Learning, Big Data, Distributed Systems or SRE. </li><li> Experience in at least one of the following: Golang, Java, or C/C++, Spark</li><li> Familiarity with web service standards and related patterns (REST, gRPC)</li><li> Experience implementing solutions for low-latency, distributed services using open standard technologies. <br/><br/></li></ul><strong>Additional Information<br/><br/></strong><strong>Work Hours:</strong> Varies upon the needs of the department.<br/><br/><strong>Travel Requirements:</strong> This position requires travel 5-10% of the time.<br/><br/><strong>Mental/Physical Requirements:</strong> This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.<br/><br/>Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.<br/><br/>Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.<br/><br/><strong>U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 89,600.00 to 114,300.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.</strong>
</div>",No Salary Info Found,Database Engineer
"Staff Streaming Data Engineer, Data Science Platform",NVIDIA,12/19/2023,https://www.linkedin.com/jobs/view/3789796216,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Database Administrator III,Texas Health and Human Services,12/20/2023,https://www.linkedin.com/jobs/view/3790832336,0,https://media.licdn.com/dms/image/C4E0BAQH1GwRpPT_nlg/company-logo_100_100-alternative/0/1630609595744/hhsc_logo?e=2147483647&v=beta&t=ydOr4Zqm5J6mwTJGg8-qMTSs9cX0oYiMZDsSSe87Ums,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Under the general supervision of the Branch Manager in the Public Health Applications Division of HHS IT, serves as a Senior Database Administrator performing highly advanced (Senior-level) database administration work. Work involves providing for the efficient and effective storage, retrieval, customization, and archiving of data to ensure integrated database systems. Candidate selected for this position will ensure that data is available to users; data remains consistent across the database; is clearly defined and there is provision for data security and recovery control (ensuring all data is retrievable in an emergency), maintain the integrity, performance and security of the database, initiate, plan, direct and coordinate the implementation of a department electronic integrated surveillance system for reporting diseases, including diseases reported to the Infectious Disease Control Unit. This position provides product and/or process expertise necessary to support design, development, testing and execution of solutions, utilizes business and technical knowledge of server platforms/operating systems to develop and support data, databases or vendor products, implements data monitoring solutions to monitor the database performance and evaluate complex information coming from a variety of sources, develops and implements data validation processes, works under minimal supervision, with extensive latitude for initiative and independent judgement, performs advanced analysis and design duties, maintains an understanding of how technology can enhance and offer a range of solutions for continual improvement of processes in order to increase business value and/or improve efficiencies. Attends work on a regular and predictable schedule in accordance with agency leave policy and performs other duties as assigned. Work outside of regular hours may be required. </p><p><br/></p><p><strong>Essential Job Functions:</strong></p><p>Attends work on a regular and predictable schedule in accordance with agency leave policy and performs other duties as assigned.</p><p><br/></p><p>(40%) Coordinates the installation of database software and migrations to new data management system software levels and ensures that migrations are appropriately tested and validated. Coordinates and provides application and database operations triage support to troubleshoot and resolve functional and performance issues encountered in production, development and test environments. Provides advanced database development and oversees and/or modifies and maintains database structures. Performs logical and physical data modeling, evaluates relational database models, and reviews physical data models created from logical data models.</p><p><br/></p><p>(30%) Plans and develops database, as well as in troubleshooting any issues on behalf of the users. Communicate regularly with technical, applications and operational staff to ensure database integrity and security. Control access permissions and privileges.</p><p><br/></p><p>(10%) Make requested changes, updates and modifications to the database structure and data to ensure security, integrity, stability and system availability. Prepare regular reports to summarize all database operating issues and appropriate resolutions.</p><p><br/></p><p>(10%) Maintain database backup and recovery infrastructure.</p><p><br/></p><p>(5%) Assists in developing strategic plans. Assists in developing agency data processing plans, budgets and justification. May prepare management level reports, such as priority lists, quarterly reports, and operating plan. Advise management of the status and progress of projects and other tasks being conducted.</p><p><br/></p><p>(5%) Other duties as assigned include but are not limited to actively participating and/or serving in a supporting role to meet the agency’s obligations for disaster response and/or recovery or Continuity of Operations (COOP) activation. Such participation may require an alternate shift pattern assignment and/or location. </p><p><br/></p><p><strong>Knowledge Skills Abilities:</strong></p><p>•Knowledge of the principals, practices and techniques of database design and development, database structures and theories and current database technologies.</p><p>•Knowledge of the construction, function, and creation of database systems for epidemiology surveillance purposes.</p><p>•Knowledge of the principles and methods of epidemiology, especially disease risk measures for monitoring public health.</p><p>•Knowledge of ETL, Rhapsody and/or PHINMS</p><p>•Knowledge of SNOMED, LOINC, ICD-9, ICD-10</p><p>•Knowledge of enterprise-wide IT systems design, implementation techniques, and structured management techniques</p><p>•Skill in designing, writing and maintaining database architecture.</p><p>•Skill in proactively monitoring the database environment and making changes to data structures, SQL, application logic or the DBMS subsystem to optimize performance.</p><p>•Skill in using Oracle and Microsoft SQL Server</p><p>•Skill in database administration, management, data imports and exports and developing reports</p><p>•Skill in predicting capacity requirements based on application and data usage patterns and implementing the necessary database changes to accommodate the growth</p><p>•Ability to translate a data model or logical database design into an actual physical database implementation and to manage that database once it has been implemented.</p><p>•Ability to perform database performance tuning</p><p>•Ability to create an efficient physical database design from a logical data model and application specifications</p><p>•Ability to manage database security, integrity and backup procedures</p><p>•Ability to provide technical expertise in the design, implementation and maintenance of database management systems</p><p>•Ability to plan and lead collaboration with IT, CDC and Business SMEs to document the NEDSS Ecosystem routes and message paths</p><p>•Ability to provide excellent customer service and public relations outreach</p><p><br/></p><p><strong>Initial Selection Criteria:</strong></p><p>Bachelors or higher degree from an accredited college or university in Computer applications or related field.</p><p>Experience and education may be substituted for one another.</p>
</div>",No Salary Info Found,Database Engineer
Data Engineer,"VMC Soft Technologies, Inc",12/20/2023,https://www.linkedin.com/jobs/view/3788678633,0,https://media.licdn.com/dms/image/C560BAQFYJzWt3lrZxw/company-logo_100_100/0/1638373652009?e=2147483647&v=beta&t=HcBXf5MuP4MnSHIjz8gEQQP0vWkkqiOw1Tpihg4GwOY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title: Data Engineer</strong></p><p><strong>Location: Austin, TX</strong></p><p><strong>Contract: W2 Only</strong></p><p><br/></p><p><strong>Job Description,</strong></p><p>- Fluency in Advanced SQL (complex joins, stored procedures, subqueries, window functions, performance optimization, etc.), Snowflake, Python.</p><p>- Provide analytical reporting and analytics to the operations team and external partners.</p><p>- Ability to operate in a fast paced, rapidly changing environment.</p><p>- Ability to rapidly learn and adapt to business changes.</p><p>- Excellent communication, project management, and presentation skills</p><p>- Create and maintain reports, create and manage data models, leverage data across complex hierarchies using multiple data sources.</p><p>- Leverage process improvement techniques to drive improvements in data quality.</p><p>Perform testing to support system implementations and upgrades</p><p><br/></p><p><strong>Note: This is a W2 Contract. So, candidates must work on VMC SOFT TECH Payroll. For Immediate response please reach out to me at sai2@galaxyitech.com</strong></p><p><br/></p><p><strong>Thanks</strong></p><p><strong>SAII</strong></p><p><strong>480-992-9904</strong></p><p></p>
</div>",No Salary Info Found,Database Engineer
Senior Data Engineer (GCP Platform) (R-15496),Dun & Bradstreet,12/20/2023,https://www.linkedin.com/jobs/view/3785602179,0,https://media.licdn.com/dms/image/D4E0BAQHlVerw9jUZmg/company-logo_100_100/0/1688672958148/dun__bradstreet_logo?e=2147483647&v=beta&t=_mgRTudaSVLFKA6zm6txCsxAfmA4ocrV9hhizz5z2Ro,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Why We Work at Dun &amp; Bradstreet<br/><br/></strong>Dun &amp; Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!<br/><br/><strong>The Role<br/><br/></strong>Dun &amp; Bradstreet is looking for a Senior Data Engineer - GCP Platform to join our Technology team.<br/><br/>Senior Data Engineer - GCP Platform will be part of a group responsible for designing, implementing, maintaining and supporting Data &amp; Analytics Platform applications.<br/><br/>The Senior Data Engineer - GCP Platform will leverage modern processes and tools in ensuring highest quality data in the Dun &amp; Bradstreet Data Supply Chains.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>Strong organization skills with high attention to detail </li><li>Able to work independently with minimal supervision </li><li>Excellent communication skills – written, verbal, presentation and interpersonal </li><li>Willing to learn new skills and implement new technologies</li><li>A thirst for knowledge, learning, and problem solving </li><li>Develop Data pipelines/Ingestion/Engineering and Analytic Application processes to business specification and technology standards that leverage/extend existing Data &amp; Analytics platforms using a variety of Tech stack including (but not limited to) AWS, Google Cloud Platform, Informatica, Streamsets and Acceldata.</li><li>Collaborate with project teams (solution architects, business, QA and project management) to ensure solutions meet business objectives and fall within timelines and acceptance criteria</li><li>Participate in testing of prototypes &amp; validate test procedures to ensure that they are applicable to the design </li><li>Application support/ bug fixes / QA </li><li>Perform root-cause analysis (RCA) of complex issues ranging from hardware, operating system, application, network, and information security platforms while working closely with various infrastructure teams and business users to quickly arrive at creative, tactical and long-term solutions. <br/><br/></li></ul><strong>Key Requirements<br/><br/></strong><ul><li>Bachelor’s degree in computer science, information systems, or other related field or equivalent work experience.</li><li>5+ years of high-tech industry and/or IT work experience in Big Data project hands on development and solution engineering roles. </li><li>Experience in Data Analytics, SQL, Python, PySpark, Shell Script, DataBricks.</li><li>Experience with Google Cloud Platforms (and capabilities) is required.</li><li>Experience with Informatica, Streamsets and Acceldata a strong plus. </li><li>Experience in Informatica BDM, AXON &amp; Analyst, Power BI.</li><li>Experience with working on projects in multiple technological and business environments simultaneously.</li><li>Understanding of micro-services, web-based applications and REST APIs.<br/><br/></li></ul><strong>Benefits We Offer<br/><br/></strong><ul><li> Generous paid time off in your first year, increasing with tenure.</li><li> Up to 16 weeks 100% paid parental leave after one year of employment.</li><li> Paid sick time to care for yourself or family members.</li><li> Education assistance and extensive training resources.</li><li> Do Good Program: Paid volunteer days &amp; donation matching.</li><li> Competitive 401k &amp; Employee Stock Purchase Plan with company matching.</li><li> Health &amp; wellness benefits, including discounted Gympass membership rates.</li><li> Medical, dental &amp; vision insurance for you, spouse/partner &amp; dependents.</li><li> Learn more about our benefits: http://bit.ly/41Yyc3d .<br/><br/></li></ul>All Dun &amp; Bradstreet job postings can be found at https://www.dnb.com/about-us/careers-and-people/joblistings.html . Official communication from Dun &amp; Bradstreet will come from an email address ending in @dnb.com.<br/><br/>Notice to Applicants: Please be advised that this job posting page is hosted and powered by Lever. Your use of this page is subject to Lever's Privacy Notice and Cookie Policy , which governs the processing of visitor data on this platform.<br/><br/><strong><em>Equal Employment Opportunity (EEO):</em></strong><em> Dun &amp; Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law. View the EEO is the Law poster </em><em> here </em><em> and its supplement </em><em> here. </em><em> View the pay transparency policy </em><em> here </em><em>.</em>
</div>",No Salary Info Found,Database Engineer
Senior Data Engineer,Incedo Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3788682248,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Senior Data Platform Engineer,Salesforce,12/25/2023,https://www.linkedin.com/jobs/view/3762359993,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Cloud Database Administrator,"Stem, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3759608034,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Senior Data Engineer,Zoox,12/19/2023,https://www.linkedin.com/jobs/view/2938046886,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Database Engine Internals - Staff Software Engineer,Databricks,12/19/2023,https://www.linkedin.com/jobs/view/3644437650,0,https://media.licdn.com/dms/image/D560BAQFPIRKiPVETuw/company-logo_100_100/0/1697215766274?e=2147483647&v=beta&t=faRGBPLYB4yh6WgGVy42GjwjqgOsBan4-CyL51NzK5w,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        P-188<br/><br/>Our mission at Databricks is to radically simplify the whole data lifecycle from ingestion to ETL, BI, and all the way up to ML/AI with a unified platform. To achieve this goal, we believe the data warehouse architecture as we know it today will be replaced by a new architectural pattern, Lakehouse (CIDR 2021 paper), open platforms that unify data warehousing and advanced analytics. The new architecture will help address several major challenges, including data staleness, reliability, total cost of ownership, data lock-in, and limited use-case support.<br/><br/>A critical part of realizing this vision is the next generation (decoupled) query engine and structured storage system that can outperform specialized data warehouses in relational query performance, yet retain the expressiveness and of general purpose systems such as Spark to support diverse workloads ranging from ETL to data science.<br/><br/>As Part Of This Team, You Will Be Working In One Or More Of The Following Areas To Design And Implement These Next Gen Systems That Leapfrog State-of-the-art:<br/><br/><ul><li>Query compilation and optimization</li><li>Distributed query execution and scheduling</li><li>Vectorized execution engine</li><li>Data security</li><li>Resource management</li><li>Transaction coordination</li><li>Efficient storage structures (encodings, indexes)</li><li>Automatic physical data optimization<br/><br/></li></ul><strong><strong>What We Look For:<br/><br/></strong></strong><ul><li>A passion for database systems, storage systems, distributed systems, language design, or performance optimization</li><li>Experience working towards a multi-year vision with incremental deliverables</li><li>Motivated by delivering customer value and impact</li><li>8+ years of experience working in a related system (preferred)</li><li>Optional: PhD in databases or distributed systems<br/><br/></li></ul><strong><strong>Benefits<br/><br/></strong></strong><ul><li>Comprehensive health coverage including medical, dental, and vision</li><li>401(k) Plan</li><li>Equity awards</li><li>Flexible time off</li><li>Paid parental leave</li><li>Family Planning</li><li>Gym reimbursement</li><li>Annual personal development fund</li><li>Work headphones reimbursement</li><li>Employee Assistance Program (EAP)</li><li>Business travel accident insurance<br/><br/></li></ul><strong><strong>About Databricks<br/><br/></strong></strong>Databricks is the data and AI company. Thousands of organizations worldwide — including Comcast, Condé Nast, Nationwide and H&amp;M — rely on Databricks' open and unified platform for data engineering, machine learning and analytics. Databricks is venture-backed and headquartered in San Francisco, with offices around the globe. Founded by the original creators of Apache Spark™, Delta Lake and MLflow, Databricks is on a mission to help data teams solve the world's toughest problems. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.<br/><br/><strong>Our Commitment to Diversity and Inclusion<br/><br/></strong>At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.<br/><br/><strong>Pay Range Transparency<br/><br/></strong>Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.<br/><br/>Local Pay Range<br/><br/>$192,000—$260,000 USD<br/><br/><strong><strong>About Databricks<br/><br/></strong></strong>Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.<br/><br/><strong>Our Commitment to Diversity and Inclusion<br/><br/></strong>At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.<br/><br/><strong>Compliance<br/><br/></strong><strong>If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.</strong>
</div>",$192000- $260000,Database Engineer
Data Engineer II,W3Global,12/19/2023,https://www.linkedin.com/jobs/view/3782804245,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Sr. Data Systems Engineer,BioSpace,12/19/2023,https://www.linkedin.com/jobs/view/3789864477,0,https://media.licdn.com/dms/image/C4D0BAQGZiHXPauZl9A/company-logo_100_100/0/1630473326310/biospaceinc_logo?e=2147483647&v=beta&t=tC-U6iX2Ao1xP9PItnGRnOEwuNFzs-wcVjsXXhTR1gA,"San Carlos, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Profile<br/><br/></strong><strong>Vaxcyte, Inc. (Nasdaq: PCVX) </strong>is a vaccine innovation company engineering high-fidelity vaccines to protect humankind from the consequences of bacterial diseases. The Company is developing broad-spectrum conjugate and novel protein vaccines to prevent or treat bacterial infectious diseases. Vaxcyte’s lead candidate, VAX-24, is a 24-valent, broad-spectrum, carrier-sparing pneumococcal conjugate vaccine (PCV) being developed for the prevention of invasive pneumococcal disease (IPD). The Company is re-engineering the way highly complex immunizations are made through modern synthetic techniques, including advanced chemistry and our exclusively licensed XpressCFTM cell-free protein synthesis platform. Unlike conventional cell-based approaches, the Company’s system for producing difficult-to-make proteins and antigens is intended to accelerate its ability to efficiently create and deliver high-fidelity vaccines with enhanced immunological benefits. Vaxcyte’s pipeline also includes VAX-31, a 31-valent PCV candidate; VAX-A1, a prophylactic vaccine candidate designed to prevent Group A Strep infections; VAX-PG, a therapeutic vaccine candidate designed to slow or stop the progression of periodontal disease; and VAX-GI, a vaccine program designed to prevent Shigella. The Company is driven to eradicate or treat invasive bacterial infections, which have serious and costly health consequences when left unchecked. For more information, visit www.vaxcyte.com.<br/><br/>Vaxcyte, headquartered in San Carlos, CA, went public in June 2020 and currently has a team of approximately 180 employees and anticipates continued, significant growth. Following equity offerings in October 2022 and April 2023, which generated over $1.1 billion in net proceeds, the Company’s balance sheet is further strengthened to advance its pipeline of novel vaccines, including VAX-24. These financings followed positive data readouts from Vaxcyte’s Phase 1/2 proof-of-concept study evaluating VAX-24 in adults aged 18-64 and Phase 2 study in adults 65 and older. The Company believes these results support a best-in-class potential for VAX-24, which was designed to replace the current standard-of-care in adults and children. VAX-24 is being investigated for the prevention of IPD, which can be most serious for infants, young children, older adults and those with immune deficiencies or certain chronic health conditions. Given the global impact of pneumococcal disease remains significant, the public health community continues to advocate for vaccines that can offer broader protection to prevent IPD. Vaxcyte’s PCV franchise, consisting of VAX-24 and VAX-31, is designed specifically to address this need and has the potential to deliver the broadest protection for this very serious disease. We believe that our PCVs could receive regulatory approval based on successful completion of clinical studies utilizing well-defined surrogate immune endpoints, consistent with how other PCVs have obtained regulatory approval in the past, rather than requiring clinical field efficacy studies.<br/><br/><strong>Summary<br/><br/></strong>We are seeking an experienced and detail-oriented Data Systems Engineer with knowledge of System administration and DevOps with on premise and cloud-based platforms to join our IT team. In this role you will implement and administer Windows Domain and Active Directory, compute, storage, database, networking and security implementation and management. Strong knowledge in domain controllers, group policies, Active Directory, cloud services, databases, and web app deployment are essential for this position.<br/><br/><strong>Infrastructure Management<br/><br/></strong><ul><li>Provision, configure, and maintain cloud and VMWare resources, including virtual machines, databases, storage, WebApps and networking components.</li><li>Monitor and optimize cloud infrastructure for performance, cost, and security.</li><li>Implement and maintain backup and disaster recovery solutions.</li><li>Ensure cloud resources are compliant with security policies and best practices.<br/><br/><br/></li></ul><strong>System Administration<br/><br/></strong><ul><li>Administer and maintain Windows-based servers and systems.</li><li>Configure and manage domain controllers and Active Directory services.</li><li>Implement and manage group policies to ensure security and compliance.</li><li>Troubleshoot and resolve issues related to Windows infrastructure.</li><li>Implement security updates and patches for Windows environments.<br/><br/><br/></li></ul><strong>Database Administration<br/><br/></strong><ul><li>Possess knowledge in configuring, administering, and optimizing relational databases hosted on cloud.</li><li>Understand the principles of database availability, security, and performance.</li><li>Collaborate with development teams to support database-related tasks.<br/><br/><br/></li></ul><strong>Web Application Deployment In Azure<br/><br/></strong><ul><li>Deploy web applications on cloud.</li><li>Configure and manage web app settings, scaling, and monitoring.</li><li>Ensure high availability and performance of web applications.<br/><br/><br/></li></ul><strong>DevOps Integration (Basic)<br/><br/></strong><ul><li>Collaborate with development teams to support basic CI/CD pipelines on cloud platforms.</li><li>Assist in automation and scripting tasks to streamline administration processes.</li><li>Provide basic support for containerization technologies like Docker and Kubernetes.<br/><br/><br/></li></ul><strong>Documentation And Training<br/><br/></strong><ul><li>Maintain detailed documentation of infrastructure, systems, databases, Python web applications, and administration processes.</li><li>Provide training and support to internal teams regarding system administration, database management, and web app deployment.<br/><br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li>Bachelor's degree in computer science, information technology, or a related field (or equivalent workexperience).</li><li>8 -12 years of experience in Systems Administration.</li><li>Proven experience as a Windows Administrator with knowledge in domain controllers, group policies, Active Directory.</li><li>Strong understanding of Azure services, networking, and security.</li><li>Expertise in Windows Server administration and troubleshooting.</li><li>Experience administering on premise VMWare infrastructure.</li><li>Proficiency in scripting and automation using PowerShell and/or other relevant tools.</li><li>Knowledge in PostgreSQL administration, including database setup, optimization, and maintenance.</li><li>Experience in deploying Python web applications in Azure.</li><li>Familiarity with DevOps practices, including CI/CD concepts and automation.</li><li>Excellent problem-solving and troubleshooting skills.</li><li>Strong communication and collaboration abilities.</li><li>Azure certifications (e.g., Azure Administrator, Azure Solutions Architect) and relevant Python web app deployment experience are highly desired.</li><li>All Vaxcyte employees require vaccination against COVID-19.<br/><br/><br/></li></ul><strong>Reports to:</strong> Senior Director, CMC IT Systems<br/><br/><strong>Location:</strong> San Carlos, CA<br/><br/><strong>Compensation<br/><br/></strong>The compensation package will be competitive and includes comprehensive benefits and an equity component.<br/><br/><strong>Salary Range: </strong>$171,000 – $185,000
      </div>",$1.1- $171000,Database Engineer
"Senior Data Engineer (Relocate to Shanghai, Beijing or Singapore)",Airwallex,12/19/2023,https://www.linkedin.com/jobs/view/3735618575,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Lead Data Engineer,GoodRx,12/19/2023,https://www.linkedin.com/jobs/view/3771703198,0,https://media.licdn.com/dms/image/C4D0BAQEqY0JPdZEDFw/company-logo_100_100/0/1634331204199/goodrx_logo?e=2147483647&v=beta&t=WX-OOnQagHgq1KecoVE5rKXXYURXN9Q_F94JbIJJ2CU,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        GoodRx is America’s healthcare marketplace. Each month, millions of people visit goodrx.com to find reliable health information and discounts for their healthcare — and we’ve helped people save $60 billion since 2011. We provide prescription discounts that are accepted at more than 70,000 pharmacies in the U.S., as well as telehealth services including doctor visits and lab tests. Our services have been positively reviewed by Good Morning America, The New York Times, NBC News, AARP, and many others.<br/><br/>Our goal is to help Americans find convenient and affordable healthcare. We offer solutions for consumers, employers, health plans, and anyone else who shares our desire to provide affordable prescriptions to all Americans.<br/><br/><strong>About The Role<br/><br/></strong>GoodRx is looking for extremely smart and innovative data engineers, who are deft at working with a wide variety of languages, such as Python and SQL, a variety of raw data formats, such as parquet and CSV, in a fast-paced and friendly environment. You will collaborate and work with teams across GoodRx to build an outstanding data platform that supports hundreds of data pipelines which move big data accurately and quickly to guide enterprise data decisions.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Collaborate with product managers, data scientists, data analysts and engineers to define features needed for a data platform</li><li>Provide mentorship and technical leadership for a team</li><li>Work closely with other engineers to scale infrastructure, improve reliability and efficiency</li><li>Improve developer tooling with a focus on reliability and efficiency</li><li>Write good technical documentation</li><li>Perform large system upgrades and migrations</li><li>Maintenance and improvement of multiple CI/CD pipelines</li><li>Act as an in-house data expert who makes recommendations regarding standards for code quality and pipeline architecture</li><li>Develop, deploy and maintain data processing pipelines using cloud technology such as AWS, Kubernetes, Lambda, Kafka, Airflow, Redshift, S3, Glue, and EMR</li><li>Make smart engineering and infra decisions based on data auditing and collaboration</li><li>Lead and architect cloud-based data infrastructure solutions to meet stakeholder needs<br/><br/></li></ul><strong>Skills &amp; Qualifications<br/><br/></strong><ul><li>8+ years of professional experience in any one of the Cloud providers such as AWS, Azure or GCP</li><li>8+ years experience in engineering data pipelines using data technologies (Python, Databricks, pySpark, Kafka) on large scale data sets</li><li>Experience building or maintaining a Data Platform that supports multiple engineering teams and processes big data</li><li>Ability to quickly learn complex domains and new technologies</li><li>Innately curious and organized with the drive to analyze data to identify deliverables, anomalies and gaps and propose solutions to address these findings</li><li>Experience designing data models that have been implemented in production</li><li>Strong experience in writing complex SQL and ETL development with experience processing large data sets</li><li>Familiarity with AWS services (Redshift, RDS, EKS, S3, EMR, Glue, Lambda)</li><li>Experience using GitHub, Docker, Terraform, CodeFresh, Jira</li><li>Experience contributing to full lifecycle deployments with a focus on quality and scalability<br/><br/></li></ul><strong>Good to Have<br/><br/></strong><ul><li>Experience with customer data platform tools such as Segment</li><li>Experience contributing to full lifecycle deployments with a focus on testing and quality</li><li>Experience with data quality processes, data quality checks, validations, data quality metrics definition and measurement</li><li>AWS/Kafka/Databricks or similar certifications<br/><br/></li></ul>At GoodRx, pay ranges are determined based on work locations and may vary based on where the successful candidate is hired. The pay ranges below are shown as a guideline, and the successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, and other relevant business and organizational factors. These pay zones may be modified in the future. Please contact your recruiter for additional information.<br/><br/><strong>San Francisco Office<br/><br/></strong>$180,000.00 - $288,000.00<br/><br/><strong>New York And Seattle Offices<br/><br/></strong>$165,000.00 - $264,000.00<br/><br/><strong>Santa Monica Office<br/><br/></strong>$150,000.00 - $240,000.00<br/><br/>Other Office Locations:<br/><br/>$135,000.00 - $216,000.00<br/><br/>GoodRx also offers additional compensation programs such as annual cash bonuses and annual equity grants for most positions as well as generous benefits. Our great benefits offerings include medical, dental, and vision insurance, 401(k) with a company match, an ESPP, unlimited vacation, ""Take Care of Yourself"" days, 11 paid holidays, and 72 hours of sick leave. GoodRx also offers additional benefits like mental wellness and financial wellness programs, fertility benefits, supplemental life insurance for you and your dependents, company-paid short-term and long-term disability, and more!<br/><br/>We’re committed to growing and empowering a more inclusive community within our company and industry. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has a seat at the table and the tools, resources, and opportunities to excel.<br/><br/>With that said, research shows that women and other underrepresented groups apply only if they meet 100% of the criteria. GoodRx is committed to leveling the playing field, and we encourage women, people of color, those in the LGBTQ+ communities, and Veterans to apply for positions even if they don’t necessarily check every box outlined in the job description. Please still get in touch - we’d love to connect and see if you could be good for the role!<br/><br/>GoodRx is America's healthcare marketplace. The company offers the most comprehensive and accurate resource for affordable prescription medications in the U.S., gathering pricing information from thousands of pharmacies coast to coast, as well as a telehealth marketplace for online doctor visits and lab tests. Since 2011, Americans with and without health insurance have saved $60 billion using GoodRx and million consumers visit goodrx.com each month to find discounts and information related to their healthcare. GoodRx is the #1 most downloaded medical app on the iOS and Android app stores. For more information, visit www.goodrx.com.
      </div>",$60- $180000.00,Database Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789085808,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Oakland, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $160,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$160000- $173000,Database Engineer
Data Platform Engineer (Staff / Sr Staff),Equilibrium Energy,12/20/2023,https://www.linkedin.com/jobs/view/3788476927,0,https://media.licdn.com/dms/image/C560BAQEWt26IIcCkVA/company-logo_100_100/0/1645568367435?e=2147483647&v=beta&t=GwRBD9HbwSlBhqGJclX77yDjEfQ8xGfzWfJUnd0QhxY,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Our Company<br/><br/></strong>Equilibrium Energy is a well-funded, Series A clean energy startup backed by some of the most prominent institutional investors in climate. We are building a digital native power company operating at the intersection of grid variability, market volatility, economic optimization, commercial structuring, and risk management, across the end-to-end power value chain. Our mission is to accelerate our collective path to climate, energy, and societal equilibriums. Our goal is to become one of the next-generation, digital-native, end-to-end global clean power companies that reshapes the energy industry.<br/><br/>New colleagues will share our vision that a next-generation energy company must be built from the ground up on deep industry expertise combined with an unwavering commitment to modern digital approaches. We design our commercial strategies, operational approaches, and product suites so as to best leverage data-driven insights, automated workflows, ML-infused pipelines, and fully automated decision engines. These capabilities are enabled by our progressively modern software stack and engineering best practices, which in turn provide the scalable platform we need to put a serious dent in carbon emissions. We're looking for collaborative, talented, passionate and resourceful folks to join our team and help us lay the foundation for our important mission and ambitious plan.<br/><br/><strong>What We Are Looking For<br/><br/></strong>Equilibrium was founded with a vision for building a company where innovation, collaboration, machine learning, and data science power all aspects of our algorithmic decision-making. We are looking for a <strong><em>Data Platform Engineer (Staff / Sr Staff)</em></strong> who can multitask, demonstrate flexibility, and deal with many different situations at a time like writing specifications and documentation for the server-side features, analyzing the technology currently being used and developing plans and processes for improvement and expansion. Must be able to quickly identify problems or bottlenecks in everyday processes and procedures.<br/><br/>As a key member of our Platform group, you will be responsible for designing, building and maintaining the core infrastructure used by Equilibrium's development teams &amp; empower critical developer workflows.<br/><br/><strong>What You Will Do</strong> <br/><br/><ul><li>Help define, design, develop and deploy EQ's Internal Data Platform</li><li>Apply and advance best practices Data Platform Engineering</li><li>Participate in project planning meetings to share knowledge of system options, risk, impact, and costs vs. benefits. In addition, communicate operational requirements and development forecasts. </li><li>Perform routine maintenance to ensure the production environment runs smoothly. Develop maintenance requirements and procedures. </li><ul><li>Implement advanced monitoring and alerting</li><li>Share on-call responsibilities with the rest of the Platform group, and the Engineering department as a whole</li><li>Participate in and lead blameless post mortems to build a culture of continuous improvement<br/></li></ul></ul><strong>The Minimum Qualifications You'll Need<br/><br/></strong><ul><li>Passion for clean energy and fighting climate change. </li><li>BS/Master's degree in an technical discipline, or equivalent practical experience. </li><li>8+ years of relevant work experience</li><li>Deep working experience with Data-Platform-as-a-Service providers like Snowflake, Databricks</li><li>Deep working experience with operational databases like Postgres, Mysql</li><li>Strong working experience in application software development (preferred language: Python). A commitment to writing readable, reliable and well tested code. </li><li>Strong working experience with AWS cloud technologies (IAM, EKS, RDS, EC2). </li><li>Working experience with infrastructure-as-code (preferred language: Terraform). </li><li>Knowledge and experience working in an agile team and/or a willingness to learn. </li><li>Strong communication skills. <br/><br/></li></ul><strong>Nice To Have Additional Skills<br/><br/></strong><ul><li>PhD in Computer Science or closely related field</li><li>Expert level experience with big data, AWS, infrastructure-as-code, or application software engineering<br/><br/></li></ul><strong>Not sure this is the right role for you?<br/><br/></strong>We are a high growth company with accelerating hiring needs so there's a great chance we'll be able to create a custom role for you, now or in the future. All roles, titles and compensation packages are tailored to the applicant, so apply anyways and tell us in your cover letter about your dream role.<br/><br/><strong>What We Offer<br/><br/></strong>Equilibrium is composed of deeply knowledgeable industry experts across all our functions, with decades of experience in energy-specific commercial structuring, power systems engineering, machine learning, computational research, operations research, distributed and compute-intensive infrastructure, and modern software &amp; ML engineering. Our experience in the space means we've previously built versions of nearly every technical component of our platform. We are now designing them better, and combining them in a holistic and novel way, to achieve global scale and climate impact. We pride ourselves on our deeply empathetic &amp; collaborative culture, honest and direct but respectful communication, and our balanced, flexible, and remote-first work environment.<br/><br/>Employee benefits include:<br/><br/><ul><li>Competitive base salary and a comprehensive medical, dental, vision, and 401k package</li><li>Opportunity to own a significant piece of the company via a meaningful equity grant</li><li>Unlimited vacation and flexible work schedule</li><li>Ability to work remotely from anywhere in the United States &amp; Europe, or join one of our regional hubs in Boston, SF Bay Area, or London</li><li>Accelerated professional growth and development opportunities through direct collaboration and mentorship from leading industry expert colleagues across energy and tech<br/><br/></li></ul><em>Equilibrium Energy is a diverse and inclusive, equal opportunity employer that does not discriminate on the basis of race, gender, nationality, sexual orientation, veteran status, disability, age, or other legally protected status.</em>
</div>",No Salary Info Found,Database Engineer
"Analytics Engineer, Data Insights",MERU,12/25/2023,https://www.linkedin.com/jobs/view/3599305298,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791628110,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
"Staff Data Engineer, Data Products (Contract)",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3759870591,0,https://media.licdn.com/dms/image/C560BAQH0xjWQVXJr6w/company-logo_100_100/0/1630660955481/sofi_logo?e=2147483647&v=beta&t=FVZG0dNVAhdZ-W3Op_NDxjxwWCaIzunudLIIydaqJQI,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Employee Applicant Privacy Notice<br/><br/></strong><strong>Who we are:<br/><br/></strong>Shape a brighter financial future with us.<br/><br/>Together with our members, we’re changing the way people think about and interact with personal finance.<br/><br/>We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. <strong>Join us to invest in yourself, your career, and the financial world.<br/><br/></strong><strong>Team: <br/><br/></strong>SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.<br/><br/><strong>Role:<br/><br/></strong>A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.<br/><br/><strong>What you’ll do:<br/><br/><br/></strong><ul><li>Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.</li><li>Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,</li><li>Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.<br/><br/><br/></li></ul><strong>What you’ll need:<br/><br/><br/></strong><ul><li>A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;</li><li>Over 8 years of experience in data engineering and analytics technical strategy. </li><li>Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..</li><li>Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP</li><li>Strong in Python and/or another data centric language. </li><li>Thorough knowledge of data modeling, database design, data architecture principles, and data operations.</li><li>Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.</li><li>Experience in the Fintech industry is advantageous.<br/><br/><br/></li></ul><em><strong>Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.<br/><br/></strong></em><strong>Compensation And Benefits<br/><br/></strong>The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.<br/><br/>To view all of our comprehensive and competitive benefits, visit our <strong>Benefits at SoFi </strong>page!<br/><br/>SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.<br/><br/>The Company hires the best qualified candidate for the job, without regard to protected characteristics.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.<br/><br/>New York applicants: Notice of Employee Rights<br/><br/>SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.<br/><br/>Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.<br/><br/><strong>Internal Employees<br/><br/></strong>If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.
      </div>",No Salary Info Found,Database Engineer
Cloud Data Engineer,Talener,12/19/2023,https://www.linkedin.com/jobs/view/3748836564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Engineer IT,JetBlue,12/19/2023,https://www.linkedin.com/jobs/view/3732582931,0,https://media.licdn.com/dms/image/D4E0BAQG7WW9ALUsLog/company-logo_100_100/0/1696016819906?e=2147483647&v=beta&t=L7PqtwBmL8gLdGKgw93szjr4QtfAyWOEjlsnQbr6X7I,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Position Summary<br/><br/>The Data Engineer is responsible for integrating and modeling data in JetBlue’s modern data stack to support analysts, business intelligence users, data scientists, and decision-makers across the company. The Data Engineer must have a deep understanding of Structured Query Language (SQL) and be familiar with Snowflake, dbt (data build tool), and git version control. In this role, the Data Engineer collaborates with stakeholders across the company to understand and address their needs. The Data Engineer must enjoy working with others and be comfortable expressing ideas in a public setting. The Data Engineer reports to the Manager of IT Data Engineering.<br/><br/>Essential Responsibilities:<br/><br/><ul><li>Work with business stakeholders to understand problems and data sources, playing the pivotal role of architecting data models to address Crewmember needs</li><li>Gather requirements, build roadmaps, and write great documentation for data sources that need to be modeled</li><li>Build Extract, Load, Transform (ELT) jobs based on jointly defined requirements</li><li>Perform end-to-end unit testing &amp; code reviews to promote data integrity across a variety of products built by the development team</li><li>Support bug fixing and performance analysis along the data pipeline, including writing tests &amp; coordinating with Quality Assurance teams</li><li>Be comfortable presenting to large groups &amp; expressing ideas in public settings with high visibility</li><li>Be a strong advocate for a culture of process and data quality across development teams</li><li>Follow an agile development methodology</li><li>Other duties as assigned<br/><br/><br/></li></ul>Minimum Experience and Qualifications:<br/><br/><ul><li>Bachelor Degree in Mathematics, Operations Research, Statistics, Computer Science, Engineering, or Physics; OR demonstrated capability to perform job responsibilities with a High School Diploma/GED and at least four (4) years of previous relevant work experience</li><li>Three (3) years of relevant experience in a data role working with data warehouses and business intelligence tools</li><li>Proven experience with dbt (data build tool) &amp; Snowflake</li><li>Strong SQL skills</li><li>Experience with modern ELT orchestration tools like Azure Data Factory or Airflow</li><li>Experience with git and git-based workflows</li><li>Available for occasional overnight travel (10%)</li><li>Must pass a pre-employment drug test</li><li>Must be legally eligible to work in the country in which the position is located</li><li>Authorization to work in the US is required. This position is not eligible for visa sponsorship <br/><br/><br/></li></ul>Preferred Experience and Qualifications:<br/><br/><ul><li>Experience implementing best-practices for data modelling, especially with regards to dimensional modelling for business intelligence</li><li>Basic Python skills</li><li>Proven track record of successfully contributing to a project that transitioned a large enterprise to a new cloud data warehouse, like Snowflake</li><li>Prior airline experience<br/><br/><br/></li></ul>Crewmember Expectations:<br/><br/><ul><li>Regular attendance and punctuality </li><li>Potential need to work flexible hours (including nights &amp; weekends) and be available to respond on short-notice</li><li>Able to maintain a professional appearance</li><li>When working or traveling on JetBlue flights, and if time permits, all capable Crewmembers are asked to assist with light cleaning of the aircraft</li><li>Must be an appropriate organizational fit for the JetBlue culture, that is, exhibit the JetBlue values of Safety, Caring, Integrity, Passion and Fun</li><li>Promote JetBlue’s #1 value of safety as a Safety Ambassador, supporting JetBlue’s Safety Management System (SMS) components, Safety Policy and behavioral standards</li><li>Identify safety and/or security concerns, issues, incidents or hazards that should be reported and report them whenever possible and by any means necessary including JetBlue’s confidential reporting systems (Aviation Safety Action Program (ASAP) or Safety Action Report (SAR))<br/><br/><br/></li></ul>Equipment:<br/><br/><ul><li>Computer and other office equipment<br/><br/><br/></li></ul>Work Environment:<br/><br/><ul><li>Traditional office environment<br/><br/><br/></li></ul>Physical Effort:<br/><br/><ul><li>Generally not required, or up to 10 pounds occasionally, 0 pounds frequently. (Sedentary)<br/><br/><br/></li></ul>Compensation:<br/><br/><ul><li>The base pay range for this position is between $100,000.00 and $128,600.00 per year. Base pay is one component of JetBlue’s total compensation package, which may also include access to healthcare benefits, a 401(k) plan and company match, crewmember stock purchase plan, short-term and long-term disability coverage, basic life insurance, free space available travel on JetBlue, and more.<br/><br/><br/></li></ul>
</div>",$100000.00- $128600.00,Database Engineer
Data and Analytics Engineer,Jetty,12/19/2023,https://www.linkedin.com/jobs/view/3788131758,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
"Data Engineer, Technical Lead (Python, LLM's)",McGregor Boyall,12/19/2023,https://www.linkedin.com/jobs/view/3790303994,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Snowflake Data Engineer,Capgemini,12/20/2023,https://www.linkedin.com/jobs/view/3785037830,0,https://media.licdn.com/dms/image/D4D0BAQH7wERIbu2fvQ/company-logo_100_100/0/1702673452642/capgemini_logo?e=2147483647&v=beta&t=NBnhHRGoBlo-42X39edX25CaIyU2ED_clduyxHli004,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Title: Snowflake Data Engineer</strong></p><p><strong>Location: New York, NY</strong></p><p><br/></p><p><strong>Required Skills</strong></p><ul><li>2 years of experience in Snowflake.</li><li>5 years of experience in software development process or maintenance projects.</li><li>At least 4 years of experience in Design and architecture review.</li><li>Hands on in complex SQL python and data modeling.</li><li>Hands on experience creating Snowflake procedures UDFs.</li><li>Relevant experience with Splunk, Azure, Event Grid, Sailpoint and IDM integration.</li><li>Hands on experience in data loading into Snowflake from diverse sources.</li><li>Experience with semi structured data type.</li><li>Experience in building Enterprise DW Data Lake Provision and administer Snowflake corporate cloud infrastructure hosted on public cloud preferably on Azure Provision and manage cloud infrastructure using Terraform Cloud Formation tools.</li><li>Strong communication and Analytical skills.</li><li>Experience working in, and desire to work in, a Global delivery environment.</li><li>Good to have experience in ETL tool.</li></ul><p><br/></p><p><strong>Life at Capgemini</strong></p><p>Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:</p><ul><li>Flexible work</li><li>Healthcare including dental, vision, mental health, and well-being programs</li><li>Financial well-being programs such as 401(k) and Employee Share Ownership Plan</li><li>Paid time off and paid holidays</li><li>Paid parental leave</li><li>Family building benefits like adoption assistance, surrogacy, and cryopreservation</li><li>Social well-being benefits like subsidized back-up child/elder care and tutoring</li><li>Mentoring, coaching and learning programs</li><li>Employee Resource Groups</li><li>Disaster Relief</li></ul><p><br/></p><p><strong>About Capgemini</strong></p><p>Capgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.</p><p>Get The Future You Want | www.capgemini.com</p><p><br/></p><p><strong>Disclaimer</strong></p><p>Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.</p><p>This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.</p><p>Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.</p><p>Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law</p><p><br/></p><p><strong><span class=""ql-cursor""> </span>Salary Transparency</strong></p><p>Capgemini discloses salary range information in compliance with state and local pay transparency obligations. The disclosed range represents the lowest to highest salary we, in good faith, believe we would pay for this role at the time of this posting, although we may ultimately pay more or less than the disclosed range, and the range may be modified in the future. The disclosed range takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to, geographic location, relevant education, qualifications, certifications, experience, skills, seniority, performance, sales or revenue-based metrics, and business or organizational needs. At Capgemini, it is not typical for an individual to be hired at or near the top of the range for their role. The base salary range for the tagged location is $80420 - $106050 /yearly.</p><p>This role may be eligible for other compensation including variable compensation, bonus, or commission. Full time regular employees are eligible for paid time off, medical/dental/vision insurance, 401(k), and any other benefits to eligible employees. </p><p>Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.</p>
</div>",$80420- $106050,Database Engineer
Python Data Engineer,Synechron,12/20/2023,https://www.linkedin.com/jobs/view/3788676786,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Engineer,BeaconFire Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3788691831,0,https://media.licdn.com/dms/image/C560BAQEgZyD0JY8dTA/company-logo_100_100/0/1630645938186?e=2147483647&v=beta&t=_1a4H3IIfyJigHbi_NPBI4P5Hj_Unz3cwiUADDdNxy8,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Qualifications:</strong></p><p>• Passion for data and a deep desire to learn.</p><p>• Bachelor’s Degree in Computer Science/Information Technology, Data Analytics/Data Science, or related</p><p>discipline.</p><p>• Intermediate Python. Experience in data processing is a plus. (Numpy, Pandas, etc)</p><p>• Strong written and verbal communication skills.</p><p>• Ability to work both independently and as part of a team.</p><p><br/></p><p><strong>Responsibilities:</strong></p><p>• Collaborate with analytics team to find reliable data solutions to meet the business needs.</p><p>• Design and implement scalable ETL or ELT processes to support the business demand for data.</p><p>• Perform data extraction, manipulation, and production from database tables.</p><p>• Build utilities, user-defined functions, and frameworks to better enable data flow patterns.</p><p>• Build and incorporate automated unit tests, participate in integration testing efforts.</p><p>• Work with teams to resolve operational &amp; performance issues.</p><p>• Work with architecture/engineering leads and other teams to ensure quality solutions are implemented, and engineering best practices are defined and adhered to.</p><p><br/></p><p>Location: Remote to start</p><p><br/></p><p>Salary: $65,000.00 to $80,000.00 /year</p><p><br/></p><p>BeaconFire is an e-verified company, and we provide H1B visa sponsorship to all qualified internationalcandidates.</p>
</div>",$65000.00- $80000.00,Database Engineer
Data Engineer Graduate (Real Time Communication) - 2024 Start (BS/ MS),ByteDance,12/25/2023,https://www.linkedin.com/jobs/view/3693947782,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
data engineer sr,Starbucks,12/20/2023,https://www.linkedin.com/jobs/view/3760908330,0,https://media.licdn.com/dms/image/C4D0BAQEQxk9y2rk7Hw/company-logo_100_100/0/1631316692276?e=2147483647&v=beta&t=_fQHVDrrgPekvhAMO1vrJ4oE1EjD5wQkh5eg7vgDM6Q,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Summary And Mission<br/><br/></strong>This position contributes to Starbucks success by building enterprise data services for analytic solutions. This position is responsible for design, development, testing and support for data pipelines to enable continuous data processing for data exploration, data preparation and real-time business analytics. Models and acts in accordance with Starbucks guiding principles.<br/><br/><strong>Summary Of Key Responsibilities<br/><br/></strong>Responsibilities and essential job functions include but are not limited to the following:<br/><br/><ul><li> Work with data engineering and data science teams to support and optimize non-interactive (batch, distributed) &amp; real-time, highly available data, data pipeline and technology capabilities</li><li> Translate business requirements into technical requirements to ensure solutions meet business needs</li><li> Work with infrastructure provisioning &amp; configuration tools to develop scripts to automate deployment of physical and virtual environments; to develop tools to monitor usage of virtual resources.</li><li> Define &amp; implement data retention policies and procedures</li><li> Define &amp; implement data governance policies and procedures</li><li> Identify improvements in team coding standards and help in implementation of the improvements.</li><li> Leverage subject matter expertise to coordinate issue resolution efforts across peer support groups, technical support teams, and vendors</li><li> Develop and maintain documentation relating to all assigned systems and projects</li><li> Perform systems and applications performance characterization and trade-off studies through analysis and simulation</li><li> Perform root cause analysis to identify permanent resolutions to software or business process issues<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><ul><li> Education (minimum education level, degree or certification necessary): Bachelor’s degree in computer science, management information systems, or related discipline</li><li> 4+ years of professional industry experience with software development<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong>Skills (minimum skills required):<br/><br/><ul><li>3+ years Hadoop, Hive, Spark</li><li>3+ years Python or Scala</li><li>2+ years SQL Platform </li><li> 2+ years Data platform implementation on Azure or AWS </li><li> 2+ years CI/CD experience </li><li> 2+ years implementing data governance solutions</li><li>1+ Exposure to MPP solutions is a plus </li><li> Ability to apply knowledge of multidisciplinary business principles and practices to achieve successful outcomes in cross-functional projects and activities</li><li> Effective communication skills</li><li> Excel at problem solving</li><li> Strong working knowledge of Python or Scala</li><li> Strong working knowledge of SQL and No-SQL Platforms</li><li> Proficiency in debugging, troubleshooting, performance tuning and relevant tooling</li><li> Strong working knowledge of Hadoop, YARN, MapReduce, Hive, Spark</li><li> Proven ability to productionalize big data implementations</li><li> Experience using one of the public cloud (AWS or Azure preferred) for data applications</li><li> Proficiency in shell scripting</li><li> Solid understanding of data design patterns and best practices</li><li> Proficiency in CI/CD tools</li><li> Proficiency in logging and monitoring tools, patterns &amp; implementations</li><li> Understanding of enterprise security, REST / SOAP services, best practices around enterprise deployments</li><li> Proven ability and desire to mentor others in a team environment</li><li> Working knowledge of data visualization tools such as Tableau is a plus</li><li> Practice agile and DevOps<br/><br/></li></ul>Job Attribute<br/><br/>Job Number: 50025625<br/><br/>Job Group: Professional<br/><br/>Job Family: Technology<br/><br/>Job Subfamily: Business Intelligence<br/><br/>Job Location: United States<br/><br/>FLSA Status: Exempt<br/><br/><em>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.<br/><br/>We are committed to creating a diverse and welcoming workplace that includes partners with diverse backgrounds and experiences. We believe that enables us to better meet our mission and values while serving customers throughout our global communities. People of color, women, LGBTQIA+, veterans and persons with disabilities are encouraged to apply.<br/><br/>Qualified applicants with criminal histories will be considered for employment in a manner consistent with all federal state and local ordinances. Starbucks Corporation is committed to offering reasonable accommodations to job applicants with disabilities. If you need assistance or an accommodation due to a disability, please contact us at applicantaccommodation@starbucks.com.</em>
</div>",No Salary Info Found,Database Engineer
Data Engineer,PitchBook,12/19/2023,https://www.linkedin.com/jobs/view/3721103987,0,https://media.licdn.com/dms/image/C560BAQG-TowEuosYLQ/company-logo_100_100/0/1668555279365/pitchbook_logo?e=2147483647&v=beta&t=gtHuOyxogbs9GKkYwiLJJzQuUT54KiQ0l5nvnypDGPU,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At PitchBook, we are always looking forward. We continue to innovate, evolve, and invest in ourselves to bring out the best in everyone. We’re deeply collaborative and thrive on the excitement, energy, and fun that reverberates throughout the company.<br/><br/>Our extensive learning programs and mentorship opportunities help us create a culture of curiosity that pushes us to always find new solutions and better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there’s going to be some ambiguity along the way, but we excel when we challenge ourselves. We’re willing to take risks, fail fast, and do it all over again in the pursuit of excellence.<br/><br/>If you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you.<br/><br/><strong>About the Role:<br/><br/></strong>As a member of the Product and Engineering team at PitchBook, you will be part of a team of big thinkers, innovators, and problem solvers who strive to deepen the positive impact we have on our customers and our company every day. We value curiosity and the drive to find better ways of doing things. We thrive on customer empathy, which remains our focus when creating excellent customer experiences through product innovation.<br/><br/>We know that greatness is achieved through collaboration and diverse points of view, so we work closely with partners around the globe. As a team, we assume positive intent in each other’s words and actions, value constructive discussions, and foster a respectful working environment built on integrity, growth, and business value. We invest heavily in our people, who are eager to learn and constantly improve. Join our team and grow with us!<br/><br/>To that end, as our scope of data integration and analysis expands so do the needs of the Business Intelligence team. We’re looking for a person with the ability to work with a range of data and reporting technologies (eg. Python, Docker, Tableau, Power BI) in order to build upon a strong foundation of rigor, quantitative techniques, and efficient processing. The Data Engineer will join other Engineers and Analytics professionals as part of the team that develops data pipelines and insights for our internal stakeholders across Sales, Customer Success, Marketing, Research, Product, Finance, and Administration.<br/><br/><strong>Primary Job Responsibilities:<br/><br/></strong><ul><li>You’ll be PitchBook’s expert at building unified data tech to support advanced and automated business analytics </li><li>Design, develop, document, and maintain database and reporting structures used to compile insights </li><li>Define, develop, and review extract, transform, and load processes and data modeling solutions </li><li>Consistently evolve data processes and techniques in accordance with industry best practices </li><li>Establish and help define reports and dashboards used to translate business data into insights, identify and prioritize operational improvement opportunities, and measure business performance against objectives </li><li>Contribute to the ongoing improvement of quality assurance standards and procedures </li><li>Support the vision and values of the company through role modeling and encouraging desired behaviors </li><li>Participate in various company initiatives and projects as requested <br/><br/><br/></li></ul><strong>Skills and Qualifications:<br/><br/></strong><ul><li>Bachelor's degree in Economics, Business, Finance, Engineering, Statistics, Computer Science, or related fields </li><li>2+ years of relevant work experience creating and maintaining data pipelines and architecture </li><li>Understanding of advanced data warehousing concepts, data modeling and extract, transform, and load development </li><li>Advanced SQL skills with experience querying large datasets from multiple sources and developing automated reporting </li><li>Python skills for scripting, data manipulation, custom extract, transform, and loads and statistical/regression analysis particularly, as they apply to sales and marketing operations and performance </li><li>Experience with software programs such as Tableau, Microsoft Power BI, Docker, Linux, and Postgres </li><li>Ability to display complex quantitative data in a simple, intuitive format and to present findings in a clear and concise manner </li><li>Capable of investigating, familiarizing and mastering new data sets quickly </li><li>Excellent interpersonal skills with the ability to communicate complex data issues correctly and clearly to both internal and external customers </li><li>Experience with presenting actionable insights to business stakeholders </li><li>Experience with: Airflow, Luigi, Amazon Web Services, Microsoft Azure, Git, Postgres, Debezium, and Kafka is preferred </li><li>Experience with Snowflake development and cloud data warehousing is preferred </li><li>Proficiency with the Microsoft Office suite including in-depth knowledge of Outlook, Word, and Excel with the ability to pick up new systems and software easily <br/><br/><br/></li></ul><strong>Benefits + Compensation at PitchBook:<br/><br/></strong>Physical Health<br/><br/><ul><li>Comprehensive health benefits</li><li>Additional medical wellness incentives </li><li>STD, LTD, AD&amp;D, and life insurance<br/><br/><br/></li></ul>Emotional Health<br/><br/><ul><li>Paid sabbatical program after four years</li><li>Paid family and paternity leave </li><li>Annual educational stipend</li><li>Ability to apply for tuition reimbursement</li><li>CFA exam stipend </li><li>Robust training programs on industry and soft skills </li><li>Employee assistance program</li><li>Generous allotment of vacation days, sick days, and volunteer days <br/><br/><br/></li></ul>Social Health<br/><br/><ul><li>Matching gifts program</li><li>Employee resource groups</li><li>Subsidized emergency childcare </li><li>Dependent Care FSA</li><li>Company-wide events</li><li>Employee referral bonus program </li><li>Quarterly team building events<br/><br/><br/></li></ul>Financial Health<br/><br/><ul><li>401k match</li><li>Shared ownership employee stock program </li><li>Monthly transportation stipend </li><li>Please be aware the above PitchBook benefit and perk offerings are subject to corresponding plan and policy documents and may change during the course of your employment.<br/><br/><br/></li></ul><strong>Compensation<br/><br/></strong><ul><li>Annual base salary: $111,550-$188,600</li><li>Target annual bonus percentage: 10%</li><li>Starting pay will be based on several factors and commensurate with qualifications &amp; experience. We also have a location-based compensation structure; there may be different ranges for candidates by location.<br/><br/><br/></li></ul><strong>Working Conditions:<br/><br/></strong>The job conditions for this position are in a standard office setting. Employees in this position use PC and phone on an on-going basis throughout the day. Limited corporate travel may be required to remote offices or other business meetings and events.<br/><br/><strong>Life At PB:<br/><br/></strong>We are consistently recognized as a Best Place to Work and our culture is at the heart of our success. It’s our fundamental belief that people do and create great things and that people are the cornerstone of prosperity. We believe that proactively seeking out different points of view, listening to others, learning, and reflecting on what we’ve heard creates a sense of belonging within PitchBook and strengthens the PitchBook community.<br/><br/>We are excited to get to know you and your background. Concerned that you might not meet every requirement? We encourage you to still apply as you might be the right candidate for the role or other roles at PitchBook.<br/><br/>
</div>",$111550- $188600,Database Engineer
"Software Engineer, Data Platform",Lyft,12/19/2023,https://www.linkedin.com/jobs/view/3716407381,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
"Staff Data Engineer, Data Products (Contract)",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3759869668,0,https://media.licdn.com/dms/image/C560BAQH0xjWQVXJr6w/company-logo_100_100/0/1630660955481/sofi_logo?e=2147483647&v=beta&t=FVZG0dNVAhdZ-W3Op_NDxjxwWCaIzunudLIIydaqJQI,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Employee Applicant Privacy Notice<br/><br/></strong><strong>Who we are:<br/><br/></strong>Shape a brighter financial future with us.<br/><br/>Together with our members, we’re changing the way people think about and interact with personal finance.<br/><br/>We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. <strong>Join us to invest in yourself, your career, and the financial world.<br/><br/></strong><strong>Team: <br/><br/></strong>SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.<br/><br/><strong>Role:<br/><br/></strong>A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.<br/><br/><strong>What you’ll do:<br/><br/><br/></strong><ul><li>Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.</li><li>Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,</li><li>Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.<br/><br/><br/></li></ul><strong>What you’ll need:<br/><br/><br/></strong><ul><li>A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;</li><li>Over 8 years of experience in data engineering and analytics technical strategy. </li><li>Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..</li><li>Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP</li><li>Strong in Python and/or another data centric language. </li><li>Thorough knowledge of data modeling, database design, data architecture principles, and data operations.</li><li>Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.</li><li>Experience in the Fintech industry is advantageous.<br/><br/><br/></li></ul><em><strong>Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.<br/><br/></strong></em><strong>Compensation And Benefits<br/><br/></strong>The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.<br/><br/>To view all of our comprehensive and competitive benefits, visit our <strong>Benefits at SoFi </strong>page!<br/><br/>SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.<br/><br/>The Company hires the best qualified candidate for the job, without regard to protected characteristics.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.<br/><br/>New York applicants: Notice of Employee Rights<br/><br/>SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.<br/><br/>Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.<br/><br/><strong>Internal Employees<br/><br/></strong>If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.
      </div>",No Salary Info Found,Database Engineer
Data Engineer,Meta,12/20/2023,https://www.linkedin.com/jobs/view/3703435524,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
"Data Engineer , Amazon Pharmacy",Amazon,12/20/2023,https://www.linkedin.com/jobs/view/3768741058,0,https://media.licdn.com/dms/image/C560BAQHTvZwCx4p2Qg/company-logo_100_100/0/1630640869849/amazon_logo?e=2147483647&v=beta&t=ckUoyDcKb4OtrPrnkiepZRIH4rOREd9cewh-TTrMVJE,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Are you looking for a role that allows you to shape the future of how customers access healthcare and essential medication? At Amazon Pharmacy, we are committed to building the world’s most customer-centric pharmacy experience. We do this by delivering a convenient, shoppable pharmacy experience, allowing customers to compare prices and purchase medications for home delivery, all in one place. Join our team and help create the future of medicine.<br/><br/>As a Data Engineer in Pharmacy team, you will partner with Software Engineers, Business Intelligence Engineers and product managers. In close collaboration with the Senior DE on the team, you will design, implement, and maintain next generation BI solutions for large scale, highly secure and complex data structures to ensure the data is auditable, available and accessible. You will gain a deep understanding of our services and the data they produce, and become our resident expert in how to transform that data into a format that is useful for analytics and business intelligence. You will proactively help to identify new data for integration with our platform, and propose and implement new technologies to help us better understand our data.<br/><br/>Key job responsibilities<br/><br/>Key job responsibilities<br/><br/>Design, implement, maintain and support a secure and robust data lake in native AWS with 300+ datasets which contain both PII and PHI data.<br/><br/>Implement ingestion routines both real time and batch using best practices in modeling, ETL/ELT processes by leveraging AWS technologies and big data tools.<br/><br/>Interface with other technology teams to extract, transform, and load data from a wide variety of data sources using SQL, Python and AWS big data technologies.<br/><br/>Gather business and functional requirements and translate into secure, robust, scalable, operable solutions with a flexible and adaptable architecture.<br/><br/>Collaborate with engineers to help adopt best practices in system creation, integrity, test design, analysis, validation, and documentation.<br/><br/>Help continually improve ongoing reporting and analysis processes, automating or simplifying self-service tools for customers.<br/><br/>Explore and learn the latest AWS technologies to provide new capabilities and increase efficiency.<br/><br/>We are open to hiring candidates to work out of one of the following locations:<br/><br/>Seattle, WA, USA<br/><br/><strong>Basic Qualifications<br/><br/></strong><ul><li> 2+ years of data engineering experience</li><li> Experience with data modeling, warehousing and building ETL pipelines</li><li> Experience with one or more query language (e.g., SQL, PL/SQL, DDL, MDX, HiveQL, SparkSQL, Scala)</li><li> Experience with one or more scripting language (e.g., Python, KornShell)<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li> Experience with big data technologies such as: Hadoop, Hive, Spark, EMR</li><li> Experience with any ETL tool like, Informatica, ODI, SSIS, BODI, Datastage, etc.<br/><br/></li></ul>Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.<br/><br/>Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $81,000/year in our lowest geographic market up to $185,000/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.<br/><br/><br/><strong>Company</strong> - Amazon.com Services LLC<br/><br/>Job ID: A2504745
      </div>",$81000- $185000,Database Engineer
Data Engineer,People Tech Group Inc,12/20/2023,https://www.linkedin.com/jobs/view/3790448486,0,https://media.licdn.com/dms/image/D560BAQEPOko7pmrlpA/company-logo_100_100/0/1697543948515/people_tech_group_inc_logo?e=2147483647&v=beta&t=7L18noPCVRe76XIeGG8rv1y4_2cckJooeZE5gqBdbhw,"Redmond, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Title: Data Engineer</strong></p><p><strong>Duration: Fulltime with People Tech Group</strong></p><p><strong>Location: Redmond, WA</strong></p><p> </p><p><strong>Can implement a Pentaho to Glue migration project.</strong></p><p><strong>Job Description:</strong></p><p>• Responsible for Design and Development of ETL Jobs which follow.</p><p>standards, best practices and are maintainable, modular, and reusable.</p><p>• Proficiency with Pentaho Data Integration.</p><p>• Hands-on Experience with AWS and AWS Glue Mandatory</p><p>• Analyze and review complex object and data models and the metadata repository to structure the processes and data for better management and efficient access.</p><p>• Preparing mapping document to extract, transform, and load data ensuring compatibility</p><p>with all tables and requirement specifications.</p><p>• Experience in ETL system design and development with Pentaho PDI is essential.</p><p>• Tune Pentaho jobs for performance optimization.</p><p>• Write relational(sql) and multidimensional(mdx) database queries.</p><p>• Functional Knowledge of Pentaho data integrator, Job Servers &amp; Load balancing setup,</p><p>and all its administrative functions.</p><p>• Develop, maintain, and enhance unit test suites to verify the accuracy of ETL processes, dimensional data, OLAP cubes and various forms of BI content including reports, dashboards, and analytical models.</p><p>• Comprehensive understanding and working knowledge in Data Warehouse loading,</p><p>tuning, and maintenance.</p><p>• Working knowledge of relational database theory and dimensional database models.</p><p>• Creating and deploying Pentaho custom components is an add-on advantage</p><p></p>
</div>",No Salary Info Found,Database Engineer
Data Engineer II,The Pokémon Company International,12/20/2023,https://www.linkedin.com/jobs/view/3774999827,0,https://media.licdn.com/dms/image/C4E0BAQEH1-l_RgwF3A/company-logo_100_100/0/1646325210472/pokemon_logo?e=2147483647&v=beta&t=Oe28Lc38w305caI5gYviqmBOc7OFu4sMH1IucxnlGmY,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><strong>Get to know The Pokémon Company International <br/><br/></strong></strong>The Pokémon Company International, a subsidiary of The Pokémon Company in Japan, manages the property outside of Asia and is responsible for brand management, licensing, marketing, the Pokémon Trading Card Game, the animated TV series, home entertainment, and the official Pokémon website. Pokémon was launched in Japan in 1996 and today is one of the most popular children's entertainment properties in the world.<br/><br/>Learn more online at Corporate.Pokemon.com and Pokemon.com . And check out Twitter ( twitter.com/Pokemon ), LinkedIn ( linkedin.com/company/Pokémon ), Youtube ( youtube.com/pokemon ), and Instagram ( instagram.com/pokemon ).<br/><br/><strong><strong> Get to know the role <br/><br/></strong></strong><ul><li>Job Title: Data Engineer</li><li>Job Summary: Designs, builds and oversees the deployment and operation of technology architecture, solutions and software to capture, manage, store and utilize structured and unstructured data from internal and external sources.</li><li>FLSA Classification (US Only): Exempt</li><li>People Manager: No<br/><br/></li></ul><strong><strong> What you’ll do <br/><br/></strong></strong><ul><li>Establish and build processes and structures based on business and technical requirements to channel data from multiple inputs, route appropriately and store using a combination of distributed (cloud) structures, local databases, and other applicable storage forms as required.</li><li>Develops technical tools and programming that leverage available technologies (e.g., artificial intelligence, machine learning and big-data techniques) to cleanse, organize and transform data and to maintain, defend and update data structures and integrity on an automated basis.</li><li>Create and establish documentation, design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements.</li><li>Reviews internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.</li><li>Participate in data migration and data onboarding efforts to consolidate data locations and promote consistency, security and accessibility to enable our engineering and business partners to make data-informed decisions. <br/><br/></li></ul><strong><strong> What you’ll bring <br/><br/></strong></strong><ul><li>Three (3) to four (4) years of relevant professional experience or a demonstrated equivalent level of expertise.</li><li>Bachelor's degree in a related field or a demonstrated equivalent level of applicable experience.</li><li>Experience in data architecture.</li><li>Experience in cloud data engineering (S3, RDS, Redshift).</li><li>Demonstrated strength in SQL, data modeling, ETL development, and data warehousing.</li><li>Coding proficiency in at least one modern programming language (Python, Scala, Spark, Java, etc.).</li><li>Communication and leadership experience, with experience initiating and driving projects.</li><li>Experience leading data driven discussions and designing scalable data platforms.</li><li>Knowledge of industry best practices and the ability to evaluate the applicability of new processes and technologies.</li><li>Analytical and mathematical mind, capable of evaluating and solving various complex problems.</li><li> Proficiency with Databricks, Terraform, Data Streaming, DBT, RBAC (Role Based Access Control) a strong plus. </li><li> Prior DBA experience a strong plus. <br/><br/></li></ul><strong><strong> How you’ll be successful <br/><br/></strong></strong><ul><li>Passion for Pokémon: Develops an understanding of the Pokémon brand, the impact it has on our people, culture, business, fans, and communities, and applying that knowledge and passion to everything you do.</li><li>Challenging the Expected: Approaches challenges with curiosity and creativity, embracing the possibility of failure as an opportunity to learn something new, develop innovative ideas, solve complex problems and identify unique opportunities. </li><li>Integrity and Respect: Demonstrates integrity and respect by leading with empathy, listening to others, seeking out different perspectives, and taking personal responsibility for decisions, actions, and results.</li><li>Dedicated to Quality: Takes ownership to maintain and promote high standards, looks for new ways to learn and improve, and embraces a growth mindset to seek and apply feedback from others in an effort to continuously improve. </li><li>Building Relationships: Develops and strengthens relationships, adopting a “team first” mentality and working collaboratively to solve problems and meet shared goals. </li><li>Delighting Customers: Listens and understands the interests and needs of our customers and stakeholders, making them feel heard and important, and embracing these learnings to continue delivering a unique Pokémon experience.<br/><br/></li></ul><strong><strong> What to expect <br/><br/></strong></strong><ul><li>An employee first culture</li><li>Company events that celebrate the spirit of Pokémon</li><li>Competitive cash-based compensation programs</li><li>Base salary range: For this role, new hires generally start between $102,000 - $121,600 . The full range is $102,000 - $154,000. This range is applicable for the labor market where the role is intended to be hired. Final base salary is directly related to each candidates' qualifications and professional experience uniquely.</li><li>100% employer-paid healthcare premiums for you</li><li>Generous paid family leave</li><li>Employer-paid life insurance</li><li>Employer-paid long and short-term income protection insurance</li><li>US Employees: 401k Employer Matching</li><li>UK/IRE Employees: Pension Employer Contributions</li><li>Fitness reimbursement</li><li>Commuter benefit</li><li>LinkedIn learning</li><li>Comprehensive relocation package</li><li>Hybrid work environment<br/><br/></li></ul>The above statements are intended to describe the general nature and level of work being performed by people assigned to this role. They are not to be construed as an exhaustive list of all responsibilities, duties, and skills required. Employees may be required to perform duties outside of their normal responsibilities from time to time, as needed. For roles in the United Kingdom, candidates will need the right to work. In some cases, and for some roles, the Company may be able to arrange a visa. For roles in Ireland, this role requires candidates to have the right to live and work in the Republic of Ireland. However, we welcome applications from all nationalities and may consider supporting an employment permit application, in appropriate and suitable cases.<br/><br/>
</div>",$102000- $121600,Database Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083989,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
SQL Server - DBA Services,Devonshire,12/25/2023,https://www.linkedin.com/jobs/view/3793315252,0,https://media.licdn.com/dms/image/D4E0BAQEK8X_ixQDMJQ/company-logo_100_100/0/1684446073826/devonshire_recruitment_logo?e=2147483647&v=beta&t=BenqlPfCuIciXbIaHwtc_VA5mJNs9MIvfbxht3v5IKY,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>Job Overview:<br/><br/></strong>Devonshire Recruiting &amp; Consulting Partners is actively seeking a skilled SQL Server DBA to join a fast-paced team that is redefining the role of networks to enable greater bandwidth, capacity, efficiency, and ease of deployment. In this position, youll maintain and optimize database environments, ensuring high availability, performance, and reliability. Your work will impact critical aspects of our operations, making you an essential part of our team.<br/><br/><strong>Key Responsibilities:<br/><br/></strong><ul><li>Manage multiple database environments, monitor performance, and implement updates, maintenance, patches, and fixes. </li><li>Maintain high availability in the production environment and oversee database replication to the disaster recovery site. </li><li>Collaborate with developers and QA teams to design and optimize database environments. </li><li>Diagnose and resolve database-related errors and performance issues across various application environments. </li><li>Develop database deployment plans and scripts for application rollouts. </li><li>Design and maintain database reporting infrastructure. </li><li>Execute database administration tasks, including installation, configuration, monitoring, space management, backup and recovery, and disaster recovery procedures. </li><li>Plan and execute database server upgrades and migrations. </li><li>Review and optimize stored procedures and scripts, providing recommendations for schema, indexing, maintenance, and deployment improvements. <br/><br/></li></ul><strong>Qualifications:<br/><br/></strong><ul><li>Bachelors degree in Computer Science, Computer Engineering, or related fields. </li><li>5-8+ years of professional experience in Microsoft SQL Server database administration in an enterprise-level setting. </li><li>Strong understanding of Relational Databases, T-SQL Scripting, database normalization, and related concepts. </li><li>Experience in database design within a Software Development environment. </li><li>Proficiency in Performance Tuning and Optimization, including the use of native monitoring and troubleshooting tools. </li><li>Competence in database backups, restores, and recovery models. </li><li>Familiarity with Windows server environments. </li><li>Knowledge of High Availability (HA), replication, and Disaster Recovery (DR) options for SQL Server. </li><li>Ability to multitask effectively and work independently. </li><li>Strong written and verbal communication skills. </li><li>Proven experience in troubleshooting and resolving database integrity and performance issues. </li><li>Expertise in Performance Tuning and Query Optimization. </li><li>Familiarity with SSIS, SSRS, or SSAS. <br/><br/></li></ul><strong>Your application will stand out if you possess the following:<br/><br/></strong><ul><li>Experience with SAP (Sybase) SQL Anywhere database system management. </li><li>Administrator experience with Team Foundation Server and SharePoint server. </li><li>Proficiency in one of the following Scripting languages: Python, PowerShell, Bash, or Shell Script. </li><li>Familiarity with monitoring and logging services such as Elasticsearch, Wavefront, Uptime, Solarwinds, etc. <br/><br/></li></ul><strong>Please note that applicants must be authorized to work for any employer in the U.S., and we are unable to sponsor or take over sponsorship of an employment Visa at this time.<br/><br/></strong>#ZR<br/><br/><strong>Company Description<br/><br/></strong>Devonshire Recruiting &amp; Consulting Partners is a leading search and consulting firm headquartered in Boston, Massachusetts and with a global footprint in more than 5 countries. As an independent, employee-owned organization, we share a single-minded focus to produce impactful and measurable results for our clients and candidates. Our experienced team of partners offers the depth, breadth and specialized business experience necessary to deliver top talent within demanding time frames.<br/><br/>Devonshire Recruiting &amp; Consulting Partners is a leading search and consulting firm headquartered in Boston, Massachusetts and with a global footprint in more than 5 countries. As an independent, employee-owned organization, we share a single-minded focus to produce impactful and measurable results for our clients and candidates. Our experienced team of partners offers the depth, breadth and specialized business experience necessary to deliver top talent within demanding time frames.
      </div>",No Salary Info Found,Database Engineer
Database Administrator,Kyriba,12/24/2023,https://www.linkedin.com/jobs/view/3728895428,0,https://media.licdn.com/dms/image/C560BAQF47pI3TnrqjA/company-logo_100_100/0/1630563216998/kyriba_logo?e=2147483647&v=beta&t=lezVorkZCtuAg8UNnBXwBVJCuW_8HkxfvIg4r0ei9WA,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        It's fun to work in a company where people truly BELIEVE in what they're doing!<br/><br/><em>We're committed to bringing passion and customer focus to the business.<br/><br/></em><strong>About The Role<br/><br/></strong>You will be managing, maintaining, and monitoring PostgreSQL, MongoDB and Oracle database systems, ensuring high availability, scalability, and security. You will perform routine database maintenance tasks, including backups, recovery, patching and leading the efforts on optimizing MongoDB and well as troubleshooting and resolving database-related issues in a timely manner.<br/><br/><strong>Essential Duties And Responsibilities<br/><br/></strong><ul><li>Performance Optimization:</li><ul><li>Collaborate with software developers to optimize SQL queries and database code for maximum efficiency and performance.</li><li>Implement best practices and industry standards to improve database performance.</li></ul><li>Code Review:</li><ul><li>Review and assess database-related code written by developers for adherence to best practices, performance, and security standards.</li><li>Provide feedback and recommendations for code improvements, with a focus on enhancing query performance.</li></ul><li>Database Security:</li><ul><li>Implement and maintain database security measures to protect sensitive data.</li><li>Monitor and audit database access and activities to ensure compliance with security policies.</li></ul><li>Backup and Recovery:</li><ul><li>Design and implement database backup and recovery strategies to ensure data integrity and availability.</li><li>Conduct regular disaster recovery testing.</li></ul><li>Documentation:</li><ul><li>Create and maintain comprehensive documentation related to database configurations, procedures, and best practices.</li></ul><li>Collaboration:</li><ul><li>Work closely with cross-functional teams, including developers, system administrators, and network engineers, to ensure seamless integration and optimal performance of database systems.</li></ul><li>AWS Migration:</li><ul><li>Participate in the planning and execution of the migration of our database systems to Amazon Web Services (AWS).</li><li>Work closely with the cloud engineering team to ensure a smooth transition to AWS while maintaining data integrity and performance.<br/></li></ul></ul><strong>Education, Experience And Skills<br/><br/></strong><ul><li>Bachelor's degree in Computer Science, Information Technology, or a related field (Master's degree preferred).</li><li>Minimum of 3+ years of hands-on experience in Oracle Database Administration.</li><li>Proficiency in PostgreSQL and MongoDB</li><li>Extensive experience in performance tuning and query optimization.</li><li>Solid understanding of database security principles and Linux/Centos</li><li>Excellent problem-solving and troubleshooting skills.</li><li>Windows Experience.<br/><br/></li></ul>Base compensation for this role is: $109,500.00 - $138,700.00 annual salary. In addition to the base pay this position includes a variable compensation. The role might also be potentially eligible to long term Incentive. The final package may vary and will be determined by various factors including candidate profile and ideal qualifications as well as specific cost of living circumstances in some specific locations.<br/><br/>Comprehensive benefits package may be found here: www.kyriba.com/company/careers/benefits/<br/><br/>Kyriba believes that everyone has the ability to make an impact, and we are proud to be an equal opportunity employer committed to providing employment opportunity regardless of sex, race, creed, color, gender, religion, marital status, domestic partner status, age, national origin or ancestry, physical or mental disability, medical condition, sexual orientation, pregnancy, military or veteran status, citizenship, and genetic information. See EEO is the Law.<br/><br/>If reasonable accommodation is needed to participate in the job application or interview process and/or to perform essential job functions, please send an email to HR_NORAM@kyriba.com
      </div>",$109500.00- $138700.00,Database Engineer
Senior Database Engineer II,Jobs via eFinancialCareers,12/19/2023,https://www.linkedin.com/jobs/view/3788137312,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Engineer,PA Consulting,12/19/2023,https://www.linkedin.com/jobs/view/3752017186,0,https://media.licdn.com/dms/image/D4E0BAQGzMvnsrZOkxA/company-logo_100_100/0/1688328174598/pa_consulting_logo?e=2147483647&v=beta&t=Ec8QVvRnf_DVjk0c5JfZAs23urJGlPyEs7bqBhsMsWM,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>We believe in the power of ingenuity to build a positive human future.<br/><br/>As strategies, technologies and innovation collide, we create opportunity from complexity.<br/><br/>Our diverse teams of experts combine innovative thinking and breakthrough use of technologies to progress further, faster. Our clients adapt and transform, and together we achieve enduring results.<br/><br/>An innovation and transformation consultancy, we are over 4000 specialists in consumer and manufacturing, defence and security, energy and utilities, financial services, government and public services, health and life sciences, and transport. Our people are strategists, innovators, designers, consultants, digital experts, scientists, engineers and technologists. We operate globally from offices across the UK, US, Netherlands and Nordics.<br/><br/>PA. Bringing Ingenuity to Life<br/><br/><strong>Job Description<br/><br/></strong><strong>Your day to day <br/><br/></strong>We’re an innovation and transformation consultancy that believes in the power of ingenuity to build a positive-human future in a technology-driven world. Our diverse teams of experts combine innovative thinking with breakthrough-technologies to progress further, faster.<br/><br/>Are you ready to harness the power of data to drive advancements in healthcare? Are you passionate about designing, building, and maintaining data infrastructure that plays a pivotal role in improving patient outcomes and shaping the future of medicine? If you're seeking a rewarding career at the intersection of healthcare and technology, we invite you to be part of our dynamic team. This is a unique, multi-year, project-based opportunity to build and grow a clinical data registry platform over many years working with a dedicated team of collaborators and customers. As a Data Engineer for our cutting-edge medical data registry, you'll be at the forefront of managing, optimizing, and expanding our data infrastructure, enabling critical insights that can positively impact patient outcomes. If you're excited about leveraging your data engineering skills to make a difference in the world of healthcare, we want to hear from you.<br/><br/><strong>Qualifications<br/><br/></strong>Minimum qualifications:<br/><br/><br/><ul><li>Advanced SQL and Python</li><li>Expertise in the design and construction of Big Data Lakes and Data Warehouses capable of ingesting, standardizing, and serving billions of data rows spanning diverse datasets ranging from tens to hundreds</li><li>Experience building dynamic, metadata driven pipelines and analyses</li><li>Building and managing fully automated data pipelines (ETL, ELT, ELTL) including:</li><ul><li>Designing and building data interfaces to source systems</li><li>Combining and transforming data into the appropriate format for storage</li><li>Developing data sets for analytics purposes</li><li>Developing pipelines that can handle common issues/errors in a robust and automated way</li></ul><li>Cloud experience in Azure, AWS or GCP<br/><br/></li></ul>Preferred qualifications:<br/><br/><br/><ul><li>Spark / PySpark experience highly preferable</li><li>Working in Agile and DevOps environments</li><li>Basic Python, Bash, or PowerShell for automation</li><li>Data modelling – Kimball, Data Vault, Star/Snowflake schema, Query-first etc.</li><li>Data visualisation in Power BI, Tableau, Qlik or similar</li><li>Architecting Data Platforms - designing BI/MI/Analytics solutions using Big Data, Relational or Streaming technologies</li><li>One or more of the following certifications:</li><ul><li>Microsoft Certified: Azure Data Engineer Associate</li><li>AWS Certified Data Analytics - Specialty</li><li>GCP Professional Data Engineers<br/><br/><br/></li></ul></ul><strong>Additional Information<br/><br/></strong>Life At PA encompasses our peoples' experience at PA. It's about how we enrich peoples’ working lives by giving them access to unique people and growth opportunities and purpose led meaningful work.<br/><br/>We believe diversity fuels ingenuity. Diversity of thought brings exciting perspectives; diversity of experience brings a wealth of knowledge, and diversity of skills brings the tools we need. When we bring people together with diverse backgrounds, identities, and minds, embracing that difference through an inclusive culture where our people thrive; we unleash the power of diversity – bringing ingenuity to life. We are dedicated to supporting the physical, emotional, social and financial well-being of our people.<br/><br/>The Salary for this role is between $90,000 - $110,000
      </div>",$90000- $110000,Database Engineer
Senior Database Administrator,HarbourVest Partners,12/19/2023,https://www.linkedin.com/jobs/view/3737508577,0,https://media.licdn.com/dms/image/D4E0BAQFKfA9rt51pBQ/company-logo_100_100/0/1688577904303/harbourvest_partners_logo?e=2147483647&v=beta&t=AZXXTEac2VBTEGu800Oynz5GDX8zOisuZwdQndHLpnY,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description Summary<br/><br/></strong>For over forty years, HarbourVest has been home to a committed team of professionals with an entrepreneurial spirit and a desire to deliver impactful solutions to our clients and investing partners. As our global firm grows, we continue to add individuals who seek a collaborative, open-door culture that values diversity and innovative thinking.<br/><br/>In our collegial environment that’s marked by low turnover and high energy, you’ll be inspired to grow and thrive. Here, you will be encouraged to build on your strengths and acquire new skills and experiences.<br/><br/>We are committed to fostering an environment of inclusion that promotes mutual respect among all employees. Understanding and valuing these differences optimizes the potential of both the individual and the firm.<br/><br/>HarbourVest is an equal opportunity employer.<br/><br/>This position will be a hybrid work arrangement, which translates to 2-3 days minimum per week in the office.<br/><br/>The Senior Database Administrator is responsible for the administration of SQL Servers for a private equity firm with a growing footprint of important systems and data warehousing, both on-premises and in Azure. This includes but is not limited to planning, configuration, administration with an emphasis on security, backup and recovery, deployment, and documentation. Must possess vital skills to triage performance issues found in ETL and large-scale reporting workloads in a data warehouse, recommend solutions to these problems, and partner with engineering teams to deliver performance improving changes. The administrator must be able to act as a leader with vision around SQL Server able provide knowledge and mentorship around new features and capabilities of SQL Server and its closely related Platform as a Service offerings including Azure SQL Database and Managed Instance.<br/><br/>The Senior Database Administrator is encouraged to work autonomously with a firm grasp of the role. This person will mentor and lead a small team of DBAs with varying skills and experience.<br/><br/>The ideal candidate is someone who has:<br/><br/><ul><li>Considerable experience with architecting SQL Server on VMWare, including knowledge of standard processes and common pitfalls for performance</li><li>Knowledge of high availability architecture including AlwaysOn Availability Groups, Windows Server Failover Cluster</li><li>Solid understanding of backup and recovery techniques in SQL Server, ability to gather meaningful RPO (Recovery Point Objective) and RTO (Recover Time Objective) requirements from non-database professionals, and ability to implement backup/recovery solutions based on said requirements</li><li>Ability to perform in-depth performance tuning and analysis of SQL Server on VMware and in PaaS offerings such as Managed Instance and Azure SQL Database. This requires a solid understanding of SQL Server internals including query plans and their operators, query optimizer behavior, and techniques for encouraging optimal query plan generation</li><li>Ability to use third party tools such as Solarwinds Orion and SentryOne to identify bottlenecks in performance and recommend solutions. Additionally, DBA must understand SQL Server wait types, how to gather and understand meaningful wait types (from noise) and potential solutions to alleviate these issues to promote scalability and performance</li><li>Solid understanding of optimization through indexing, including clustered, non-clustered and column-store indexes</li><li>Knowledge of data warehousing schema concepts such as star and snowflake, changing dimensions and loading fact tables, characteristics of OLTP vs OLAP style workloads</li><li>Solid experience with Visual Studio and SSDT to use database projects to manage database code, Azure DevOps including repos and pipelines for deploying change</li><li>Experience with SQL encryption technologies including SQL Server’s TDE (Transparent Data Encryption). </li><li>Able to automate administration of databases using PowerShell</li><li>Prior experience with compliance, audit and organizational change controls as relates to SOC1<br/><br/></li></ul>What you will do:<br/><br/><ul><li>Design, configure, implement, and administer all databases for the respective parties involved</li><li>Develop, implement, and supervise standards and procedures to ensure optimum performance, scalability and reliability</li><li>Advise on storage and raid configurations, VMWare setup, optimization, performance tuning and Microsoft standard processes, as it relates to database performance</li><li>Identify and resolve all issues related to database systems to ensure that systems are online and without service interruption</li><li>Maintain and improve the database disaster recovery and backup plan</li><li>Develop new and improve existing standards, processes and procedures, and guidelines for database environments</li><li>Provide consistent SQL Server installations for Dev/QA/UAT/Prod including related components and version upgrades</li><li>Monitor production, development and QA hardware utilization and make recommendations as needed to ensure systems are working optimally</li><li>Adhere to company security policies and standards to provide database access to groups of users and administrators</li><li>Automate maintenance tasks to gain operational efficiencies</li><li>Be part of on-call rotation, including nights and weekends as needed</li><li>Mentor other members of the team<br/><br/></li></ul>What you bring:<br/><br/><ul><li>Strong initiative and willingness to lead the general operating model for the DBA function</li><li>Superb communication skills both written and verbal</li><li>A positive approach to problem-solving and troubleshooting<br/><br/></li></ul><strong>Education Preferred<br/><br/></strong><ul><li>Bachelor of Science (B.S) or equivalent experience<br/><br/></li></ul><strong>Experience<br/><br/></strong><ul><li>5-8 Years of DBA experience preferred<br/><br/></li></ul>
</div>",No Salary Info Found,Database Engineer
Lead Data Engineer,Plymouth Rock Assurance,12/19/2023,https://www.linkedin.com/jobs/view/3755173097,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Principal Data Engineer,ENGIE Impact,12/19/2023,https://www.linkedin.com/jobs/view/3710265264,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Lead Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788695813,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Senior Lead Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788696428,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Job Title: Senior Lead Data Engineer Location: McLean, Virginia, United States About Us: At Capital One, we believe in creating a diverse and inclusive environment where everyone's talents are valued. We are a group of passionate individuals who love working with technology and solving complex business problems. We are looking for Data Engineers who are excited about using data to drive innovation and are eager to work with emerging technologies. As a Senior Lead Data Engineer at Capital One, you will be at the forefront of driving transformation within our organization. Your Role: - Collaborate with agile teams to design, develop, test, implement, and support technical solutions using full-stack development tools and technologies. - Lead a team of developers experienced in machine learning, distributed microservices, and full stack systems. - Utilize programming languages like Java, Scala, Python, and open-source databases to build data solutions. - Stay up-to-date with tech trends, experiment with new technologies, and mentor other members of the engineering community. - Collaborate with product managers to deliver cloud-based solutions that empower millions of Americans to achieve financial well-being. - Conduct unit tests and reviews to ensure code quality and performance. Basic Qualifications: - Bachelor's degree. - At least 8 years of experience in application development. - At least 2 years of experience in big data technologies. - At least 1 year of experience with cloud computing (AWS, Microsoft Azure, Google Cloud). Preferred Qualifications: - Master's degree. - 9+ years of experience in application development using Python, SQL, Scala, or Java. - 4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud). - 5+ years of experience with distributed data and computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL). - 4+ years of experience working on real-time data and streaming applications. - 4+ years of experience with NoSQL databases (Mongo, Cassandra). - 4+ years of experience with data warehousing (Redshift or Snowflake). - 4+ years of experience with UNIX or Linux, including basic commands and shell scripting. - 2+ years of experience with Agile engineering practices. Benefits: Capital One offers a comprehensive and competitive set of benefits that support your total well-being. Eligibility varies based on employment status and level. Note to Applicants: We are an equal opportunity employer committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to sex, race, age, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited by law. We promote a drug-free workplace and comply with regulations regarding criminal background inquiries. If you require an accommodation to apply for a position, please contact Capital One Recruiting. All information provided will be kept confidential and used only to provide necessary accommodations. For technical support or questions about our recruiting process, please email Careers@capitalone.com. Please note that Capital One Financial is made up of several entities. Position postings vary depending on the location. Thank you for considering Capital One as your potential employer. We look forward to hearing from you soon! Note: This version of the job ad has been rewritten in simpler and more inclusive language to accommodate individuals from all walks of life, including the elderly, refugees, people with disabilities (both visible and invisible), LGBTQIA+ individuals, veterans, and anyone else.
      </div>",No Salary Info Found,Database Engineer
Database Engineer,RA Capital Management,12/20/2023,https://www.linkedin.com/jobs/view/3789089623,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
"Data Engineer, Data Platform",Grammarly,12/25/2023,https://www.linkedin.com/jobs/view/3656898066,0,https://media.licdn.com/dms/image/C560BAQFroT18wpIblQ/company-logo_100_100/0/1669669290715/grammarly_logo?e=2147483647&v=beta&t=ztA7DBsCxjynNbw6oGlEHqtgqJneLWUJ1rfYbYVi91A,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>Grammarly is excited to offer a </em><em>remote-first hybrid working model</em><em>. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.<br/><br/></em><em>All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków. </em><em>This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.<br/><br/></em><em>Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.<br/><br/></em><strong>The opportunity <br/><br/></strong>Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.<br/><br/>To achieve our ambitious goals, we’re looking for a Data Engineer to join our Data Engineering Platform team. This person will build highly automated, low latency core datasets that will help data engineers and end users across Grammarly to work with analytical data at scale.<br/><br/>Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.<br/><br/><strong>Your impact<br/><br/></strong>As a Data Engineer on our Data Engineering Platform team, you will:<br/><br/><ul><li>Drive improvements to make our analytics effortless by creating and adjusting core data models and storage structures, all while understanding the needs of our users. </li><li>Make analytical data and metrics usable within a few minutes of real world events occuring, and build streaming processes for the output derived events and aggregate data.</li><li>Model structure, storage, and access of data at very high volumes for our data lakehouse.</li><li>Improve developer productivity and self-serve solutions by contributing components to our stream data processing framework(s).</li><li>Own data engineering's infrastructure-as-code for provisioning services that allow our engineers to deploy mature software installations within a few hours.</li><li>Build a world-class process that will allow our systems to scale.</li><li>Mentor other back-end engineers on the team and help them grow.</li><li>Build and contribute to AWS high-scale distributed systems on the back-end.<br/><br/></li></ul><strong>We’re Looking For Someone Who<br/><br/></strong><ul><li>Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.</li><li>Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.</li><li>Is able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub where the team is based.</li><li>Has experience with Python, Scala, or Java.</li><li>Has experience with designing database objects and writing relational queries</li><li>Has experience designing and standing up APIs and services.</li><li>Has experience with system design and building internal tools.</li><li>Has experience handling applications that work with data from data lakes.</li><li>Has at least some experience building internal Admin sites.</li><li>Has good knowledge of and at least some experience with AWS (or, alternatively, has deep expertise in Azure or GCE and is willing to learn AWS in a short time frame).</li><li>Can knowledgeably choose an open source or third-party service to accomplish what they need or, alternatively, can devise a quick and simple solution on their own.<br/><br/></li></ul><strong>Support for you, professionally and personally<br/><br/></strong><ul><li>Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.</li><li>A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs. <br/><br/></li></ul><strong>Compensation And Benefits<br/><br/></strong>Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:<br/><br/><ul><li>Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)</li><li>Disability and life insurance options</li><li>401(k) and RRSP matching </li><li>Paid parental leave</li><li>Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days </li><li>Home office stipends</li><li>Caregiver and pet care stipends</li><li>Wellness stipends</li><li>Admission discounts</li><li>Learning and development opportunities<br/><br/></li></ul>Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.<br/><br/>Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.<br/><br/><strong>United States<br/><br/></strong>Zone 1: $167,000 - $242,000/year (USD)<br/><br/>Zone 2: $150,000 – $218,000/year (USD)<br/><br/>Zone 3: $142,000 – $206,000/year (USD)<br/><br/>Zone 4: $134,000 – $194,000/year (USD)<br/><br/><strong>We encourage you to apply<br/><br/></strong>At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).<br/><br/><em>Please note that EEOC is optional and specific to US-based candidates.<br/><br/></em>#NA<br/><br/><em>All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.<br/><br/></em>
</div>",$167000- $242000,Database Engineer
Data Solutions Engineer,Analytica,12/20/2023,https://www.linkedin.com/jobs/view/3785044139,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Warehouse Engineer,Professional Diversity Network,12/19/2023,https://www.linkedin.com/jobs/view/3790079003,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Database Engineer,"Acuity, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3757720675,0,https://media.licdn.com/dms/image/C4E0BAQEerlYKBPC8gw/company-logo_100_100/0/1631538609008/acuity_inc_logo?e=2147483647&v=beta&t=TFDQCvCE3FQ73ccuNiQG1P1YgEmEeqe4v72IX3c93c0,"Herndon, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>This position will use your advanced technical database knowledge and capabilities to build an advanced database-driven workflow application for a customer. You will work as part of an engineering team that will re-design and rebuild an application that serves as the mission enabler for the customer’s environment.<br/><br/>Seeking individuals who have or are driven towards achieving certifications/competencies in the software development or database development tracks. You will be a true technologist at heart, subscribing to multiple feeds and resources to remain aware of evolving trends. Candidates MUST reside in DC/MD/VA and available to work onsite in Herndon, VA.<br/><br/><strong>Responsibilities<br/><br/></strong>You will be a part of an Agile team modernizing a series of legacy customer applications, some of which are data intensive. In concert with a data architect, you will implement the new database solutions across multiple infrastructures including AWS, GCP, and Microsoft Azure.<br/><br/><strong>Duties Include<br/><br/></strong><ul><li> Designing and developing databases </li><li> Writing database queries to extract and manipulate data </li><li> Ensuring database performance, security, and integrity requirements are met </li><li> Troubleshooting database issues and optimizing for efficiency </li><li> Writing technical documentation <br/><br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> At least 5 years working with database solutions, preferably both SQL and NoSQL based. </li><li> Experience with schema management automation tools such as Liquibase, Flyway, etc. </li><li> Experience with cloud-native data services such as AWS Aurora RDS, PostgreSQL, MySQL, DynamoDB, OpenSearch, Glue, Athena, QuickSight, etc. </li><li> Experience managing data sets to include duties such as data cleansing, data transformation, data loading, and data streaming. </li><li> Experience implementing and maintaining common data architectures such as Data Lakes, Data Warehouses, Lake Houses, and Data Mesh. </li><li> Solid understanding of Zero Trust architectures and security best practices. </li><li> Experience in a DevSecOps culture + CI/CD best practices. </li><li> Heavy experience and comfort level with Infrastructure as Code (e.g. Terraform, AWS CloudFormation, AWS CDK). </li><li> Heavy experience and comfort level with Pipeline Automation Tools such as Jenkins, AWS CodePipeline, GitHub Actions, Tekton Pipelines, etc. </li><li> Demonstrated experience working with production database solutions. </li><li> Demonstrated experience with database management tools for monitoring and performance. </li><li> Extensive experience scripting – leveraging repurpose-able scripts. </li><li> Have significant experience working in a Team Management/DevSecOps tool on par with Jira/Confluence, Visual Studio Team, or similar. </li><li> Solid understanding of cloud solutions, and an immense appetite for learning and capacity to digest new capabilities and apply them to your solutions. </li><li> Must have experience working on a team, understanding that the chemistry of the team is crucial to the delivery of any solution. <br/><br/><br/></li></ul><strong>Clearance Requirement<br/><br/></strong><ul><li> Must posses an active DOD Secret clearance and/or Public Trust. <br/><br/><br/></li></ul><strong>About Acuity Inc<br/><br/></strong>Acuity is a leading management and technology consulting firm that specializes in serving the federal government. Our innovative, collaborative, and rewarding work environment has earned repeat honors from the Washington Business Journal’s “Best Places to Work”, Washington Post’s “Top Workplace”, and SmartCEO Corporate Culture awards.<br/><br/>We are an equal employment opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, national origin, disability status, protected veteran status or any other characteristic protected by law.<br/><br/>© Acuity INC; 11710 Plaza America Drive; Suite 700; Reston, VA 20190; USA
      </div>",No Salary Info Found,Database Engineer
Senior SQL Server/SSIS Developer - CDC Contract - hybrid - Federal exp a plus,ASD | SKY,12/19/2023,https://www.linkedin.com/jobs/view/3784428724,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Senior Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3789240736,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Senior Data Engineer Opportunity at Capital One Are you passionate about technology and enjoy solving complex business problems in a collaborative and inclusive environment? Capital One is looking for Data Engineers who love marrying data with emerging technologies. As a Data Engineer at Capital One, you will be at the forefront of driving a major transformation within the company. What You'll Do: - Collaborate with Agile teams to design, develop, test, implement, and support technical solutions using full-stack development tools and technologies - Work with experienced developers in machine learning, distributed microservices, and full stack systems - Utilize programming languages like Python, SQL, Scala, and Open Source RDBMS and NoSQL databases, as well as Cloud-based data warehousing services - Stay up-to-date with tech trends, experiment with new technologies, participate in tech communities, and mentor other members of the engineering community - Collaborate with digital product managers to deliver cloud-based solutions that empower millions of Americans financially - Perform unit tests and code reviews to ensure high-quality and high-performance code Basic Qualifications: - Bachelor's Degree - At least 4 years of application development experience (Internship experience does not apply) - At least 1 year of experience in big data technologies Preferred Qualifications: - 5+ years of application development experience with Python, SQL, or Scala - 2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) - 3+ years experience with distributed data/computing tools - 2+ years of experience working on real-time data and streaming applications - 2+ years of experience with NoSQL implementation - 2+ years of data warehousing experience - 3+ years of experience with UNIX/Linux including basic commands and shell scripting - 2+ years of experience with Agile engineering practices At Capital One, we offer comprehensive and competitive benefits that support your total well-being. Learn more about our benefits on the Capital One Careers website. Eligibility varies based on employment status. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We do not discriminate on the basis of sex, race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other prohibited basis under applicable law. We promote a drug-free workplace and comply with laws regarding criminal background inquiries. If you require accommodations during the application process, please contact Capital One Recruiting. All provided information will be kept confidential and used only for necessary accommodations. For technical support or questions about our recruiting process, please contact Careers@capitalone.com. Note: Capital One Financial consists of different entities. Positions vary based on location. _Don't contact me, I'm just an AI language model.
      </div>",No Salary Info Found,Database Engineer
Database Developer,Raytheon,12/20/2023,https://www.linkedin.com/jobs/view/3758981650,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083990,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $140,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$140000- $173000,Database Engineer
Database Engineer (Oracle),Leidos,12/20/2023,https://www.linkedin.com/jobs/view/3790471005,0,https://media.licdn.com/dms/image/D4E0BAQErlxWb6HoHUg/company-logo_100_100/0/1689671151495/leidos_logo?e=2147483647&v=beta&t=9BAJQm1zuhkzTDtsTP7UFfPy5CK-_sWfyHq9T-Ow6Mw,"Annapolis Junction, MD","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>The <strong>Database Engineer/Admin with Streams Experience</strong> will join a high performing agile team using the Scaled Agile Framework (SAFe) methodology to support a nationally significant program. The program is using Behavior Driven Development (BDD) and test automation tools alongside a full suite of team collaboration tools. Program execution follows DEVOPS best practices and employs robust development, test, and production environments. The program provides system engineering, development, test, integration, and operational support to a large, fast-paced program, and is developing infusing new technology and adding advanced capabilities while continuing to support an on-going mission and operational system.<br/><br/><strong>Job Summary<br/><br/></strong>A Database Engineer is needed to provide support to maintain and add new capabilities a complex system with exacting interface, performance, and security requirements. The selected candidate will provide database engineering expertise in the following areas: architecture, design, development, requirements analysis, data flow, network design/implementation, testing, and documentation for the system. She/he will analyze user requirements, system architecture, and system requirements specifications, and will provide database engineering expertise and develop system architecture and system design documentation. She/he will support the development of system configuration documentation, including designs for capacity and performance planning, and will perform engineering activities, to include risk assessments and analyses of alternatives for a variety of system related issues and concerns. The selected candidate will provide solutions to challenging technical problems in distributed data replication, concurrent data access, and high availability.<br/><br/><strong>Primary Responsibilities<br/><br/></strong>The selected candidate will provide guidance and support for database engineering of large-scale systems, major system elements, and interfacing systems that are part of a large complex network environment with geographically distributed components. She/he will interface with technical managers, system and software integration engineers, test engineers, information assurance engineers, and other project team members in an Agile environment. The selected candidate will be responsible for implementing database engineering practices to ensure the proper degree of engineering rigor is applied to all assigned tasks. She/he will be responsible for communicating with and effectively collaborating with internal technical professionals on a day-to-day basis, and with POCs from customer organizations when necessary. The selected individual will actively participate in Program Increment Planning and related Agile team activities. Assigned duties may include:<br/><br/><ul><li>Supporting database design, development, implementation, information storage and retrieval, data flow, and analysis activities.</li><li>Supporting the analysis and evaluation of system improvements, optimization, development, and/or maintenance efforts.</li><li>Supporting the development of long term and short-term requirements for database administration and design.</li><li>Assisting in developing databases, database parser software, and database loading software.</li><li>Translating requirements and data into usable database schemas by creating or recreating ad hoc queries, scripts and macros, making updates to existing queries, and creating new queries to manipulate data into a master file.</li><li>Assisting in the development of database structures that fit into the overall architecture of the system under development.</li><li>Developing requirement recommendations from a project’s inception to its conclusion for a particular Business and IT subject matter area (i.e., simple to complex systems).</li><li>Developing database structures that fit into the overall architecture of the system under development.<br/><br/></li></ul><strong>Security Clearance Requirement<br/><br/></strong><ul><li>Must possess an active TS/SCI with Polygraph security clearance to be considered for this role.<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><ul><li>Bachelor's Degree in a technical discipline and a minimum of eight (8) years of related experience, or a master’s degree and six (6) to ten (10) years of relevant experience. Additional experience may be substituted for a Degree.</li><li>Must have experience as a Database Administrator to include tasks such as data migration, data replication, user administration, backup and recovery, performance tuning, issue investigation, issue resolution, and general administration.</li><li>Must have a good understanding of databases, primarily Oracle and/or other relational and non-relational/NoSQL databases such as PostgreSQL and MongoDB.</li><li>Must have experience using Oracle SQL/PLSQL, and SQL in general.</li><li>Must have experience scripting with JavaScript, Bash/Linux shell scripting (in general), Perl, and/or Python.</li><li>Must have knowledge of programming languages to include Java.</li><li>Must be committed to adopting and adhering to best practices. </li><li>Must be able to effectively plan and prioritize tasking.</li><li>Must be capable of performing high quality work both independently, and with a team, in a fast-moving environment.<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Experience with the Scaled Agile Framework (SAFe) methodology and/or as a member of an Agile team.</li><li>Experience with Cassandra.</li><li>Experience with MongoDB.</li><li>Experience with Scaled Agile Framework agile methodology.<br/><br/></li></ul>careers.leidos.com<br/><br/>CSSKEY<br/><br/>CONMD<br/><br/><strong>Pay Range<br/><br/></strong>Pay Range $101,400.00 - $183,300.00<br/><br/>The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.<br/><br/><strong>Original Posting Date<br/><br/></strong>12/19/2023<br/><br/>While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.
      </div>",$101400.00- $183300.00,Database Engineer
Data Engineer,Definitive Logic a ManTech Company,12/20/2023,https://www.linkedin.com/jobs/view/3785058078,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
"Analytics Engineer, Data Insights",MERU,12/25/2023,https://www.linkedin.com/jobs/view/3599301708,0,https://media.licdn.com/dms/image/C4E0BAQEVuf3UK2EhgQ/company-logo_100_100/0/1631333559352?e=2147483647&v=beta&t=KDydjKATbpF7A3q6-c3kxeDG9KTxggW0DkHeCIqNdcw,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><u>Meet the Company:</u></strong></p><p>We are MERU. A values-driven, impact-oriented team dedicated to fixing companies. We provide advisory services and data analytics support to middle-market companies ($50M - $2B in annual sales), and our clients include private equity firms, credit funds, investment banks, and law firms. We bring deep turnaround experience, a group of veteran operators, and an incentive-aligned approach to any situation. MERU was founded by professionals from Alvarez &amp; Marsal and McKinsey and has seen rapid growth in the five-plus years since its founding.</p><p><br/></p><p><strong><u>The MERU Way &amp; Valuing Our Team:</u></strong></p><p>We're Partners, not consultants. When you join MERU, you will help our clients solve their most pressing problems, supported by a team of people who will challenge you, support you, and inspire you.</p><p><br/></p><p>In order to be Partners, we don't silo people into just one functional area of the business, instead advancing our team's capabilities by providing training for every service that MERU offers. Additionally, we don't just focus on technical skills but also leadership style and soft skills, so MERU team members not only know what it means to manage a client engagement but to lead a team to success. In training team members to be well-rounded individuals, we can deliver an overall higher impact to clients, allowing each individual the ability to gain experience in diligence, turnarounds, interim management, data science, and more.</p><p><br/></p><p>To aid this career advancement and development, MERU provides an internal Coach to each team member in order to guide and maintain their professional development plan goals. Unlike most Firms, we actually focus on the achievement of those goals for each individual team member, providing opportunities that would not usually be offered.</p><p><br/></p><p>Finally, MERU values personal time, only traveling when necessary, in order to celebrate and respect your personal life. We believe that by encouraging and mandating balance, it will lead to happier and longer-tenured team members.</p><p><br/></p><p>When you come to MERU, you come to further your career and maintain your entrepreneurial spirit, never losing sight of the desire to provide meaningful impact, solutions, and value to clients. Learn more about our colleagues’ core characteristics and culture here: https://wearemeru.com/meru-way/</p><p><br/></p><p><strong><u>Responsibilities: </u></strong></p><ul><li>Demonstrates ownership of individual workstreams with minimal supervision from senior team members, with the ability to coach junior team members on the engagement</li><li>Complete ownership for end-to-end process of engaging stakeholders for design sessions and requirements gathering and solution build​</li><li>Produces high quality, production level code, balances on-time delivery with long-term sustainability</li><li>Proactively communicates progress and roadblocks to senior team members on an ongoing basis; proactively develops solutions to the roadblocks</li><li>Contributes to proposal development (i.e., assistance with analysis/presentation, etc.) and proactively identifies ways to improve the proposal quality (i.e., research, package case studies, etc.)</li><li>Assists Partners in preparation for pitches and attends as required</li><li>Proactively identifies ways to improve proposal quality</li><li>Supports in the development of Firm Contribution areas, such as Recruiting, Professional Development, Marketing, etc.</li></ul><p><br/></p><p><strong><u>Qualifications:</u></strong></p><ul><li><strong>3+ years of business intelligence or data analytics experience</strong></li><li><strong>Previous experience in data and analytics consulting or a client-facing role, required</strong></li><li>Bachelor’s degree from a top university, required</li><li>Strong knowledge and delivery experience with Tableau, Power BI, Qlik, or any other data visualization tools</li><li>Working knowledge of ETL tools like Power Query, Azure Data Factory, FiveTran, Stitch, Alteryx, and languages like SQL, Python, or R</li><li>Relevant certifications associated with business intelligence tools, and enthusiasm to learn new tools and technologies and attain certifications</li><li>Experience in mentoring junior analysts and leading cross-functional teams to deliver data products</li><li>Demonstrated ability to interact and work collaboratively with junior and senior team members, senior management, and other stakeholders or professionals</li><li>Experience in independently managing deliverables with little oversight</li><li>Effective communication skills to explain technical concepts to a non-technical audience or senior executives</li><li>“Roll up your sleeves” mentality and willingness to complete any task if needed, no matter the role</li><li>Ability to assist with internal firm initiatives (e.g., marketing, client pitches)</li><li>Willingness to travel up to 20%</li><li>Ability to work full time in an office and remote environment; physically able to sit/stand at a computer and work in front of a computer screen for significant portions of the workday</li><li>Authorization to work in the United States</li><li>Commitment to living MERU’s values and core characteristics</li></ul><p><br/></p><p><strong><u>Overview of MERU Service Offerings: </u></strong></p><p><br/></p><p>Data Insights:</p><p>Work with companies at all stages of their digital transformation journey to automate reporting processes, build scalable data platforms, and leverage predictive analytics to transform data from a liability into an asset. Services include Data Discovery and Analysis, Data Prep and Integration, Self-Service Analytics, Data Visualization and Reporting, Data Science and Advanced Analytics, and Strategy Enablement.</p><p><br/></p><p>Performance Improvement:</p><p>Help companies identify and achieve their full potential by leveraging a value-focused approach to driving sustainable margin expansion impact. Services include MERU 360° Assessment, Transformation Plan Development, Chief Transformation Officer placement, Cash Cycle and Working Capital Optimization, and Implementation Performance Management.</p><p><br/></p><p>Turnaround &amp; Restructuring:</p><p>Partner with clients during uncertain times to help stabilize operations and rapidly triage the causes of financial distress, charting a path back to long-term sustainability. Services include Interim Management, Turnaround Plan Development and Execution, Liquidity Management, Stakeholder Negotiations, Strategic Alternatives Assessment, Bankruptcy, Insolvency, and Case Management.</p><p><br/></p><p>Transaction Services:</p><p>Partner with private equity firms across the investment lifecycle, from due diligence to portfolio value creation and exit planning. Services include Due Diligence, Pre-Close Planning, Post-Close Implementation, and Exit Planning.</p><p><br/></p><p><strong><u>Salary Range:</u></strong><u> </u></p><p>$105,000 – $155,000. In addition to benefits, MERU also offers an extremely competitive bonus program that is based on firm contribution efforts and performance.</p><p><br/></p><p><strong><u>Voluntary Inclusion:</u></strong></p><p>It is MERU’s policy to provide and promote equal opportunity in employment, compensation, and other terms and conditions of employment without discrimination because of race, color, sex, sexual orientation, family medical history or genetic information, political affiliation, military service, pregnancy, marital status, family status, religion, national origin, age or disability or any other non-merit based factor in accordance with all applicable laws and regulations.</p><p><br/></p><p><strong><u>Unsolicited Resumes from Third-Party Recruiters:</u></strong></p><p>Please note that we do not accept unsolicited resumes from third-party recruiters unless such recruiters are engaged to provide candidates for a specified opening. Any employment agency, person, or entity that submits an unsolicited resume does so with the understanding that MERU will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person, or entity.</p>
</div>",$50- $2,Database Engineer
Insights Data Engineer,SCIENTIFIC GAMES,12/21/2023,https://www.linkedin.com/jobs/view/3791523755,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Engineer,Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3766608708,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
"Lead, Data Engineer",Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3738302241,0,https://media.licdn.com/dms/image/C560BAQHZ9xYomLW7zg/company-logo_100_100/0/1630658255326/salesforce_logo?e=2147483647&v=beta&t=GvAdJRB6d3hWoiMBjIAOP9tjZzbWxLNF84FnSTgWblE,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.<br/><br/></em>Job Category<br/><br/>Software Engineering<br/><br/>Job Details<br/><br/><strong><strong><strong>About Salesforce<br/><br/></strong></strong></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/>Job Category<br/><br/>Software Engineering<br/><br/>Job Details<br/><br/><strong><strong><strong>About Salesforce<br/><br/></strong></strong></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/><strong><strong>Org Overview<br/><br/></strong></strong>The Data and Analytics Organization is Salesforce's cornerstone for fostering growth and margins through unparalleled data insights. From robust governance to strategic execution, we support data pioneers with an unbiased approach. Our Enterprise Data Strategy builds a solid data foundation, fostering a culture of data-driven decisions. We ensure end-to-end quality through a cohesive data supply chain. By deploying and integration platform tools, we enable seamless data access and automated data management driving efficiency and growth with actionable insights. As a steadfast partner, we shape a data ecosystem that fuels innovation. Our commitment to integrity and accessibility propels informed decision-making, propelling Salesforce to new heights of excellence.<br/><br/><strong><strong>Team Overview<br/><br/></strong></strong>Data Strategy and Management Engineering team brings Data to life, partnering with data producers and platform engineers to empower data consumers (data scientists, data analysts and visualization engineers) who consume data for business analytics and AI augmented solutions. We do this by delivering trusted data, in an agile way and make it accessible for a variety of use cases. We pride ourselves in being data curious (one who has an intrinsic need to understand a data point). We architect, automate, and scale our data curation frameworks, services, and processes to rapidly integrate disconnected and disparate raw data into a business-relevant asset and work towards one common theme - Customer Success.<br/><br/><strong><strong>Responsibilities:<br/><br/></strong></strong><ul><li>Design efficient and scalable data pipelines for collecting, transforming, and loading data from various sources.</li><li>Implement error handling and monitoring mechanisms to ensure data quality and pipeline reliability.</li><li>Partner with data producers in understanding data sources, enable data contracts and define the data model that drives analytical use cases</li><li>Optimize data storage solutions while implementing strategies for query performance, cost and scalability</li><li>Monitor and enhance data pipelines' performance, availability and scalability, addressing bottlenecks and latency.</li><li>Ensure data security and compliance with relevant regulations (e.g., GDPR,) implements data masking, access control and other data protection measures</li><li>SME of the solution, able to connect work with the business impact</li><li>Collaborate with cross-functional teams, provide technical guidance, and mentor junior engineers.</li><li>Evaluate various technologies and platforms in open source and internal solutions. Execute proof of concept on new technology and tools to pick the best tools and solutions as needed<br/><br/></li></ul><strong><strong>Requirements<br/><br/></strong></strong><ul><li>B.S/M.S. in Computer Sciences or equivalent experience in big data engineering, data acquisition and integration projects.</li><li>5+ years experience designing, implementing and maintaining relational / data warehousing environments (custom or structured ETL, preferably working with large data environments)</li><li>Strong background in Data Warehousing concepts and schema design.</li><li>Strong proficiency in programming languages commonly used in data engineering, such as Python, SQL and big data technologies such as Hadoop, Spark, Kafka, and distributed computing frameworks.</li><li>In-depth understanding of data modeling, lakehouse/data mesh technologies, proficiency in building frameworks and data pipelines. Experience in using test driven frameworks, version control, conducting efficient code reviews, deployment strategies</li><li>Strong problem-solving skills and the ability to troubleshoot complex data-related issues with prime focus on data quality and management</li><li>Excellent communication skills to collaborate with technical and non-technical stakeholders, laser focus on the impact, curious, team player</li><li>A beginner and continuous improvement mindset, always seeking opportunities for automation, process enhancement, and reusable tool creation.<br/><br/></li></ul><strong><strong>Preferred:<br/><br/></strong></strong><ul><li>Salesforce products knowledge, working with Salesforce metadata is a plus</li><li>Experience working with Public Cloud platforms like GCP, AWS, Snowflake</li><li>Familiar with production debugging techniques such as thread dump analysis and GC performance tuning<br/><br/></li></ul>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.<br/><br/>﻿Salesforce welcomes all.<br/><br/>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.<br/><br/>﻿Salesforce welcomes all.
      </div>",No Salary Info Found,Database Engineer
Sr Data Engineer,The Fountain Group,12/19/2023,https://www.linkedin.com/jobs/view/3784094967,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Center Engineer,Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3732380840,0,https://media.licdn.com/dms/image/C4D0BAQG16gpXzS14DQ/company-logo_100_100/0/1630499898593/cloudflare_logo?e=2147483647&v=beta&t=JnWbIHRMM7IEd6GKOBdDcOcAwe8GlG6X05cH_ptu3Rc,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world’s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine’s Top Company Cultures list and ranked among the World’s Most Innovative Companies by Fast Company.<br/><br/>We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!<br/><br/><strong> Data Center Operations Engineer </strong> <strong><strong>About the department<br/><br/></strong></strong>In this role, you will be focused on maintaining the Clou dflare global network. You 'll work closely with Cloudflare’s SRE (Site Reliability Engineering) team, Network Engineering team, Network Deployment Engineering team and with various vendors and partners (including hardware vendors, datacenter and network providers, and ISPs) to maintain and improve our global infrastructure. You will further be responsible for the development and implementation of consistent processes and visibility measurements for consistent and effective management of our infrastructure. This is a highly visible position that requires deep technical understanding of datacenter infrastructure, networking (physical), and basic experience with data analysis and project management.<br/><br/>To be successful in this position, you should have excellent technical skills, communication skills, and be able to navigate a range of challenges and constraints (e.g. schedule adherence, time zones, and cultures). You will have the opportunity to (literally) build a faster, safer Internet for our millions of users and the billions of web surfers that visit their sites each month.<br/><br/><strong>Who You Are<br/><br/></strong>You will thrive in a hypergrowth engineering environment and be self driven with a keen attention to detail. You will come with a deep technical understanding of Data Center colocation environments, network architecture and server technologies. You will be used to working through partners to support infrastructure delivery to a number of remote locations. You will have had experience managing operational environments, and used to developing new approaches to improve delivery efficiency or operational stability.<br/><br/><strong>What You'll Do<br/><br/></strong><ul><li> Collaborating with internal teams (Infrastructure, Network Engineering and SRE). Create documentation and manage remote contractors to complete datacenter tasks, working with hardware manufacturers, datacenter and network providers, logistics partners and other service providers in support of our 300+ datacenter locations </li><li> Maintain Data Center environment operational availability </li><li> Creating and maintaining documentation, plans, SOP’s, MOP’s etc. </li><li> Support and configure network infrastructure where required </li><li> Providing feedback to internal teams to support internal tools and external vendor partnerships <br/><br/><br/></li></ul><strong>Required Experience<br/><br/></strong><ul><li> Minimum of 5 yrs of Linux systems administration </li><li> Experience with Juniper, Cisco and DWDM network equipment </li><li> Experience managing and instructing remote contractors </li><li> Familiarity with work required to stand up infrastructure in remote colocation facilities </li><li> Experience running and improving operational processes, including automation tooling, in a rapidly changing environment </li><li> Familiarity with day-to-day tasks and projects common to Data Center Operations (deployment, migration, decommissioning etc.) </li><li> Comfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA </li><li> Incident management <br/><br/><br/></li></ul><strong>Other Responsibilities May Include<br/><br/></strong><ul><li> Aggressively seek opportunities to introduce cutting-edge technology and automation solutions that are effective, efficient and scalable in order to improve our ability to deploy and maintain our global infrastructure </li><li> Assist with the definition, documentation and implementation of consistent processes across all region </li><li> Limited travel <br/><br/><br/></li></ul><strong>Examples Of Desirable Skills, Knowledge And Experience<br/><br/></strong><ul><li> Bachelor’s degree; technical background in engineering, computer science, or MIS </li><li> Direct experience executing on complex data center/infrastructure projects </li><li> Previous experience installing / maintaining data center (and other IT) infrastructure and DCIM tools </li><li> Experience running and improving operational processes in a rapidly changing environment </li><li> Strong verbal and written communication skills, problem-solving skills, attention to detail, and interpersonal skills </li><li> Must be proactive with proven ability to learn fast and execute on multiple tasks simultaneously </li><li> Ability to manage MS excel and Google spreadsheets </li><li> Comfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA </li><li> Must be a team player <br/><br/><br/></li></ul><strong>Bonus Points<br/><br/></strong><ul><li> Multi-lingual; experience working with infrastructure in multiple countries </li><li> Comfortable with remote “lights-out” and out-of-band access to data center resources </li><li> Linux certifications (RHCSA etc.) </li><li> Network certifications (CCNA, JNCIA or higher) <br/><br/><br/></li></ul><strong>Compensation<br/><br/></strong>Compensation may be adjusted depending on work location.<br/><br/><ul><li>For Colorado-based hires: Estimated annual salary of $ 111,000 - $ 135,000 .</li><li>For New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $ 135,000 - $ 165,000 </li><li>For Bay Area-based hires: Estimated annual salary of $ 142,000 - $ 174,000 .<br/><br/><br/></li></ul><strong>Equity<br/><br/></strong>This role is eligible to participate in Cloudflare’s equity plan.<br/><br/><strong>Benefits<br/><br/></strong>Cloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S.<br/><br/><strong>Health &amp; Welfare Benefits<br/><br/></strong><ul><li>Medical/Rx Insurance</li><li>Dental Insurance</li><li>Vision Insurance</li><li>Flexible Spending Accounts</li><li>Commuter Spending Accounts</li><li>Fertility &amp; Family Forming Benefits</li><li>On-demand mental health support and Employee Assistance Program</li><li>Global Travel Medical Insurance<br/><br/><br/></li></ul><strong>Financial Benefits<br/><br/></strong><ul><li>Short and Long Term Disability Insurance</li><li>Life &amp; Accident Insurance</li><li>401(k) Retirement Savings Plan</li><li>Employee Stock Participation Plan<br/><br/><br/></li></ul><strong>Time Off<br/><br/></strong><ul><li>Flexible paid time off covering vacation and sick leave</li><li>Leave programs, including parental, pregnancy health, medical, and bereavement leave<br/><br/><br/></li></ul><strong>What Makes Cloudflare Special?<br/><br/></strong>We’re not just a highly ambitious, large-scale technology company. We’re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.<br/><br/><strong>Project Galileo</strong> : We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare’s enterprise customers--at no cost.<br/><br/><strong> Athenian Project </strong> : We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.<br/><br/><strong>Path Forward Partnership</strong> : Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.<br/><br/><strong>1.1.1.1</strong> : We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here’s the deal - we don’t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.<br/><br/>Sound like something you’d like to be a part of? We’d love to hear from you!<br/><br/>This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.<br/><br/>Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.<br/><br/>Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.
      </div>",No Salary Info Found,Database Engineer
AWS Data Engineer,Intellectt Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788188147,0,https://media.licdn.com/dms/image/C560BAQFOYtI3qgbARA/company-logo_100_100/0/1630625069813/intellecttinc_logo?e=2147483647&v=beta&t=QjDuPUOAXTaOhbAni4QxTWKLIOJeaSPWmg-8rdZ7lJ0,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<ul><li>12+ years experience required.</li><li>Must be able to handle Data engineering operations / enhancement project with a technical consultant bend. </li><li>SQL, Python, PySpark , S3, Lambda, EMR, Glue, Athena, EC2, IAM, Redshift, DMS, Airflow, Jenkins, Snowflake. </li><li>End-to-end data solutions (ingest, storage, integration, processing, access) on AWS. </li><li>Migrate data from traditional relational database systems to AWS relational databases such as Amazon RDS, Aurora, and Redshift. </li><li>12+ years IT experience. Background and experience in data engineering/analytics. </li><li>Should have a very good hands-on experience in Cloud DB platforms (Snowflake is preferable), Building data pipelines &amp; SQL, Python for Data Engineering. </li><li>Got experience to Perform, Support and Lead all aspects of Data Engineering strategy. </li><li>Excellent root cause analysis skills. </li><li>Ensure effective data pipeline engineering, deployment, ongoing operations, and continuous improvement. </li><li>Certification in Data Engineering and/or Cloud Platforms are a plus. </li><li>Good written and verbal communication skills, and comfortable presenting findings to Sr. Management.</li></ul>
</div>",No Salary Info Found,Database Engineer
Senior Data Engineer,SiriusXM,12/19/2023,https://www.linkedin.com/jobs/view/3732586345,0,https://media.licdn.com/dms/image/D560BAQGZYZJBUsuzbg/company-logo_100_100/0/1700146850253/siriusxm_logo?e=2147483647&v=beta&t=mV830XuN8ytZ4D5kSWTIg2jiQLNLiCpQLTTSfAE8xhY,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Who We Are<br/><br/></strong>SiriusXM and its brands (Pandora, SXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners -- in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories and music they love wherever they are.<br/><br/>This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically-acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day.<br/><br/><strong>SiriusXM<br/><br/></strong>SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150 million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics and monetization. The Company’s advertising sales organization, which operates as SXM Media, leverages its scale, cross-platform sales organization and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through Sirius XM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers.<br/><br/><strong>How You’ll Make An Impact<br/><br/></strong>In this role you’ll join a team who designs, builds, and maintains data products that enable critical decision making across the company through experimentation. Experimentation is a key driver of the product development process, and this role will put you at the center of the platform that solves this at scale.<br/><br/><strong>What You’ll Do<br/><br/></strong><ul><li>Build flexible cloud-based data pipeline frameworks to produce statistical analyses of user outcomes</li><li>Build and improve workflow orchestration tooling to support efficient data pipelines. E.g. airflow plugins, systems integration, deployments</li><li>Build tooling to support ML workflows for statistical analysis</li><li>Build monitoring dashboards for stakeholders to better understand the health, performance, and cost of the platform</li><li>Write documentation to encourage adoption of platform tools and support users in their use</li><li>Strengthen corporate best practices around data engineering software development processes</li><li>Collaborate closely with cross-functional teams to launch new analyses in a way that’s reliable and scalable<br/><br/></li></ul><strong>What You’ll Need<br/><br/></strong><ul><li>5+ years’ experience developing data ETL pipelines and data tools in Scala and/or Python</li><li>BS/MS or above in Computer Science or relevant experience</li><li>Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Sqoop</li><li>Experience with streaming technologies - Kafka, Kafka Connect, KStreams, KSQL, Beam, Flink, Spark</li><li>Experience developing SQL applications of significant complexity</li><li>Experience with cloud computing - Google Cloud Platform, Amazon Web Services</li><li>Experience developing for Linux-based deployment platforms, developing scalable server-side software for deployment</li><li>Experience developing service-oriented architectures/orchestration</li><li>Experience with API design/development – RPC, REST, JSON</li><li>Experience with unit and integration testing frameworks</li><li>Experience with CI/CD, build and deployment technologies such as Jenkins</li><li>Experience with Data Visualization or Data Notebook tools (i.e Zeppelin, Tableau, etc.)</li><li>Experience working in a Cloud Environment (AWS, GCP, etc.)</li><li>Experience developing and deploying machine learning algorithms</li><li>Experience developing with additional languages - R, Scala</li><li>Experience with workflow tools – Airflow/Composer/Luigi</li><li>Experience with data serialization system - Avro, Protobuf</li><li>Interpersonal skills and ability to interact and work with staff at all levels.</li><li>Excellent written and verbal communication skills.</li><li>Ability to work independently and in a team environment.</li><li>Ability to project professionalism over the phone and in person.</li><li>Ability to handle multiple tasks in a fast-paced environment.</li><li>Commitment to “internal client” and customer service principles.</li><li>Willingness to take initiative and to follow through on projects.</li><li>Creative writing ability.</li><li>Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.</li><li>Must have legal right to work in the U.S<br/><br/></li></ul>At SiriusXM, we carefully consider a wide range of factors when determining compensation, including your background and experience. These considerations can cause your compensation to vary. We expect the base salary for this position to be in the range of $126,000 to $145,800 and will depend on your skills, qualifications, and experience. Additionally, this role might be eligible for discretionary short-term and long-term incentives. We encourage all interested candidates to apply.<br/><br/><strong> <br/><br/></strong>Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.<br/><br/>The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.<br/><br/>R-2023-08-81
      </div>",$126000- $145800,Database Engineer
Senior Data Engineer,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3738099369,0,https://media.licdn.com/dms/image/C560BAQHZ9xYomLW7zg/company-logo_100_100/0/1630658255326/salesforce_logo?e=2147483647&v=beta&t=GvAdJRB6d3hWoiMBjIAOP9tjZzbWxLNF84FnSTgWblE,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.<br/><br/></em>Job Category<br/><br/>Software Engineering<br/><br/>Job Details<br/><br/><strong>About Salesforce<br/><br/></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/>The <strong>Data and Analytics Organization (DnA)</strong> is Salesforce's cornerstone for fostering growth and margins through unparalleled data insights. From robust governance to strategic execution, we support data pioneers with an unbiased approach. Our Enterprise Data Strategy builds a solid data foundation, fostering a culture of data-driven decisions. We ensure end-to-end quality through a cohesive data supply chain. By deploying and integration platform tools, we enable seamless data access and automated data management driving efficiency and growth with actionable insights. As a steadfast partner, we shape a data ecosystem that fuels innovation. Our commitment to integrity and accessibility propels informed decision-making, propelling Salesforce to new heights of excellence.<br/><br/><strong><em>Interesting Articles about some of our work and our culture:<br/><br/></em></strong><ul><li>https://www.salesforce.com/blog/what-does-salesforce-do/</li><li>https://www.salesforce.com/company/equality/</li><li>https://www.salesforce.com/resources/data<br/><br/></li></ul><strong>Team Overview<br/><br/></strong>Data Strategy and Management Engineering team brings Data to life, partnering with data producers and platform engineers to empower data consumers (data scientists, data analysts and visualization engineers) who consume data for business analytics and AI augmented solutions. We do this by delivering trusted data, in an agile way and make it accessible for a variety of use cases. We pride ourselves in being data curious (one who has an intrinsic need to understand a data point). We architect, automate, and scale our data curation frameworks, services, and processes to rapidly integrate disconnected and disparate raw data into a business-relevant asset and work towards one common theme - Customer Success.<br/><br/><strong>Role Description<br/><br/></strong><ul><li>Design, build, and maintain scalable and efficient data pipelines and ETL processes to support data-driven decision-making.</li><li>Implement data validation and monitoring processes to ensure data quality and integrity throughout the data lifecycle.</li><li>Have opinionated views on how data will be collected, stored, consumed &amp; managed.</li><li>Ensure compliance with governing standards, data quality &amp; protection principles.</li><li>Optimize data storage and retrieval mechanisms to enhance performance and cost-effectiveness, making data readily accessible for analytics.</li><li>Participate in code reviews and contribute to the development of coding standards and best practices to ensure high-quality data engineering solutions.<br/><br/></li></ul><strong>If You Are,<br/><br/></strong><ul><li>Experienced Data Engineer: Demonstrated experience in data engineering roles with a strong foundation in data pipeline development.</li><li>Experienced Professional:</li><ul><li>Proficient in big data technologies like Hadoop, Spark, Presto, Hive, Snowflake etc...</li><li>Strong coding skills in Python/Java/Scala or equivalent</li><li>Understanding of scalability and reliability concerns for data-intensive applications</li></ul><li>Data Engineering Enthusiast: Passion for data engineering and a desire to grow in this field.</li><li>Collaborative &amp; Communicative: Effective communication skills and the ability to work well within a team.</li><li>Data Advocate: Strong commitment to data quality, security, and compliance.</li><li>Preferred: Familiarity with cloud-based data platforms (e.g., AWS, GCP, Azure).<br/></li></ul><strong>Minimum Requirements (Senior Data Engineer)<br/><br/></strong><ul><li>Bachelor’s or Master's degree in Computer Science, Information Technology, or related field.</li><li>6+ years of experience in data engineering and related roles.<br/><br/></li></ul>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.<br/><br/>﻿Salesforce welcomes all.
      </div>",No Salary Info Found,Database Engineer
Senior Database Engineer,AGM Tech Solutions - A Woman and Latina-owned IT Staffing Firm-an Inc5000 company.,12/19/2023,https://www.linkedin.com/jobs/view/3784451240,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Engineer III - Remote | WFH,Get It Recruit - Information Technology,12/25/2023,https://www.linkedin.com/jobs/view/3787808700,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"La Mesa, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a dynamic and innovative team seeking a skilled Data Engineer III to join us remotely. At our company, we value collaboration, creativity, and a passion for transforming data into meaningful insights. If you thrive in a fast-paced, agile environment and are excited about building solutions that make a real impact, we invite you to explore this opportunity.<br/><br/><strong>Responsibilities<br/><br/></strong>Design and implement features in collaboration with a diverse team of engineers, product owners, data analysts, and business partners using Agile/Scrum methodology.<br/><br/>Develop programs and systems that translate data into meaningful information for analysis.<br/><br/>Build ETL/ELT jobs and workflows to integrate data from various sources.<br/><br/>Install continuous pipelines of filtered information for data analysts/scientists.<br/><br/>Construct data workflows using SQL Server Integration Services (SSIS), Microsoft Azure (Azure Data Factory, Storage Accounts, Synapse), and Databricks.<br/><br/>Collaborate with business stakeholders and product engineering teams to analyze business problems and implement solutions.<br/><br/>Document software architecture, create roadmap plans, and assist in the design, implementation, and maintenance of complex solutions.<br/><br/>Build systems that collect, manage, and convert raw data into usable information for business analysts.<br/><br/>Ensure data accessibility for evaluation and optimization.<br/><br/><strong>Qualifications<br/><br/></strong>Required:<br/><br/>Master's degree in computer science, systems engineering, or a related technical discipline (preferred).<br/><br/>5 years of experience as a Data Engineer/Administrator or in a similar role.<br/><br/>6 additional years of relevant experience may substitute for education.<br/><br/><strong>Preferred<br/><br/></strong>Proficiency in back-end data organization using SQL scripts and SSIS.<br/><br/>Experience with Microsoft Azure, Databricks, and Python or other scripting languages in data pipelines.<br/><br/>Familiarity with Microsoft Power BI.<br/><br/>Ability to work independently and provide technical and non-technical support to multiple users.<br/><br/>Capable of working under pressure, handling multiple tasks simultaneously.<br/><br/>Occasional overtime and weekend availability may be required.<br/><br/><strong>Salary Range<br/><br/></strong>Experience providing services to the federal government is preferred.<br/><br/>Target salary range: $165,001 - $175,000. The estimate displayed represents the typical salary range for this position based on experience and other factors.<br/><br/><strong>COVID Policy<br/><br/></strong>We prioritize the health and safety of our team members. While we do not require COVID-19 vaccinations or boosters, we adhere to customer site vaccination requirements when work is performed at a customer site.<br/><br/>Employment Type: Full-Time
      </div>",$165001- $175000,Database Engineer
MySQL Database Administrator III,Expedite Technology Solutions LLC,12/21/2023,https://www.linkedin.com/jobs/view/3786113789,0,https://media.licdn.com/dms/image/C4E0BAQGeGMJ9ulTrag/company-logo_100_100/0/1635179023686?e=2147483647&v=beta&t=f2uJcztHqdHX34OndQfgRlUsfSsEyPYGZgsK1uSBeMg,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are seeking a seasoned Senior Aurora RDS MySQL DBA with a strong background in database administration and a willingness to explore MongoDB. As a Senior DBA, you will play a crucial role in managing, optimizing, and securing our Aurora RDS MySQL databases while also contributing your expertise to enhance our MongoDB environments. This position requires a deep understanding of MySQL, Aurora RDS, and the ability to adapt and apply your skills to MongoDB.<br/><br/>Extensive experience as a Senior Database Administrator, with a focus on Aurora RDS MySQL and a willingness to learn MongoDB.<br/><br/>Expertise in MySQL and Aurora RDS database administration and optimization.<br/><br/>Familiarity with MongoDB database administration, including replication, sharding, and scaling.<br/><br/>Strong knowledge of database security practices and compliance.<br/><br/>Proficiency in SQL, NoSQL, query optimization, and database design principles.<br/><br/>Exceptional problem-solving and troubleshooting skills.<br/><br/>Strong communication, leadership, and teamwork abilities.
      </div>",No Salary Info Found,Database Engineer
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789762711,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        A market leader in the analytics space, specifically focusing on analytics for the entertainment space is hiring a Senior Data Engineer to join their team of 5. This role will be a lot of new development and migrations as they are moving their SQL based pipelines over to Python, AWS, and Spark so strong SQL experience is a big plus. This company processes tens of billions of rows of data every year and has almost 20TB of processing data. The main tech stack for this role is SQL, Python, AWS, and Spark experience. This team also uses Glue, Power BI, Anthem, EMR, PySpark, and any experience working with marketing metrics/analysis is a plus. You will be building new capabilities for their analytics teams, integrating big data tools and moving to AWS within their pipelines.<br/><br/>This role is looking for someone to work PST hours. If you are local to Southern California that is a big plus but not required as this role is 100% fully remote. This is a small team so they ideally need someone open to wearing a few different hats who can interact with various teams within the organization so good communication is a must.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>5+ years professional Data Engineering Experience </li><li>Background in DBA/SQL Development </li><li>5 years of experience building ETL pipelines with Python, AWS, and Spark/PySpark </li><li>Experience working with large amounts of data <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Bachelors in STEM field </li><li>Excellent written and verbal communication skills </li><li>Any experience with Glue, Power BI, Anthem, or EMR </li><li>Experience working with marketing metrics data <br/><br/></li></ul>The Offer<br/><br/><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Sick Time </li><li>Paid Time Off </li><li>401(k) with match </li><li>Annual Bonus </li><li>Remote PST time <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Cassi Benson
      </div>",No Salary Info Found,Database Engineer
Senior Oracle Database Developer,"Data Intelligence, LLC",12/19/2023,https://www.linkedin.com/jobs/view/3764321370,0,https://media.licdn.com/dms/image/C560BAQFl46m5rYOFOw/company-logo_100_100/0/1631380861055?e=2147483647&v=beta&t=qOvibjC3knnc76MjvKxHV93DjM1wQkZy5-UPxLx-dFQ,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Data Intelligence, LLC (DI) is searching for a full time Senior Oracle Database Developer in the San Diego area. This is a hybrid position.</p><p><br/></p><p><strong>Required Skills/Experience</strong></p><ul><li>Minimum 5 years hands on PL/SQL programming experience</li><li>Must be able to use and understand most of the commands form the sample list below</li><li>Write Packages</li><li>Procedures</li><li>Functions</li><li>Exception Blocks</li><li>Understand Case and Decode</li><li>Object Types</li><li>Table Arrays</li><li>Regular Expression functions</li><li>Bulk collect</li><li>Use of Cursors</li><li>Pipe Row</li><li>Sub-queries</li><li>Loop structures</li><li>Merge</li><li>Views</li><li>Analytical functions (First_value, Lag, Lead, etc.)</li><li>Experience with JSON objects</li><li>Ability to analyze and trance code, familiar with object-oriented programming</li><li>Must have experience in a Linux environment</li><li>At least a ""secret level"" security clearance</li></ul><p><br/></p><p><strong>Desired Skills/Experience</strong>Hands on database administrator (DBA) Experience</p><ul><li>Oracle Database Certificates</li><li>Experience working with Oracle in AWS GovCloud</li></ul><p><br/></p><p><br/></p><p> Data Intelligence, DI is an established small business that has supported the critical missions of our government clients since 2005. We provide full life cycle system development, systems engineering, cybersecurity, and supporting analytical and logistics support to C4ISR and other complex systems. We are an equal opportunity employer that offers competitive salaries, comprehensive benefits, a team-oriented environment, and opportunities for advancement. Our excellent employee retention record reflects our employee focus. We work with Veteran’s organization to proactively hire those who have served our country. We offer medical, dental and vision insurance, 401k, PTO and 11 paid holidays.</p><p><br/></p><p>Data Intelligence is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, age, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.</p>
</div>",No Salary Info Found,Database Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765472151,0,https://media.licdn.com/dms/image/D560BAQFsPZUT0bTpJg/company-logo_100_100/0/1689000656484/bdo_usa_logo?e=2147483647&v=beta&t=-M1FfX9Kow8d2drx-DmltN3u3liHKtB3vVhqpNf3A8Q,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>Job Summary:<br/><br/></strong>This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.<br/><br/><strong>Job Duties<br/><br/></strong><ul><li> Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS </li><li> Listens to client needs to align solution with business requirements and delivery schedule </li><li> Creates written functional and technical designs </li><li> Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers </li><li> Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions </li><li> Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles </li><li> Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency) </li><li> Assists with implementation of data governance programs and best practices </li><li> Performs the cleaning and transforming of data from source systems into analytics models </li><li> Implements models to support data visualizations and integrations </li><li> Assists with implementing DevOps, DataOps and MLOps methodologies on projects </li><li> Writes custom integration logic in applicable programming languages </li><li> Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle </li><li> Assists clients with licensing, security, and cost estimation of solutions </li><li> Performs code reviews to ensure adherence to standards </li><li> Works directly with clients and team members to establish secure data analytics platforms and infrastructure </li><li> Contributes to successful deployments of developed solutions and integration of DevOps tools </li><li> Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools </li><li> Builds client relationships during project execution, effectively becoming a trusted advisor of the client </li><li> Participates in support activities for existing software solutions </li><li> Other duties as assigned <br/><br/><br/></li></ul><strong>Supervisory Responsibilities<br/><br/></strong><ul><li> Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product <br/><br/><br/></li></ul><strong>Education<br/><br/></strong><strong>Qualifications, Knowledge, Skills and Abilities:<br/><br/></strong><ul><li> High School Diploma or GED equivalent, required </li><li> Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred <br/><br/><br/></li></ul><strong>Experience<br/><br/></strong><ul><li> Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required </li><li> One (1) or more years of experience technically leading development projects, preferred </li><li> One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred <br/><br/><br/></li></ul><strong>Software<br/><br/></strong><ul><li> Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required </li><li> Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required </li><li> Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred </li><li> Experience with one (1) or more of the following computer languages, preferred:</li><ul><li> C# </li><li> Python </li><li> Java </li><li> Scala </li></ul><li> Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred </li><li> Experience with Git and DevOps deployment technologies, preferred </li><li> Experience with Linux, preferred </li><li> Experience with one (1) or more of the following, preferred:</li><ul><li> Data Lake Medallion Architecture </li><li> Batch and/or streaming data ingestion into a data lake </li><li> AI Algorithms/Machine Learning </li><li> Automation tools such as UiPath, Alteryx, etc. </li><li> Computer Vision based AI technologies <br/></li></ul></ul><strong>Other Knowledge, Skills &amp; Abilities<br/><br/></strong><ul><li> Ability to work with a high degree of professionalism and autonomy </li><li> Excellent verbal and written communication skills </li><li> Solid organizational skills, especially the ability to meet project deadlines with a focus on details </li><li> Ability to successfully multi-task while working independently or within a group environment </li><li> Ability to work in a deadline-driven environment, and handle multiple projects simultaneously </li><li> Ability to interact effectively with people at all organizational levels of the Firm </li><li> Ability to effectively interact with a team of professionals and delegating work assignments, as needed </li><li> Ability to build and maintain strong relationships with internal and client personnel </li><li> Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel <br/><br/><br/></li></ul><strong>Keywords:</strong> Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL<br/><br/>Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.<br/><br/>California Range: $111,000 - $152,000<br/><br/>Colorado Range: $111,000 - $152,000<br/><br/>New York City/ Valhalla Range: $111,000 - $152,000<br/><br/>Washington Range: $111,000 - $152,000<br/><br/><strong>About Us<br/><br/></strong>BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.<br/><br/><ul><li>Unparalleled partner-involvement </li><li>Deep industry knowledge and participation</li><li>Geographic coverage across the U.S.</li><li>Cohesive global network </li><li>Focused capabilities across disciplines<br/><br/><br/></li></ul>BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.<br/><br/>BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best &amp; Brightest Companies to Work For and more.<br/><br/><strong>Some Examples Of Our Total Rewards Offerings Include<br/><br/></strong><ul><li>Competitive pay and eligibility for an annual performance bonus. </li><li>A 401k plan plus an employer match</li><li>Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one</li><li> Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays </li><li>Paid Parental Leave</li><li>Adoption Assistance</li><li>Firm paid life insurance</li><li>Wellness programs</li><li>Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance <br/><br/><br/></li></ul>Above offerings may be subject to eligibility requirements.<br/><br/>Click here to find out more!<br/><br/>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.<br/><br/>""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""<br/><br/>
</div>",$111000- $152000,Database Engineer
Principal Communications Data Analyst Engineer,Northrop Grumman,12/20/2023,https://www.linkedin.com/jobs/view/3784989719,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment Partners LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785064004,0,https://media.licdn.com/dms/image/C4E0BAQGbIGAVD9Ugtg/company-logo_100_100/0/1630587145865/motion_recruitment_partners_llc_logo?e=2147483647&v=beta&t=alBjyOtSVLguJoyqNF0DXJ9Pwg7PtTJhNsISoDSt9QU,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Motion Recruitment Partners, LLC, is seeking the following. Apply via Dice today!<br/><br/>A market leader in the analytics space, specifically focusing on analytics for the entertainment space is hiring a Senior Data Engineer to join their team of 5. This role will be a lot of new development and migrations as they are moving their SQL based pipelines over to Python, AWS, and Spark so strong SQL experience is a big plus. This company processes tens of billions of rows of data every year and has almost 20TB of processing data. The main tech stack for this role is SQL, Python, AWS, and Spark experience. This team also uses Glue, Power BI, Anthem, EMR, PySpark, and any experience working with marketing metrics/analysis is a plus. You will be building new capabilities for their analytics teams, integrating big data tools and moving to AWS within their pipelines.<br/><br/>This role is looking for someone to work PST hours. If you are local to Southern California that is a big plus but not required as this role is 100% fully remote. This is a small team so they ideally need someone open to wearing a few different hats who can interact with various teams within the organization so good communication is a must.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>5+ years professional Data Engineering Experience </li><li>Background in DBA/SQL Development </li><li>5 years of experience building ETL pipelines with Python, AWS, and Spark/PySpark </li><li>Experience working with large amounts of data <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Bachelors in STEM field </li><li>Excellent written and verbal communication skills </li><li>Any experience with Glue, Power BI, Anthem, or EMR </li><li>Experience working with marketing metrics data <br/><br/></li></ul>The Offer<br/><br/><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Sick Time </li><li>Paid Time Off </li><li>401(k) with match </li><li>Annual Bonus </li><li>Remote PST time <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Data Engineer / Background in SQL / Migrate to AWS
      </div>",No Salary Info Found,Database Engineer
Data Engineer,National Funding,12/20/2023,https://www.linkedin.com/jobs/view/3785066474,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
MySQL Database Administrator,GDH,12/20/2023,https://www.linkedin.com/jobs/view/3790466575,0,https://media.licdn.com/dms/image/D560BAQHYGkMB83Sh0Q/company-logo_100_100/0/1698857059553/gdh_consulting_logo?e=2147483647&v=beta&t=iZHQ5adSt66wPUhJ0nttbWwvEHTuciQIj378rQ12nVs,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>Seasoned Senior Aurora RDS MySQL DBA with a strong background in database administration and a willingness to explore MongoDB. As a Senior DBA, you will play a crucial role in managing, optimizing, and securing our Aurora RDS MySQL databases while also contributing your expertise to enhance our MongoDB environments. This position requires a deep understanding of MySQL, Aurora RDS, and the ability to adapt and apply your skills to MongoDB.<br/><br/><strong>Desired Skills<br/><br/></strong>– Extensive experience as a Senior Database Administrator, with a focus on Aurora RDS MySQL and a willingness to learn MongoDB.<br/><br/>– Expertise in MySQL and Aurora RDS database administration and optimization.<br/><br/>– Familiarity with MongoDB database administration, including replication, sharding, and scaling.<br/><br/>– Strong knowledge of database security practices and compliance.<br/><br/>– Proficiency in SQL, NoSQL, query optimization, and database design principles.<br/><br/>– Exceptional problem-solving and troubleshooting skills.<br/><br/>– Strong communication, leadership, and teamwork abilities.<br/><br/><strong>Educational Background<br/><br/></strong>Bachelor’s degree in computer science, information technology, or a related field (or equivalent experience).<br/><br/><strong>Preferred Certifications &amp; Licenses<br/><br/></strong>Proficiency in SQL, NoSQL, query optimization, and database design principles
      </div>",No Salary Info Found,Database Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083991,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Junior Data Engineer (US),Fitness Matrix Inc,12/25/2023,https://www.linkedin.com/jobs/view/3793120666,0,https://media.licdn.com/dms/image/D4E0BAQGmk8ZefBUxLg/company-logo_100_100/0/1698352894604/fitness_matrix_inc_logo?e=2147483647&v=beta&t=72cgj7Ot5k670-7oCMGX7QoHQoicVzzbGuWzPstPuXw,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Junior Data Engineer (US) - Onsite<br/><br/></strong><strong>Full-time<br/><br/></strong><strong>$66K - $77K per annum<br/><br/></strong><strong>1+ Year Experience Required<br/><br/></strong><strong>Introduction:<br/><br/></strong>FitnessMatrixInc is a unique approach to health and wellness that is based on the principle of bio-individuality. This means that we believe that everyone is different and has their own unique needs and challenges. We will work with you to understand your biochemistry and develop a personalized plan that is right for you.<br/><br/><strong>Position Summary<br/><br/></strong>Join the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.<br/><br/><strong>Key Responsibilities include:<br/><br/></strong><ul><li>Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. </li><li>Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency </li><li>Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency </li><li>Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data </li><li>Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently </li><li>Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation </li><li>Create/maintain documentation for data processes, data flows, and system configurations </li><li>Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness <br/><br/></li></ul><strong>Characteristics of this role:<br/><br/></strong><ul><li>Team Player: Willing to teach, share knowledge, and work with others to make the team successful. </li><li>Communication: Exceptional verbal, written, organizational, presentation, and communication skills. </li><li>Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. </li><li>Attention to detail: Systematically and accurately research future solutions and current problems. </li><li>Strong work ethic: The innate drive to do work extremely well. </li><li>Passion: A drive to deliver better products and services than expected to customers. <br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><ul><li>2+ years of programming experience in languages such as Python, Java, SQL </li><li>2+ years of experience with ETL tools and database management (relational, non-relational) </li><li>2+ years of experience in data modeling techniques and tools to design efficient scalable data structures </li><li>Skills in data quality assessment, data cleansing, and data validation <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Knowledge of big data technologies and cloud platforms </li><li>Experience with technologies like PySpark, Databricks, and Azure Synapse. <br/><br/></li></ul><strong>Education<br/><br/></strong>Bachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience<br/><br/><strong>Why should we work with Fitness Matrix?<br/><br/></strong>Fitness Matrix Inc is the leading provider of holistic and multidimensional health and wellness services. We offer a comprehensive approach to health and wellness. We take into account all aspects of your life, from your physical fitness and nutrition to your mental, emotional, and spiritual well-being. We use the latest science and technology to develop our programs and services. We are constantly innovating and finding new ways to help our clients achieve their goals. We offer a variety of programs and services to meet your needs and budget.<br/><br/>
</div>",$66- $77,Database Engineer
Lead Data Engineer (FinOps),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788644595,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Lead Data Engineer - Job Opportunity Do you enjoy working in technology and solving complex problems? At Capital One, we are a diverse and inclusive group of professionals who are passionate about using data and emerging technologies to drive efficiency. We are currently seeking Data Engineers to join our team and be part of a major transformation at Capital One. What You'll Do: - Design, deploy, and support cost-efficient solutions for data collection, storage, access, and analytics using AWS - Collaborate with a team of developers experienced in machine learning and full stack systems - Utilize programming languages such as Java, Scala, Python, and databases like Redshift and Snowflake - Stay up-to-date with technology trends, experiment with new technologies, and mentor others - Research and provide insights into cloud cost abnormalities and propose solutions for optimization - Collaborate with different teams to implement cost-saving opportunities in their cloud applications - Provide technical leadership and guidance for cost optimization strategies Basic Qualifications: - Bachelor's Degree - At least 6 years of application development experience - At least 2 years of experience in big data technologies - At least 1 year of cloud computing experience (AWS, Microsoft Azure, Google Cloud) Preferred Qualifications: - 7+ years of application development experience including Python, SQL, Scala, or Java - 4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) - 4+ years of experience with distributed data and computing tools - 4+ years of experience with real-time data and streaming applications - 4+ years of experience with NoSQL databases and data warehousing - 4+ years of experience with UNIX/Linux and shell scripting - 2+ years of experience with Agile engineering practices At Capital One, we offer a comprehensive and inclusive set of benefits to support your well-being. Salary ranges for this role in New York City (Hybrid On-Site) are $197,400 - $225,300 for Lead Data Engineer. Salaries for part-time roles will be prorated based on agreed upon hours. Performance-based incentive compensation may also be available. Capital One is committed to diversity and inclusion in the workplace. We are an equal opportunity employer and welcome applicants from all backgrounds. If you require any accommodations during the application process, please contact our recruiting team. Please note: This job posting is only for applicants seeking work in the specified locations. Salary and benefits may vary for positions offered in other locations. To apply or learn more about our benefits, please visit our website. Thank you for considering Capital One as your potential employer. We look forward to reviewing your application. Sincerely, [Your Name] Bullet points: - Join our diverse and inclusive team at Capital One as a Lead Data Engineer - Use emerging technologies to solve complex business problems - Collaborate with experienced developers in a fast-paced environment - Design, deploy, and support cost-efficient AWS solutions for data - Stay updated with tech trends and mentor others in the engineering community - Research and provide insights into cloud cost abnormalities for optimization - Implement cost-saving opportunities in collaboration with different teams - Provide technical leadership and guidance for cost optimization strategies - Bachelor's Degree required, along with 6+ years of application development experience - Experience with big data technologies and cloud computing is desired - Competitive salary range of $197,400 - $225,300 for Lead Data Engineer in New York City (Hybrid On-Site) - Performance-based incentives and comprehensive benefits package available - Capital One is an equal opportunity employer committed to diversity and inclusion - If you require accommodations during the application process, please contact our recruiting team - Visit our website for more information and to apply for the position.
      </div>",$197400- $225300,Database Engineer
Sr/Engineer-Data Science & Analytics - 90261266 - Philadelphia,Amtrak,12/19/2023,https://www.linkedin.com/jobs/view/3784453205,0,https://media.licdn.com/dms/image/C4D0BAQFFA5eXL3C_Bw/company-logo_100_100/0/1630519023586/amtrak_logo?e=2147483647&v=beta&t=KJai3kunau8ncxW5qOX4HXYZRHXSVzTb7YROjNsSGI8,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Your success is a train ride away!<br/><br/></strong>As we move America’s workforce toward the future, Amtrak connects businesses and communities across the country. We employ more than 20,000 diverse, energetic professionals in a variety of career fields throughout the United States. The safety of our passengers, our employees, the public and our operating environment is our priority, and the success of our railroad is due to our employees.<br/><br/><strong>Are you ready to join our team?<br/><br/></strong>Our values of ‘Do the Right Thing, Excel Together and Put Customers First’ are at the heart of what matters most to us, and our Core Capabilities, ‘Building Trust, Accountability, Effective Communication, Customer Focus, and Proactive Safety &amp; Security’ are what every employee needs to know and do to be most impactful at Amtrak. By living the Amtrak values, focusing on our capabilities, and actively embracing and fostering diverse ideas, backgrounds, and perspectives, together we will honor our past and make Amtrak a company of the future.<br/><br/><strong> This position is a tiered position. Incumbents will have a position level assigned based on their skills and experience, and in alignment with position development plans. Position placement is at Amtrak’s sole and absolute discretion. <br/><br/></strong><strong>Summary Of Duties<br/><br/></strong>The Engineer Data Science &amp; Analytics is responsible for data storage, processing, and analysis to provide information for the development of data-driven scopes of work for maintenance activities. This role will be responsible for collaborating with colleagues in the Research, Analytics &amp; Test Group and other key stakeholders to develop new tools for the visualization and analysis of infrastructure condition data.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li>Develop and implement graphical display and analytical software used by the Engineering Department for condition monitoring, work planning, and degradation analysis.</li><li>Collaborate with Senior Engineer Data Management &amp; Analytics to expand database and analysis capabilities of AssetWise software. </li><li>Collaborate with Manager Engineering Track Geometry Improvements to analyze curve data and develop recommendations for curve modifications.</li><li>Collaborate with Research &amp; Development Group to research and assess new software tools for data analysis. </li><li>Assist in providing technical, logistical, and administrative support to ensure the successful completion of assigned project tasks within scope, schedule and budget. </li><li>May be called upon to assist in inspections utilizing track geometry and catenary measurement cars.</li><li>May be called upon to assist in field inspections.<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>Bachelor of Science Degree in Civil/Transportation/Mechanical/Computer Engineering, or equivalent work experience and training in position of similar capacity.</li><li>Must be able to interface with all levels of employees and both external and internal customers.</li><li>Must be skilled and experienced with MS Office, creating spreadsheets, presentations, memorandums, and utilizing other applications to perform job functions.</li><li>Demonstrated effective communication skills both written and verbal.</li><li>Must become qualified in Roadway Worker Protection, AMT-2, NORAC/GCOR operating rules, and MW100 and maintain these qualifications.</li><li>Ability to learn and understand the use of software such as Matlab, Python, Bentley AssetWise, GeoDrive, PowerBI, Survey123, ArcGIS, ESRI, and Bentley Microstation.<br/><br/></li></ul><strong>MIMINUM KSA (Knowledge, Skills, And Abilities)<br/><br/></strong><ul><li>Must have excellent communication skills, both verbal and written</li><li>Understands how to collaborate with various work groups<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>3-6 years of relevant experience preferred </li><li>Familiarity with Matlab and/or Python coding languages </li><li>Experience with railroad construction, design, and maintenance</li><li>Experience with railroad operations<br/><br/></li></ul><strong>Work Environment<br/><br/></strong><ul><li>Up to 10% travel<br/><br/></li></ul><strong>Communications And Interpersonal Skills<br/><br/></strong>Must have excellent oral and written communication skills.<br/><br/>The salary/hourly range is $86,500 - $111,996 for the Engineer position and $103,700 - $134,460 for the Sr Engineer position. Pay is based on several factors including but not limited to education, work experience, certifications, internal equity, etc. Depending on an employee’s assigned worksite or location, Amtrak may consider a geo-pay differential to be applied to the employee’s base salary. Amtrak may offer additional incentive and pay programs to recognize and reward our employees, including a short-term incentive bonus based upon factors such as individual and company performance that is commensurate with the level of the position and/or long-term incentive plan compensation. In addition to your salary, Amtrak offers a comprehensive benefit package that includes health, dental, and vision plans; health savings accounts; wellness programs; flexible spending accounts; 401K retirement plan with employer match; life insurance; short and long term disability insurance; paid time off; back-up care; adoption assistance; surrogacy assistance; reimbursement of education expenses; Public Service Loan Forgiveness eligibility; Railroad Retirement sickness and retirement benefits; and rail pass privileges. Learn more about our benefits offerings here .<br/><br/><strong>Requisition ID:</strong>160551<br/><br/><strong>Posting Location(s):</strong>Pennsylvania<br/><br/><strong>Job Family/Function:</strong>Engineering<br/><br/><strong>Relocation Offered:</strong>Yes<br/><br/><strong>Travel Requirements:</strong>Up to 25%<br/><br/><strong>You power our progress through your performance.<br/><br/></strong>We want your work at Amtrak to be more than a job. We want your career at Amtrak to be a fulfilling experience where you find challenging work, rewarding opportunities, respect among colleagues, and attractive compensation. Amtrak maintains a culture that values high performance and recognizes individual employee contributions.<br/><br/>Amtrak is committed to a safe workplace free of drugs and alcohol. All Amtrak positions requires a pre-employment background check that includes prior employment verification, a criminal history check and a pre-employment drug screen.<br/><br/>Candidates who test positive for marijuana will be disqualified, regardless of any state or local statute, ordinance, regulation, or other law that legalizes or decriminalizes the use or possession of marijuana, whether for medical, recreational, or other use. Amtrak's pre-employment drug testing program is administered in accordance with DOT regulations and applicable law.<br/><br/>In accordance with DOT regulations (49 CFR<br/><br/><ul><li>40.25), Amtrak is required to obtain prior drug and alcohol testing records for applicants/employees intending to perform safety-sensitive duties for covered Department of Transportation positions. If an applicant/employee refuses to provide written consent for Amtrak to obtain these records, the individual will not be permitted to perform safety-sensitive functions.<br/><br/></li></ul>In accordance with federal law governing security checks of covered individuals for providers of public transportation (Title 6 U.S.C.<br/><br/><ul><li>1143), Amtrak is required to screen applicants for any permanent or interim disqualifying criminal offenses.<br/><br/></li></ul>Note that any education requirement listed above may be deemed satisfied if you have an equivalent combination of education, training and experience.<br/><br/>Amtrak is an EOE/Affirmative Action Minority/Female employer, and we welcome all to apply. We consider candidates regardless of race/color, religion, sex (including pregnancy, childbirth and related conditions), national origin/ethnicity, age, disability (intellectual, mental and physical), veteran status, marital status, ancestry, sexual orientation, gender identity and gender expression, genetic information, citizenship or any other personal characteristics protected by law.<br/><br/>
</div>",$86500- $111996,Database Engineer
Data Engineer,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3790367661,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
"Lead Data Engineer (AWS, Azure, GCP)",CapTech,12/19/2023,https://www.linkedin.com/jobs/view/3751642559,0,https://media.licdn.com/dms/image/D4E0BAQEzvZZT9k7tQg/company-logo_100_100/0/1688216361303/captechconsulting_logo?e=2147483647&v=beta&t=wV_XeINYC7gUtPXYwqonUqAssSaid9KiHLw1Hxp4Z7Q,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>CapTech is an award-winning consulting firm that collaborates with clients to achieve what’s possible through the power of technology. At CapTech, we’re passionate about the work we do and the results we achieve for our clients. From the outset, our founders shared a collective passion to create a consultancy centered on strong relationships that would stand the test of time. Today we work alongside clients that include Fortune 100 companies, mid-sized enterprises, and government agencies, a list that spans across the country.<br/><br/><strong>Job Description<br/><br/></strong>CapTech Data Engineering consultants enable clients to build and maintain advanced data systems that bring together data from disparate sources in order to enable decision-makers. We build pipelines and prepare data for use by data scientists, data analysts, and other data systems. We love solving problems and providing creative solutions for our clients. Cloud Data Engineers leverage the client’s cloud infrastructure to deliver this value today and to scale for the future. We enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other developers, architects, and our clients. <br/><br/>The Value You Deliver (or What You’ll Do)<br/><br/><ul><li>Be trusted advisor to customers with best practices, methodologies, and technologies to implement data engineering solutions. </li><li>Design, implement, and maintain modern data pipelines to deliver optimal solutions utilizing appropriate cloud technologies. </li><li>Partner with product owners and business SMEs to analyze customer requirements and provide a supportable and sustainable engineered solution. </li><li>Provide technical leadership and collaborate within and across teams to ensure that the overall technical solution is aligned with the customer needs. </li><li>Stay current with the latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Experience building/operating highly available distributed systems of data extraction, ingestion, and processing large data sets </li><li>5+ years of experience delivering data engineering solutions on cloud platform </li><li>5+ years of experience implementing modern designs using at least one cloud-based solution/platform (AWS, Azure, GCP) </li><li>Advanced level proficiency with at least one ETL / Data Orchestration technology (Azure Data Factory, SSIS, Informatica, Alteryx, Ab Initio, Pentaho, Talend, Matillion) </li><li>Experience cloud-based data warehousing and data lake solutions like Snowflake, Redshift, Databricks </li><li>5+ years of experience with SQL or NoSQL database (PostgreSQL, MySQL, SQL server, Oracle, Aurora, Presto, BigQuery) </li><li>Expertise with SQL, database design/structure and data structure (star, snowflake schemas, de/normalized designs) </li><li>5+ years of experience with at least one programming language (Python, Java, R, C / C# / C++, Shell) </li><li>Familiarity with one or more DevOps tools (git, Jenkins, CI/CD, Jira) </li><li>Fundamental understanding of big data, open source, and data streaming concepts </li><li>Ability to think strategically and provide recommendations utilizing traditional and modern architectural components based on business needs    </li><li>Experience providing technical leadership and mentoring other engineers in data engineering space </li><li>Cloud certification on any platform a plus <br/><br/></li></ul><strong>Additional Information<br/><br/></strong>We want everyone at CapTech to be able to envision a lasting and rewarding career here, which is why we offer a variety of career paths based on your skills and passions. You decide where and how you want to develop, and we help get you there with customizable career progression and a comprehensive benefits package to support you along the way. Alongside our suite of traditional benefits encompassing generous PTO, health coverage, disability insurance, paid family leave and more, we’ve launched extended benefits to help meet our employees’ needs.<br/><br/><ul><li>CapFlex – Employee-first mentality that supports a remote and hybrid workforce and empowers daily flexibility while servicing our clients</li><li>Learning &amp; Development – Programs offering certification and tuition support, digital on-demand learning courses, mentorship, and skill development paths</li><li>Modern Health –A mental health and well-being platform that provides 1:1 care, group support sessions, and self-serve resources to support employees and their families through life’s ups and downs</li><li>Carrot Fertility –Inclusive fertility and family-forming coverage for all paths to parenthood – including adoption, surrogacy, fertility treatments, pregnancy, and more – and opportunities for employer-sponsored funds to help pay for care</li><li>Fringe –A company paid stipend program for personalized lifestyle benefits, allowing employees to choose benefits that matter most to them – ranging from vendors like Netflix, Spotify, and GrubHub to services like student loan repayment, travel, fitness, and more</li><li>Employee Resource Groups – Employee-led committees that embrace and incorporate diversity and inclusion into our day-to-day operations</li><li>Philanthropic Partnerships – Opportunities to engage in partnerships and pro-bono projects that support our communities. </li><li>401(k) Matching – Generous matching and no vesting period to help you continue to build financial wellness<br/><br/></li></ul>CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace. For more information about our Diversity, Inclusion and Belonging efforts, click HERE. As part of this commitment, CapTech will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact Laura Massa directly via email lmassa@captechconsulting.com.<br/><br/>At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.<br/><br/>
</div>",No Salary Info Found,Database Engineer
"Principal Associate, Data Loss Prevention (DLP) Engineer",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3789004010,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Data Engineer,Hyperloop Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3788678577,0,https://media.licdn.com/dms/image/D4E0BAQE5-wtGV9fWBQ/company-logo_100_100/0/1683619007636/hyperlooprecruitment_logo?e=2147483647&v=beta&t=4GRFib2T7ZuyTWESWmNt0g2NBzu40ZTgn23wPDBKEO8,"North Wales, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Data Engineer/Science<br/><br/></strong><strong>Circa 70k<br/><br/></strong><strong>North Wales<br/><br/></strong><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>The Client<br/><br/></strong>We’re representing a multi-billion pound Data Analytics and Software house who’re experience a period of high growth. They’re revolutionising their channel bringing new insights to their tracking software and work with the main players in global performance.<br/><br/>The role sits in the R&amp;D channel and at the crossover of software, hardware, data science and AI. You’ll help come up with new solutions to hard problems, create novel products and support the dev team in building and maintaining core software.<br/><br/>We’re looking for a hybrid Data Science/Engineer to join the team as their first specialist Data employee to leverage the extensive data volume we harvest<br/><br/><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>The Role<br/><br/></strong>As the companies first Data Specialist you’ll be confident working autonomously and help shape the companies Data profile. The role offers the chance to really shape the long term direction of the Data Dept with your decision making influential to the companies plans to scale<br/><br/><strong>Requirements<br/><br/></strong><ul><li>Strong coding skills, Python, Java </li><li>AWS experience</li><li>Ability to create data pipelines and storage in AWS</li><li>Ability to analyse large data sets and present findings</li><li>(nice to have) AI skills<br/><br/></li></ul><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>Benefits<br/><br/></strong><ul><li>Competitive salary, contributory pension scheme</li><li>Hybrid working.</li><li>International travel available</li><li>20% bonus scheme</li><li>Electric Vehicle Salary Sacrifice scheme (after 6 months of joining)<br/><br/></li></ul><strong>AWS - Python - AI - CICD</strong>
</div>",No Salary Info Found,Database Engineer
Sr. Data Engineer (Hybrid),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788642988,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Database Engineer
Senior Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788479916,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>HTML Formatted Response: Senior Data Engineer Job Application Senior Data Engineer Job Application Name:<br/><br/>Email:<br/><br/>Phone:<br/><br/>Upload Resume:<br/><br/>Bullet Points: - Position: Senior Data Engineer - Location: Plano, Texas, United States - About the company: Capital One is a diverse and inclusive company that solves real customer problems using technology - Responsibilities: - Collaborate with Agile teams to design, develop, test, implement, and support technical solutions - Work with a team of experienced developers in machine learning, microservices, and full stack systems - Use programming languages like Java, Scala, Python, and databases like RDBMS and NoSQL - Stay updated on tech trends, learn new technologies, and mentor other engineers - Collaborate with product managers to deliver cloud-based solutions for financial empowerment - Perform unit tests, code reviews, and optimize code performance - Basic Qualifications: - Bachelor's Degree - 4+ years of application development experience - 1+ year of big data technologies experience - Preferred Qualifications: - 5+ years of application development experience in Python, SQL, Scala, or Java - 2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) - 3+ years of experience with distributed data/computing tools - 2+ years of experience in real-time data and streaming applications - 2+ years of experience with NoSQL databases - 2+ years of data warehousing experience - 3+ years of experience with UNIX/Linux and Agile engineering practices - Compensation: - New York City (Hybrid On-Site): $161,900 - $184,800 - San Francisco, California (Hybrid On-Site): $171,500 - $195,800 - Benefits: Capital One offers comprehensive health, financial, and other benefits. Learn more at the Capital One Careers website. - Diversity and Inclusion: Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. - Application Process: Fill out the form above with your name, email, phone, and resume to apply for the position. Thank you for your interest in the Senior Data Engineer position at Capital One.
      </div>",$161900- $184800,Database Engineer
Lead Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788695810,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong><ul><li>Lead Data Engineer - Join our Team at Capital One** *Are you passionate about technology and solving complex business problems? Do you thrive in a collaborative and inclusive work environment? At Capital One, we are a diverse group of problem solvers who use data and emerging technologies to create solutions for our customers. Join us as a Lead Data Engineer and be part of a major transformation within Capital One.* **What You'll Do:** - Collaborate with Agile teams to design, develop, test, implement, and support technical solutions using full-stack development tools and technologies. - Work alongside developers experienced in machine learning, distributed microservices, and full stack systems. - Utilize programming languages like Java, Scala, Python, and open-source databases to work with big data and cloud-based data warehousing services. - Stay up to date with tech trends, experiment with new technologies, join technology communities, and mentor other engineers. - Collaborate with product managers to deliver cloud-based solutions that empower millions of Americans. - Conduct unit tests and code reviews to ensure high-quality and efficient code. **Basic Qualifications:** - Bachelor's Degree. - At least 6 years of experience in application development. - At least 2 years of experience in big data technologies. - At least 1 year of experience with cloud computing (AWS, Microsoft Azure, Google Cloud). **Preferred Qualifications:** - 7+ years of application development experience in Python, SQL, Scala, or Java. - 4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud). - 4+ years of experience with distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL). - 4+ years of experience working on real-time data and streaming applications. - 4+ years of experience with NoSQL implementation (Mongo, Cassandra). - 4+ years of data warehousing experience (Redshift or Snowflake). - 4+ years of experience with UNIX/Linux and basic shell scripting. - 2+ years of experience with Agile engineering practices. *Capital One is committed to providing equal employment opportunities to all individuals regardless of sex, race, age, national origin, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state, or local law. We promote diversity and inclusion in the workplace.* ***To apply, please fill out the form below:*** [HTML FORM HERE - Please provide form details] ***Benefits:*** Capital One offers a comprehensive package of health, financial, and other benefits to support your well-being. Learn more at the [Capital One Careers website](https://www.capitalonecareers.com/benefits). *Note: The salary range for this role will depend on the location. Please refer to the job posting for specific salary information.* *At Capital One, we are committed to providing reasonable accommodations for applicants who require them. If you need accommodation during the application process, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com.* *For technical support or questions about Capital One's recruiting process, please contact Careers@capitalone.com.* *Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe, and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).*</li></ul>
</div>",No Salary Info Found,Database Engineer
Kinaxis Solutions Architect,AMD,12/25/2023,https://www.linkedin.com/jobs/view/3673370369,0,https://media.licdn.com/dms/image/C560BAQEkjpiqeCK9Ag/company-logo_100_100/0/1654804896089/amd_logo?e=2147483647&v=beta&t=YxV2icD1OewEHhtp3fVkCg4oGYgjQFeYAJcgierl4gs,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>WHAT YOU DO AT AMD CHANGES EVERYTHING</strong><p><br/></p>We care deeply about transforming lives with AMD technology to enrich our industry, our communities, and the world. Our mission is to build great products that accelerate next-generation computing experiences – the building blocks for the data center, artificial intelligence, PCs, gaming and embedded. Underpinning our mission is the AMD culture. We push the limits of innovation to solve the world’s most important challenges. We strive for execution excellence while being direct, humble, collaborative, and inclusive of diverse perspectives.<p><br/></p>AMD together we advance_<p><br/></p><strong>The Role</strong><p><br/></p>The Supply Chain Solutions Architect will function as a supply chain planning expert to help design and architect all supply chain planning applications including S&amp;OP, Master, and Factory Planning as well as ATP solution for AMD. Collaborate with individuals across multiple organizations and levels to implement complex business processes and solutions. In addition, the SCM Solution Architect will lead cross-functional teams on global enterprise providing SCM technical strategy, solution design and process transformation initiatives in area of process expertise, delivering defined objectives and business value. You will lead SCM technical strategy by taking the lead analyzing, proposing, designing, and implementing new functionality and solutions within the SCM landscape.<p><br/></p><strong>The Person</strong><p><br/></p>The ideal person for this role has exceptional drive, good people skills and effective communication skills, both verbal and written, with the ability to immediately contribute to a team environment. Proven ability to manage multiple priorities and perform well in a challenging environment, while maintaining an elevated level of client focus. Strong work ethic and high diligence, with a desire to learn.<p><br/></p><strong>Key Responsibilities</strong><p><br/></p><ul><li>Leading, Mentoring and being the primary point of contact for all Kinaxis Rapid Response Authorship, Data Chain Commands and automation flows, performance improvements</li><li>Designing, facilitating, and implementing technology solutions in the field of Supply Chain. e.g., Supply Planning MRP, ATP, Data Management and Analytics.</li><li>Performing comprehensive supply chain analytics to enable strategic and operational decisions.</li><li>Driving solution architecture, ensure technical alignment and facilitate solution delivery across the SCM Function.</li><li>Developing future technology roadmap for Supply Chain.</li><li>Accountable for maintaining elevated levels of solution performance, availability, and stability, demonstrating a commitment to quality.</li></ul><p><br/></p><strong>Preferred Experience</strong><p><br/></p><ul><li>Kinaxis Rapid Response Administrator Level 1 or 2 &amp; Author Level 2 or 3 certification.</li><li>Solid experience working in the supply chain technology space. Semiconductor industry experience strongly preferred.</li><li>Strong experience developing and implementing advanced planning solutions such as Kinaxis Rapid Response, blue yonder, SAP IBP.</li><li>Experience developing and implementing ATP Solutions connecting a supply planning engine to an ERP order management system.</li><li>Firsthand experience with query building and analytics, including supporting application development. Data warehouse development a plus.</li><li>Experience running SQL, Python, Java or J2EE.</li></ul><p><br/></p><strong>Academic Credentials</strong><p><br/></p>Bachelor’s degree in computer science, Industrial Engineering, Operations Research, or other relevant technical engineering degree.<p><br/></p><strong>LOCATION:</strong><p><br/></p>Austin, TX<p><br/></p>At AMD, your base pay is one part of your total rewards package. Your base pay will depend on where your skills, qualifications, experience, and location fit into the hiring range for the position. You may be eligible for incentives based upon your role such as either an annual bonus or sales incentive. Many AMD employees have the opportunity to own shares of AMD stock, as well as a discount when purchasing AMD stock if voluntarily participating in AMD’s Employee Stock Purchase Plan. You’ll also be eligible for competitive benefits described in more detail here.<p><br/></p><em>AMD does not accept unsolicited resumes from headhunters, recruitment agencies, or fee-based recruitment services. AMD and its subsidiaries are equal opportunity, inclusive employers and will consider all applicants without regard to age, ancestry, color, marital status, medical condition, mental or physical disability, national origin, race, religion, political and/or third-party affiliation, sex, pregnancy, sexual orientation, gender identity, military or veteran status, or any other characteristic protected by law. We encourage applications from all qualified candidates and will accommodate applicants’ needs under the respective laws throughout all stages of the recruitment and selection process.</em><p><br/></p>
</div>",No Salary Info Found,Data Architect
Principal Solutions Architect - Data & Analytics,"McLane Company, Inc.",12/24/2023,https://www.linkedin.com/jobs/view/3792744874,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Lead/Principal Technical Architect,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3762362796,0,https://media.licdn.com/dms/image/C560BAQHZ9xYomLW7zg/company-logo_100_100/0/1630658255326/salesforce_logo?e=2147483647&v=beta&t=GvAdJRB6d3hWoiMBjIAOP9tjZzbWxLNF84FnSTgWblE,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.<br/><br/></em>Job Category<br/><br/>Sales<br/><br/>Job Details<br/><br/><strong>About Salesforce<br/><br/></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/>We are currently looking for Lead and Principal level Pre-Sales Technical Architects across multiple verticals, including Communications Media and Tech, Manufacturing, and other industries/verticals.<br/><br/><strong>Team &amp; Role Description<br/><br/></strong>Salesforce’s pre-sales Technical Architects are the solutions team members who know what’s possible and how to make it happen, no matter how sophisticated the challenge appears to be. Their domain and product knowledge allows them to serve as domain experts on the account team, not only in terms of product and domain knowledge, but also in how to craft the right solutions to satisfy both business and IT buyers. They are not afraid to dig into the inner workings of our platform to answer an exciting question or address an objection, and are equally comfortable speaking to a room of software developers as they are to the CIO. They are willing to be honest about potential challenges and always keep the long-term success of the customer in mind. People who enjoy both working with technology in a deep way and relating to people will excel in this role. Curiosity, communication, and capacity for learning, are key pillars for successful Technical Architects.<br/><br/><strong>Your Impact<br/><br/></strong>The most effective Technical Architects focus on these areas of impact:<br/><br/><ul><li></li><ul><li>Work with customers in their aligned vertical or market segment to address and tackle a wide variety of technical challenges, using the industry -leading capabilities of the Salesforce Platform and portfolio solutions.</li><li>Develop relationships with customer IT partners, and help them to understand how the Salesforce platform fits into their overall technology strategy.</li><li>Act as a trusted advisor, and guide customers towards solutions that have the greatest likelihood of long-term success.</li><li>Hone knowledge of the Salesforce platform through hands-on training and exploration in the areas of customization, integration, and service delivery, and support our account-aligned solution engineers when this deeper level of expertise is needed to tackle customer challenges.</li><li>Promote the value proposition, benefits, and advantages, of the Salesforce Platform including Hyperforce, Data Cloud, Einstein AI, Mulesoft, Slack and more. Educate customers and peers on the possibilities of building and customizing Platform applications.</li><li>Understand and advise on the broad ecosystem of ISV and partner solutions that collaborate and integrate with Salesforce.</li><li>Guide deal strategy by providing insight into the technical buyer, and craft influence strategies that resonate with this audience.</li><li>Keep current with both partner and competitive technologies in order to put proposed solutions into the context of the broader technology landscape.</li><li>Highlight insights from customer conversations with our product teams to help ensure we are moving in the direction of market needs.</li><li>Share your knowledge, best practices, and lessons learned with the broader solution engineering teams to multiply the impact of your work.</li><li>Continue to develop yourself as a technologist and as a presales professional in an encouraging, collaborative team environment.<br/></li></ul></ul><strong>Baseline Requirements<br/><br/></strong><ul><li></li><ul><li>Ability to understand business &amp; IT department requirements, translate those business needs into a compelling solution, and present your recommendations to executive, technical, and business audience.</li><li>Deep knowledge of enterprise software applications and their delivery</li><li>Some coding experience and a willingness to work with code (Apex, Node, Go, R, Java or C#, JavaScript, python, Ruby, etc.)</li><li>Database and data management fundamentals</li><li>Web and mobile application development and architecture</li><li>Application lifecycle management</li><li>Integration principles and tools</li><li>Enterprise data management tools and methods</li><li>Process orchestration</li><li>Principles of network, application, and information security</li><li>Strong oral, written, presentation, and interpersonal communication and relationship skills.</li><li>Strategic problem solver, thought leadership and comfort communicating with executive audiences.</li><li>Excellent time management skills and the ability to support multiple, concurrent projects.</li><li>Lifelong learner, inquisitive, practical, and passionate about technology and sharing knowledge.</li><li>Willing and able to travel domestically.</li><li>Bachelor’s degree in Computer Science, MIS, Software Engineering, Electrical Engineering, Data Science, Management Information Systems, other STEM degrees or equivalent work experience. Graduate study a plus.<br/></li></ul></ul><strong>Preferred Requirements<br/><br/></strong><ul><li></li><ul><li>Experience working as an architect, solution engineer, IT consultant or developer in a customer facing role that provided differentiated software technology solutions. We are open to a variety of backgrounds.</li><li>Experience in roles that required working hands-on to build, implement, administrate, or maintain enterprise software (e.g. software engineer, implementation architect, integration architect, or similar).</li><li>Understanding of risk mitigation, compliance and security.</li><li>Experience with design thinking, persona-based discovery or other innovation techniques.</li><li>Proven experience in a specific field, vertical or market segment is helpful.</li><li>Knowledge of the Salesforce platform, including Salesforce Certifications and/or Trailhead Superbadges<br/></li></ul></ul>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.<br/><br/>﻿Salesforce welcomes all.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.<br/><br/>For New York-based roles, the base salary hiring range for this position is $127,960 to $277,480.<br/><br/>For Colorado-based roles, the base salary hiring range for this position is $116,270 to $252,210.<br/><br/>For Washington-based roles, the base salary hiring range for this position is $127,960 to $277,480.<br/><br/>For California-based roles, the base salary hiring range for this position is $127,960 to $277,480.<br/><br/>Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.
      </div>",$127960- $277480,Data Architect
Hiring: Cloud Data Architect - 100% Remote - Only for Texas Candidates,My3Tech,12/19/2023,https://www.linkedin.com/jobs/view/3788166760,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
SoC Architect,Meta,12/19/2023,https://www.linkedin.com/jobs/view/3737754962,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Meta is seeking a SoC Architect to join its silicon team within the Infrastructure organization which is responsible for designing and operating all of Meta’s Data Centers. These Data Centers are the foundation upon which our rapidly scaling business operates, and upon which all of our services such as Facebook, Instagram, Messenger, WhatsApp etc. are delivered to our worldwide user base consisting of approximately half of the world’s population. This silicon team is responsible for building hardware accelerators for Data Center servers, to offload the most computationally demanding workloads and execute them with higher performance and lower energy consumption as compared to running them on the CPU/GPU of the server. This is an architect role in which you will be defining the architecture of the next generation of Machine Learning ASICs being built on the most modern process technologies and featuring industry leading performance and feature sets.<br/><br/>SoC Architect Responsibilities:<br/><br/><ul><li>Work on modeling, performance analysis and architecture definition of Machine Learning ASICs.</li><li>Map Data Center workloads to heterogeneous ASICs that contain multiple different programmable processors and hardware accelerators. Perform detailed calculations to specify computation throughput, memory bandwidth and latency, evaluate performance v/s area v/s power tradeoffs.</li><li>Identify appropriate workloads and micro-benchmarks to be used for performance analysis and drive this analysis on simulation and emulation platforms to define and validate the architecture.</li><li>Evangelize your innovative architectural solutions with your peers and leadership, while mentoring members of the architecture team.</li><li>Collaborate with cross functional teams working on RTL design, Design Verification, Firmware/Software development, Pre-Post silicon validation and Program Management to deliver first pass functional silicon on an aggressive schedule.</li><li>Collaborate with software and firmware teams to ensure that the ASIC meets end to end application performance goals while maintaining ease and efficiency of software development.<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.</li><li>Experience and knowledge of Computer Architecture concepts such as microprocessor architecture, memory systems, on-chip interconnection networks, hardware/software partitioning etc.</li><li>Programming in C or C++ with knowledge of mapping hardware algorithms to efficient C/C++ code.</li><li>12+ years of prior experience in defining and delivering multiple high performance ASICs into production, with focus on architecture definition and performance analysis.<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Master's or PhD degree in Electrical Engineering, Computer Engineering or related field.</li><li>Domain knowledge in one or more of power/performance tradeoffs, digital signal processing, ML networks, ML frameworks such as Pytorch.<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data Architect
Cloud Data Architect,My3Tech,12/20/2023,https://www.linkedin.com/jobs/view/3789027593,0,https://media.licdn.com/dms/image/C4E0BAQEOpna1Pdu6LA/company-logo_100_100/0/1645490261667/my3tech_inc_logo?e=2147483647&v=beta&t=8gm_uZtYJq75aMUknU4Srp8WJI3ACXhgTDf3wLyfbZc,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Hello, </p><p>Wishes for the day,</p><p>Hope you’re doing great! </p><p>I am Niranjan from My3Tech, we are one of the leading “IT professional services provider”.</p><p><br/></p><p><strong>Cloud Data Architect</strong></p><p><strong>Austin, TX 78754 (Remote within TX)</strong></p><p><strong>7 months Contract with possibility to extension.</strong></p><p><br/></p><p> Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes. Investigates problem areas. Prepares and installs solutions by determining and designing system specifications, standards, and programming.</p><p><br/></p><p> Client requires the services of a Cloud Data Architect who will provide strategic guidance in the development process, make technical decisions regarding solutions and explain how they will impact the organization.</p><p>As part of Clients’ IT Applications – Social Services Applications initiatives, the Cloud Data Architect will be responsible for:</p><ul><li>Provide services in relation to data modeling, data integration, data warehousing, data governance, and data security</li><li>Develop migration strategies from on-premises databases to cloud-native database technologies</li><li>Develop, update and maintain conceptual, logical, and physical data models to support changing business requirements</li><li>Design and implement data architectures that enable efficient data storage, retrieval and analysis</li><li>Ensure data integrity, security, and performance for all databases</li><li>Design and implement data integration solutions to enable seamless dataflow across systems</li><li>Collaborate with cross functional teams to implement cloud-based data integration solutions</li><li>Perform database optimization, capacity planning and performance monitoring </li><li>Provide expertise with data migration and data archival in AWS cloud</li><li>Provide expertise on AWS Cloud database infrastructure</li><li>Design and implement high availability and disaster recovery solutions to minimize database downtime for planned/unplanned outages</li><li>Perform database tuning, benchmark techniques, database sharding, table partitioning, horizontal/vertical scaling, user load, identification/measuring bottlenecks, system optimization</li><li>Leads and ensures Clients’ best practices and methodologies are applied to the design, deployment, and operations in the cloud. </li><li>Supporting DevOps functions to best utilize cloud resources with software configuration management and continuous integration tools.</li><li>Other duties as assigned.</li></ul><p> </p><p><strong>Education:</strong></p><ul><li>Graduation from an accredited four-year college or university with major course work in computer science, computer information systems, engineering, or management information systems is preferred.</li></ul><p> </p><p><strong>Certification:</strong></p><ul><li>Cloud Solutions Architect Certification </li><li>Cloud Infrastructure Certifications</li></ul><p> </p><p><strong>Candidate Skills And Qualifications:</strong></p><p> Years</p><p> Required/Preferred</p><p> Experience</p><p> 8 Required</p><p> Experience with data modeling, data integration, data warehousing, data governance, and data security</p><p> 8 Required</p><p> Experience developing migration strategies for on-premises databases to cloud-native database technologies</p><p> 8 Required</p><p> Experience developing, updating and maintaining conceptual, logical, and physical data models to support changing business requirements</p><p> 8 Required</p><p> Experience designing and implementing data architectures that enable efficient data storage, retrieval and analysis</p><p> 8 Required</p><p> Experience designing and implementing high availability and disaster recovery solutions to minimize database downtime for planned/unplanned outages</p><p> 8 Required</p><p> Experience with Oracle and/or PostgreSQL in HA deployments and Expertise in data storage</p><p> 8 Required</p><p> Experience migrating Oracle RAC/Exadata infrastructure to a public cloud environment</p><p> 8 Required</p><p> Experience designing and implementing effective and efficient data models</p><p> 8 Required</p><p> Experience with database performance tuning benchmark techniques, database sharding, table partitioning, horizontal/vertical scaling, user load, identification/measuring bottlenecks, system optimization</p><p> 8 Required</p><p> Hands-on experience with Agile development, Program management/project management experience for large cloud migrations</p><p> 8 Required</p><p> Hands on experience with database services like RDS, RDS Proxy and other Data Services.</p><p> 8 Required</p><p> Experience with replication of databases and other types of data.</p><p> 8 Required</p><p> Experience transforming data into cloud native storage and other formats.</p><p> 8 Required</p><p> Experience using standard concepts, practices, and procedures of cloud technology, including Software as a Service (SaaS), Platform as a Service (PaaS), or Infrastructure as a Service (IaaS).</p><p> 8 Required</p><p> Hands-on experience with adjacent technology areas including Security, Identity / Access </p><p>Management and Monitoring.</p><p> 6 Preferred</p><p> Hands-on experience as a platform engineer for Cloud platform</p><p> 6 Preferred</p><p> Hands-on experience with CI/CD methodology</p><p> 6 Preferred</p><p> Hands-on development experience for mobile and tablet platforms</p><p> 6 Preferred</p><p> Experience with APIs design and implementation.</p><p> 6 Preferred</p><p> Experience with Web services and RESTful APIs</p><p> 6 Preferred</p><p> Experience with Monitoring tools </p><p> 6 Preferred</p><p> Experience with DevOps tools GitLab, Jenkins, and Container</p><p><br/></p><p>Kindly respond if you are interested and willing to apply to this role. You can contact me on 605-954-2319 or email me at niranjan.chekka@my3tech.com</p><p> </p><p>Thank you,</p><p></p>
</div>",No Salary Info Found,Data Architect
Cloud Solution Architect,TechFetch.com - On Demand Tech Workforce hiring platform,12/20/2023,https://www.linkedin.com/jobs/view/3790517870,0,https://media.licdn.com/dms/image/C4D0BAQGtxK8lQK4Fjw/company-logo_100_100/0/1631303270093?e=2147483647&v=beta&t=CPAuTDoADgdQXNI3fnXooGxEOZTebEi7kiV0wvX4d-o,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong>""ALL our jobs are US based and candidates must be in the US with valid US Work Authorization. Please apply on our website directly."" We are looking for a Full-time contractor or employee for a Cloud Solution Architect role.Develops software solutions by studying information needs, conferring with users, and studying systems flow, data usage, and work processes. Investigates problem areas. Prepares and installs solutions by determining and designing system specifications, standards, and programming.As part of HHSC IT Applications – Social Services Applications initiatives, the Cloud Data Architect will be responsible for:<br/><br/><ul><li> Provide services in relation to data modeling, data integration, data warehousing, data governance, and data security</li><li> Develop migration strategies from on-premises databases to cloud-native database technologies</li><li> Develop, update and maintain conceptual, logical, and physical data models to support changing business requirements</li><li> Design and implement data architectures that enable efficient data storage, retrieval and analysis</li><li> Ensure data integrity, security, and performance for all databases</li><li> Design and implement data integration solutions to enable seamless dataflow across systems</li><li> Collaborate with cross functional teams to implement cloud-based data integration solutions</li><li> Perform database optimization, capacity planning and performance monitoring</li><li> Provide expertise with data migration and data archival in AWS cloud</li><li> Provide expertise on AWS Cloud database infrastructure</li><li> Design and implement high availability and disaster recovery solutions to minimize database downtime for planned/unplanned outages</li><li> Perform database tuning, benchmark techniques, database sharding, table partitioning, horizontal/vertical scaling, user load, identification/measuring bottlenecks, system optimization</li><li> Leads and ensures HHSC best practices and methodologies are applied to the design, deployment, and operations in the cloud.</li><li> Supporting DevOps functions to best utilize cloud resources with software configuration management and continuous integration tools.</li><li> Other duties as assigned.<br/><br/></li></ul>Education<br/><br/>Graduation from an accredited four-year college or university with major course work in computer science, computer information systems, engineering, or management information systems is preferred.<br/><br/><strong>Certification<br/><br/></strong>Cloud Solutions Architect Certification<br/><br/>Cloud Infrastructure Certifications<br/><br/><strong>Skills(Required)<br/><br/></strong>Experience with data modeling, data integration, data warehousing, data governance, and data security<br/><br/>Experience developing migration strategies for on-premises databases to cloud-native database technologies<br/><br/>Experience developing, updating and maintaining conceptual, logical, and physical data models to support changing business requirements<br/><br/>Experience designing and implementing data architectures that enable efficient data storage, retrieval and analysis<br/><br/>Experience designing and implementing high availability and disaster recovery solutions to minimize database downtime for planned/unplanned outages<br/><br/>Experience with Oracle and/or PostgreSQL in HA deployments and Expertise in data storage<br/><br/>Experience migrating Oracle RAC/Exadata infrastructure to a public cloud environment<br/><br/>Experience designing and implementing effective and efficient data models<br/><br/>Experience with database performance tuning benchmark techniques, database sharding, table partitioning, horizontal/vertical scaling, user load, identification/measuring bottlenecks, system optimization<br/><br/>Hands-on experience with Agile development, Program management/project management experience for large cloud migrations<br/><br/>Hands on experience with database services like RDS, RDS Proxy and other Data Services.<br/><br/>Experience with replication of databases and other types of data.<br/><br/>Experience transforming data into cloud native storage and other formats.<br/><br/>Experience using standard concepts, practices, and procedures of cloud technology, including Software as a Service (SaaS), Platform as a Service (PaaS), or Infrastructure as a Service (IaaS<br/><br/>Hands-on experience with adjacent technology areas including Security, Identity / Access Management and Monitoring.<br/><br/><strong>Skills(Preferred)<br/><br/></strong>Hands-on experience as a platform engineer for Cloud platform<br/><br/>Hands-on experience with CI/CD methodology<br/><br/>Hands-on development experience for mobile and tablet platforms<br/><br/>Experience with APIs design and implementation.<br/><br/>Experience with Web services and RESTful APIs<br/><br/>Experience with Monitoring tools<br/><br/>Experience with DevOps tools GitLab, Jenkins, and Container
      </div>",No Salary Info Found,Data Architect
Principal Solution Architect,Cognite,12/20/2023,https://www.linkedin.com/jobs/view/3747220481,0,https://media.licdn.com/dms/image/C4D0BAQGC13jzkSlNzA/company-logo_100_100/0/1630519344428/cognitedata_logo?e=2147483647&v=beta&t=RCiDA6hWBIcQnVdAQBuw92JFbPphdZ_muja84nPbTb4,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Cognite And Cogniters<br/><br/></strong>Cognite is a global leader in industrial software with our Industrial DataOps platform, Cognite Data Fusion®, at the core. We were awarded the 2022 Technology Innovation Leader for Global Digital Industrial Platforms .<br/><br/>At Cognite, the Global Delivery team leads software implementation, deployment &amp; adoption for clients, and helps them accelerate their digital transformation efforts with Cognite’s product suite. We consist of people with diverse and high-performance backgrounds, ranging from Management Consulting, to Industry and Software development. We seek to continuously improve how we work with our clients, how we work together as a team, and how we develop as individuals.<br/><br/>The <strong>Principal Solutions Architect</strong> is responsible for the design of complex end to end solutions, merging our flagship products with the customer's portfolio, for both new and existing clients. You are a technical subject matter expert in all offerings across the professional and managed services catalog. From discovery through implementation, you will work closely with the sales team and the delivery teams, as well as our data scientists and customers to map out technical requirements and architect robust and familiar solutions.<br/><br/>Through your work with our strategic customers, you will identify opportunities for new products and features, and work with our product managers and tech leads to continuously improve Cognite's SaaS offering.<br/><br/>This role is a mix of consulting, architecture, and product development in a welcoming cross-functional team. Above all else, we strive to foster a supportive team environment where everyone is excited to share ideas, ask for help, and learn from each other.<br/><br/><strong>This role is a Hybrid role our of the Austin office. Unfortunately, we are unable to offer relocation assistance. <br/><br/></strong><strong>What You'll Do<br/><br/></strong><ul><li>As a Principal Solutions Architect, you will be an expert in how we implement our Cognite SaaS offerings and applications. </li><li>Your primary responsibility will be to work with project teams to map requirements for a quality implementation ensuring that:</li><li>The right data visualization technology is used in the right way (E.g Power BI, Grafana, Plotly Dash)</li><li>The right data transformation technology is used in the right way (E.g Databricks, Azure, GCP, AWS)</li><li>The data is efficiently modeled and contextualized in Cognite Data Fusion (E.g graph and relational)</li><li>Integrations are well thought out and robustImportant quality criteria for the solution are met (E.g. CI/CD, logging, security)</li><li>Operational responsibility and support agreements for the delivered solution are clearly defined</li><li>Design overall technical solution and ensure technical fit within the customer ecosystem and target architecture</li><li>Design integration and data model using Cognite data connectors, SQL, Python/Java and Rest APIs</li><li>Credible advisor to our customers and partners on Cognite Data Fusion<br/><br/></li></ul><strong>Who You Are<br/><br/></strong><ul><li>10+ years experience as an application/data/solution/enterprise architect</li><li>3+ years of experience from the heavy asset industry related to downstream, petrochemicals or energy is required</li><li>Experience with operational data and customer business drivers in the heavy asset industry</li><li>Bachelor's degree is required; Masters degree a plus</li><li>Consulting experience that allows you to confidently negotiate requirements with customers and colleagues</li><li>Have experience with enterprise integration, customer relationships or IT integration design</li><li>Data and analytics project experience and able to confidently lead an implementation</li><li>Broad technical experience with data and analytics stacks</li><li>Familiarity with Business Intelligence tools and enterprise analytics stacks (Power BI or similar)</li><li>Familiarity with SQL and big data tooling (E.g Apache Spark ecosystem)</li><li>Experience with a public cloud, preferably AWS, GCP or Azure, including familiarity with network security concepts, identity providers and application hosting</li><li>Experience with operations, including support and change control, as well as experience architecting centralized monitoring, logging and reporting</li><li>Have a DevOps mindset, and experience with Git, CI/CD, deployment environments</li><li>Technical background, willing and able to dive in and contribute code for advanced topics when needed</li><li>Have architectural skills dealing with data modeling and infrastructure solutions, such as classical data warehousing and big data architectures<br/><br/></li></ul><strong>Why choose Cognite? 🏆 🚀<br/><br/></strong><ul><li>Join us in making a real and lasting impact in one of the most exciting and fastest-growing new software companies in the world. </li><li>We have repeatedly demonstrated that digital transformation, when anchored on strong DataOps, drives business value and sustainability for clients and allows front-line workers, as well as domain experts, to make better decisions every single day. </li><li>We were recognized as one of CNBC's top global enterprise technology startups powering digital transformation ! </li><li>And just recently, Frost &amp; Sullivan named Cognite a Technology Innovation Leader !<br/><br/></li></ul><strong>A snapshot of our many perks and benefits as a Cogniter<br/><br/></strong><ul><li>Competitive Compensation including base plus bonus</li><li>401(k) with 4% employer matching</li><li>Health, Dental, Vision &amp; Disability Coverages with premiums fully covered for employees and all dependents</li><li>Unlimited PTO + flexibility to enjoy it</li><li>18 Company Holidays including the week between Christmas &amp; New Years</li><li>Paid Parental Leave Program</li><li>Employee Stock Purchase Program (ESPP)</li><li>Employee Referral Program</li><li>Company Paid Friday Lunch via DoorDash + Fully Stocked Fridges in the offices</li><li>Join a team of 70 different nationalities 🌐 with Diversity, Equality and Inclusion (DEI) in focus 🤝.</li><li>A highly modern and fun working environment with sublime culture across the organization, follow us on Instagram @ cognitedata 📷 to know more</li><li>Opportunity to work with and learn from some of the best people on some of the most ambitious projects found anywhere, across industries</li><li>Join our HUB 🗣️ to be part of the conversation directly with Cogniters and our partners.</li><li>Paid mobile phone and WiFI</li><li>A pet lover? Get the chance to meet Spot 🐶!<br/><br/></li></ul>Cognite is a global industrial SaaS company that was established with one clear vision: to rapidly empower industrial companies with contextualized, trustworthy, and accessible data to help drive the full-scale digital transformation of asset-heavy industries around the world. Our core Industrial DataOps platform, <strong>Cognite Data Fusion™, </strong>enables industrial data and domain users to collaborate quickly and safely to develop, operationalize, and scale industrial AI solutions and applications to deliver both profitability and sustainability. Visit us at www.cognite.com and follow us on Twitter @CogniteData or LinkedIn: https://www.linkedin.com/company/cognitedata<br/><br/><strong>Equal Opportunity<br/><br/></strong>Cognite is committed to creating a diverse and inclusive environment at work and is proud to be an equal opportunity employer. All qualified applicants will receive the same level of consideration for employment; everyone we hire will receive the same level of consideration for training, compensation, and promotion.<br/><br/>We ask for gender as part of our application because we want to ensure equal assessment in the recruitment process. Your answer will help us reach this commitment! However, the question about gender is optional and your choice not to answer will not affect the assessment of your application in any way.
      </div>",No Salary Info Found,Data Architect
Senior Data Engineer (GCP Platform) (R-15496),Dun & Bradstreet,12/20/2023,https://www.linkedin.com/jobs/view/3785602179,0,https://media.licdn.com/dms/image/D4E0BAQHlVerw9jUZmg/company-logo_100_100/0/1688672958148/dun__bradstreet_logo?e=2147483647&v=beta&t=_mgRTudaSVLFKA6zm6txCsxAfmA4ocrV9hhizz5z2Ro,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Why We Work at Dun &amp; Bradstreet<br/><br/></strong>Dun &amp; Bradstreet unlocks the power of data through analytics, creating a better tomorrow. Each day, we are finding new ways to strengthen our award-winning culture and accelerate creativity, innovation and growth. Our 6,000+ global team members are passionate about what we do. We are dedicated to helping clients turn uncertainty into confidence, risk into opportunity and potential into prosperity. Bold and diverse thinkers are always welcome. Come join us!<br/><br/><strong>The Role<br/><br/></strong>Dun &amp; Bradstreet is looking for a Senior Data Engineer - GCP Platform to join our Technology team.<br/><br/>Senior Data Engineer - GCP Platform will be part of a group responsible for designing, implementing, maintaining and supporting Data &amp; Analytics Platform applications.<br/><br/>The Senior Data Engineer - GCP Platform will leverage modern processes and tools in ensuring highest quality data in the Dun &amp; Bradstreet Data Supply Chains.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>Strong organization skills with high attention to detail </li><li>Able to work independently with minimal supervision </li><li>Excellent communication skills – written, verbal, presentation and interpersonal </li><li>Willing to learn new skills and implement new technologies</li><li>A thirst for knowledge, learning, and problem solving </li><li>Develop Data pipelines/Ingestion/Engineering and Analytic Application processes to business specification and technology standards that leverage/extend existing Data &amp; Analytics platforms using a variety of Tech stack including (but not limited to) AWS, Google Cloud Platform, Informatica, Streamsets and Acceldata.</li><li>Collaborate with project teams (solution architects, business, QA and project management) to ensure solutions meet business objectives and fall within timelines and acceptance criteria</li><li>Participate in testing of prototypes &amp; validate test procedures to ensure that they are applicable to the design </li><li>Application support/ bug fixes / QA </li><li>Perform root-cause analysis (RCA) of complex issues ranging from hardware, operating system, application, network, and information security platforms while working closely with various infrastructure teams and business users to quickly arrive at creative, tactical and long-term solutions. <br/><br/></li></ul><strong>Key Requirements<br/><br/></strong><ul><li>Bachelor’s degree in computer science, information systems, or other related field or equivalent work experience.</li><li>5+ years of high-tech industry and/or IT work experience in Big Data project hands on development and solution engineering roles. </li><li>Experience in Data Analytics, SQL, Python, PySpark, Shell Script, DataBricks.</li><li>Experience with Google Cloud Platforms (and capabilities) is required.</li><li>Experience with Informatica, Streamsets and Acceldata a strong plus. </li><li>Experience in Informatica BDM, AXON &amp; Analyst, Power BI.</li><li>Experience with working on projects in multiple technological and business environments simultaneously.</li><li>Understanding of micro-services, web-based applications and REST APIs.<br/><br/></li></ul><strong>Benefits We Offer<br/><br/></strong><ul><li> Generous paid time off in your first year, increasing with tenure.</li><li> Up to 16 weeks 100% paid parental leave after one year of employment.</li><li> Paid sick time to care for yourself or family members.</li><li> Education assistance and extensive training resources.</li><li> Do Good Program: Paid volunteer days &amp; donation matching.</li><li> Competitive 401k &amp; Employee Stock Purchase Plan with company matching.</li><li> Health &amp; wellness benefits, including discounted Gympass membership rates.</li><li> Medical, dental &amp; vision insurance for you, spouse/partner &amp; dependents.</li><li> Learn more about our benefits: http://bit.ly/41Yyc3d .<br/><br/></li></ul>All Dun &amp; Bradstreet job postings can be found at https://www.dnb.com/about-us/careers-and-people/joblistings.html . Official communication from Dun &amp; Bradstreet will come from an email address ending in @dnb.com.<br/><br/>Notice to Applicants: Please be advised that this job posting page is hosted and powered by Lever. Your use of this page is subject to Lever's Privacy Notice and Cookie Policy , which governs the processing of visitor data on this platform.<br/><br/><strong><em>Equal Employment Opportunity (EEO):</em></strong><em> Dun &amp; Bradstreet is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, creed, sex, age, national origin, citizenship status, disability status, sexual orientation, gender identity or expression, pregnancy, genetic information, protected military and veteran status, ancestry, marital status, medical condition (cancer and genetic characteristics) or any other characteristic protected by law. View the EEO is the Law poster </em><em> here </em><em> and its supplement </em><em> here. </em><em> View the pay transparency policy </em><em> here </em><em>.</em>
</div>",No Salary Info Found,Data Architect
Cloud Data Architect,Dice,12/21/2023,https://www.linkedin.com/jobs/view/3791475781,0,https://media.licdn.com/dms/image/C560BAQEYK67Tel_mng/company-logo_100_100/0/1630655500596/dice_logo?e=2147483647&v=beta&t=rllH_-w7fwNGRPjMmwRghSwN8osS0JKW18T_-sIwDn4,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Vignesh Technological Solutions Inc, - VTSI, is seeking the following. Apply via Dice today!<br/><br/><strong>Title: Cloud Data Architect<br/><br/></strong><strong>Duration: 12 months<br/><br/></strong><strong>Location: This is a remote role from anywhere within Texas.<br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li>Experience with data modeling, data integration, data warehousing, data governance, and data security.</li><li>Experience developing migration strategies for on-premises databases to cloud-native database technologies.</li><li>Experience developing, updating and maintaining conceptual, logical, and physical data models to support changing business requirements.</li><li>Experience designing and implementing data architectures that enable efficient data storage, retrieval and analysis.</li><li>Experience designing and implementing high availability and disaster recovery solutions to minimize database downtime for planned/unplanned outages.</li><li>Experience with Oracle and/or PostgreSQL in HA deployments and Expertise in data storage.</li><li>Experience migrating Oracle RAC/Exadata infrastructure to a public cloud environment.</li><li>Experience designing and implementing effective and efficient data models.</li><li>Experience with database performance tuning benchmark techniques, database sharding, table partitioning, horizontal/vertical scaling, user load, identification/measuring bottlenecks, system optimization.</li><li>Hands-on experience with Agile development, Program management/project management experience for large cloud migrations.</li><li>Hands on experience with database services like RDS, RDS Proxy and other Data Services.</li><li>Experience with replication of databases and other types of data.</li><li>Experience transforming data into cloud native storage and other formats.</li><li>Experience using standard concepts, practices, and procedures of cloud technology, including Software as a Service (SaaS), Platform as a Service (PaaS), or Infrastructure as a Service (IaaS).</li><li>Hands-on experience with adjacent technology areas including Security, Identity / Access Management and Monitoring.<br/><br/></li></ul><strong>Certification:<br/><br/></strong><ul><li>Cloud Solutions Architect Certification</li><li>Cloud Infrastructure Certifications<br/><br/></li></ul><strong>Thanks and Regards</strong>
</div>",No Salary Info Found,Data Architect
Junior Data Analyst - US Residents Only,Team Remotely Incorporation,12/25/2023,https://www.linkedin.com/jobs/view/3793150443,0,https://media.licdn.com/dms/image/D4D0BAQFKPwUb2y1chw/company-logo_100_100/0/1702987730303?e=2147483647&v=beta&t=-X5LVvheBqm_7DpHnmichw7-gf09NLhB7Tq6GJJcKm8,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong> Junior Data Analyst - US Residents Only, 1 year experience, remote)<br/><br/></strong>Team Remotely Inc. is a staffing and recruitment agency that offers a comprehensive solution for talent acquisition, including sourcing, vetting, pay rolling, and managing talent. Whether you need contract staffing, direct hire, direct sourcing, talent pools, or diversity initiatives, our model can support your hiring strategy.<br/><br/><strong> Hiring Type:</strong> Full-Time<br/><br/><strong> Base Salary:</strong> $60K-$70K Per Annum.<br/><br/><strong> How to Apply:</strong> Please visit teamremotely.com to learn more &amp; apply.<br/><br/><strong>Role Responsibilities:<br/><br/></strong>Work in close collaboration with the Business Intelligence Lead, Federal Data Lead, and other Program teams<br/><br/>Develop, maintain, and improve BI tools, build and enhance standard operating procedures (SOPs)<br/><br/>Manage various data sets and active Google workbooks with adjacent contract teams, monitor and analyze financial health information at the project and program levels<br/><br/>Communicate with client leadership to assess data needs and emerging requirements<br/><br/>Work with large data sets, workbooks, and spreadsheets to manipulate and manage program-level information using macros, queries, scripts, etc.<br/><br/>Gather requirements and lead the development of long-term data management tools, processes, and solutions based on organizational needs.<br/><br/>Be comfortable working with collaboration tools such as; Google Suite, Microsoft Office<br/><br/>Providing general support to the client including, but not limited to, analysis, data calls, financial management, risk management, audits, and project management-related tasks.<br/><br/><strong>Qualifications:<br/><br/></strong>Bachelor's Degree in business, business intelligence, data or information management, or similar.<br/><br/>Proficient in Google Scripts<br/><br/>Minimum 1 year of data or information management and/or data analysis experience.<br/><br/>Experience using Microsoft Excel and Google Sheets (macros, imports, query functions).<br/><br/>Experience with developing in Google App Script is a plus.<br/><br/>Experience using SQL Developer is a plus.<br/><br/>Excellent written and verbal communication skills.<br/><br/>Willing to work in an administratively manual environment while working towards automation of processes in the future.<br/><br/><strong> Why work with Team Remotely?<br/><br/></strong>Team Remotely Inc. is a staffing platform offering a seamless experience for employers and candidates. Employers can post job openings and specify their requirements, while candidates can create profiles and upload resumes.<br/><br/>The team of Team Remotely continuously learns and adapts based on previous successful placements, constantly improving its matching capabilities. This ensures that the recommendations provided by Team Remotely are tailored and accurate, increasing the likelihood of a successful match between employers and candidates. By providing intelligent and data-driven solutions, they strive to enhance the efficiency and effectiveness of the hiring process, ultimately helping companies find the best talent and individuals find their dream jobs.<br/><br/>
</div>",$60- $70,Data Architect
Sr. Salesforce Data Cloud Solutions Architect,GoodRx,12/20/2023,https://www.linkedin.com/jobs/view/3774984195,0,https://media.licdn.com/dms/image/C4D0BAQEqY0JPdZEDFw/company-logo_100_100/0/1634331204199/goodrx_logo?e=2147483647&v=beta&t=WX-OOnQagHgq1KecoVE5rKXXYURXN9Q_F94JbIJJ2CU,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        GoodRx is America’s healthcare marketplace. Each month, millions of people visit goodrx.com to find reliable health information and discounts for their healthcare — and we’ve helped people save $60 billion since 2011. We provide prescription discounts that are accepted at more than 70,000 pharmacies in the U.S., as well as telehealth services including doctor visits and lab tests. Our services have been positively reviewed by Good Morning America, The New York Times, NBC News, AARP, and many others.<br/><br/>Our goal is to help Americans find convenient and affordable healthcare. We offer solutions for consumers, employers, health plans, and anyone else who shares our desire to provide affordable prescriptions to all Americans.<br/><br/><strong>About The Role<br/><br/></strong>GoodRx is in search of a Senior Salesforce Data Cloud Solutions Architect to assist the Enterprise Business Solutions team to design, implement and recommend best practices on our Salesforce Data Cloud platform. We are looking for someone with a unique combination of technical skills and strategic thinking who can transform complex analyses into solutions supporting a high growth business area. An ideal candidate will also have some Marketing Cloud experience, and be a self-motivated, independent problem solver who is excited to dive into the details, ask questions, make recommendations, and drive results.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Develop, build, implement and support our new Salesforce Data Cloud instance, along with Marketing Cloud</li><li>Drive end-to-end project execution with analysis, documentation, solutions, testing and performance that meets the expectations of the business</li><li>Identify and confirm technical design risks and develop mitigating approaches</li><li>Participate in technical design workshops with the wider Salesforce Team, IT and Engineering Teams, and the business</li><li>Ensure technical documentation is kept up to date, following any system changes and new project implementations</li><li>Collaborate closely with the Product Development and IT business applications teams on technologies that interface with CRM systems</li><li>Translate and communicate technical requirements and solutions for the business using story-based narratives as well as presenting the strategy and recommendations to executives</li><li>Develop and run User Acceptance Testing with training and documentation</li><li>Follow GoodRx project planning methodologies and Agile development process, for successful, timely delivery of projects</li><li>Review and take ownership of legacy debt and API’s on our systems and design, present, and implement new solutions that are both efficient for our business and cost effective</li><li>Utilize knowledge of new &amp; upcoming features in the Salesforce ecosystem to provide recommendations for greater efficiencies</li><li>Ensure that systems are kept safe, secure, and compliant in alignment to our corporate GoodRx policies and standards<br/><br/></li></ul><strong>Skills &amp; Qualifications<br/><br/></strong><ul><li>Bachelor’s degree in computer science or Management Information Systems preferred</li><li>4+ years in a Solutions Architect role</li><li>Hands-on Salesforce Data Cloud (CDP) experience</li><li>Salesforce Data Cloud Consultant certification preferred</li><li>Salesforce Marketing Cloud Consultant, Admin or Developer certifications a huge plus</li><li>Strong understanding of customer data platforms and modern data infrastructure</li><li>Experience with standard and extensible functionality of Salesforce Sales &amp; Marketing Clouds</li><li>Knowledge of Apex, Visualforce &amp; Lightning</li><li>Integration experience using both Web based technologies (SOAP, REST)</li><li>Experience with integration tools such as Jitterbit and MuleSoft<br/><br/></li></ul>At GoodRx, pay ranges are determined based on work locations and may vary based on where the successful candidate is hired. The pay ranges below are shown as a guideline, and the successful candidate’s starting pay will be determined based on job-related skills, experience, qualifications, and other relevant business and organizational factors. These pay zones may be modified in the future. Please contact your recruiter for additional information.<br/><br/><strong>San Francisco Office<br/><br/></strong>$128,000.00 - $205,000.00<br/><br/><strong>New York And Seattle Offices<br/><br/></strong>$118,000.00 - $188,000.00<br/><br/><strong>Santa Monica Office<br/><br/></strong>$107,000.00 - $171,000.00<br/><br/>Other Office Locations:<br/><br/>$96,000.00 - $154,000.00<br/><br/>GoodRx also offers additional compensation programs such as annual cash bonuses and annual equity grants for most positions as well as generous benefits. Our great benefits offerings include medical, dental, and vision insurance, 401(k) with a company match, an ESPP, unlimited vacation, ""Take Care of Yourself"" days, 11 paid holidays, and 72 hours of sick leave. GoodRx also offers additional benefits like mental wellness and financial wellness programs, fertility benefits, supplemental life insurance for you and your dependents, company-paid short-term and long-term disability, and more!<br/><br/>We’re committed to growing and empowering a more inclusive community within our company and industry. That’s why we hire and cultivate diverse teams of the best and brightest from all backgrounds, experiences, and perspectives. We believe that true innovation happens when everyone has a seat at the table and the tools, resources, and opportunities to excel.<br/><br/>With that said, research shows that women and other underrepresented groups apply only if they meet 100% of the criteria. GoodRx is committed to leveling the playing field, and we encourage women, people of color, those in the LGBTQ+ communities, and Veterans to apply for positions even if they don’t necessarily check every box outlined in the job description. Please still get in touch - we’d love to connect and see if you could be good for the role!<br/><br/>GoodRx is America's healthcare marketplace. The company offers the most comprehensive and accurate resource for affordable prescription medications in the U.S., gathering pricing information from thousands of pharmacies coast to coast, as well as a telehealth marketplace for online doctor visits and lab tests. Since 2011, Americans with and without health insurance have saved $60 billion using GoodRx and million consumers visit goodrx.com each month to find discounts and information related to their healthcare. GoodRx is the #1 most downloaded medical app on the iOS and Android app stores. For more information, visit www.goodrx.com.
      </div>",$60- $128000.00,Data Architect
Data Center Project Architect,Amazon Web Services (AWS),12/19/2023,https://www.linkedin.com/jobs/view/3702285566,0,https://media.licdn.com/dms/image/C560BAQER_QnUTXrPJw/company-logo_100_100/0/1670264051233/amazon_web_services_logo?e=2147483647&v=beta&t=tI5mZm2XR_yMnLD5LQNmk8dQtVwGevKFXUHJlb8I_wE,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Amazon Web Services (AWS) is seeking a Data Center Project Architect to join its design team in Herndon, Virginia. This position is also available in Seattle Washington.<br/><br/>AWS designs, builds, and operates Data Centers (DC) around the world and is a leader in worldwide cloud-computing infrastructure.<br/><br/>Architects at AWS work to design resilient, cost effective DC facilities. Our team is responsible for achieving a world class uptime for our customers and drive to develop a fleet of buildings that emphasize security, safety, efficiency, and cost effectiveness, while finding new ways to meet AWS’s growing demand.<br/><br/>As a DC Project Architect at AWS, you will lead designs for Amazon DCs in our Americas Region and impact other projects around the world. As a DC Project Architect, you will be part of a highly creative and efficient design team comprised of Architects, Engineers, and Designers tasked with solving problems and challenging the status quo. As a subject matter expert, you will have a direct impact on the design of prototypical DC facilities, provide technical guidance, solve large scale implementation issues, and be responsible for architectural design requirements.<br/><br/>Key job responsibilities<br/><br/><ul><li> Communicate conceptual designs and create/maintain project documentation before, during, and after construction.</li><li> Maintenance of Basis of Design, prototype design, and template specifications for architectural elements.</li><li> Review and inform design RFPs.</li><li> Manage our external design consultants through the design and construction process.</li><li> Coordinate with internal and external Civil, Structural, Mechanical, Electrical, Controls, Cabling, and Security design engineers.</li><li> Effectively communicate design standards to internal and external project partners.</li><li> Manage multiple fast paced projects simultaneously.</li><li> Think outside of the box to find innovative solutions prior to and during the construction process to reduce costs without negative impacts on quality or reliability.</li><li> Travel for site assessments, internal design meetings, construction review, and interfacing with design consultants. Anticipated travel not to exceed 25%.<br/><br/></li></ul><strong>About The Team<br/><br/></strong>Why AWS?<br/><br/><strong>About AWS<br/><br/></strong>Amazon Web Services (AWS) is the world’s most comprehensive and broadly adopted cloud<br/><br/>platform. We pioneered cloud computing and never stopped innovating — that’s why customers<br/><br/>from the most successful startups to Global 500 companies trust our robust suite of products and<br/><br/>services to power their businesses.<br/><br/>Inclusive Team Culture<br/><br/>Here at AWS, it’s in our nature to learn and be curious. Our employee-led affinity groups foster<br/><br/>a culture of inclusion that empower us to celebrate our differences. Ongoing events and learning<br/><br/>experiences, including our Conversations on Race and Ethnicity (CORE) and AmazeCon (gender<br/><br/>diversity) conferences, inspire us to never stop embracing our uniqueness.<br/><br/>Mentorship &amp; Career Growth<br/><br/>We have a career path for you no matter what stage you’re in when you start here. We’re continuously raising our performance bar as we strive to become Earth’s Best Employer.<br/><br/>That’s why you’ll find endless knowledge-sharing, mentorship and other career-advancing<br/><br/>resources here to help you develop into a better-rounded professional.<br/><br/>We are open to hiring candidates to work out of one of the following locations:<br/><br/>Austin, TX, USA | Columbus, OH, USA | Herndon, VA, USA | Seattle, WA, USA<br/><br/><strong>Basic Qualifications<br/><br/></strong><ul><li> NCARB recognized architecture license.</li><li> 5+ years of design experience in commercial / industrial / other complex technical projects.</li><li> 1+ years of Data Center or Mission Critical facility design experience.</li><li> 1+ years leading sub-consultants and project teams.</li><li> Proficiency in building codes, regulations, and standards including IBC or equivalent.</li><li> Excellent communication skills and attention to detail.<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li> 1+ years of large scale Data Center facility design experience.</li><li> Solid working proficiency with AutoCAD, Revit, Bluebeam, and MS Office Suite.</li><li> Proficiency in building codes, regulations, and standards including IBC, IFC, NFPA, and Unified Facility Criteria (UFC).</li><li> Experience designing projects to comply with ICD/ICS 705 accreditation requirements.</li><li> Vendor and consultant management skills.</li><li> Excellent communication skills and attention to detail.</li><li> Ability to travel internationally.</li><li> Meets/exceeds Amazon’s leadership principles requirements for this role.</li><li> Meets/exceeds Amazon’s functional/technical depth and complexity for this role.<br/><br/></li></ul>Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.<br/><br/>Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $77,300/year in our lowest geographic market up to $219,700/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.<br/><br/><br/><strong>Company</strong> - Amazon Data Services, Inc.<br/><br/>Job ID: A2436281
      </div>",$77300- $219700,Data Architect
Lead/Principal Technical Architect,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3762359988,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Senior Solutions Architect - GIS-SAP Integration - Remote,Get It Recruit - Professional Services,12/19/2023,https://www.linkedin.com/jobs/view/3784428507,0,https://media.licdn.com/dms/image/C560BAQF643loyPIYvg/company-logo_100_100/0/1674662515600?e=2147483647&v=beta&t=FKGYwBuJJlFSwOxPw4iTLWcGFWs1YE3gY1Rfs-ihbsA,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Welcome to our team! We are a global leader in technology consulting and geospatial systems development. Our mission is to harness the power of location data, business intelligence, and integrated systems to drive enterprise collaboration and business performance for our diverse clientele. With top-tier partnerships and a comprehensive approach, we deliver all components of a geospatial program, from data collection to mobile solution development.<br/><br/><strong>Who We Are Looking For<br/><br/></strong>We are seeking an experienced Senior Solutions Architect – GIS-SAP Integration with substantial SAP technology experience and strong leadership skills. Join us in developing, delivering, and managing industry-leading solutions for utility clients. Our consultants work across various disciplines and industries, understanding clients’ business needs, influencing stakeholders, and building credibility quickly in fast-paced environments.<br/><br/><strong>Role Overview<br/><br/></strong>As a Senior Solutions Architect, you will be a lead collaborator on software implementation projects involving integrations between SAP and GIS. Your responsibilities will include identifying and documenting business processes, recommending process improvements, evaluating project approaches, coordinating interdependencies, and applying technical development and configurations to GIS and SAP applications. Additionally, you will participate in business development endeavors.<br/><br/>The Senior Solutions Architect Provides Primary Support, Oversight, And Strategic Recommendations On Decisions Impacting Data Management, Technology Implementations, And Data Integration. You Will Work Closely With Clients, Serving As a Trusted Advisor And Establishing Credibility In Fast-paced Environments. Key Areas Of Expertise Include<br/><br/>Leading the delivery of technical data management and integration solutions.<br/><br/>Supporting business development activities, including client workshops and demos.<br/><br/>Providing guidance and oversight for all aspects of data design and delivery.<br/><br/>Working directly with clients to assess business needs and translate them into functional and technical requirements.<br/><br/>Monitoring solution design and delivery to ensure adherence to requirements, scope, and schedule.<br/><br/><strong>Skills And Experience We Seek<br/><br/></strong>Bachelor's or Master's degree in Computer Science, Engineering, Geoscience, or a related discipline.<br/><br/>Demonstrated experience with SAP, including S/4HANA and the HANA platform.<br/><br/>Familiarity with Esri ArcGIS Enterprise, including ArcGIS Pro, ArcGIS Portal, and ArcGIS Server.<br/><br/>Experience designing, developing, administering, and maintaining Esri Geodatabases.<br/><br/>Proficiency in SQL.<br/><br/>Experience integrating SAP data with other systems via web services, APIs, and other technologies.<br/><br/>Strong experience in capturing and translating business requirements into technical approaches.<br/><br/>Understanding of geospatial data formats, transformations, and coordinate systems.<br/><br/>Familiarity with SAP ERP system and modules.<br/><br/>Knowledge of SAP Fiori apps and their use in business workflows is a plus.<br/><br/><strong>Why Join Us<br/><br/></strong>We value our team and offer exciting perks and benefits, including:<br/><br/>Flexible work schedule for a healthy work-life balance.<br/><br/>Comprehensive medical, dental, and vision plans with a low employee premium.<br/><br/>Healthcare Spending Accounts (HSAs) and Flexible Spending Accounts (FSAs).<br/><br/>Short and long-term disability insurance and life insurance.<br/><br/>401k plan with a generous employer contribution.<br/><br/>Plentiful PTO and 9 paid holidays.<br/><br/>Paid parental leave.<br/><br/>Generous annual home office reimbursement.<br/><br/><strong>How To Apply<br/><br/></strong>Excited? We'd love to hear from you! Click 'Apply' to share your information, and we will be in touch soon.<br/><br/><strong>Compensation<br/><br/></strong>We offer a competitive compensation package, including salary, bonus, and highly valued benefits programs. The annual starting salary range for this position is $150,000 to $180,000, with opportunities for higher earnings based on qualifications.<br/><br/><strong>Equal Opportunity Employer<br/><br/></strong>We are committed to providing a diverse, inclusive, and equitable work environment. All qualified applicants will receive consideration for employment without regard to age, ancestry, color, family or medical care leave, gender identity or expression, genetic information, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran status, race, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable laws, regulations, and ordinances.<br/><br/>Employment Type: Full-Time<br/><br/>
</div>",$150000- $180000,Data Architect
Project Executive – Commercial,Lease Crutcher Lewis,12/19/2023,https://www.linkedin.com/jobs/view/3756979913,0,https://media.licdn.com/dms/image/C4D0BAQHrhcBLoiqHow/company-logo_100_100/0/1631314859608?e=2147483647&v=beta&t=szIU5EfwXQ6Nczw9733IKVsJd5a0NjX41BTdYswW9nQ,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Lewis<br/><br/></strong>At Lewis where an employee is an owner, our people are empowered to make decisions—big and small—to meet the goals of our clients. Our promise: “Every Decision. Every Detail. Every Day.” means we are passionate about getting it right, day in and day out, and driven to deliver cool projects and build quality buildings that stand the test of time. With fulfillment as one of our six core values, Lewis has a collaborative and supportive culture committed to the success and development of our people.<br/><br/><strong>The opportunity<br/><br/></strong>We are looking for a Project Executive for our Commercial Market sector. This is an exciting opportunity for someone who wants to make a big impact on the business and on a team!<br/><br/><strong>Who We Are Seeking…..<br/><br/></strong><strong>Experienced.</strong> You have a solid understanding of overall profitability and are able to deliver successful outcomes on all assigned projects.<br/><br/><strong>Relationship Focused</strong>. You understand the power of relationships! You provide direction and support to Project Engineers, Superintendents and Project Managers from Preconstruction to closeout. You are also well versed in cultivating external relationships.<br/><br/><strong>Business Oriented</strong>. You are a leader who believes in what the company is doing. You are comfortable creating and maintaining business systems, and processes that support achievement of the company vision, mission and strategic objectives.<br/><br/><strong>Primary Functions And Essential Responsibilities<br/><br/></strong><strong>Client Development<br/><br/></strong><ul><li>Develop and implement strategies for obtaining new project opportunities. Identify potential clients and project leads in targeted segments, research background data, prioritize pursuits with other Project Executives, and coordinate efforts with Marketing and Precon groups.</li><li>Leads negotiated sales efforts including differentiation strategy, proposal management and interview preparation.</li><li>Oversees all assigned project bids and new work proposals. Leans on the estimating team in preparing budgets and proposals.</li><li>Maintains positive working relationships with clients &amp; architect and/or engineer contacts to facilitate successful project execution.</li><li>Establishes effective relationships with clients, vendors, design teams, subcontractors, suppliers, and user groups that reflect and support Company core values and meet or exceed the customer’s expectations.<br/><br/></li></ul><strong>People Leadership<br/><br/></strong><ul><li>Effectively leads project teams to achieve optimum results on projects and the highest levels of team accomplishment. Supports and fosters effective communication between field and office teams.</li><li>Responsible for fostering company safety culture and accountability on all projects.</li><li>Leads and motivates diverse teams to achieve high levels of performance. Establishes and fosters team environment.</li><li>Identifies and communicates staffing needs, participates in company recruitment efforts, identifying candidates and persuading them to join the company.</li><li>Provides stewardship for, and is actively engaged in, company initiatives such as mentoring, succession planning and the development of team members for future career opportunities.<br/><br/></li></ul><strong>Construction Management<br/><br/></strong><ul><li>Oversees the development of a comprehensive Project Schedule, regular updates, and handles delays to assure all projects are completed within the contractual duration.</li><li>Directs multiple projects in various stages of development.</li><li>Oversees performance of project(s) including: project status, schedule, cost control, and change management systems.</li><li>Reviews work of Project Managers to ensure client satisfaction, contract terms, schedule terms and safety are consistent with Company agreements and policies.</li><li>Periodically represents Lewis and/or the Division to report on current events and key performance indicators.</li><li>Advises and champions continuous improvement to enhance and improve company procedures, practices, policies.<br/><br/></li></ul><strong>In order to succeed in this role<br/><br/></strong><ul><li>15+ years of industry experience.</li><li>Bachelor’s Degree in Construction Management, Engineering, or equivalent.</li><li>Extensive experience and knowledge working with regulatory agencies throughout the critical construction process.</li><li>Lead multiple projects at once while maintaining high levels of performance on cost, quality, and safety.</li><li>Lead and perform as necessary all aspects of construction operations and sales including proposals, interviews, estimating, scheduling, cost management, buyout, contract negotiations, and staff management.</li><li>Working knowledge of BIM required.</li><li>Ability to hire, develop, and lead high-performance teams.</li><li>Proficiency in Microsoft Office Suite (Word, Excel, Outlook) and project management software required; preferred Primavera (P6) or Microsoft Project. Familiarity with CMiC or other project planning tools is preferred.</li><li>Excellent communication skills, both written and verbal.</li><li>Experience in business development and sales.</li><li>Ability to take on complex problems in a collaborative, team-based culture.<br/><br/></li></ul>Wage range: $170,000-$190,000, depending on experience.<br/><br/><em>Lease Crutcher Lewis is an Equal Opportunity Employer. All qualified applicants will receive consideration for employment regardless of, and will not be discriminated against, based on the basis of race, color, gender, pregnancy or breastfeeding, sexual orientation, gender identity or expression, religion, national origin, age, genetic information, marital status, veteran status, disability, or other status protected by state or federal law. </em><em>#FP1</em>
</div>",$170000- $190000,Data Architect
Architect - TikTok Privacy,TikTok,12/19/2023,https://www.linkedin.com/jobs/view/3682811926,0,https://media.licdn.com/dms/image/C510BAQGCdThXIss7UQ/company-logo_100_100/0/1630606162248/tiktok_logo?e=2147483647&v=beta&t=139uJTX7-HNeX1_kJsHK-Ztmj2K9yb9XfIIGQoNOW3c,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong> TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo. <br/><br/>Why Join Us<br/>Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. <br/>Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. <br/>To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. <br/>At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. <br/>Join us.<br/><br/>TikTok Privacy &amp; Security Product team is responsible for building compliant and user-friendly privacy solutions for TikTok, with the goal of building trust among TikTok users, regulators, and the public. The team is working on TikTok's privacy-related backend systems, including data access controls, data retention policies, and user data protection.<br/><br/>The Backend Software Architect, TikTok Privacy will be responsible for designing and implementing scalable, reliable, and high-performance backend systems for TikTok's platform while ensuring that user data is protected and used ethically. This role will require a deep understanding of privacy principles and laws, as well as the ability to work collaboratively with cross-functional teams to develop and implement solutions that meet business requirements and privacy requirements. The Backend Software Architect will work closely with product, engineering, privacy, and security teams to ensure that the backend systems are designed and built to meet TikTok's privacy requirements and standards.<br/><br/>Key Responsibilities:<br/>- Design and implement scalable, reliable, and high-performance backend systems with a focus on user privacy and data protection<br/>- Work with product and engineering teams to ensure that privacy considerations are integrated into the backend architecture and development process<br/>- Collaborate with privacy and security teams to ensure that the backend systems comply with relevant privacy laws and regulations<br/>- Develop and maintain backend architecture and technology roadmaps that prioritize user privacy and data protection<br/>- Identify and evaluate new technologies and tools that could improve the backend systems' privacy and security features<br/>- Provide technical guidance and mentorship to other engineers on the team on privacy-related topics <br/><br/><strong>Qualifications<br/><br/></strong> - Bachelor's or Master's degree in Computer Science or related field<br/>- 7+ years of experience in backend development<br/>- Strong understanding of backend technologies, such as distributed systems, databases, messaging systems, and caching<br/>- Experience with microservices architecture and containerization technologies such as Docker and Kubernetes<br/>- Experience with cloud platforms such as AWS or GCP<br/>- Experience with Agile development methodologies and DevOps practices<br/>- Strong communication and collaboration skills<br/>- Ability to work independently and manage multiple priorities<br/><br/>Preferred Qualification<br/>- Experience with privacy principles and laws, such as GDPR, CCPA, and COPPA<br/>- Experience with privacy impact assessments and risk management<br/>- Experience with implementing privacy by design and default principles in backend systems<br/><br/>TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.<br/><br/>TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at gprd.accommodations@tiktok.com.<br/><br/> <br/><br/><strong>Job Information:<br/><br/></strong>【For Pay Transparency】Compensation Description (annually) <p>The base salary range for this position in the selected city is $212800 - $389500 annually.<span>​</span></p><p>Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.<span>​</span></p><p>Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: <span>​</span></p><p>We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&amp;D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. <span>​</span></p><p>Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. <span>​</span></p><p>We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.<span>​</span></p>
</div>",$212800- $389500,Data Architect
Senior Data Scientist,Coinbase,12/19/2023,https://www.linkedin.com/jobs/view/3620841954,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Lead Data Scientist,aKube Inc,12/19/2023,https://www.linkedin.com/jobs/view/3784448106,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Senior Backend Software Engineer - Data-E-Commerce Supply Chain & Logistics,TikTok,12/19/2023,https://www.linkedin.com/jobs/view/3671208196,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Software Engineer II, Service Integrations",Wayfair,12/25/2023,https://www.linkedin.com/jobs/view/3793429749,0,https://media.licdn.com/dms/image/C4E0BAQHHS2RPVTXtRw/company-logo_100_100/0/1630610081926/wayfair_logo?e=2147483647&v=beta&t=UiJrSFGQXRpNdpuPziPSSbwMSyMpMkJG0EnJUCkBFL8,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>Candidates for this position are preferred to be based in Boston, MA and will be expected to comply with their team's hybrid work schedule requirements.<br/><br/></em><strong><strong>Who We Are:<br/><br/></strong></strong>The Service Integration team serves the data needs of various other service engineering teams which build applications on top of the APIs provided by the team. The team works with external teams like Order Systems, Sales, Storefront, Global Supplier Tech, Supply Chain, Transportation etc., to integrate their data and events for service engineering consumption. The work done by this team impacts all of the service post order customer journey as well the service platform teams. Its mission is to provide a unified platform for Service Eng data requirements ensuring performant and consistent distributed data access.<br/><br/>The projects that our teams work on are built from the ground up – we look for entrepreneurial individuals who want to take ownership over their own agenda and thrive in a collaborative team environment. The team works on distributed async event streams based architecture, owns designing event contracts between various systems, translating data available through various external APIs into a unified GraphQL schema and interesting problems related to GraphQL federation.<br/><br/><strong><strong>What You'll Do:<br/><br/></strong></strong><ul><li>Provide high-quality contributions to the code base, with a mind to best practices and an equally high degree of autonomy.</li><li>Work with senior leadership to architect solutions and ensure that we deliver the right functionality, in a timely manner.</li><li>Mentor junior engineers to develop the next generation of Wayfair engineering talent.</li><li>Handle ambiguity with limited oversight; leverage technical acumen, experience, and network to answer questions and remove roadblocks.</li><li>Architect and write code to implement high-quality, scalable, future-proof services that will have effective system boundaries and will support long-term vision &amp; strategy</li><li>Propose and own initiatives to completion while balancing various trade-offs including speed to delivery vs. ongoing maintainability and others.</li><li>Identify risks and gaps in technical approaches and propose solutions to meet the department's technical vision</li><li>Collaborate well with senior management, product managers, and all other stakeholders.<br/><br/><br/></li></ul><strong><strong>We Are a Match Because You Have:<br/><br/></strong></strong><ul><li>6+ years of experience as a full-stack, full lifecycle software engineer and a deep understanding of a modern programming language (such as, Java, Spring Boot, PHP, GraphQL, C#, or others)</li><li>Passion for leading a large, cross-cutting technical initiative to delivery, cross-functional consensus building, and influencing design decisions</li><li>Ample experience gathering requirements from business stakeholders and deriving software requirements</li><li>Experience mentoring engineers and leading code reviews</li><li>Excellent communication skills and ability to work effectively with engineers, product managers, design and business stakeholders alike</li><li>Proficient in effective troubleshooting and issue resolution techniques with minimal guidance</li><li>Experience in building and working with APIs/Restful services</li><li>Working knowledge of large scale distributed systems and streaming platforms is a plus</li><li>Experience working with Docker Containers and Kubernetes is plus<br/><br/><br/></li></ul><strong>Why You’ll Love Wayfair:<br/><br/></strong><ul><li>Time Off:</li><ul><li>Paid Holidays</li><li>Paid Time Off (PTO)<br/></li></ul><li>Health &amp; Wellness:</li><ul><li>Full Health Benefits (Medical, Dental, Vision, HSA/FSA)</li><li>Life Insurance</li><li>DIsability Protection (Short Term &amp; Long Term DIsability)</li><li>Global Wellbeing: Gym/Fitness discounts (including US Peloton, Global ClassPass, and various regional gym memberships)</li><li>Mental Health Support (Global Mental Health, Global Wayhealthy Recordings)</li><li>Caregiver Services<br/></li></ul><li>Financial Growth &amp; Security:</li><ul><li>401K Matching (Employee Matching Program)</li><li>Tuition Reimbursement</li><li>Financial Health Education (Knowledge of Financial Education - KOFE)</li><li>Tax Advantaged Accounts<br/></li></ul><li>Family Support:</li><ul><li>Family Planning Support</li><li>Parental Leave</li><li>Global Surrogacy &amp; Adoption Policy<br/></li></ul><li>Professional Development &amp; Recognition:</li><ul><li>Rewards &amp; Recognition</li><li>Global Employee Anniversary Awards</li><li>Paid Volunteer Work<br/></li></ul><li>Unique Perks:</li><ul><li>Employee Discount</li><li>U.S. Bluebikes Membership</li><li>Global Pod Outings<br/></li></ul><li>Work/Life Balance:</li><ul><li>Emphasizing a supportive &amp; flexible work environment that encourages a balance between personal and professional commitments<br/><br/><br/></li></ul></ul>We are looking forward to your application!<br/><br/><strong>Assistance For Individuals With Disabilities<br/><br/></strong>Wayfair is fully committed to providing equal opportunities for all individuals, including individuals with disabilities. As part of this commitment, Wayfair will make reasonable accommodations to the known physical or mental limitations of qualified individuals with disabilities, unless doing so would impose an undue hardship on business operations. If you require a reasonable accommodation to participate in the job application or interview process, please let us know by completing our .<br/><br/><strong>Need Assistance?<br/><br/></strong>For more information about applying for a career at Wayfair, visit our .<br/><br/><strong>About Wayfair Inc.<br/><br/></strong>Wayfair is one of the world’s largest online destinations for the home. Whether you work in our global headquarters in Boston or Berlin, or in our warehouses or offices throughout the world, we’re reinventing the way people shop for their homes. Through our commitment to industry-leading technology and creative problem-solving, we are confident that Wayfair will be home to the most rewarding work of your career. If you’re looking for rapid growth, constant learning, and dynamic challenges, then you’ll find that amazing career opportunities are knocking.<br/><br/>No matter who you are, Wayfair is a place you can call home. We’re a community of innovators, risk-takers, and trailblazers who celebrate our differences, and know that our unique perspectives make us stronger, smarter, and well-positioned for success. We value and rely on the collective voices of our employees, customers, community, and suppliers to help guide us as we build a better Wayfair – and world – for all. Every voice, every perspective matters. That’s why we’re proud to be an equal opportunity employer. We do not discriminate on the basis of race, color, ethnicity, ancestry, religion, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, veteran status, genetic information, or any other legally protected characteristic.<br/><br/>We are interested in retaining your data for a period of 12 months to consider you for suitable positions within Wayfair. Your personal data is processed in accordance with our Candidate Privacy Notice (which can found here: ). If you have any questions regarding our processing of your personal data, please contact us at . If you would rather not have us retain your data please contact us anytime at dataprotectionofficer@wayfair.com.
      </div>",No Salary Info Found,Data Architect
Tableau Developer,UNIQUE System Skills LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785065021,0,https://media.licdn.com/dms/image/C4E0BAQFfUeyRtklMXA/company-logo_100_100/0/1631325587182?e=2147483647&v=beta&t=rrvKccDkZ2-L0VqHeZ9YyNWOCP33B4Yu45_zQPqK1wo,"Wilmington, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Unique System Skills LLC, is seeking the following. Apply via Dice today!<br/><br/>We Have An Opening For Tableau Developer At Wilmington, MA. Kindly Apply With Your Updated Resume If You Are Interested. Please Find The Job Details Below<br/><br/><strong>Position:</strong> Tableau Developer<br/><br/><strong>Location:</strong> Wilmington, MA<br/><br/><strong>Duration</strong><strong>: </strong>12 Months<br/><br/><strong>Local to Massachusetts Candidates only<br/><br/></strong><strong>Skill To Evaluate<br/><br/></strong><ul><li>Design, develop, conducts unit testing, and maintains complex Tableau reports for scalability, manageability, extensibility, performance, and re-use.</li><li>Experience with Data Analytics</li><li>Provide technical expertise in areas of architecture, design, and implementation.</li><li>Determine the best implementation that will meet the design of the architect.</li><li>Work with team members to create useful reports and dashboards that provide insight, improve/automate processes, or otherwise add value to the team.</li><li>Work through iterative review cycles to deliver results that meet or exceed user expectations.</li><li>Ensure consistency by adhering to a set of software coding and style guides.</li><li>Resolve support tickets related to Tableau reports.</li></ul>
</div>",No Salary Info Found,Data Architect
"Data Conversion Developer, Senior Associate",PwC,12/19/2023,https://www.linkedin.com/jobs/view/3749936653,0,https://media.licdn.com/dms/image/D4D0BAQH3qXh7nyImoQ/company-logo_100_100/0/1697100791441/pwc_logo?e=2147483647&v=beta&t=egwzMH-OEEIdbRMowwJcaDKwrISS95b4zQiwpJJhhyw,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Specialty/Competency: </strong>Functional &amp; Industry Technologies<br/><br/><strong>Industry/Sector: </strong>Not Applicable<br/><br/><strong>Time Type: </strong>Full time<br/><br/><strong>Travel Requirements: </strong>Up to 80%<br/><br/>A career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients’ user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.<br/><br/>To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.<br/><br/><strong>Responsibilities<br/><br/></strong>As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:<br/><br/><ul><li>Use feedback and reflection to develop self awareness, personal strengths and address development areas.</li><li>Delegate to others to provide stretch opportunities, coaching them to deliver results.</li><li>Demonstrate critical thinking and the ability to bring order to unstructured problems.</li><li>Use a broad range of tools and techniques to extract insights from current industry or sector trends.</li><li>Review your work and that of others for quality, accuracy and relevance.</li><li>Know how and when to use tools available for a given situation and can explain the reasons for this choice.</li><li>Seek and embrace opportunities which give exposure to different situations, environments and perspectives.</li><li>Use straightforward communication, in a structured way, when influencing and connecting with others.</li><li>Able to read situations and modify behavior to build quality relationships.</li><li>Uphold the firm's code of ethics and business conduct.<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><strong><strong>Minimum Degree Required:<br/><br/></strong></strong>Bachelor Degree<br/><br/><strong>Minimum Years Of Experience<br/><br/></strong>4 years<br/><br/><strong>Preferred Qualifications<br/><br/></strong><strong><strong>Degree Preferred:<br/><br/></strong></strong>Master Degree<br/><br/><strong>Certification(s) Preferred<br/><br/></strong>Azure Data Engineer Associate<br/><br/>Databricks Certified Data Engineer Associate<br/><br/><strong>Preferred Fields Of Study<br/><br/></strong>Computer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology<br/><br/><strong>Preferred Knowledge/Skills<br/><br/></strong>Demonstrates a thorough level of abilities with, and/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:<br/><br/><ul><li>Supports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;</li><li>Leads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;</li><li>Identifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;</li><li>Supports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion; </li><li>Showcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;</li><li>Identifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;</li><li>Supports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);</li><li>Utilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;</li><li>Developes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo; </li><li>Customizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;</li><li>Identifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,</li><li>Showcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL. <br/><br/></li></ul>Learn more about how we work: https://pwc.to/how-we-work<br/><br/>PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.<br/><br/>All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.<br/><br/>For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.<br/><br/>Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines<br/><br/>For positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https://pwc.to/payrange-v1-advisoryseniorassociate<br/><br/>
</div>",No Salary Info Found,Data Architect
"State Street Global Advisors, ESG Business Data Analyst, Assistant Vice President",State Street Global Advisors,12/19/2023,https://www.linkedin.com/jobs/view/3735643976,0,https://media.licdn.com/dms/image/C4D0BAQHAGKfEFfhNLQ/company-logo_100_100/0/1631319787937?e=2147483647&v=beta&t=AI_5qXv21qRtyT_THLuDRk26dtwuj8rXB1e9oxmP7Mc,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Business &amp; Data Analyst will support ESG reporting services and business analysis. The role will execute data operations and business analysis functions supporting ESG Client, Product, and Regulatory Reporting. This includes daily operations responsibilities, data monitoring and issue resolution while supporting new projects by defining scope, business and data requirements, and success criteria. This role will contribute to project execution, implementation, and testing activities. The Candidate must be proficient in analysis, definition, communication, assessment, and validation of data and business requirements used for software development. Previous experience working with mutual funds, ETFs, and Institutional funds across a range of data domains such as performance, holdings, accounting, pricing, and analytics is required.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Support operational procedures and daily tasks while also delivering on new project initiatives.</li><li>Produce ESG client, product, and regulatory reports according to defined requirements and schedules. </li><li>Receive and respond to client and consultant ESG data inquires promptly, completely, and accurately.</li><li>Manage the operational aspects of reporting and data provisioning while providing operational support to stakeholders.</li><li>Support RFP and due diligence questionnaire ESG data requests as required.</li><li>Gather business data requirements by effectively coordinating activities between business users, developers, and managers.</li><li>Develop use cases, functional specifications, and test cases. Ensure test coverage and complete documentation is provided.</li><li>Provide input into potential areas of improvement to drive continuous enhancement to data and reporting processes.</li><li>Analyze, assess, and solicit data and business requirements.</li><li>Explore external and internal data sources covering all domains of investment product periodic and reference data.</li><li>Document data sourcing, delivery, and extraction solutions.</li><li>Develop, communicate, and explain epics &amp; stories for agile sprints.</li><li>Liaise between the business, technical areas, and vendors throughout project cycle.</li><li>Lead requirements and technical design discussions as subject matter expert, producing business requirements and other key artifacts.</li><li>Develop and maintain detailed requirements with considerations for scope, success factors/measures, assumptions, constraints, and dependencies.</li><li>Partner with 3rd Party Software Vendors and Data Vendors as needed.</li><li>Collaborate with functional areas of project teams including Project Management, Product Management, Development, Data Integration, Business Systems Analysis, Quality Assurance, and User Experience.</li><li>Participate in test-plan preparation, reviews &amp; end user acceptance testing execution.</li><li>Document supporting project deliverables including process and training guides.</li><li>Develop and maintain detailed requirements with considerations for scope, success factors/measures, assumptions, constraints, and dependencies.</li><li>Communicate status with stakeholders, business partners and team.</li><li>Develop, implement, and enforce best practices and operating standards.<br/><br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>5+ years working experience in the Investment Industry with 3+ years hands on data operations experience. </li><li>BS/BA or equivalent required.</li><li>Able to balance business-as-usual work and project work.</li><li>Strong Microsoft Excel skills and working proficiency of Visio, Powerpoint, and Word.</li><li>Familiarity with ESG metrics such as ESG ratings, climate metrics, and asset stewardship and engagement data.</li><li>Knowledge of Data development/Operations in Finance, Factset, a plus.</li><li>Understanding of Mutual Funds, ETFs, and Institutional funds across a range of data domains including performance, holdings, accounting, pricing, and analytics.</li><li>Proven ability to effectively manage time and balance priorities across multiple assignments.</li><li>Great attention to detail.</li><li>Strong interpersonal and collaboration skills.</li><li>Experience working with globally distributed project teams required.</li><li>Proven track record of successfully delivering and executing on data driven projects through all aspects of data operations, business requirements analysis, solicitation, definition, communication, assessment, and validation. <br/><br/><br/></li></ul><strong>Are you the right candidate? Yes!<br/><br/></strong>We truly believe in the power that comes from the diverse backgrounds and experiences our employees bring with them. Although each vacancy details what we are looking for, we don’t necessarily need you to fulfil all of them when applying. If you like change and innovation, seek to see the bigger picture, make data driven decisions and are a good team player, you could be a great fit.<br/><br/><strong>About State Street Global Advisors<br/><br/></strong><strong>What We Do.</strong> As the asset management arm of State Street Corporation, State Street Global Advisors has served the world’s governments, institutions and financial advisors for over four decades. With a rigorous, risk-aware approach built on research, analysis and market-tested experience, we build from a breadth of active and index strategies to create cost-effective solutions. As stewards, we help portfolio companies see that what is fair for people and sustainable for the planet can deliver long-term performance. And, as pioneers in index, ETF, and ESG investing, we are always inventing new ways to invest. As a result, we have become one of the world’s largest asset managers with trillions of dollars under our care.<br/><br/><strong>Our Mission. </strong>At State Street Global Advisors our mission is to invest responsibly to enable economic prosperity and social progress. We are driven by a desire to help our clients, and those who rely on them, achieve a better future. We have a long history of developing innovative investment strategies to provide our clients with reliable and transparent returns, cost-effectively, and without excessive risk.<br/><br/><strong>Work, Live and Grow.</strong> We make all efforts to create a great work environment. Our benefits packages are competitive and comprehensive. Details vary by location, but you may expect generous medical care, insurance and savings plans, among other perks. You’ll have access to Flexible Work Programs to help you match your needs. And our wealth of development programs and educational support will help you reach your full potential.<br/><br/><strong>Inclusion, Diversity and Social Responsibility. </strong>We truly believe our employees’ diverse backgrounds, experiences and perspectives are a powerful contributor to creating an inclusive environment where everyone can thrive and reach their maximum potential while adding value to both our organization and our clients. We warmly welcome candidates of diverse origin, background, ability, age, sexual orientation, gender identity and personality. Another fundamental value at State Street is active engagement with our communities around the world, both as a partner and a leader. You will have tools to help balance your professional and personal life, paid volunteer days, matching gift programs and access to employee networks that help you stay connected to what matters to you.<br/><br/>State Street is an equal opportunity and affirmative action employer.<br/><br/>Company: State Street Global Advisors<br/><br/><strong>Salary Range<br/><br/></strong>$80,000 - $132,500 Annual<br/><br/>The range quoted above applies to the role in the primary location specified. If the candidate would ultimately work outside of the primary location above, the applicable range could differ.<br/><br/>Job ID: R-740972
      </div>",$80000- $132500,Data Architect
Senior Data Analyst,Candex,12/19/2023,https://www.linkedin.com/jobs/view/3784025657,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Lead Data Engineer - Hybrid,Incendia Partners,12/19/2023,https://www.linkedin.com/jobs/view/3724314055,0,https://media.licdn.com/dms/image/C560BAQH9RSncE7GcSw/company-logo_100_100/0/1631377003997?e=2147483647&v=beta&t=J9v5VVLAQDYb7S9PP3zNWsHrZ2DbaAz-P1-3psidELg,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description</strong>:<br/><br/>We are searching for a Lead Data Engineer to implement data engineering and analytics solutions .<br/><br/>Primary responsibilities include full implementation and maintenance of data ingestion, data maintenance, data validation and data delivery of investment data.<br/><br/>We are looking for someone who thrives in an agile, collaborative, team-based environment, working closely with technology peers across the organization, investment professionals and key vendor partners.<br/><br/>This position offers the opportunity to shape the future of investment data here.<br/><br/><strong>Duties:<br/><br/></strong><ul><li>Design, develop, and implement data pipelines to maintain unified data platform for the Investment Data Management group </li><li>Lead and participate in all development activities, develop and implement solutions to meet business requirements that align with program strategic objectives </li><li>Responsible for new and on-going development of data pipelines sourcing from internal and external sources </li><li>Drive continuous improvement of data quality, resiliency, control, efficiency, and monitoring </li><li>Troubleshooting complex system interactions to find the root cause to problems </li><li>Partner with platform lead to design, develop, implement and deploy new software components to investment data platform </li><li>Partner with data architect to evaluate and finalize the unified data model </li><li>Partner with integration architect to upgrade and integrate data ingestion and data delivery tools with the unified data platform </li><li>Upgrade and integrate transformation tool, data validation tool and orchestration tools with the unified data platform to implement data engineering, analytical engineering and data maintenance capabilities. </li><li>Provide support during unexpected outages <br/><br/><br/></li></ul><strong>Qualifications:<br/><br/></strong><ul><li>Bachelor’s degree in Computer Science or related disciplines. </li><li>Minimum of 5 years of experience in design, development and building data oriented complex applications. </li><li>Deep understanding of Agile SDLC, DevOps and Cloud technologies required, in addition to exposure to multiple, diverse technologies, platforms, and processing environments. </li><li>Experience in data integration, data warehouse, data modeling and data analytics architecture and design principles. Knowledge of and experience with Snowflake and other cloud native databases is highly preferred. </li><li>Knowledge about various architectures, patterns such as unified data management architecture (UDM), data mesh architecture, event-driven architecture, real-time data flows, non-relational repositories, data virtualization, tc. </li><li>Experience with building solutions in the financial services domain with an understanding of financial instruments, transactions, and positions, is desired. </li><li>Good interpersonal and communication skills with the ability to lead cross-team collaboration and partnerships across a variety of internal and external constituencies. <br/><br/><br/></li></ul>#ZR<br/><br/>
</div>",No Salary Info Found,Data Architect
Software Engineer - Data Center Networking,Meta,12/20/2023,https://www.linkedin.com/jobs/view/3725828514,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The DC Networking team is responsible for developing, deploying, and operating Meta's global data center networks. Our work covers the entire network lifecycle, including hardware development, capacity planning, distributed and centralized control systems, modeling/provisioning/automation, monitoring/troubleshooting/analytics, and simulation/design/failure analysis. We are actively seeking Software Engineers to help build and scale our rapidly evolving network infrastructure. We are looking for Software Engineers with a passion for networking and aptitude for building scalable distributed systems. Do you want to work on one of the most dynamic, fast-paced networks in the world? Do you want to develop innovative solutions to our challenges and ship them into production? Then a role on one of our network engineering teams is for you!<br/><br/>Software Engineer - Data Center Networking Responsibilities:<br/><br/><ul><li>Design and implement drivers (and/or Firmware) for (network) ethernet adapter functions, Transport stack for RDMA, control functions with the host/accelerators.</li><li>Design and implement Platform services such as programming, monitoring, and controlling system components (Optics, PHY, FPGAs, sensors, fan control, power etc).</li><li>Develop and enhance HPC collective communication and parallel computing libraries such as NCCL, RCCL, OneCCL, and MPI</li><li>Debug complex, system-level, multi-component issues that typically span across multiple layers from Kernel, and user-mode applications.<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.</li><li>4+ years of experience in C/C++ and Python</li><li>4+ years experience in Systems programming, TCP/IP, HTTP/HTTPS, SPDY, DNS, and load balancers</li><li>Experience with network devices (routers, switches, load balancers) and an understanding of network routing protocols</li><li>Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Experience with Linux Kernel, especially drivers and network stack</li><li>Working knowledge of transport stack particularly RDMA (RoCEv2)</li><li>Experience with Qemu, FPGA Emulation environment is a plus</li><li>Experience with parallel computing platforms such as CUDA, RoCM and OpenCL</li><li>Experience with parallel computing platforms such as CUDA, RoCM and OpenCL Platform services (program, control, and monitor Optics, PHY, FPGAs, sensors, fan control, power etc), BSP/Board Support Package, Operating Systems, Kernel, Bootloader, Power Management, RTOS, Linux.<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data Architect
Business Data Analyst,RICEFW Technologies Inc,12/20/2023,https://www.linkedin.com/jobs/view/3784499688,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Data Engineer III - Network,Crown Castle,12/20/2023,https://www.linkedin.com/jobs/view/3772653825,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Manager, Data Loss Prevention (DLP) Engineer (Symantec)",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788483116,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Cambridge, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Job Advertisement: Manager, Data Loss Prevention (DLP) Engineer (Symantec) Capital One is looking for a data protection expert to help us improve our cybersecurity and keep our customers' data safe. We believe in excellence and doing the right thing. As a technology-oriented company, we deliver financial products using modern technology and constant innovation on a large scale. Part of this innovation involves using technology to provide the best cybersecurity solutions for our business. In this role, you will be a key part of our team of cyber technicians and engineers. Your main responsibility will be to create, implement, and maintain DLP Controls using SaaS and IaaS based solutions. These controls will help reduce risk and enforce Capital One's Information Security Policy and Standards. We are looking for someone who is curious, stays updated on emerging trends and threats, and is not afraid to question existing processes and solutions. You should be able to prioritize business needs and have excellent problem-solving and communication skills. You should also be comfortable working in a fast-paced, technologically advanced environment. What you'll do: - Use your expertise in data loss prevention to design, build, and implement tools to safeguard data against cyber risks. - Analyze the problem space, document your approach, and work with architecture to identify a target state architecture. - Work closely with cross-functional teams to implement technical resolutions. - Maintain relationships with stakeholders, developers, and engineers across the company to ensure our services meet their evolving needs. - Collaborate with partners in different teams to resolve any dependencies with data loss prevention products. - Design, build, and maintain cloud-based infrastructure to meet the organization's requirements and ensure high availability. About You: - You are an expert in data loss prevention tools. - You have a strong understanding of web proxy, email, and endpoint solutions. - You pay attention to detail and can clearly communicate technical information. - You can lead complex technical initiatives using cybersecurity practices, software engineering principles, agile frameworks, and customer engagement. - You can build collaborative relationships with technology groups and other stakeholders, including vendors. - You are a clear communicator and can interact effectively with people at all levels. - You have experience managing high-visibility cybersecurity projects with cross-functional teams. - You have passion and expertise in technical delivery, product security, software development practices, or platform engineering. - You have hands-on knowledge and expertise in securing technology, including operating systems, databases, virtualization, cloud computing environments, and networks. - You can troubleshoot, investigate, configure, and support data loss prevention products. Basic Qualifications: - High School Diploma, GED, or equivalent certification. - At least 6 years of experience in cybersecurity or information technology. - At least 5 years of experience in the data protection field. - At least 3 years of experience with Symantec Data Loss Prevention (DLP) infrastructure engineering. - At least 3 years of experience with URL filtering, proxy, or Network DLP. Preferred Qualifications: - Bachelor's Degree in Cybersecurity, Systems Engineering, or Computer Science. - 4+ years of experience in scripting and solving cyber technical challenges. - 4+ years of experience in the Agile delivery model. - 4+ years of experience in public cloud security and multi-cloud environments. - 3+ years of experience in IT Delivery projects and technical writing. - 3+ years of hands-on JIRA experience. - 2 or more professional cybersecurity certifications: CISSP, GIAC, CISM, CCSP, CISA, or Security+. - 1 or more professional cloud certifications: AWS Cloud Practitioner, AWS Solution Architect - Associate, AWS Developer - Associate, AWS Security - Specialty, or AWS Solution Architect - Professional. At this time, Capital One will not sponsor a new applicant for employment authorization for this position. Salary and Benefits: - The minimum and maximum full-time annual salaries for this role vary by location. Please visit our website for specific salary information. - We offer a comprehensive set of health, financial, and other benefits that support your total well-being. Eligibility varies based on employment status and level. To apply, please visit our website and submit your application. We are committed to diversity and inclusion in the workplace and are an equal opportunity employer. We consider all qualified applicants regardless of sex, race, age, religion, disability, genetic information, marital status, sexual orientation, gender identity, citizenship, veteran status, or any other basis prohibited by law. If you require accommodations during the application process, please contact Capital One Recruiting. All information you provide will be kept confidential and used only to provide necessary accommodations. We appreciate your interest in joining our team. For technical support or questions about the recruiting process, please send an email to Careers@capitalone.com. Note: This job advertisement is subject to applicable laws regarding criminal background inquiries. Thank you, [Your Name] --- Response: Subject: Application for Manager, Data Loss Prevention (DLP) Engineer (Symantec) Dear Hiring Manager, I am writing to express my interest in the Manager, Data Loss Prevention (DLP) Engineer position at Capital One. I believe my skills and experience make me a strong candidate for the role. I have attached my resume for your review. I have extensive experience working with data loss prevention tools and a strong understanding of web proxy, email, and endpoint solutions. I am detail-oriented and have excellent communication skills, both in conversation and in technical writing. I have successfully led complex technical initiatives and built collaborative relationships with various stakeholders. In addition, I have a passion for technical delivery and product security. I am excited about the opportunity to contribute to Capital One's cybersecurity efforts and help protect customer data. I am confident that my expertise and skills align with the requirements of the role. Thank you for considering my application. I look forward to the opportunity to discuss my qualifications further. Sincerely, [Your Name] --- Bullet Points: - Seeking a Manager, Data Loss Prevention (DLP) Engineer at Capital One to help improve cybersecurity and protect customer data. - Responsible for creating, implementing, and maintaining DLP Controls using SaaS and IaaS solutions. - Looking for candidates who are curious, stay updated on emerging trends, and are not afraid to question existing processes. - Must have expertise in data loss prevention tools and a strong understanding of web proxy, email, and endpoint solutions. - Excellent problem-solving and communication skills are essential. - Will work closely with cross-functional teams to implement technical resolutions. - Must be able to collaborate with stakeholders, developers, and engineers to ensure services meet evolving needs. - Experience with Symantec DLP infrastructure engineering and URL filtering, proxy, or Network DLP is required. - Preferred qualifications include a degree in Cybersecurity, Systems Engineering, or Computer Science, and experience in scripting, Agile delivery, and public cloud security. - Competitive compensation and comprehensive benefits package available. - Capital One is an equal opportunity employer committed to diversity and inclusion. All qualified applicants will receive consideration for employment without regard to sex, race, age, religion, disability, genetic information, marital status, sexual orientation, gender identity, citizenship, veteran status, or any other basis prohibited by law.
      </div>",No Salary Info Found,Data Architect
Principal Solutions Architect,Maximus,12/24/2023,https://www.linkedin.com/jobs/view/3787235968,0,https://media.licdn.com/dms/image/D4E0BAQGKt6jHfc2R7w/company-logo_100_100/0/1683829081773/maximus_logo?e=2147483647&v=beta&t=B9QvW8doL7MfiGhy0b9yJbDN07J-Zm_HoQbOO80WODA,"McLean, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Maximus continues to grow our Digital Solutions organization to better serve the needs of our organization and our customers in the government, health, and human services space. Digital Transformation is one of our primary strategic pillars and is a significant part of our long-term corporate strategy. We are a group of skilled practitioners who are laser-focused on continuing to introduce differentiated solution offerings aligned with the mission requirements of our customers to improve overall service delivery across our operations. We believe that great outcomes define our success. We use an approach grounded in design thinking, lean, and agile to help solve complicated problems and turn bold ideas into delightful solutions.<br/><br/>We are looking for a Principal Solutions Architect with experience architecting, developing, and implementing enterprise applications. The Ideal candidate will have a wide range of experience architecting solutions on J2EE, web-based frontend frameworks, and a variety of open-source technology platforms across N-tier architectures. The individual will have experience to operate independently and demonstrate experience leading/guiding a team to architect, develop, and implement business applications.<br/><br/>Position is remote but must be able to work on eastern standard time zone<br/><br/><strong>Essential Duties And Responsibilities:<br/><br/></strong><ul><li>Engage with internal teams to understand and architect technical solutions, facilitate solutions design and manage implementations.</li><li>Participate in the requirements gathering sessions to understand business needs and provide inputs to the technical requirements.</li><li>Review, guide and support RFIs, RFPs and RFQs, response development including writing of whitepapers and concept development.</li><li>Provide technical solution support during proposal process, to include technology stack, solution architecture, and implementation methodology.</li><li>Develop and provide presentations and demonstrations of technology solutions to both internal and external stakeholders as needed. The candidate must be comfortable presenting technical solutions to internal and external stakeholders.</li><li>Design and develop specific solutions leveraging technologies and design practices that enable a secure, scalable, sustainable, extensible and flexible solution.</li><li>Contribute to the design and architecture of software and infrastructure to ensure projects meet goals and should be able to clearly articulate and present the implications of design/architectural decisions, issues and plans to leadership.</li><li>Review the solution in the implementation and post deployment phases, to validate that the final solution matches the original approved design and architecture.</li><li>Work with engineering team to integrate approved solutions into the existing infrastructure and proactively identify associated potential risks and pitfalls involved, translate technical needs, and remove technical barriers.</li><li>Responsible for recommending and developing technical architectures, tools and processes that support the automation of environment management, build, testing, deployment and support processes.</li><li>Assist with builds and design of high-level architecture documentation and roadmap</li><li>Collaborate with other teams in the organization to define supporting infrastructure and software tools needed to enable DevOps practices in a large-scale environment.</li><li>Develop reusable patterns and encourage innovation that will enable team velocity.</li><li>Learn and analyze new technologies and industry best practices to identify suitability for adoption by the organization.<br/><br/></li></ul><strong>Minimum Requirements:<br/><br/></strong><ul><li>Bachelor's degree required in the field of computer science or equivalent. Master's degree a plus.</li><li>The candidate must have over 10 years of experience designing &amp; implementing enterprise solutions with working knowledge across numerous technology platforms.</li><li>Strongly preferred the candidate has over 15 years of experience in J2EE, with a strong focus on the Spring Boot framework; .net framework experience a big plus; C++ nice to have.</li><li>The candidate must have over 10 years in open-source technology-based development.</li><li>The candidate must have over 5 years in web frontend framework experience.</li><li>Experience across many of the following areas (listed in priority): N-Tier applications, Distributed Computing, Databases &amp; Storage, Data Analytics Cloud Architecture, eCommerce, Application Containerization &amp; Container Orchestrations, DevOps, Enterprise Architecture, Agile development, Robotic Process Animation (RPA), Machine Learning, Artificial Intelligence, Internet of Things (IoT), BlockChain, Low Code Platforms, and Digital Transformation &amp; Application Modernization</li><li>Strong working knowledge of Enterprise Software Design Patterns &amp; Cloud Software Architecture; AWS experience required; Azure experience a big plus</li><li>Works on significant and unique issues where analysis of situations or data requires an evaluation of intangibles.</li><li>Consistently works on complex assignments requiring independent action and a high degree of initiative to resolve issues.</li><li>Exercises independent judgement in methods, techniques and evaluation criteria for obtaining results.</li><li>Demonstrated ability to build trusted advisor relationships with clients</li><li>Experience supporting sales, pre-sales and business development is a key requirement</li><li>Individual contributor who oversees large, technically complex projects.</li><li>Knowledgeable of emerging trends and may contribute to and influence best practices within discipline.</li><li>Great oral and written communications<br/><br/></li></ul><strong><strong> Job Summary <br/><br/></strong></strong>Essential Duties and Responsibilities:<br/><br/><ul><li> Determine optimal architecture to support business requirements and solve highly complex technical challenges.</li><li> Keep up with industry trends and development and contribute to ongoing R&amp;D.</li><li> Guide and mentor architects and engineers establishing and maintaining architecture of highly complex solutions.</li><li> Produce solution architecture and estimates to support initiative proposals and business development.</li><li> Contribute to standards and approaches for architecture of enterprise data solutions.</li><li> Optimize overall data/information flow by reducing redundancy and enabling accessibility within security boundaries.</li><li> Identify data-related business requirements and service standards and translate these into actionable architecture design.<br/><br/></li></ul><strong>Minimum Requirements:<br/><br/></strong><ul><li> Bachelor's degree or equivalent experience in a technology related field, e.g., Computer Science, Data Science, Information Systems, Information Technology, or another relevant field.</li><li> Bachelor's degree and 10-12 years of relevant experience or equivalent combination of education and experience required.</li><li> 10-12 years of technical experience.</li><li> 10+ years of technical experience in a data-centric area, such as: enterprise data solutions, data architecture, data integration.</li><li> 3+ years of related technical experience in a lead or architect role.</li><li> Advanced technical and business knowledge of enterprise data solutions.</li><li> Theoretical and practical knowledge of cloud-based and cloud-native systems and applications.</li><li> Strong relationship management skills and the ability to effectively communicate (including written, verbal, and visual) at all organizational levels: customer, team member, management, and executive.</li><li> Understanding of enterprise business concepts, including processes, capabilities, enabling technologies, and governance.</li><li> Extensive experience contributing to technical initiatives supporting a large organization.</li><li> Ability and willingness to undertake a wide variety of challenging tasks.</li><li> Superior decision making and critical thinking ability.<br/><br/></li></ul><strong><strong> Education And Experience Requirements <br/><br/></strong></strong>#techjobs<br/><br/><strong> MAXIMUS Introduction <br/><br/></strong>Since 1975, Maximus has operated under its founding mission of Helping Government Serve the People, enabling citizens around the globe to successfully engage with their governments at all levels and across a variety of health and human services programs. Maximus delivers innovative business process management and technology solutions that contribute to improved outcomes for citizens and higher levels of productivity, accuracy, accountability and efficiency of government-sponsored programs. With more than 30,000 employees worldwide, Maximus is a proud partner to government agencies in the United States, Australia, Canada, Saudi Arabia, Singapore and the United Kingdom. For more information, visit https://www.maximus.com.<br/><br/><strong> EEO Statement <br/><br/></strong>EEO Statement: Active military service members, their spouses, and veteran candidates often embody the core competencies Maximus deems essential, and bring a resiliency and dependability that greatly enhances our workforce. We recognize your unique skills and experiences, and want to provide you with a career path that allows you to continue making a difference for our country. We're proud of our connections to organizations dedicated to serving veterans and their families. If you are transitioning from military to civilian life, have prior service, are a retired veteran or a member of the National Guard or Reserves, or a spouse of an active military service member, we have challenging and rewarding career opportunities available for you. A committed and diverse workforce is our most important resource. Maximus is an Affirmative Action/Equal Opportunity Employer. Maximus provides equal employment opportunities to all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status or disabled status.<br/><br/><strong> Pay Transparency <br/><br/></strong>Maximus compensation is based on various factors including but not limited to job location, a candidate's education, training, experience, expected quality and quantity of work, required travel (if any), external market and internal value analysis including seniority and merit systems, as well as internal pay alignment. Annual salary is just one component of Maximus's total compensation package. Other rewards may include short- and long-term incentives as well as program-specific awards. Additionally, Maximus provides a variety of benefits to employees, including health insurance coverage, life and disability insurance, a retirement savings plan, paid holidays and paid time off. Compensation ranges may differ based on contract value but will be commensurate with job duties and relevant work experience. An applicant's salary history will not be used in determining compensation. Maximus will comply with regulatory minimum wage rates and exempt salary thresholds in all instances.<br/><br/><strong> Posted Max <br/><br/></strong>USD $195,000.00/Yr.<br/><br/><strong> Posted Min <br/><br/></strong>USD $78,300.00/Yr.<br/><br/>
</div>",$195000.00- $78300.00,Data Architect
Data Architect (100% Remote),RemoteWorker US,12/21/2023,https://www.linkedin.com/jobs/view/3790980750,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Data Architect,Booz Allen Hamilton,12/19/2023,https://www.linkedin.com/jobs/view/3756108919,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Data Architect, Senior",Booz Allen Hamilton,12/19/2023,https://www.linkedin.com/jobs/view/3751777196,0,https://media.licdn.com/dms/image/D560BAQFONzmexEjnKQ/company-logo_100_100/0/1688152881727/booz_allen_hamilton_logo?e=2147483647&v=beta&t=WObdLZdWUtVerjHd32dAqEjay9aR9sBz2AI2Y4tN_44,"Arlington, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Number: R0183666<br/><br/></strong>Data Architect, Senior<br/><br/><strong>Key Role:<br/><br/></strong>Initiate data architecture (DA)-related activities, including extract-transform-load (ETL) processes and data warehouse solutions design, through business needs analysis and routine issue resolution. Apply advanced consulting and extensive technical expertise and full industry knowledge. Develop innovative solutions to complex problems. Work without considerable direction and mentor and supervise team members.<br/><br/><strong>Basic Qualifications:<br/><br/></strong><ul><li>5+ years of experience with modern data architectures and data warehousing</li><li>Experience with data platform technologies, including Databricks</li><li>Experience with designing solutions leveraging data lakehouses and paradigms</li><li>Experience with implementing AWS cloud solutions</li><li>Experience with business process reengineering, business process assessment, or business architectural development</li><li>Experience with data management, transformation, and migration using cloud data management pipelines, technologies, or open-source tools</li><li>Experience with working in an Agile development environment and collaborating with Application Development and Architecture Teams</li><li>Ability to automate operations and workflow procedures for data transformations</li><li>Secret clearance</li><li>Bachelor's degree<br/><br/><br/></li></ul><strong>Additional Qualifications</strong>:<br/><br/><ul><li>Experience with managing classified and sensitive data</li><li>Experience with architecture framework, including DoDAF</li><li>Knowledge of DoD and Air Force enterprise cloud environments</li><li>Bachelor's degree in CS, Computer Engineering, or Systems Engineering<br/><br/><br/></li></ul><strong>Clearance:<br/><br/></strong>Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.<br/><br/><strong>Compensation<br/><br/></strong>At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.<br/><br/>Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $81,800.00 to $186,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.<br/><br/><strong>Work Model<br/><br/></strong>Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.<br/><br/><ul><li>If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.</li><li>If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.<br/><br/><br/></li></ul><strong>EEO Commitment<br/><br/></strong>We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.
      </div>",$81800.00- $186000.00,Data Architect
Enterprise Solution Architect - Remote | WFH,Get It Recruit - Professional Services,12/19/2023,https://www.linkedin.com/jobs/view/3784461346,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Data Architect,Technology Ventures,12/20/2023,https://www.linkedin.com/jobs/view/3788678399,0,https://media.licdn.com/dms/image/C510BAQFzMaw0qgMjMA/company-logo_100_100/0/1630584764447/technology_ventures_logo?e=2147483647&v=beta&t=cYVX3EBL7Y0gKN4Udi1bsnwhU7ouODP-zJHqPZygG0E,"Reston, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>This role is specifically designed to support the LMFS (loan management future state) initiative. This role is helping establish a series of architecture and data structures that will support management. Candidates will replace a series of outdated structures and eliminating multiple data hops. This will also be automating the loan process.</p><p><br/></p><p>Description:</p><ul><li>As a valued contributor to our team, you will consult with management on the development of processes and procedures for designing and implementing components of technological structures. In this role, you will create solutions with a process-driven view, as well as maintain and/or update existing structures.</li><li>Determine the needs of diverse and complex customer groups by applying understanding and resolution of complex or unusual business problems.</li><li>Translate functional requirements into technical solutions, and engage matrixed teams.</li><li>Oversee existing structures, as well as the implementation and ongoing monitoring of governance.</li><li>Perform modeling, analysis, and planning to solve technical business problems and identify opportunities and risks.</li></ul><p><br/></p><p>Skills</p><ul><li>Develop target state architectures, including compliance for cloud inventory – influence delivery toward target state with the business and firm-wide technology products.</li><li>Promote deeper understanding of the executing production architecture to address and optimize patterns, anti-patterns and areas requiring agility for more rapid innovation.</li><li>Strategic thought leadership to advance product architecture tooling and operation models related to application portfolio modernization and tech debt that is visible and actioned.</li><li>Ensure standards, principles and tech stack are refreshed and guide application modernization.</li><li>Manage Single Family Domain Architecture agenda, including transparent technology strategy and strategic architecture direction that guide engineers.</li><li>Maintain active list of strategies and position papers required for emerging opportunities and/or challenges, to establish common understanding and clear direction.</li><li>Design architecture patterns.</li><li>Experience Leading strategy and roadmap of capabilities from architecture perspective. Coach and mentor other Architects within the organization.</li><li>Collaborate with other Architects on application architecture, data architecture, deployment architectures, functional design specifications; assist with other project deliverables as needed.</li><li>Expertise in Database and Management technologies including both relational and NoSQL DBs. Expertise in AWS Data Migration Service and Test Data management frameworks including encryption, masking, data and database migration</li><li>Experience with cloud migration, microservices architecture</li><li>Skilled in Amazon Web Services (AWS) offerings, development, and networking platforms</li><li>Experience using JIRA and Confluence.</li></ul>
</div>",No Salary Info Found,Data Architect
Sr. Data Architect - Remote,Veradigm®,12/20/2023,https://www.linkedin.com/jobs/view/3759667272,0,https://media.licdn.com/dms/image/D560BAQEWVyw-sP00mA/company-logo_100_100/0/1693413360236/veradigm_logo?e=2147483647&v=beta&t=vdDry8QfYxaXItdYIFDBt74xxcjn-Vo8qEsgdyuwST4,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Welcome to Veradigm! Our Mission is to be the most trusted provider of innovative solutions that empower all stakeholders across the healthcare continuum to deliver world-class outcomes. Our Vision is a Connected Community of Health that spans continents and borders. With the largest community of clients in healthcare, Veradigm is able to deliver an integrated platform of clinical, financial, connectivity and information solutions to facilitate enhanced collaboration and exchange of critical patient information.<br/><br/><strong>Veradigm Life Science<br/><br/></strong>The Veradigm Network is well-positioned to address the unique needs of Life Sciences customers. By leveraging the Veradigm Network, research data and associated insights become both an output of care delivery, as well as additional knowledge to improve quality of care, a true virtuous cycle.<br/><br/>Our portfolio of solutions provides insights using real-world data directly sourced from the Veradigm Network. These solutions can help Life Sciences customers discover timely, actionable real-world evidence to improve patient experience and outcomes, and demonstrate how their products can benefit appropriate patient populations.<br/><br/><strong>Overview<br/><br/></strong>Veradigm is an integrated data systems and services business that combines data-driven clinical insights with actionable tools for clinical workflow, research, analytics and media. Our solutions are designed to help key healthcare stakeholders to improve the quality, efficiency, and value of healthcare delivery – from biopharma to health plans, healthcare providers, health technology partners, and most importantly, the patients they serve. We are dedicated to simplifying the complicated healthcare system with next-generation healthcare solutions.<br/><br/>The Data Architect will provide input into the use of technology and definition of architectural approaches applied within Veradigm Life Sciences software solutions to meet the company and customer's long-term requirements.<br/><br/><strong>Are you the Right Fit? Are you passionate about data in Healthcare?<br/><br/></strong><strong>What You Will Contribute<br/><br/></strong><ul><li>Provide input into the use of technology and definition of architectural approaches applied within Allscripts' Veradigm Life Sciences software solutions to meet the company and customer's long-term requirements.</li><li>Assist development teams in the appropriate selection and use of technical frameworks, platforms and design patterns</li><li>Development and technology planning – provide guidance in best practice and tool use in the design and build of technical frameworks and the applications built on them.</li><li>Architecture and design –implement technical solutions or components of complex solutions and ensure their integrity</li><li>Technical design authority – internally recognized as highly competent in technical areas, will review and participate in benchmarking, installation, upgrade, configuration, deployment and testing activity</li><li>Improve quality – investigate and prototype innovative approaches to improve software quality</li><li>Industry knowledge – familiar with industry changes in technology standards, information management, development standards, methods and emerging 3rd party software in order to advise on technology and leverage industry best practice in the design and construction of Allscripts’ software products</li><li>Able to support day to day technical control of development projects by:</li><li> Assisting Project Management in planning technical aspects of projects</li><li> Providing regular updates on project status</li><li> Supporting and mentoring of individual junior developers</li><li> Performing detailed technical reviews to ensure design components are being correctly implemented</li><li>Provide input into the best application of technology to create the next generation of Allscripts’ Veradigm Life Sciences solutions</li><li>In concert with other architects within Veradigm Life Sciences create a center of expertise and forum for common component design, reuse and exploitation.</li><li>Participate in the definition and documentation of development standards and best practices.</li><li>Provide input in the drive for constantly improving the scalability, extensibility, interoperability, reliability, availability and performance of Veradigm Life Sciences software products.<br/><br/></li></ul><strong>Required Experience<br/><br/></strong><strong>The Ideal Candidate Will Have:<br/><br/></strong><ul><li>Bachelor’s Degree with a major in Computer Science, Mathematics, MIS or equivalent experience</li><li>7+ yrs relevant work experience, with 2-3 yrs at senior level or equivalent</li><li>Demonstrable understanding of architecture principles and methods, technology and standards</li><li>Cloud architectures</li><li>Data security and governance</li><li>Data modeling and design</li><li>Performance and cost analysis and improvement</li><li>Planning and estimating<br/><br/></li></ul><strong>Desired Experience<br/><br/></strong><ul><li>Cloud-based data technologies such as Snowflake and Databricks</li><li>Design and deployment of PaaS, serverless and container-based components</li><li>Data lakes and data warehouses</li><li>Processing big data</li><li>Process orchestration and event-based functions</li><li>Python, PySpark, SQL, R, Terraform</li><li>Developing and deploying solutions in AWS or Azure</li><li>Cloud infrastructure, application deployment and database deployment in CI/CD pipelines</li><li>Knowledge and experience building secure platforms in accordance with secure development lifecycle standards, in healthcare setting and EHR data</li><li>Industry knowledge related to healthcare data and analytics<br/><br/></li></ul><strong>Enhancing Lives and Building Careers<br/><br/></strong>Veradigm believes in empowering our associates with the tools and flexibility to bring the best version of themselves to work and to further their professional development. Together, we are <strong>In the Network</strong>. Interested in learning more?<br/><br/>Take a look at our Culture, Benefits, Early Talent Program, and Additional Openings.<br/><br/>We strongly advocate that our associates receive all CDC recommended vaccinations in prevention of COVID-19.<br/><br/>Visa Sponsorship is not offered for this position.<br/><br/>Veradigm’ policy is to provide equal employment opportunity and affirmative action in all of its employment practices without regard to race, color, religion, sex, national origin, ancestry, marital status, protected veteran status, age, individuals with disabilities, sexual orientation or gender identity or expression or any other legally protected category. Applicants for North American based positions with Veradigm must be legally authorized to work in the United States. Verification of employment eligibility will be required as a condition of hire. Veradigm is proud to be an equal opportunity workplace dedicated to pursuing and hiring a diverse and inclusive workforce.<br/><br/>From a ""VEVRAA Federal Contractor"" We request Priority Referral of Protected Veterans<br/><br/>This is an official Veradigm Job posting. To avoid identity theft, please only consider applying to jobs posted on our official corporate site.<br/><br/>Thank you for reviewing this Veradigm opportunity! Does this look like a great match for your skill set? If so, scroll on down and tell us more about yourself!<br/><br/>
</div>",No Salary Info Found,Data Architect
Architect,HHS Careers,12/21/2023,https://www.linkedin.com/jobs/view/3786794091,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Solutions Architect, Senior",Booz Allen Hamilton,12/21/2023,https://www.linkedin.com/jobs/view/3789914379,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Sr. Resident Solutions Architect, Financial Services",Databricks,12/23/2023,https://www.linkedin.com/jobs/view/3776982660,0,https://media.licdn.com/dms/image/D560BAQFPIRKiPVETuw/company-logo_100_100/0/1697215766274?e=2147483647&v=beta&t=faRGBPLYB4yh6WgGVy42GjwjqgOsBan4-CyL51NzK5w,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        CSQ125R52<br/><br/>While candidates in the listed location(s) are encouraged for this role, candidates in the US will be considered located anywhere in Eastern time zone.<br/><br/>As a Resident Solutions Architect, you will have the opportunity to shape the future big data landscape for leading Fortune 500 organizations. This position is a senior level customer-facing role that requires deep expertise in Apache Spark™ along with a breadth of big data solution architecture experience.<br/><br/>On a weekly basis, you will guide customers through architecture, design, and implementation while strategically aligning their technical roadmap for expanding the usage of the Databricks platform. As part of the RSA team, you will continue to strengthen your technical expertise through mentorship, continuous learning, and internal training programs. This role can be remote, but the ideal candidate will be located in the job listing area and have a willingness to travel up to 30%. You will report to the Professional Services Director.<br/><br/><strong>The Impact You Will Have<br/><br/></strong><ul><li>You will work on a variety of impactful customer technical projects which may include building reference architectures, how-to's and production grade MVPs</li><li>Guide strategic customers as they implement transformational lakehouse projects, 3rd party migrations, including end-to-end design, build and deployment of industry-leading Data and AI solutions</li><li>Consult on architecture and design; bootstrap or implement strategic customer projects which leads to a customers' successful understanding, evaluation and adoption of Databricks</li><li>Provide an escalated level of support for customer operational issues</li><li>You will work with the Databricks account team, Project Manager, Architect and customer team to ensure the technical components of the engagement are delivered to meet customer's needs<br/><br/></li></ul><strong>What We Look For<br/><br/></strong><ul><li>Must be eligible / willing to be processed for a US Government clearance.</li><li>Preferred: DoD Secret or Top Secret Clearance</li><li>Comfortable traveling to government customer sites on an as-needed basis</li><li>Proven experience in a technical consulting role, preferably within the Public Sector</li><li>5+ years of experience working as a software engineer using a JVM language</li><li>Proficient in SQL and either Python or Scala</li><li>Proven experience doing design and implementation in the modern data stack</li><li>2+ years of development experience with either AWS or Azure native services</li><li>Preferred: 2+ years of development experience in Spark <br/><br/></li></ul><strong>Benefits<br/><br/></strong><ul><li>Comprehensive health coverage including medical, dental, and vision </li><li>401(k) Plan </li><li>Equity Awards </li><li>Flexible Time Off </li><li>Paid Parental Leave </li><li>Family Planning </li><li>Fitness Reimbursement </li><li>Annual Career Development Fund </li><li>Home Office/Work Headphones Reimbursement</li><li>Employee Assistance Program (EAP) </li><li>Business Travel Accident Insurance </li><li>Mental Wellness Resources<br/><br/></li></ul><strong>Pay Range Transparency<br/><br/></strong>Databricks is committed to fair and equitable compensation practices. The pay range(s) for this role is listed below and represents base salary range for non-commissionable roles or on-target earnings for commissionable roles. Actual compensation packages are based on several factors that are unique to each candidate, including but not limited to job-related skills, depth of experience, relevant certifications and training, and specific work location. Based on the factors above, Databricks utilizes the full width of the range. The total compensation package for this position may also include eligibility for annual performance bonus, equity, and the benefits listed above. For more information regarding which range your location is in visit our page here.<br/><br/>Zone 1 Pay Range<br/><br/>$137,900—$244,000 USD<br/><br/>Zone 2 Pay Range<br/><br/>$137,900—$244,000 USD<br/><br/>Zone 3 Pay Range<br/><br/>$137,900—$244,000 USD<br/><br/>Zone 4 Pay Range<br/><br/>$137,900—$244,000 USD<br/><br/><strong>About Databricks<br/><br/></strong>Databricks is the data and AI company. More than 10,000 organizations worldwide — including Comcast, Condé Nast, Grammarly, and over 50% of the Fortune 500 — rely on the Databricks Data Intelligence Platform to unify and democratize data, analytics and AI. Databricks is headquartered in San Francisco, with offices around the globe and was founded by the original creators of Lakehouse, Apache Spark™, Delta Lake and MLflow. To learn more, follow Databricks on Twitter, LinkedIn and Facebook.<br/><br/><strong>Our Commitment to Diversity and Inclusion<br/><br/></strong>At Databricks, we are committed to fostering a diverse and inclusive culture where everyone can excel. We take great care to ensure that our hiring practices are inclusive and meet equal employment opportunity standards. Individuals looking for employment at Databricks are considered without regard to age, color, disability, ethnicity, family or marital status, gender identity or expression, language, national origin, physical and mental ability, political affiliation, race, religion, sexual orientation, socio-economic status, veteran status, and other protected characteristics.<br/><br/><strong>Compliance<br/><br/></strong><strong>If access to export-controlled technology or source code is required for performance of job duties, it is within Employer's discretion whether to apply for a U.S. government license for such positions, and Employer may decline to proceed with an applicant on this basis alone.</strong>
</div>",$137900- $244000,Data Architect
Data Architect,Fenway Group,12/24/2023,https://www.linkedin.com/jobs/view/3793000713,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
DevOps Architect,"Redapt, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3785073536,0,https://media.licdn.com/dms/image/C560BAQE4523IdJBa-w/company-logo_100_100/0/1641230862650/redapt_inc_logo?e=2147483647&v=beta&t=hvq1tXnLG7PSmghFVz5qhkhwBxpq6IzHl1MoG040GTg,Dallas-Fort Worth Metroplex,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Redapt Inc. is a pioneering world-class data center infrastructure integrator, technology engineering firm, and cloud services provider. Our teams focus on delivering innovative solutions and services that power our customers' most demanding applications and enable them to extract powerful insights from data that drive true business value.</p><p><br/></p><p>Redapt is looking for a self-motivated highly experienced DevOps Architect with deep experience in infrastructure solutions and services. The focus of this particular role is around Kubernetes and Infrastructure as Code (IaC) area of Cloud Development and DevOps. In this role, the qualified candidate will have experience in customer-facing consulting, leading teams in cloud solutions development and delivery. The qualified candidate is expected to possess cloud solution engineering skills as well as experience in building out architecture utilizing the latest in IaC technologies.</p><p><br/></p><p>Responsibilities:</p><ul><li>Lead requirements gathering, analysis and solution development for cloud-based DevOps solutions</li><li>Partner with project teams, functional architects, systems specialists, and other technical resources</li><li>Lead and deliver projects, remotely, in a hands-on role driving cloud migration/adoption from inception to production</li><li>Assume responsibility for technical presentations, and technical deliverables.</li><li>Mentor and provide technical oversight and guidance to implementation teams while working in a coordinated manner to deliver and deploy the designed architecture</li><li>Provide Cloud &amp; Code thought leadership through publications and speaking engagements as needed</li><li>Support the development and growth of Modern Data Center Practice / DevOps Team</li></ul><p><br/></p><p>Professional Qualifications:</p><ul><li>Working experience with Splunk</li><li>Working experience with Enterprise Level Software running thousands of instances</li><li>Working experience with AWS and other major cloud platforms</li><li>Working experience with Kubernetes/EKS</li><li>Working experience with Java microservices is ideal</li><li>Working experience CI/CD and General understanding of Jenkins-like automation tools</li><li>General knowledge of Security, Authentication, MFA, Authorization, B2C, Data Privacy, Identity and Access Management (IAM), Cryptography / Key Management, Access Controls and Security Protocols a plus</li></ul><p><br/></p><p>Education and Experience:</p><ul><li>Must have extensive working experience with AWS technologies</li><li>You have 3-5+ years overall industry experience</li><li>You have 2+ years of experience with demonstrated Cloud architecture projects and deployments</li><li>You have 2+ years of experience with Cloud solutions, platforms, and technologies</li><li>You have 1+ years of experience across the business development life cycle (i.e. Pre-Sales, Solution Architecture, Pricing, and Proposal Development)</li><li>You have 1+ years of experience working with Kubernetes in production</li><li>Comfortable working in an enterprise level environment</li><li>Mid-level to Expert level experience with Terraform in Cloud Environments</li><li>Bachelor's degree in Computer Science, Electronics, Information Systems or related field, or equivalent experience</li></ul><p><br/></p><p><br/></p><p>Compensation:</p><p>The base salary for this full-time position in the US is $140,000/yr - $170,000/yr+ bonus + benefits. Redapt salary ranges are determined by role, level, and location. The salary range displayed in each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Please note, the base pay offered may vary within the range depending on a wide array of factors including but not limited to work location, job-related knowledge/skills, relevant education/training, and level of experience. Please note that the compensation details listed in US role postings reflect the base salary only, and do not include commission/incentives or bonus or benefits.</p><p><br/></p><p>Equal Employment Opportunity:</p><p>Redapt is an equal opportunity employer. Applicants will not be discriminated against because of race, color, creed, sex, sexual orientation, gender identity or expression, age, religion, national origin, citizenship status, disability, ancestry, marital status, veteran status, medical condition, or any protected category prohibited by local, state, or federal laws. All employment is decided based on qualifications, merit, and business need.</p><p><br/></p><p>**Please no solicitations from Staffing/Recruiting firms or C2C**</p>
</div>",$140000- $170000,Data Architect
"Senior Data Architect, Principal",BAMM Staffing,12/19/2023,https://www.linkedin.com/jobs/view/3784428380,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Data Architect / Big Data Architect,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789744801,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Lewisville, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title: Senior Principal Data Architect</strong></p><p><strong>Location: Lewisville, TX (2 Days onsite per Week)</strong></p><p><strong>Duration: Full-time (Direct hire) </strong></p><p><br/></p><p>This is an individual contributor position - will be the Technical Lead to help guide the team members.</p><p> Must be hybrid Tuesdays and Wednesdays in Lewisville.</p><p> </p><p> <strong>Key requirements:</strong></p><p><strong> </strong>Architect must have Big Data platform experience.</p><p> 12-15 years of experience required.</p><p> Databricks required (should be strong)</p><p> ODS Warehouse</p><p> Data Lake experience</p><p> Azure required</p><p> Python experience </p><p> Data Governance</p><p> Data Modeling</p><p> Spark experience (can be lighter)</p><p> Financial Services/Mortgage industry experience is preferred.</p><p><br/></p><p><strong>EXPERIENCE REQUIREMENTS</strong></p><ul><li>12+ years of experience as a data architect, developer, data warehouse developer and / or data related operations.</li><li>Graduation from a 4-year college or university with major course work in a discipline related to the requirements of the position is preferred. Will consider the equivalent combination of job experience &amp; education that demonstrates the ability to perform the essential functions of this job. High school diploma or state accepted equivalency required.</li><li>5+ years of industry experience working with Big Data Platforms architecture, scalability and performance.</li><li>5+ progressive years of experience with design/architecture for transformations and modernizations of enterprise data &amp; storage solutions using Azure cloud technologies.</li><li>Deep expertise in real-time and batch data processing at large scale</li><li>Experience with Databricks design, development, administration, implementations, and operations.</li><li>Experience with data movement and transformation capabilities (Azure Data Factory, Data Lake Analytics, Databricks, Stream Analytics, and Azure Functions).</li><li>Strong development background creating data pipelines and complex data transformations using one of the languages like Python, Databricks/Spark, T-SQL.</li><li>5+ progressive years of experience in Data Warehouse and Business Intelligence technologies including data modeling techniques (Logical &amp; Physical)</li><li>Experience with visualization tools such as SSRS, Tableau, Microsoft Power BI.</li><li>Demonstrated experience in creating Data Governance strategies including MDM and Data Quality tools &amp; processes.</li><li>Well versed in SDLC, DevOps, and CI/CD deployment pipelines</li><li>Strong track record of interviewing business partners, setting and managing expectations in relation to deliverables and requirements.</li><li>Excellent problem-solving skills and analytical skills.</li><li>Excellent verbal and written communication skills with the ability to establish deep understanding of clients' business issues.</li><li>Mortgage and/or financial industry knowledge is strongly preferred.</li><li>Xome is committed to nurturing a diverse and inclusive environment where every employee is empowered to be their authentic self. We know that a large part of our success as a business is directly tied to our ongoing efforts to attract and retain diverse talent and maintain an inclusive environment where each employee can thrive. Embracing and leveraging diversity through an inclusive work environment fosters new ideas, new insights, and constant innovation. We strive to weave the principles of diversity and inclusion throughout the fabric of how we work, how we interact, and how we engage with our customers and the community.</li></ul><p><br/></p><p><strong>ESSENTIAL JOB FUNCTIONS</strong></p><ul><li>Be able to architect, design and develop data models (actual models, DDLs and as required be able to create physical structures of those models).</li><li>Have a hands-on approach to solving problems; when required, be able to lead-by-example-type of person in developing snippets of the SQLs, any code references that team can use and follow.</li><li>Have deep knowledge of data architectures, ODS, Data warehouse and methodologies.</li><li>Good working knowledge of data models and be able to use any industry leading data modeling tools to create data models and update them as needed.</li><li>Maps the systems and interfaces used to manage data sets, set standards for data management</li><li>Analyzes current state and conceives desired future state; and conceives projects needed to close the gap between current and future goals with new data technologies and industry trends.</li><li>Ability to astutely operate in the organization, and being able to emphasize methodology, modelling and governance.</li><li>Ability to work closely with the users, systems designers and the developers on a project both in Agile &amp; SDLC methodology</li><li>Need to be able to have an end-to-end vision, and to see how a logical design will translate into one or more physical databases, and how the data will flow through the successive stages involved.</li><li>The data architect will need to be able to address issues of data migration (validation, clean-up and mapping), and understanding the importance of data dictionaries</li><li>Coordinate with Business partners, Technical Analysts and Developers to identify and define specifications, indicate areas of system impact and continuously communicate project status and needs.</li><li>Manages change control processes, and ensures program/project communications.</li><li>Negotiates project plans, time frames, and trade-off with Business partners, and apprises management of impact to project.</li><li>Strong leadership, communications and presentation skills with the ability to clearly communicate status to senior management team.</li></ul><p>Mentor, provide guidance, advice, and support to team members</p>
</div>",No Salary Info Found,Data Architect
Senior Cloud Systems Architect,Verily,12/19/2023,https://www.linkedin.com/jobs/view/3725195208,0,https://media.licdn.com/dms/image/D4D0BAQE_emsFllk5sA/company-logo_100_100/0/1694611858408/verily_logo?e=2147483647&v=beta&t=T0RNoczI_jkULsHOKyjpxgtzJAyxELyGrNEz3p_0cr8,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Who We Are<br/><br/></strong><strong>Verily is a subsidiary of Alphabet</strong> that is using a data-driven approach to change the way people manage their health and the way healthcare is delivered. Launched from Google X in 2015, our purpose is to bring the promise of precision health to everyone, every day. We are focused on generating and activating data from a variety of sources, including clinical, social, behavioral and the real world, to arrive at the best solutions for a person based on a comprehensive view of the evidence. Our unique expertise and capabilities in technology, data science and healthcare enable the entire healthcare ecosystem to drive better health outcomes.<br/><br/><strong>Description<br/><br/></strong>As a Senior Cloud Architect at Verily you will help us develop and maintain our cloud IT capabilities and tools that enable Verily teams to deliver scalable, reliable, secure, and performant IT and infrastructure systems. You will work with IT and product teams to help them learn, adapt, and adopt our core cloud management tools and best practices. You will also help develop documentation and training material and evangelize these technologies and capabilities to the broader engineering organization. As an expert in Cloud technologies, you will also help influence architecture and infrastructure decisions within the broader engineering organization.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Assist with design and implementation of Verily’s virtual cloud IT data center infrastructure. Including platforms, host virtualization and internal tooling.</li><li>Develop and drive adoption of core cloud provisioning systems (eg. Terraform, Atlantis, Google Cloud tooling).</li><li>Build and deliver training material for Verily engineering teams to help them measure and improve the reliability, observability, scalability, and automation level of their services. </li><li>Integrate Google Cloud services with our core cloud management systems, utilizing Terraform templates and developing or modifying scripts that integrate with 1st party and 3rd party operational and observability tools.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><strong>Minimum Qualifications: <br/><br/></strong><ul><li>Practical experience and/or Bachelor’s degree in Computer Science or a related technical field.</li><li>5+ years experience in Terraform development and testing.</li><li>5+ years experience in programming in at least one of the following: Go, Python, Rust, BASH, Typescript, Java.</li><li>Strong written and verbal communication skills.<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Experience working with Google Cloud and Kubernetes.</li><li>Experience working with Splunk and/or DataDog.</li><li>Experience designing, implementing, and managing complex distributed systems in a public cloud environment (GCP, AWS, or Azure).</li><li>Experience writing technical documentation or building codelabs.<br/><br/></li></ul>The US base salary range for this full-time position is $124,000 - $191,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.<br/><br/><em>Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits.<br/><br/></em><strong>Why Join Us<br/><br/></strong><strong>Build What’s Vital.<br/><br/></strong>At Verily, you are a part of something bigger. We are a diverse team of builders innovating at the intersection of health and technology—united by a shared spirit of curiosity, resilience and determination to make better health possible for all. This builder mindset means your fingerprints will be on the work that shapes the future of health.<br/><br/>Fulfilling our precision health purpose starts with the health of our Veeps, which is why we offer flexibility, resources, and competitive benefits to support you in your whole-person well being.<br/><br/>Our culture reflects the behaviors that stem from living our values every day in how we Innovate Healthcare and Technology, Gain Velocity as One Verily, and Respect Individuals. As One Verily, we uphold our collective accountability to sustain this culture and to create a VIBE (Verily’s Culture of Inclusion, Belonging, and Equitability) where all Veeps feel included, a sense of belonging, and have opportunities to grow.<br/><br/>If this sounds exciting to you, we would love to hear from you.<br/><br/>You can find out more about our company culture on our LinkedIn Company Page and Verily Careers page.<br/><br/>
</div>",$124000- $191000,Data Architect
Data Architect,Virtusa,12/19/2023,https://www.linkedin.com/jobs/view/3773979740,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Principal Services Architect,CyberCoders,12/19/2023,https://www.linkedin.com/jobs/view/3734017521,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Data Analytics Architect,Anblicks,12/19/2023,https://www.linkedin.com/jobs/view/3790098176,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Principal Data Architect (Remote),Stryker,12/19/2023,https://www.linkedin.com/jobs/view/3771907522,0,https://media.licdn.com/dms/image/C4E0BAQHa7kowBO7CeQ/company-logo_100_100/0/1631319537543?e=2147483647&v=beta&t=mbPNvpZ3COq7NAhA9rdZ9CoyF11uVz2hY0qkmP9IZS8,"Flower Mound, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Why join Stryker?<br/><br/>We are proud to be named one of the World’s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting stryker.com<br/><br/>We are seeking a highly skilled and experienced Data Architect to join our newly formed data engineering team within Finance. This data engineering team is part of the larger Finance Data Science &amp; Analytics organization and works closely with an in-house team of data science experts and functions across Stryker. The Finance Data Engineering team is responsible for overseeing the design, development, and maintenance of our data infrastructure and systems to enable AI, automation, and innovative analytics. This person’s efforts will be dually focused on aggregating data from Stryker’s ERPs and partner systems for the Finance organization, while also spearheading internal data engineering activities for the Finance Data Science team.<br/><br/>As a leader in this space, you will provide technical leadership and strategic guidance to the data engineering team, ensuring the successful delivery of projects and adherence to best practices. Your expertise in managing large-scale data pipelines, optimizing data workflows, and implementing predefined data governance policies will be crucial in driving the organization's data strategy and enabling data-driven decision-making. Join our team and contribute to building robust and scalable data solutions that empower our business to harness the full potential of data analytics.<br/><br/>**While the role is listed as remote, the ideal candidate will be within driving distance of our Flower Mound, TX or Mahwah, NJ office and will be required to be in office based on business needs.**<br/><br/><strong>Who We Want:<br/><br/></strong><ul><li>Data translators. Highly effective communicators who can transform data findings into recommendations to compose reports and executive level presentations.</li><li>Strategic thinkers. People who enjoy analyzing data or trends for the purposes of planning, forecasting, advising, budgeting, reporting, or sales opportunities.</li><li>Collaborative partners. People who build and leverage cross-functional relationships to bring together ideas, data and insights to drive continuous improvement in functions.<br/><br/></li></ul><strong>What You Will Do:<br/><br/></strong><ul><li>Provide technical and project leadership in the development and execution of a comprehensive data architecture strategy and project portfolio aligned with business objectives, ensuring scalability, reliability, and performance.</li><li>Design and implement efficient and robust data models, data integration pipelines, and data storage solutions to meet business requirements.</li><li>Collaborate with cross-functional leadership to understand data needs, identify opportunities for data-driven solutions, and recommend appropriate technologies and methodologies.</li><li>Partner across functions to leverage domain expertise and capabilities to curate raw data to ensure it is fit for purpose and in line with defined acceptance criteria.</li><li>Coach and mentor a team of data engineers, providing guidance, technical expertise, and fostering a collaborative and high-performing environment.</li><li>Work with Data Scientists in developing architectures that incubate our growing capabilities in generative AI and LLMs.</li><li>Conduct performance tuning and optimization of databases, data pipelines, and data processing systems to maximize efficiency and minimize latency.</li><li>Evaluate and select appropriate tools, frameworks, and technologies for data engineering tasks, ensuring alignment with the organization's technology stack and goals.</li><li>Establish and maintain data catalogs and data dictionaries to enable data understanding, usability, and promote data governance.</li><li>Collaborate with stakeholders to establish data governance practices, data quality standards, and data security measures to ensure data integrity and compliance.</li><li>Orchestrate requirements gathering, needs assessments, and development/maintenance of technical documentation for key systems and data assets.</li><li>Demonstrate financial acumen to develop financial impacts for existing projects and evaluating new opportunities.</li><li>Orchestrate presentations and communications to leadership level as needed through effective conveying of complex topics.</li><li>Stay up to date with emerging data technologies, industry trends, and best practices, and assess their applicability to the organization's data architecture.<br/><br/></li></ul><strong>What You Need:<br/><br/></strong><ul><li>Bachelor's Degree in data engineering, data science, computer science, software engineering, or related field with applicable data architecture work experience.</li><li>Master's Degree or PhD in quantitative discipline preferred.</li><li>Minimum of 8 years’ experience in data engineering, big data technologies, or data management, including design and implementing data solutions across multiple projects and domains.</li><li>Experience in leading projects with a team of data engineers or data architects, ensuring effective collaboration and delivery of high-quality solutions.</li><li>Extensive knowledge of data modeling principles and practices, including conceptual, logical, and physical data modeling, data integration, and data governance.</li><li>Advanced in at least one programming language central to data engineering (e.g., SQL/Python/Spark) or skilled in multiple languages.</li><li>Expert in ETL/ELT, pipeline creation, orchestration, &amp; data store/warehouse/systems architecture.</li><li>Advanced in working knowledge of native tools such as data storage, distributed computing, business intelligence, and infrastructure as code (Power BI, Apache Spark, Azure, GCP, AWS etc.).</li><li>Expertise in database technologies, both relational and non-relational, such as Oracle, SQL Server, MongoDB, Cassandra, etc., including performance tuning and optimization.</li><li>Deep understanding of cloud platforms (AWS, Azure, Google Cloud) and experience architecting data solutions in a cloud environment, leveraging cloud-based data storage and processing services. Experience with Azure preferred.</li><li>Experienced in DataOps, DevOps, and/or SecOps in an Agile environment.</li><li>Experienced in implementing/managing Agile/DevOps using GitHub/GitLab for versioning control, and infrastructure as code.<br/><br/></li></ul>$122,800.00 - $271,400.00 salary plus bonus eligible + benefits. Actual minimum and maximum may vary based on location. Individual pay is based on skills, experience, and other relevant factors.<br/><br/><strong>About Stryker<br/><br/></strong>Our benefits:<br/><br/><ul><li>12 paid holidays annually </li><li>Health benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program. </li><li>Financial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&amp;D insurance, and short-term disability insurance. <br/><br/></li></ul>For a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits<br/><br/><strong>About Stryker<br/><br/></strong>Stryker is one of the world’s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.<br/><br/>Know someone at Stryker?<br/><br/>Be sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page<br/><br/>Stryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.<br/><br/>R510058
      </div>",$122800.00- $271400.00,Data Architect
Sr. Data Architect - Remote,Veradigm®,12/19/2023,https://www.linkedin.com/jobs/view/3759664536,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Senior Data Analyst – Strong Python Skill (Bangkok based, relocation provided)",Agoda,12/25/2023,https://www.linkedin.com/jobs/view/3791652168,0,https://media.licdn.com/dms/image/C4D0BAQGBa_7QNZNwpw/company-logo_100_100/0/1656643826660/agoda_logo?e=2147483647&v=beta&t=5V7q9sl3YFGW99Fa_-fGJ8jjK_dhtppZ8mxz8836vy4,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Agoda<br/><br/></strong>Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.<br/><br/><strong> Get to Know our Team: <br/><br/></strong>The Supply Equity Platform (SEP) team sits within the Product Supply team at Agoda Bangkok. We work closely with the sales department (Partner Services) to identify and optimize growth opportunities on accommodations supply for the company and to set up experiments to measure and implement changes. The projects SEP team works on directly impact Agoda’s bottom line and have long lasting structural impact to the business. We cover a range of topics including resource and product optimization. We collaborate with multiple departments and produce high quality results backed up by experimentation and data. Utilizing powerful tools and possessing an end-to-end view of how Agoda works, the SEP offers a team of learning and experience that will push you (and Agoda) into new territory.<br/><br/><strong> In this Role, you’ll get to:  <br/><br/></strong><ul><li> Manage complex analytics processes and algorithms to ensure their continued smooth operation, identifying root causes and debugging them where needed. </li><li> Use and analyze data from multiple large-scale data warehouses and understand data flows across the entire organization. </li><li>Identify, support, and lead projects aimed at improving the operations of our automated systems (e.g. root cause detection, anomaly detection, performance analysis)</li><li>Develop automated infrastructure supporting business intelligence at a global level as well as the analytics processes supporting them</li><li>Drive new analytical initiatives and projects aimed at improving resource and product optimization. <br/><br/></li></ul><strong>What you’ll Need to Succeed:<br/><br/></strong><ul><li>Experience in big data cleaning and wrangling as well as simple analytical processing (SQL is a must).</li><li>Have 3 years working experience in Python for data analysis.</li><li>A basic understanding of statistics and data, and the ability to implement this understanding in complex business situations</li><li>The ability to visualize and understand complex data flows, pipelines, and processes. </li><li>⁠A hacker’s mindset – the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping</li><li>Either Bachelor’s degree in Computer Science or Bachelor’s degree in a quantitative discipline with extensive programming experience<br/><br/></li></ul><strong> Must-Have Skill: <br/><br/></strong><ul><li> Experience with complex analytics and statistical/machine learning techniques using R/Python/Spark. </li><li> Experience building automated analytical processes and functionality. <br/><br/></li></ul>#telaviv #jerusalem #IT #ENG #4 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #sydney #melbourne #perth #toronto #vancouver #montreal #prague #Brno #Ostrava #cairo #alexandria #giza #estonia #paris #berlin #munich #hamburg #stuttgart #cologne #frankfurt #budapest #bali #dublin #telaviv #milan #rome #venice #florence #naples #turin #palermo #bologna #osaka #malta #amsterdam #oslo #warsaw #krakow #alrayyan #riyadh #jeddah #mecca #medina #singapore #seoul #barcelona #madrid #stockholm #zurich #taipei #tainan #taichung #kaohsiung #bangkok #Phuket #istanbul #london #manchester  #edinburgh #hcmc #hanoi #lodz #wroclaw #poznan #katowice #rio #salvador #newdelhi #bangalore #bandung #yokohama #nagoya #okinawa #fukuoka #jerusalem #IT #4 #bangalore #delhi #hyderabad #pune #singapore #beijing #shanghai #shenzhen #tokyo #seoul #hongkong #taipei #kualalumpur #jakarta #hochiminh #hochiminhcity #manila #instanbul #makati #dubai #riyadh #gurgaon #noida<br/><br/><strong>Equal Opportunity Employer <br/><br/></strong>At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.<br/><br/>We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .<br/><br/>To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.<br/><br/>
</div>",No Salary Info Found,Data Architect
Data Catalog and Lineage Central Governance Analyst,PwC,12/20/2023,https://www.linkedin.com/jobs/view/3785061774,0,https://media.licdn.com/dms/image/D4D0BAQH3qXh7nyImoQ/company-logo_100_100/0/1697100791441/pwc_logo?e=2147483647&v=beta&t=egwzMH-OEEIdbRMowwJcaDKwrISS95b4zQiwpJJhhyw,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Specialty/Competency: </strong>IFS - Information Technology (IT)<br/><br/><strong>Industry/Sector: </strong>Not Applicable<br/><br/><strong>Time Type: </strong>Full time<br/><br/><strong>Travel Requirements: </strong>Up to 20%<br/><br/>A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.<br/><br/>To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.<br/><br/><strong>Responsibilities<br/><br/></strong>As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:<br/><br/><ul><li>Use feedback and reflection to develop self awareness, personal strengths and address development areas.</li><li>Delegate to others to provide stretch opportunities, coaching them to deliver results.</li><li>Demonstrate critical thinking and the ability to bring order to unstructured problems.</li><li>Use a broad range of tools and techniques to extract insights from current industry or sector trends.</li><li>Review your work and that of others for quality, accuracy and relevance.</li><li>Know how and when to use tools available for a given situation and can explain the reasons for this choice.</li><li>Seek and embrace opportunities which give exposure to different situations, environments and perspectives.</li><li>Use straightforward communication, in a structured way, when influencing and connecting with others.</li><li>Able to read situations and modify behavior to build quality relationships.</li><li>Uphold the firm's code of ethics and business conduct.<br/><br/></li></ul><strong>Additional Responsibilities<br/><br/></strong>Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.<br/><br/><strong>Custom Orgs<br/><br/></strong><strong>Global LoS</strong>:<br/><br/>Internal Firm Services<br/><br/><strong>Basic Qualifications<br/><br/></strong><strong>Job Requirements and Preferences</strong>:<br/><br/><strong>Minimum Degree Required<br/><br/></strong>High School Diploma<br/><br/><strong>Minimum Years Of Experience<br/><br/></strong>2 year(s)<br/><br/><strong>Preferred Qualifications<br/><br/></strong><strong>Degree Preferred</strong>:<br/><br/>Bachelor Degree<br/><br/><strong>Preferred Fields Of Study<br/><br/></strong>Computer and Information Science, Data Processing/Analytics/Science<br/><br/><strong>Additional Educational Preferences<br/><br/></strong>Other related fields of study with relevant experience may be considered.<br/><br/><strong>Preferred Knowledge/Skills<br/><br/></strong>Demonstrates thorough abilities and/or a proven record of success as a team leader:<br/><br/><ul><li>Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;</li><li>Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes;</li><li>Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;</li><li>Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;</li><li>Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;</li><li>Exhibiting proven knowledge and working experience in Microsoft Purview;</li><li>Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;</li><li>Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;</li><li>Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;</li><li>Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;</li><li>Facilitating the capture of metadata as core change and operational deliverables;</li><li>Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;</li><li>Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;</li><li>Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;</li><li>Possessing ability to create and maintain automated workflows for periodic metadata refresh;</li><li>Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable);</li><li>Helping manage the inventory of data-related controls on systems that support segment processes and customers;</li><li>Showcasing thorough understanding of data steward/data owner operating model; </li><li>Ability in designing and rolling out training programs to train the trainer/end-users;</li><li>Being a collaborative team player; and,</li><li>Having a business outcome focused problem-solving mindset.<br/><br/></li></ul>Learn more about how we work: https://pwc.to/how-we-work<br/><br/>PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.<br/><br/>All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.<br/><br/>For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.<br/><br/>Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines<br/><br/>For positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate<br/><br/>
</div>",No Salary Info Found,Data Architect
Principal Data Scientist,Intuit,12/19/2023,https://www.linkedin.com/jobs/view/3739158009,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Data Scientist, Mid",Booz Allen Hamilton,12/19/2023,https://www.linkedin.com/jobs/view/3751774506,0,https://media.licdn.com/dms/image/D560BAQFONzmexEjnKQ/company-logo_100_100/0/1688152881727/booz_allen_hamilton_logo?e=2147483647&v=beta&t=WObdLZdWUtVerjHd32dAqEjay9aR9sBz2AI2Y4tN_44,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Number: R0183656<br/><br/></strong>Data Scientist, Mid<br/><br/><strong>The Opportunity: <br/><br/></strong>As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors—from fraud detection to cancer research to national intelligence—we need you to help find the answers in the data.<br/><br/>On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide teammates and lead the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used. Work with us as we use data science for good.<br/><br/>Join us. The world can’t wait.<br/><br/><strong>You Have:<br/><br/></strong><ul><li>3+ years of experience with data science, data analytics, machine learning, or statistics, including in a management or advisory role</li><li>Experience with object-oriented programming languages, including Python, C++, Java, or R</li><li>Experience with Cloud services, including AWS, Azure, or Google Cloud</li><li>Experience with identifying and analyzing data sets to meet customer requirements</li><li>Experience with preparing customer data for models, including merging and aggregating data, handling anomalies, balancing, and feature selection</li><li>Ability to help interpret model results and communicate them clearly through compelling data visualizations</li><li>Secret clearance</li><li>Bachelor’s degree<br/><br/><br/></li></ul><strong>Nice If You Have:<br/><br/></strong><ul><li>Experience with supervised and unsupervised machine learning techniques, including neural networks, decision trees, logistic regressions, or dimension reduction</li><li>Experience with data engineering and data science tools, including Databricks, ElasticSearch, Apache NiFi, or StreamSets</li><li>Experience with enterprise DataOps, DevSecOps, and MLOps processes to operationalize and monitor data science models</li><li>Experience with Agile development</li><li>Experience with CI/CD, including Git, Jenkins, and Docker</li><li>Knowledge of procedural SQL language, including PL/pgSQL</li><li>Ability to explain analytic and model findings to non-technical audiences<br/><br/><br/></li></ul><strong>Clearance:<br/><br/></strong>Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information; Secret clearance is required.<br/><br/><strong>Create Your Career: <br/><br/></strong><strong>Grow With Us <br/><br/></strong>Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.<br/><br/><strong>A Place Where You Belong <br/><br/></strong>Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time.<br/><br/><strong>Support Your Well-Being<br/><br/></strong>Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.<br/><br/><strong>Your Candidate Journey<br/><br/></strong>At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.<br/><br/><strong>Compensation<br/><br/></strong>At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.<br/><br/>Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.<br/><br/><strong>Work Model<br/><br/></strong>Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.<br/><br/><ul><li>If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.</li><li>If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.<br/><br/><br/></li></ul><strong>EEO Commitment<br/><br/></strong>We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.
      </div>",$73100.00- $166000.00,Data Architect
"Electrical Engineer, Command and Data Handling Architect",General Atomics,12/19/2023,https://www.linkedin.com/jobs/view/3639927083,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Data Analyst (Bangkok Based, relocation provided)",Agoda,12/19/2023,https://www.linkedin.com/jobs/view/3750113069,0,https://media.licdn.com/dms/image/C4D0BAQGBa_7QNZNwpw/company-logo_100_100/0/1656643826660/agoda_logo?e=2147483647&v=beta&t=5V7q9sl3YFGW99Fa_-fGJ8jjK_dhtppZ8mxz8836vy4,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Agoda<br/><br/></strong>Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.<br/><br/><strong> Get to Know our </strong><strong> Team: <br/><br/></strong>The Performance Marketing Team of Agoda is a world leader in online marketing. This department is highly data-driven and focused on developing at-scale marketing programs that improve the lifetime value of Agoda customers through measurable marketing programs and channels. The team is a blend of the best analysts, marketing strategists, and data scientists in the world. The marketing leadership at Agoda have deep experience in data science, product, strategy, and other marketing fields and have built an organization that thrives on data, creative ideas, and technology. The Performance Marketing Team also fosters a great learning environment. You will be able to learn and grow by working closely with experts from a variety of backgrounds from all over the world.<br/><br/><strong> In this Role, you’ll get </strong><strong> to: <br/><br/></strong><ul><li>Search: Experiment with text ads, bidding, and campaign structures on Google, Bing, Baidu, Naver, and other search engines. Adapt to new product features and roll out changes from successful tests</li><li>Display: Test, analyze, and optimize campaigns on Facebook, Twitter, Instagram, and others</li><li>Modeling: Analyze the vast amounts of data generated by experiments, develop models we can use for optimization, and build dashboards for account managers<br/><br/></li></ul><strong> What you’ll Need to </strong><strong> Succeed: <br/><br/></strong><ul><li>Bachelor’s Degree or higher from top university in a quantitative subject (computer science, mathematics, engineering, statistics or science)</li><li>Ability to communicate fluently in English</li><li>Exposure to one or more data analysis packages or databases, e.g., SAS, R, SPSS, Python, VBA, SQL, Tableau</li><li>Good numerical reasoning skills</li><li>Proficiency in Excel</li><li>Intellectual curiosity and analytical skills<br/><br/></li></ul><strong> It’s Great if you </strong><strong> Have: <br/><br/></strong><ul><li>Experience in digital marketing</li><li>Academic research experience<br/><br/></li></ul>#STRA#ANLS#MRKT#3 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #washdc #tirana #yerevan #sydney #melbourne #perth #vienna #graz  #baku #minsk #brussels #antwerp #ghent #charleroi  #saopaolo #sofia #toronto #vancouver #montreal #shanghai #beijing #shenzhen #zagreb #cyprus #prague #Brno #Ostrava #copenhagen #cairo #alexandria #giza #estonia #helsinki #paris #nice #marseille #rouen #lyon #toulouse #tbilisi #berlin #munich #hamburg #stuttgart #cologne #frankfurt #dusseldorf #dortmund #essen #Bremen #leipzig #dresden #hanover #nuremberg #athens #hongkong #budapest #bangalore #newdelhi #jakarta #bali #bandung #dublin #telaviv #milan #rome #naples #turin #palermo #venice #bologna #florence #tokyo #osaka #yokohama #nagoya #okinawa #fukuoka #sapporo #amman #irbid #riga #beirut #tripoli #vilnius #luxembourg #kualalumpur #malta #chisinau #amsterdam #oslo #jerusalem #manila #warsaw #krakow #sintra  #porto #braga #cascais #loures #amadora #almada #doha #alrayyan #bucharest #moscow #saintpetersburg #riyadh #jeddah #mecca #medina #belgrade #singapore #bratislava #capetown #johannesburg #seoul #barcelona #madrid #valencia #seville #bilbao #malaga #oviedo #alicante #laspalmas #zaragozbanga #stockholm #zurich #geneva #basel #taipei #tainan #taichung #kaohsiung #Phuket #bangkok #istanbul #ankara #izmir #dubai #abudhabi #sharjah #london #manchester  #edinburgh #kiev #hcmc #hanoi #sanaa #taiz #aden #gibraltar #marrakech #lodz #wroclaw #poznan #Gdansk #szczecin #bydgoszcz #lublin #katowice #rio #salvador #fortaleza #brasilia #belo #belem #manaus #curitiba #portoalegre #saoluis data representation data analysis SQL data analytics analytics python (programming language) data mining data science r (programming language) tableau analytical skills data visualization databases business analysis business intelligence (bi) microsoft sql server machine learning statistics microsoft power bi java finance shopee traveloka google facebook ctrip trip.com makemytrip grab amazon pandas (software) artificial intelligence (ai) information technology capital one accenture upwork deloitte mckinsey bain microsoft uber lyft gojek lazada alibaba shopify expedia skyscanner<br/><br/><strong>Equal Opportunity Employer <br/><br/></strong>At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.<br/><br/>We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .<br/><br/>To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.<br/><br/>
</div>",No Salary Info Found,Data Architect
Staff Business Data Analyst,Intuit,12/19/2023,https://www.linkedin.com/jobs/view/3754946151,0,https://media.licdn.com/dms/image/C560BAQFTpF8uneqScw/company-logo_100_100/0/1661446146222/intuit_logo?e=2147483647&v=beta&t=iftV6ZuJ3UG8jC5zwm-gE8RPaVtk4cAhvGG4aXrt6AA,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>Come join Intuit as a Staff Business Data Analyst!<br/><br/>We have an exciting opportunity on a team that is defining how we use analytics to transform customer experiences, accelerate business growth and optimize our growth efforts. We are looking for a data-driven individual with excellent analytical skills, experience in product conversion and a passion for delivering data-driven insights to join Intuit’s Customer Success Data and Analytics team.<br/><br/><strong>What You'll Bring<br/><br/></strong><ul><li> 7-10 years of experience working in marketing, web, product, or other related analytics fields.</li><li> Highly proficient in SQL, Tableau or other data reporting solution</li><li> Experience with multiple optimization techniques including AB Testing, Personalization, and Multi-Armed Bandits a plus</li><li> Experience in modeling or business application/evaluation of machine learning</li><li> Comfort working with large data sets (i.e., clickstream) to generate insights</li><li> Excellent problem-solving skills and end to end quantitative thinking</li><li> Ability to manage multiple projects simultaneously to meet objectives and deadlines</li><li> Ability to tell stories with data; educate and motivate stakeholders to act on recommendations</li><li> Outstanding communications skills with both technical and non-technical colleagues</li><li> Must be a proactive thinker, intellectually curious, and have a bias for action</li><li> Strong organizational skills, time management, portfolio prioritization experience, and accountability required</li><li> Bachelor’s Degree in Math, Statistics, Computer Science, or related field, or equivalent experience; Master’s Degree preferred or equivalent work experience<br/><br/></li></ul><strong>How You Will Lead<br/><br/></strong><ul><li> Identify and size new opportunities (year-round and as part of 1 &amp; 3-yr business planning)</li><li> Partner with product, UX and tech teams to design and test new personalized experiences</li><li> Design new methodologies, experiments, &amp; dashboards to ensure results are measurable and actionable</li><li> Collaborate with data scientists to identify predictive attributes &amp; build ML models that optimize outcomes</li><li> Analyze results and generate insights that inform continued iteration of models / improvement in business results</li><li> Utilize advanced analytics techniques and data mining to analyze and action on clickstream data</li><li> Provide guidance and thought leadership to business stakeholders on how best to harness available data in support of critical business needs and goals</li></ul>
</div>",No Salary Info Found,Data Architect
"Pixel System Architect Lead, Graphics",Google,12/19/2023,https://www.linkedin.com/jobs/view/3772408124,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Sr. Network Engineer,Innovative Defense Technologies (IDT),12/19/2023,https://www.linkedin.com/jobs/view/3725129821,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
IT Risk and Compliance Analyst III,Russell Tobin,12/19/2023,https://www.linkedin.com/jobs/view/3767537899,0,https://media.licdn.com/dms/image/C4E0BAQGDyf9hqiiCxQ/company-logo_100_100/0/1680195921945/russell_tobin__associates_llc_logo?e=2147483647&v=beta&t=iXvVSGtRYyYXYAQvpampnUqV2wUg2LwRgoJuwiPwyCk,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        What are we looking for in our IT Risk and Compliance Analyst III?<br/><br/><strong>Role:</strong> <strong>IT Risk and Compliance Analyst III <br/><br/></strong><strong>Location: San Diego, CA 92129, (Remote) <br/><br/></strong><strong>Rate: $80-$84/-Hr on W2<br/><br/></strong><strong>Duration: 6+ months <br/><br/></strong><strong>Job Description: <br/><br/></strong><ul><li>Collaborate with multiple teams across Client’s tech ecosystem to oversee the implementation of data governance activities, policies, and change management.</li><li>Work closely with Data Governance, Compliance, and Security Teams, as well as Legal Counsel, to gain insight into their plans and roadmaps.</li><li>This will enable effective communication to Tech teams regarding upcoming changes and developments.</li><li>Monitor Security Defect processes, work with dependent teams to remediate issues, provide status updates to senior leaders, and identify opportunities to improve efficiency of security processes.</li><li>Provide guidance and advice to development teams on data policies and processes covering data usage, security, privacy, and compliance.</li><li>Act as a compliance subject matter expert (SME) for teams developing new platform capabilities to ensure compliance requirements are accounted for upfront.<br/><br/></li></ul><strong>Skills: <br/><br/></strong><ul><li>4+ years in a technical role (software engineering, data architect, data engineering, technical analyst, etc.)</li><li>2+ years of data compliance, governance, and data privacy experience Knowledge of cloud infrastructure and security concepts, including managing compliance requirements against distributed applications on cloud infrastructure Proven ability to work with business and analytics leaders to identify and align on workable business solutions to data privacy requirements and challenges.</li><li>Ability to successfully champion the role of data governance in data privacy forums An understanding of government regulatory requirements (e.g. GDPR, CCPA, CCPR, 7216) and emerging trends and issues.</li><li>Knowledge of data governance practices, business and technology issues related to management of enterprise information assets and approaches related to data protection.</li><li>Acute attention to detail, a strong sense of accountability, collaboration and understanding of large scale cloud data platform infrastructure.</li><li>This role is remote with 10% travel expected<br/><br/></li></ul>#CB<br/><br/>Rate/Salary: $80-$84/-Hr on W2<br/><br/>
</div>",$80- $84,Data Architect
Qliksense Developers / Data Architects - Remote | WFH,Get It Recruit - Information Technology,12/24/2023,https://www.linkedin.com/jobs/view/3787273332,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a dynamic team seeking experienced Qlik Developers and Data Architects to join our ranks. While we work with Fortune 100 clients, our focus is on creating a collaborative and innovative environment where your skills can shine. Whether you're in New Jersey or working remotely, you'll be an integral part of our team, contributing to cutting-edge Qlik and QlikSense applications.<br/><br/><strong>Responsibilities<br/><br/></strong>As a Senior Consultant, you'll collaborate closely with your team and clients to develop state-of-the-art Qlik and QlikSense applications. Your role involves working with Oracle, Teradata, SAP databases, Business Objects universes, and more. Beyond application development, you'll assess data quality, design network and system architectures, and develop administration best practices. Your creativity will be essential in developing solutions for client problems.<br/><br/><strong>Key Activities<br/><br/></strong>Analyze and implement data and business processes, performing gap analysis and addressing data quality issues.<br/><br/>Organize diverse data sources into cohesive data models.<br/><br/>Install and administer Qlik software, including Qlik Server/Publisher.<br/><br/>Integrate third-party software like Snap Logic, GeoQlik, or NPrinting into Qlik applications.<br/><br/>Design and develop Qlik mobile applications.<br/><br/>Assist clients with Qlik Server integration issues.<br/><br/>Develop innovative solutions for client challenges.<br/><br/>Build positive relationships with both internal and external customers.<br/><br/>Identify customer needs and collaboratively address requirements.<br/><br/>Document process and data quality issues, propose solutions, and validate results.<br/><br/>Implement solutions, including training and support for client personnel.<br/><br/>Define project schedules, milestones, and publish progress reports.<br/><br/><strong>Requirements/Qualifications<br/><br/></strong>Technical Skills:<br/><br/>Significant experience in Qlik application development.<br/><br/>2-3 years of database development experience using star schema.<br/><br/>Strong SQL experience is a must.<br/><br/>Knowledge of Powershell and other scripting technologies.<br/><br/>Experience in installing, administering, and troubleshooting Windows Server and Qlik Server/Publisher.<br/><br/>Familiarity with Virtual Machines.<br/><br/>Strong working knowledge of Windows security, including Active Directory.<br/><br/>Development experience with ERP software (SAP or Oracle) and CRM software (Siebel) is preferred.<br/><br/>Experience with cube-based BI environments (Cognos, Business Objects, or Hyperion) is a plus.<br/><br/>Web-based application development using .NET, Visual Basic, or Java environments is a bonus.<br/><br/><strong>Business/Data Management Skills<br/><br/></strong>Experience with ETL tools, assessing data quality, and developing remediation plans.<br/><br/>Experience analyzing, designing, and defining new or re-engineered business processes and related system impacts.<br/><br/>Ability to develop functional and technical requirements.<br/><br/><strong>Excellent Communication Skills (verbal And Written) And Decision-making Abilities.<br/><br/></strong>Diplomatic problem-solving skills.<br/><br/>Strong time management and organizational skills for a multitasking environment.<br/><br/>Self-directed with proven ability to work as part of a client-consultant team.<br/><br/>Client management skills are a plus.<br/><br/>Data Modeling and Logical Database Design experience is a bonus.<br/><br/><strong>Education<br/><br/></strong>BA/BS Degree (MBA a plus) with 5-7 years of applicable business experience.<br/><br/>Qlik Developer certification is preferred.<br/><br/><strong>Position Structure<br/><br/></strong>Contractor or Full-time Bardess employee role, including benefits such as Medical, 401K, Holidays, Vacation, etc.<br/><br/>Employment Type: Full-Time
      </div>",No Salary Info Found,Data Architect
Qliksense Developers / Data Architects - Remote (Virtual Office),Bardess Group Ltd,12/24/2023,https://www.linkedin.com/jobs/view/3793003847,0,https://media.licdn.com/dms/image/C4E0BAQHYxLeL9-f3qg/company-logo_100_100/0/1631370372773/bardess_group_logo?e=2147483647&v=beta&t=rd93vKEmi9rx5NS3CfpN9RzKwc4akBLVRkBGUliYz_U,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>Experienced Qlik Developers / Data Architects -- working with Fortune 100 clients<br/><br/></strong><strong>Location Desired: </strong>New Jersey or Remote<br/><br/><strong>Location Option: </strong>Virtual Home Office with periodic travel to client sites<br/><br/><strong>Qlik Developers/Data Architects - Position Description:<br/><br/></strong>As a Senior Consultant you will work closely with your Bardess colleagues and client project team members to develop cutting edge Qlik and QlikSense applications with interfaces to Oracle, Teradata or SAP databases, Business Objects universes and the like. Additionally, you will work with other subject matter experts in assessing/analyzing data quality and developing remediation plans for data improvement. You will design and implement network and system architectures. You will analyze network communication and diagnose system behavior. You will develop and maintain administration best practices. You will develop scripts for administration and solving client problems.<br/><br/><strong>Qlik Developers/Data Architect </strong>activities include but are not limited to:<br/><br/><ul><li>Analyze, assess and implement data and business processes, perform gap analysis and identify data quality issues within those business processes</li><li>Organize disparate data sources into single data models</li><li>Install and administer Qlik software including Qlik Server / Publisher</li><li>Integrate 3rd party software such as Snap Logic, GeoQlik or NPrinting into Qlik applications</li><li>Design and develop Qlik mobile applications. </li><li>Install and administer Qlik Server and Publisher software. </li><li>Assist Client with Qlik Server integration issues. </li><li>Develop creative solutions for client problems. </li><li>Establish positive relationships with customers (internal and external)</li><li>Identify customer needs and work collaboratively to address requirements</li><li>Identification and documentation of process and data quality issues within target business processes, upstream data feeds, and client interface. </li><li>Identification, evaluation, and proposal of solutions to identified process and data quality issues, including the development of specifications. </li><li>Validation of solutions, as well as end-to-end processes, by testing programs and validating results. </li><li>Implementation of solutions, including training and support of client personnel. </li><li>Definition of project schedule and milestones, and publishing of progress reports. <br/><br/></li></ul><strong>Requirements/Qualifications for Qliksense Developers / Data Architects:<br/><br/></strong><em>Technical Skills Required:<br/><br/></em><ul><li>Significant experience developing Qlik applications a must</li><li>2-3 years database development experience using star schema a must</li><li>Strong SQL experience required. </li><li>Knowledge of Powershell and other scripting technologies. </li><li>Significant experience installing, administering and troubleshooting Windows Server and Qlik Server/Publisher required. </li><li>Experience with Virtual Machines. </li><li>Strong working knowledge of Windows security including Active Directory. </li><li>Major development experience with ERP software such as SAP or Oracle, or CRM software such as Siebel preferred</li><li>Experience with competitive cube-based BI environments such as Cognos, Business Objects, or Hyperion is a plus</li><li>Web-based application development using .net, Visual Basic, or Java environments a plus</li><li>Web-based application development using .net, Visual Basic, or Java environments a plus<br/><br/></li></ul><em>Business/Data Management Skills Required:<br/><br/></em><ul><li>Experience with ETL tools assessing data quality and developing remediation plans</li><li>Experience with analyzing, designing and defining new or re-engineered business processes and related system impacts</li><li>Experience developing functional and technical requirements</li><li>Strong communications (verbal and written) and decision-making skills required</li><li>Diplomatic problem solver</li><li>Time management and organizational skills a must for multi-task environment</li><li>Self-directed with proven ability to work as part of a client-consultant team</li><li>Client management skills a plus</li><li>Data Modeling and Logical Database Design experience a plus<br/><br/></li></ul><em>Education:<br/><br/></em><ul><li>BA/BS Degree (MBA a plus) with 5-7 years' applicable business experience</li><li>Qlik Developer certification preferred<br/><br/></li></ul><strong>Position Structure - </strong>Contractor or Full-time Bardess employee role including benefits: Medical, 401K, Holidays, Vacation, etc.
      </div>",No Salary Info Found,Data Architect
Martech Solution Architect- Data Analytics,Nityo Infotech,12/19/2023,https://www.linkedin.com/jobs/view/3784428789,0,https://media.licdn.com/dms/image/C560BAQHaxYKD0j0Vfg/company-logo_100_100/0/1630653338909/nityo_infotech_services_logo?e=2147483647&v=beta&t=cos6Df6ooTYRDz9OPBziBAx72pwl5_PhPYnXI3q58uI,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are open for <strong>Contract</strong> and <strong>Full-time</strong> both.<br/><br/>We have total three / 3 open roles, and it's a Hybird on-site at Philly, PA.<br/><br/>No of role:- 3<br/><br/><strong>Summary Of Required Skills<br/><br/></strong><ul><li>Defining solutions, applications, infrastructure, and tools for the organization for a completely cloud oriented team</li><li>Leading the solution architecture for software engineers and business stakeholders, enabling residential marketing teams. Focusing on bridging the conversation between engineers and business partners in a productive manner. Comprehension of the business context, an understanding of the Comcast ecosystems and technology, and enough technical expertise to effectively communicate with the engineering staff is critical.</li><li>Requires someone assertive who brings people together to solve complex problems with an iterative, feedback-driven approach.</li><li>Ideally, these team members would be considered generalists. Need someone who can do basic assessments of platforms and scale, resiliency, etc. Specifically identifying COTS systems that will not scale to be removed from the ecosystem. Also capable of exploring opportunities to modify COTS to meet needs.</li><li>Experience with marketing systems (marketing technology, campaign management, audiences, data exchange, profile management, etc) and Marketing Activation (targeting, personalization, content management, etc) at scale and in an organization that is multi regional.</li><li>Neutral w/r/t java vs .NET vs python, need to be able to look at code and understand it</li><li>Experience working with Data is critical - understand the metadata - identify the patterns, how it moves through the systems. Understand ETL processes, data management, specifically what data quality look like and typical standards, encryption standards, retention of data, data lineage, etc.</li><li>These people will be individual contributors and depending on staffing &amp; budget, there may be a desire to mix the skill level. While skill sets will be similar across members, you’ll likely choose to have them focus slightly differently depending on need.<br/><br/></li></ul><strong>General Responsibility Description<br/><br/></strong><ul><li>Define the platform architecture, technology strategy, and implementation standards</li><li>Provide technology guidance to shape the overall strategy</li><li>Collaborate with other architects and subject matter experts to integrate our solution with the broader ecosystem</li><li>Interface with the enterprise architecture team and other functional areas to design the most efficient solution</li><li>Present solutions to leadership, management, architects, and developers</li><li>Apply and integrate emerging technological trends into new and existing systems architecture</li><li>Monitor current and future trends, technology, and information in the technology space to positively affect organizational projects<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Over 10+ years of experience in the IT industry</li><li>Excellent organizational, technical, interpersonal, and communication skills</li><li>Strong analytical skills with the ability to think strategically and critically</li><li>Ability to work with all levels within the organization, including field service team members, management, cross-departmental teams, and senior leadership</li><li>Experience working on an enterprise-scale web application</li><li>Experience in administration of production environments in distributed enterprise-wide solutions</li><li>Experience in availability, capacity, and disaster recovery planning</li><li>Experience in data security and data privacy best practices and implementation strategies</li><li>Adept at developing strategic plans and working with large and distributed teams</li><li>Familiarity with current software design methodologies, including agile (scrum) development process</li><li>Experience with public cloud platforms (AWS, Azure, etc.) is a plus</li></ul>
</div>",No Salary Info Found,Data Architect
"Sr. Consultant, IT Architecture",Lincoln Financial Group,12/19/2023,https://www.linkedin.com/jobs/view/3718226931,0,https://media.licdn.com/dms/image/C510BAQFmAC2YdD4bxA/company-logo_100_100/0/1631311489681?e=2147483647&v=beta&t=XP1JCw30UnU03IGzIbjKQtJin9b0Y7ZIUrU4Vh4NJYQ,"Radnor, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Alternate Locations:</strong> Work from Home<br/><br/><strong> Work Arrangement:<br/><br/></strong>Hybrid/Flexible : Work at home and use the office as appropriate for in-person collaboration.<br/><br/><strong>Relocation assistance: </strong> is not available for this opportunity.<br/><br/><strong>Requisition #:</strong> 72337<br/><br/><strong>The Role at a Glance<br/><br/></strong>The Sr. Analyst, Enterprise Architect ensures that complex architecture decisions are implemented consistently across the business and IT in order to support the business and IT strategy. S/he will be primarily responsible for working across business and technology teams to deliver a 3+ year technology investment plan and implementation roadmap for the business line they are aligned.<br/><br/><strong>What You'll Be Doing<br/><br/></strong><ul><li>Maintains knowledge on current and emerging developments/trends for assigned area(s) of responsibility, assesses the impact, and collaborates with senior management to incorporate new trends and developments in current and future solutions.</li><li>Directs and enhances organizational initiatives by positively influencing and supporting change management and/or departmental/enterprise initiatives within assigned area(s) of responsibility.</li><li>Identifies and directs the implementation of process improvements that significantly improve quality across the team, department and/or business unit for his/her assigned area(s) of responsibility.</li><li>Provides subject matter expertise to team members and applicable internal/external stakeholders on complex assignments/projects for his/her assigned area(s) of responsibility.</li><li>Provides direction on complex assignments, projects, and/or initiatives to build and enhance the capability of his/her assigned area(s) of responsibility.</li><li>Translate business strategies into a technology investment roadmap for their assigned business line</li><li>Collaborates with business and technology teams and serves as a subject matter expert to deliver and understand the complex technology roadmap for their assigned business line.</li><li>Understands complex business unit needs and where business strategy is taking LFG from technology perspective and interpolates ways that systems can be used across enterprise.</li><li>S/he will define and maintain complex target technology architectures for their assigned business unit</li><li>Responsible for having an advanced understanding of IT industry trends and enterprise standards and methodology in the Insurance or Financial Services space.</li><li>The role will be knowledgeable of the complex enterprise systems and applications, and can be called upon to provide subject matter expertise in multiple areas, i.e., Java-based Architectures, Data Analytics or Mobile applications</li><li>Influencing the technology solutions &amp; technology investments that will deliver the business strategy</li><li>Provides direction and guidance to scope and architect major technology change projects, leading strategic options analysis, proposing end-to-end solutions, and highlighting trade-offs and risks</li><li>Review evolving designs of major technology projects to identify strategic opportunities and resolve design issues during delivery</li><li>Ensure IT projects align with strategic capabilities, target architectures &amp; technology standards.</li><li>Oversee the management of the application portfolio management system for their area(s) of responsibility.</li><li>Identify key technology enablers to optimize Lincoln’s IT investments including new and innovative uses of emerging enterprise technology platforms</li><li>Influence key IT vendors and partners.<br/><br/></li></ul><strong>What We’re Looking For<br/><br/></strong>4 Year/Bachelor's degree or equivalent work experience (4 years of experience in lieu of Bachelor's) (Minimum Required)<br/><br/>5 – 7+ Years of experience in Technology Architecture that directly aligns with the specific responsibilities for this position (Required)<br/><br/><strong>What’s it like to work here?<br/><br/></strong>At Lincoln Financial Group, we love what we do. We make meaningful contributions each and every day to empower our customers to take charge of their lives. Working alongside dedicated and talented colleagues, we build fulfilling careers and stronger communities through a company that values our unique perspectives, insights and contributions and invests in programs that empower each of us to take charge of our own future.<br/><br/><strong>What’s in it for YOU:<br/><br/></strong><ul><li>A clearly defined career framework to help you successfully manage your career</li><li>Leadership development and virtual training opportunities</li><li>PTO/parental leave</li><li>Competitive 401K and employee benefits</li><li>Free financial counseling, health coaching and employee assistance program</li><li>Tuition assistance program</li><li>A leadership team that prioritizes your health and well-being; offering a remote work environment and flexible work hybrid situations</li><li>Effective productivity/technology tools and training<br/><br/></li></ul><strong>Pay Range:</strong> $102,301 - $184,500<br/><br/>Actual base pay could vary based on non-discriminatory factors including but not limited to work experience, education, location, licensure requirements, proficiency and qualifications required for the role. The base pay is just one component of Lincoln’s total rewards package for employees. In addition, the role may be eligible for the Annual Incentive Program, which is discretionary and based on the performance of the company, business unit and individual. Other rewards may include long-term incentives, sales incentives and Lincoln’s standard benefits package.<br/><br/><strong>About The Company<br/><br/></strong>Lincoln Financial Group helps people to plan, protect and retire with confidence. As of Dec. 31, 2022, approximately 16 million customers trust our guidance and solutions across four core businesses – annuities, life insurance, group protection and retirement plan services. As of September 30, 2023, the company had $290 billion in end-of-period account balances, net of reinsurance. Headquartered in Radnor, Pa., Lincoln Financial Group is the marketing name for Lincoln National Corporation (NYSE: LNC) and its affiliates. Learn more at LincolnFinancial.com.<br/><br/>Lincoln is committed to creating a diverse and inclusive environment and is proud to be an equal opportunity employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status.<br/><br/>Follow us on Facebook, Twitter, LinkedIn, and Instagram. Sign up for email alerts at http://newsroom.lfg.com<br/><br/><strong>Be Aware of Fraudulent Recruiting Activities<br/><br/></strong>If you are interested in a career at Lincoln, we encourage you to review our current openings and apply on our website. Lincoln values the privacy and security of every applicant and urges all applicants to diligently protect their sensitive personal information from scams targeting job seekers. These scams can take many forms including fake employment applications, bogus interviews and falsified offer letters.<br/><br/>Lincoln will not ask applicants to provide their social security numbers, date of birth, bank account information or other sensitive information in job applications. Additionally, our recruiters do not communicate with applicants through free e-mail accounts (Gmail, Yahoo, Hotmail) or conduct interviews utilizing video chat rooms. We will never ask applicants to provide payment during the hiring process or extend an offer without conducting a phone, live video or in-person interview. Please contact Lincoln's fraud team at fraudhotline@lfg.com if you encounter a recruiter or see a job opportunity that seems suspicious.<br/><br/><strong>Additional Information<br/><br/></strong>This position may be subject to Lincoln’s Political Contribution Policy. An offer of employment may be contingent upon disclosing to Lincoln the details of certain political contributions. Lincoln may decline to extend an offer or terminate employment for this role if it determines political contributions made could have an adverse impact on Lincoln’s current or future business interests, misrepresentations were made, or for failure to fully disclose applicable political contributions and or fundraising activities.<br/><br/>Any unsolicited resumes/candidate profiles submitted through our web site or to personal e-mail accounts of employees of Lincoln Financial Group are considered property of Lincoln Financial Group and are not subject to payment of agency fees.<br/><br/>Lincoln Financial Group (“LFG”) is an Equal Opportunity employer and, as such, is committed in policy and practice to recruit, hire, compensate, train and promote, in all job classifications, without regard to race, color, religion, sex (including pregnancy), age, national origin, disability, sexual orientation, gender identity and expression, Veteran status, or genetic information. Applicants are evaluated on the basis of job qualifications. If you are a person with a disability that impedes your ability to express your interest for a position through our online application process, or require TTY/TDD assistance, contact us by calling 260-455-2558.<br/><br/>This Employer Participates in E-Verify. See the E-Verify notices.<br/><br/>Este Empleador Participa en E-Verify. Ver el E-Verify avisos.
      </div>",$102301- $184500,Data Architect
Enterprise Data Architect,Corteva Agriscience,12/19/2023,https://www.linkedin.com/jobs/view/3702651703,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
"Senior Staff Data Scientist, Loss Forecasting",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3757407679,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Finance Data Mart - Data Domain Architect - Vice President,JPMorgan Chase & Co.,12/19/2023,https://www.linkedin.com/jobs/view/3749946522,0,https://media.licdn.com/dms/image/C4E0BAQFN7ZGRjNcgeA/company-logo_100_100/0/1656681489601/jpmorganchase_logo?e=2147483647&v=beta&t=7HTiK8ZaXIlJOAOaTl79xuuUanapyO6fdUn-acFg3wY,"Wilmington, DE","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>Are you a skilled data architect with a passion for driving innovation in the cloud? We're seeking a Domain Data Architect who can transform raw data into actionable insights, leveraging cutting-edge technologies like Databricks and ThoughtSpot. In this role, you'll architect and design data solutions that empower our organization with faster, more informed decision-making. If you're ready to shape the future of data analytics within cloud platforms, this is the opportunity you've been waiting for.<br/><br/>As a Data Domain Architect for the Consumer and Community Banking (CCB) Finance Data Mart, you will contribute to the transformation and modernization of our data environment to serve the analytical and reporting needs of the CCB Finance Organization. You will partner with the Technology Team to design and deliver data domains into the Databricks powered Data Mart that brings together essential data categories to enable the Finance function to support their analytical and reporting needs. You will partner with Product teams and stakeholders across the CCB Finance Product Organization to understand their needs and make data discoverable and available for analytical and reporting needs. This role requires a deep understanding of data architecture, data integration, and data warehousing, as well as strong interpersonal skills to collaborate with stakeholders and ensure alignment with the organization's objectives.<br/><br/><strong>Job Responsibilities<br/><br/></strong><ul><li>Implement and optimize the Finance Data Mart using Databricks and ThoughtSpot to create a robust and efficient environment for data analytics and reporting</li><li>Design and implement comprehensive and efficient data mart schemas that consolidate key data categories from various source systems, tailored to the needs of the Finance&amp; Business Management function, comprehensive of our diverse set of business including banking, wealth management, credit cards, auto lending, and home lending.</li><li>Collaborate with cross-functional teams, including data engineers, data analysts, and technical specialists, to gather and analyze business requirements</li><li>Develop, implement, and optimize data workflows, Extract Transform Load(ETL) processes, and data pipelines using Databricks.</li><li>Work closely with business domain focused Area Product teams and business stakeholders to: 1) design and develop insightful reporting and analytics solutions that drive informed decision-making; 2) apply design led thinking to meet their needs, including making data discoverable and accessible for analytical needs</li><li>Maintain up-to-date documentation on data mart architecture, data models, ETL processes, and data governance policies.</li><li>Stay current on industry best practices and emerging trends in data warehousing, data integration, and data management, ensuring the organization remains at the forefront of innovation.<br/><br/></li></ul><strong>Required Qualifications, Capabilities And Skills<br/><br/></strong><ul><li>Minimum of 7 years of experience in data architecture, data warehousing, and data integration, with a focus on the retail banking or financial services industry.</li><li>Bachelor’s degree in Computer Science, Information System, or related discipline</li><li>Expertise in designing and implementing scalable and efficient data mart architectures, including star schema, snowflake schema, and other data modeling techniques.</li><li>Strong knowledge and experience with data management, data lineage, data dictionaries, and making data discoverable</li><li>Proven track record of successfully managing and delivering complex data projects in a fast-paced, dynamic environment.</li><li>Strong written and verbal communication skills</li><li>SQL, Data Modeling, ERWIN<br/><br/></li></ul><strong>Preferred Qualifications, Capabilities And Skills<br/><br/></strong><ul><li>Strong knowledge of Amazon Web Services (AWS), AWS Certifications preferred</li><li>Databricks, Snowflake, or other Cloud Data Warehouse experience preferred</li><li>Experience on market leading data catalog systems preferred</li><li>ThoughtSpot, Tableau, Alteryx, or Essbase experience a plus<br/><br/></li></ul><strong>For this particular role, we are unable to sponsor any type of work visa including but not limited to H1B, H4 – EAD, OPT, TN, or L visas.<br/><br/></strong><strong>Candidates must be able to physically work in our Wilmington, DE or Columbus, OH offices 3 days a week and remotely from home 2 days per week. The specific schedule will be determined by direct management.<br/><br/></strong><strong>About Us<br/><br/></strong>Chase is a leading financial services firm, helping nearly half of America’s households and small businesses achieve their financial goals through a broad range of financial products. Our mission is to create engaged, lifelong relationships and put our customers at the heart of everything we do. We also help small businesses, nonprofits and cities grow, delivering solutions to solve all their financial needs.<br/><br/>We recognize that our people are our strength and the diverse talents they bring to our global workforce are directly linked to our success. We are an equal opportunity employer and place a high value on diversity and inclusion at our company. We do not discriminate on the basis of any protected attribute, including race, religion, color, national origin, gender, sexual orientation, gender identity, gender expression, age, marital or veteran status, pregnancy or disability, or any other basis protected under applicable law. In accordance with applicable law, we make reasonable accommodations for applicants’ and employees’ religious practices and beliefs, as well as any mental health or physical disability needs.<br/><br/>We offer a competitive total rewards package including base salary determined based on the role, experience, skill set, and location. For those in eligible roles, discretionary incentive compensation which may be awarded in recognition of individual achievements and contributions. We also offer a range of benefits and programs to meet employee needs, based on eligibility. These benefits include comprehensive health care coverage, on-site health and wellness centers, a retirement savings plan, backup childcare, tuition reimbursement, mental health support, financial coaching and more. Additional details about total compensation and benefits will be provided during the hiring process.<br/><br/>JPMorgan Chase is an Equal Opportunity Employer, including Disability/Veterans<br/><br/><strong>About The Team<br/><br/></strong>Our Consumer&amp; Community Banking division serves our Chase customers through a range of financial services, including personal banking, credit cards, mortgages, auto financing, investment advice, small business loans and payment processing. We’re proud to lead the U.S. in credit card sales and deposit growth and have the most-used digital solutions – all while ranking first in customer satisfaction.<br/><br/>The CCB Data&amp; Analytics team responsibly leverages data across Chase to build competitive advantages for the businesses while providing value and protection for customers. The team encompasses a variety of disciplines from data governance and strategy to reporting, data science and machine learning. We have a strong partnership with Technology, which provides cutting edge data and analytics infrastructure. The team powers Chase with insights to create the best customer and business outcomes.<br/><br/>
</div>",No Salary Info Found,Data Architect
Azure Data Architect,SLK,12/19/2023,https://www.linkedin.com/jobs/view/3784443801,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Artificial Intelligence Consultant,Synapsis Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3785074734,0,https://media.licdn.com/dms/image/C4E0BAQFx8Y8IYJDRqw/company-logo_100_100/0/1630563765033/synapsis_inc_logo?e=2147483647&v=beta&t=0B1KSlK7fDEl-2rYaC6FoAVBVuQYCAFUunEWS7OkIrY,"Malvern, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Title: GEN AI Developer (Strong Python skills)</p><p>Duration: 12+ Months</p><p>Location: Malvern, PA</p><p>Client : Vanguard</p><p><br/></p><p><strong>Job Description:</strong></p><p>• Strong Python skills including libraries like LangChain, LangIndex, PyTorch, SageMaker SDK, psycopg2</p><p>• Experience with Docker and AWS ECR</p><p>• Strong AWS experience with with the following services:</p><p>◦ Bedrock</p><p>◦ SageMaker</p><p>◦ IAM</p><p>◦ Glue</p><p>◦ S3</p><p>◦ Lambda</p><p>◦ CodeCommit and CodePipeline</p><p>• Experience creating quick apps using Streamlit, NodeJS, or some other app framework</p><p>• Education and or experience in developing NLP models for text classification, completion, summarization, generation</p><p>• Experience using embeddings models to create vector embeddings and working with vector databases</p><p>• Understanding of RAG architecture, retrieval optimization, and tradeoffs of splitting methods</p><p>• Familiarity with benchmarks for model evaluation and methods of determining vector similarity</p><p>• Experience with scaling ML training workloads using distributed training techniques on GPU and/or developing microservices for AI/ML/GenAI products</p><p>• Data Preprocessing and Analysis: Work with large-scale datasets, preprocess the data, and perform in-depth analysis to derive meaningful insights, patterns, and trends for AI model training.</p><p>Preferred candidates will have:</p><p>• Real world experience fine-tuning models, methods of fine-tuning, and data preprocessing for fine-tuning</p><p>• AWS Solutions Architect and or AWS Machine Learning Specialty certifications</p>
</div>",No Salary Info Found,Data Architect
Sr. Data Architect - Remote,Veradigm®,12/20/2023,https://www.linkedin.com/jobs/view/3759662667,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Architect
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791621839,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Sr. Data Engineer,Incedo Inc.,12/21/2023,https://www.linkedin.com/jobs/view/3785699346,0,https://media.licdn.com/dms/image/C4D0BAQEzqnAdsML8AQ/company-logo_100_100/0/1656661706797/incedo_inc_logo?e=2147483647&v=beta&t=lTHWgZfnEyk0Gwvr1BTpOPP3jxHm4Xl-INBATyFxapM,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Must Skill:</strong></p><ul><li>Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities</li><li>Design and develop data applications using big data technologies (AWS, Spark) to ingest, process, and analyze large disparate datasets</li><li>Build robust data pipelines on Cloud using AWS Glue, Aurora Postgres, EKS, Redshift, PySpark, Lambda, and Snowflake.</li><li>Build Rest based Data API using Python / C#, EKS, Lambda.</li><li>Build the infrastructure required for optimal extraction, transformation, and loading of data from various data sources using SQL and AWS ‘big data’ technologies.</li><li>Work with data and analytics experts to strive for greater functionality in our data systems.</li><li>Implement architectures to handle large scale data and its organization</li><li>Execute strategies that inform data design and architecture partnering with enterprise standard</li><li>Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement</li></ul><p></p>
</div>",No Salary Info Found,ETL Developer
Entry Level Data Scientist/Analyst(REMOTE),SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784098160,0,https://media.licdn.com/dms/image/C560BAQHPrA2XO9lh7g/company-logo_100_100/0/1663564885547/synergisticit_logo?e=2147483647&v=beta&t=biDnkXeeFcJXgnh87P53V9KGn6j1mqUOEQpisfcfR74,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Job Market is Challenging due to more than 150,000 Tech Layoffs in 2022 and in 2023 more than 240,000 layoffs so almost 3,90,00 tech employees have been laid off since 2022 and its still going on . The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers.<strong> Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. </strong>In such a scenario the Job seekers need <strong> to differentiate themselves by ensuring to obtain exceptional skills and technologies to be hired by clients as its an employer's market presently and they have a lot of hiring choices.<br/><br/></strong>For more than 12+ years Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.<br/><br/>All Positions are open for all visas and US citizens<br/><br/>We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers.<br/><br/>We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like <strong> apple, google, Paypal, western union, Client, visa, walmart lab</strong>s etc to name a few.<br/><br/>We have an excellent reputation with the clients. Currently, We are looking for <strong> entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers</strong> for full time positions with clients.<br/><br/>Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry<br/><br/><strong> We assist in filing for STEM extension and also for H1b and Green card filing to Candidates <br/><br/></strong>We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.<br/><br/><strong> please check the below links to see success outcomes of our candidates</strong> and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers<br/><br/><strong> https://www.synergisticit.com/candidate-outcomes/ <br/><br/></strong><strong> We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023 <br/><br/></strong>Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTube<br/><br/><strong> https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn <br/><br/></strong><strong> https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=EmO7NrWHkLM <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=OAFOhcGy9Z8 <br/><br/></strong><strong> https://www.youtube.com/watch?v=Yy74yvjatVg <br/><br/></strong>For preparing for interviews please visit <strong> https://www.synergisticit.com/interview-questions/ <br/><br/></strong><strong> We are looking for the right matching candidates for our clients <br/><br/></strong><strong> Please apply via the job posting <br/><br/></strong><strong>Required Skills<br/><br/></strong><strong> REQUIRED SKILLS For Java /Full stack/Software Programmer <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning Positions <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow <br/><br/></strong><strong> If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements. <br/><br/></strong><strong> No phone calls please. </strong> Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates
      </div>",No Salary Info Found,ETL Developer
"Senior Software Engineer, Data Solutions-Dallas, Austin, or San Antonio, TX",H-E-B,12/19/2023,https://www.linkedin.com/jobs/view/3483760921,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,Braintrust,12/19/2023,https://www.linkedin.com/jobs/view/3789766635,0,https://media.licdn.com/dms/image/C560BAQHbQYFSQsK__A/company-logo_100_100/0/1630511738029/usebraintrust_logo?e=2147483647&v=beta&t=KwbYjG0MdxQVYAijRBYsSuBn-w2onHZNpCmM31LViso,"Austin, Texas Metropolitan Area","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality.<br/><br/><strong>About The Hiring Process<br/><br/></strong>The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match.<br/><br/>Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies.<br/><br/><strong>JOB TYPE:</strong> Direct Hire/ FTE Position (no agencies/C2C - see notes below)<br/><br/><strong>LOCATION:</strong> Work from anywhere - Anytime | No timezone overlap required<br/><br/><strong>SALARY RANGE</strong> $110,000 – $130,000 /yr<br/><br/><strong>ESTIMATED DURATION:</strong> 40/week - long term<br/><br/><strong>EXPERIENCE:</strong> 3-4 years<br/><br/><strong>BRAINTRUST JOB ID:</strong> 11526<br/><br/>The Opportunity<br/><br/><strong>Required Skills<br/><br/></strong><ul><li> T-SQL (DDL, Stored Proces, Views, CTEs, etc) </li><li> VCS (Git, SVN, etc) <br/><br/></li></ul><strong>Bonus Skills<br/><br/></strong><ul><li> Candidates with a CPA/CFA or other financial services background are preferred. </li><li> Candidates who understand web technologies and can program in other languages in addition to SQL will be preferred. JavaScript/ES6/NodeJS preferred. </li><li> VS Code, SSMS, and other IDEs. </li><li> CI/CD experience with integrating database changes into deployment models. <br/><br/></li></ul>What You'll Be Working On<br/><br/><ul><li>This is a FTE position and is only open to US-based candidates**<br/><br/></li></ul>InvestEdge is seeking a database specialist with expert knowledge in relational data modeling, querying, and data analysis.<br/><br/>This role requires expert knowledge of working with MSSQL and Postgres databases, and can write complex queries, stored procedures, and views.<br/><br/><strong>The Candidate<br/><br/></strong><ul><li> has likely worked as a senior data developer or data architect role, and also understands database administration concepts such as indexing strategies, backup and fault-tolerance strategies, and how to organize and secure data at rest. </li><li> have a background in financial services and understand how financial markets work. </li><li> Has a CPA/CFA with the ability to write advanced SQL should be a shoe-in. <br/><br/></li></ul>This role will work with InvestEdge's senior data architect to implement new solutions as well as improve existing ones. Also, the role will be working with large data sets and large database footprints and should understand concepts such as performance tuning, SQL Injection, and data security best practices.<br/><br/>In addition to an emphasis on data manipulation and storage, the candidate will also work on other aspects of the application including UX and middle-tier concerns relating to the presentation, use, and manipulation of data. The ideal candidate is a well-rounded developer that is comfortable in any layer of the application, even as their focus is data and the persistence of that data.<br/><br/><strong>Roles And Responsibilities<br/><br/></strong><ul><li> Work with the senior data architect to implement data routines in a financial services environment. </li><li> Create new queries, views, and stored procedures for a large existing relational data set. </li><li> Debug and troubleshoot logical issues in database code. </li><li> Debug and troubleshoot performance issues in database code. </li><li> Serve as a subject matter expert on a large in-house enterprise database model. </li><li> Understand the business domain of the application. </li><li> Work in an Agile environment on a cross-functional team. <br/><br/></li></ul><strong>Apply Now!<br/><br/></strong><strong>Notes<br/><br/></strong>Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.<br/><br/>Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
      </div>",$110000- $130000,ETL Developer
Data Engineer,Visa,12/19/2023,https://www.linkedin.com/jobs/view/3790090038,0,https://media.licdn.com/dms/image/C560BAQEP8_eM4zW8bw/company-logo_100_100/0/1630663392691/visa_logo?e=2147483647&v=beta&t=TzxC8Eby4Etg1Y4aK9Ul8pUVAccJ4Do5GJP4uVtlOBY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.<br/><br/>When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.<br/><br/><strong>Join Visa: A Network Working for Everyone.<br/><br/></strong><strong>Job Description<br/><br/></strong>Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area.<br/><br/>Visa AI as a Service (VAIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, VAIaS automates the updates to data, models, and applications. Combined with strong AI governance, VAIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!<br/><br/>This position is for a Data Engineer with solid development experience who will focus on creating new capabilities for Visa AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.<br/><br/>You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.<br/><br/>This position will be based in Austin, TX. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li> Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions</li><li> Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards</li><li> Responsibilities span all phases of solution development including:</li><li> Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved</li><li> Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner<br/><br/></li></ul>This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.<br/><br/><strong>Qualifications<br/><br/></strong>Basic Qualifications:<br/><br/><ul><li> Bachelors degree, OR 3+ years of relevant work experience<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li> 2 or more years of work experience</li><li> Exposure to leading-edge areas such as Machine Learning, Big Data, Distributed Systems or SRE. </li><li> Experience in at least one of the following: Golang, Java, or C/C++, Spark</li><li> Familiarity with web service standards and related patterns (REST, gRPC)</li><li> Experience implementing solutions for low-latency, distributed services using open standard technologies. <br/><br/></li></ul><strong>Additional Information<br/><br/></strong><strong>Work Hours:</strong> Varies upon the needs of the department.<br/><br/><strong>Travel Requirements:</strong> This position requires travel 5-10% of the time.<br/><br/><strong>Mental/Physical Requirements:</strong> This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.<br/><br/>Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.<br/><br/>Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.<br/><br/><strong>U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 89,600.00 to 114,300.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.</strong>
</div>",No Salary Info Found,ETL Developer
Software Engineer - Data Platform (C#/.NET/AWS) (R-15497),Dun & Bradstreet,12/20/2023,https://www.linkedin.com/jobs/view/3785098494,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,AtkinsRéalis,12/20/2023,https://www.linkedin.com/jobs/view/3785085485,0,https://media.licdn.com/dms/image/D4E0BAQENGaGvdO3TOw/company-logo_100_100/0/1695059107065/atkinsrealis_logo?e=2147483647&v=beta&t=97_WWS0g7kyFfGgXfDApNXY-v0y8Brbx7XxsaTAebUE,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Why join us? <br/><br/></strong>We are hiring! The <strong>Data Engineer</strong> is an integral part of our Community &amp; Intermodal Infrastructure Mountain Team. This is an entry-level position and is based out of <strong>Austin, TX</strong>.<br/><br/><strong>About Us<br/><br/></strong>AtkinsRéalis is one of the world’s most respected design, engineering and project management consultancies. AtkinsRéalis has been providing infrastructure planning, engineering, construction, environmental consulting, urban planning, architecture, and program management services to public and private clients across the United States for more than 50 years. AtkinsRéalis has the depth and breadth of expertise to respond to the most technically challenging and time-critical infrastructure projects and the urgent transition to a low-carbon economy.<br/><br/><strong>How will you contribute to the team?<br/><br/></strong><ul><li>Adept analytic skills including knowledge of MS Excel, PowerBI and other business analysis and intelligence software</li><li>Strong written communication skills including prior experience in MS Word and MS PowerPoint</li><li>Strong verbal communication skills</li><li>Focus on customer service<br/><br/></li></ul><strong>What will you contribute? <br/><br/></strong><ul><li>EXPERIENCE: Business analytics from one or more prior internships; basic understanding of engineering practices such as CAD</li><li>EDUCATION: Bachelor of Science in Engineering</li><li>SPECIAL SKILLS: MS Excel, PowerBI, PowerPoint</li><li>PROFESSIONAL REGISTRATIONS: None required<br/><br/></li></ul><strong>What We Offer At AtkinsRéalis<br/><br/></strong>As an Intern, you will enjoy a host of developmental benefits which includes:<br/><br/><ul><li>Competitive salary</li><li>Hands-on experience with industry leaders</li><li>Support and mentorship from various professionals throughout the business</li><li>Career and educational exploration opportunities such as Client Site Visits, Weekly Lunch &amp; Learns, &amp; various virtual and/or in-person activities<br/><br/></li></ul>As a Full-Time employee, you may enjoy a robust rewards package which includes:<br/><br/><ul><li>Opportunity to work on various projects of various sizes</li><li>Competitive salary</li><li>Flexible work schedules</li><li>Group Insurance</li><li>Retirement Savings Plan with employer match</li><li>Employee Assistance Program (EAP)</li><li>Learning and development programs, training, career opportunities and a highly regarded tuition reimbursement program<br/><br/></li></ul><strong>Expected compensation range is between $70,000 - $78,000 annually/hourly depending on skills, experience, and geographical location. <br/><br/></strong><strong>If this sounds like you and you would like to expand your career with us, apply today! <br/><br/></strong>AtkinsRéalis Is An Equal Opportunity, Drug-free Employer Committed To Diversity In The Workplace. EOE/Minorities/Females/Vet/Disability. Please Review AtkinsRéalis Equal Opportunity Statement Here<br/><br/>https://careers.atkinsrealis.com/equal-opportunities-statement<br/><br/>Upon acceptance of an offer, all candidates must go through a drug screen test and background check. AtkinsRéalis is a federal contractor which mandates a satisfactory background screening report and drug test that supersedes state laws.<br/><br/><strong>AtkinsRéalis cares about your privacy</strong> and are committed to protecting your privacy. Please consult our Privacy Notice on our Careers site to know more about how we collect, use and transfer your Personal Data. By submitting your personal information to AtkinsRéalis, you confirm that you have read and accept our Privacy Notice.<br/><br/><strong>Note To Staffing And Direct Hire Agencies<br/><br/></strong>In the event a recruiter or agency who is not on our preferred supplier list submits a resume/candidate to anyone in the company, AtkinsRéalis family of companies, we explicitly reserve the right to recruit and hire the candidate(s) at our discretion and without any financial obligation to the recruiter or agency. https://careers.atkinsrealis.com/recruitment-agencies<br/><br/>#URR222
      </div>",$70000- $78000,ETL Developer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789086619,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $130,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$130000- $173000,ETL Developer
Data Engineer,"VMC Soft Technologies, Inc",12/20/2023,https://www.linkedin.com/jobs/view/3788678633,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791628110,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Join our growing Engineering team!<br/><br/></strong>This Jobot Job is hosted by Mike Duffy<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $100,000 - $140,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>We are rapidly growing equipment finance company with over 25 years in business!<br/><br/>The Data Engineer will be responsible for building data-driven analytics tools that are used across the entire organization to improve decision making.<br/><br/>The Data Engineer should have 3+ years of experience with Python, ETL, and SQL<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Excellent pay &amp; benefits!</li><li> 100% remote flexibility!</li><li> Room for growth!</li><li> Outstanding company culture!<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.</li><li> Has demonstrated proficiency in designing and developing data marts in Snowflake schema.</li><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL Server, NoSQL, Kafka using AWS or AZURE Big Data technologies.</li><li> Use troubleshooting skills to identify and correct root cause of workflow failures based on error log outputs and environmental conditions.</li><li> Use SQL to examine, filter, and aggregate data in Microsoft SQL Server.</li><li> Experience working with data transformation processing.</li><li> Anticipate, identify, and solve issues concerning data management to improve data quality.</li><li> Experience working with Microsoft BI and Microsoft SQL server.</li><li> Perform POCs on new technology, architecture patterns.</li><li> Must have Experience with at least one Columnar MPP Cloud data warehouse (Snowflake /Azure Synapse / Redshift)</li><li> Design of complex physical data models, projects and cloud-based data lake constructs including SQL/NoSQL database systems. Leads the creation of integrated data views based on business or analytics requirements.</li><li> Design, implement, and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems and business requirements.</li><li> Experience in ETL tools like DBT is nice to have.</li><li> Experience with version control and DevOps platforms such as AZURE DevOps, GitHub, GitLab</li><li> Experience with CI/CD Pipelines and SDLC best practices.</li><li> Experience using Agile methods and project management tools like Jira preferred.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Software Engineering, Information Technology, or a related field.</li><li> Minimum of 3 years of experience in a data engineer or similar role.</li><li> Strong knowledge of Python, ETL, SQL, data integration, and data pipelines.</li><li> Experience with data architecture, data modeling, schema design, and software development.</li><li> Proficiency in data migration, transformation, and scripting.</li><li> Familiarity with machine learning models and their data needs.</li><li> Understanding of distributed systems as it pertains to data storage and computing.</li><li> Strong project management and organizational skills.</li><li> Ability to analyze problems and strategize for better solutions.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$100000- $140000,ETL Developer
Analytics Engineer Internship,New York Life Insurance Company,12/21/2023,https://www.linkedin.com/jobs/view/3789917032,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
ETL Developer- HYBRID,Phaxis,12/19/2023,https://www.linkedin.com/jobs/view/3790037030,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Cloud Data Engineer,Talener,12/19/2023,https://www.linkedin.com/jobs/view/3748836564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
ETL Developer (Pentaho),Aegistech,12/19/2023,https://www.linkedin.com/jobs/view/3774715991,0,https://media.licdn.com/dms/image/C510BAQG8-sKtDp0u1w/company-logo_100_100/0/1631367872866?e=2147483647&v=beta&t=EQSHlC1RzvR6NBbybEg_-03z4ym53Vh6Du29A3q2VI4,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>The <strong>ETL Developer</strong> provides expertise in data extraction, transformation, and loading (ETL) processes and data science methodologies to support the achievement of business goals and objectives. Leads the development and implementation of data solutions that enhance the company's competitive advantage. Collaborates with cross-functional teams and stakeholders to ensure data services meet established standards for availability, performance, security, and quality. Responsible for coordination of data-related initiatives.</p><p><br/></p><p><strong>QUALIFICATIONS:</strong></p><ul><li>Lead the design, development, and maintenance of ETL processes to extract, transform, and load data from diverse sources into Data Lakes to automate data integration.</li><li>Implement data quality checks and validation to ensure data accuracy, consistency, and reliability throughout the ETL pipeline.</li><li>Identify data discrepancies, develop error handling and monitoring mechanisms to identify and resolve issues during ETL operations.</li><li>Troubleshoot data transformation issues across multiple environments and operating platforms. Optimize ETL processes for efficiency, scalability, and performance.</li><li>Develop and implement custom scripts to automate data-related tasks.</li><li>Apply data science methodologies to analyze data sets, identify trends, patterns, and outliers, and extract meaningful insights.</li><li>Understand concepts of predictive models, machine learning algorithms, and statistical analyses to support data-driven decision-making.</li><li>Implement data governance best practices to ensure data security, compliance, and data lineage tracking.</li><li>Maintain comprehensive documentation of ETL processes, data models, and data science methodologies.</li><li>Collaborate closely with cross-functional teams, including data engineers, business analysts, and stakeholders, to understand data requirements and deliver data-related solutions.</li><li>Interpret user and functional requirements to design and implement impactful data pipelines or reports.</li><li>Lead and coordinate data-related projects to ensure timely delivery and alignment with business objectives.</li></ul><p><br/></p><p><br/></p><p><br/></p><p><strong>SKILLS:</strong></p><ul><li>Strong Knowledge of Pentaho ETL tool.</li><li>Proficiency in SQL and other data programming languages (Python, R, Java).</li><li>Knowledge of Elasticsearch tool and Lucene programming language for data indexing, searching, and analysis.</li><li>Familiar with cloud-based infrastructure and environments such as Microsoft Azure and Amazon Web Services, etc.</li><li>Familiar with MS SQL, Oracle, PostgreSQL and various pharmaceutical systems, including SAP, LIMS, PIMS, NexLynk or equivalent.</li><li>Familiar with data visualization tools like Pentaho Dashboards, Power BI, Tableau, or similar.</li><li>Familiar with Active Directory, Microsoft Office 365.</li></ul><p><br/></p><p><br/></p><p><strong>Education Requirements: </strong></p><p>Bachelor's degree in Computer Science, Data Science, Statistics, or a related field.</p><p><br/></p><p><br/></p><p><strong>Experience Requirements: </strong></p><p>Proven experience with ETL development using Pentaho. Proficiency in SQL for data manipulation and querying. Programming skills in languages like Python, R, Java or Lucene. Hands-on experience with data lake technologies, including Elasticsearch. Strong knowledge of cloud data warehousing concepts and data modeling. Ability to design and build APIs and connectors to facilitate seamless data integration and access. Experience with data visualization tools such as Power BI, Tableau, or similar.</p><p><br/></p><p><br/></p><p><strong>In addition to competitive compensation, we offer a comprehensive benefits package including:</strong></p><p>401K plan with employer match and immediate vesting</p><p>Medical, Vision, Life and Dental Insurance</p><p>Pet Insurance</p><p>Company paid STD and LTD</p><p>Company Paid Holidays</p><p>3 Weeks Paid Time Off (within the first year)</p><p>Tuition Assistance (after the first year)</p><p>Easily accessible to Tri-Rail</p><p>Free shuttle to the Boca Tri-Rail station</p><p><br/></p><p><strong>Just awarded 2023 Best Places to Work!</strong></p><p><br/></p><p><strong>After you've applied, connect directly to a recruiter at https://www.linkedin.com/in/manisha-kuril-22b310150/</strong></p>
</div>",No Salary Info Found,ETL Developer
"Software Developer, Python/SQL, nControl",Nanotronics,12/19/2023,https://www.linkedin.com/jobs/view/3771813404,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Junior Data Engineer II,"Kiss Products, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3636799852,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Senior SQL Developer,Webologix Ltd/ INC,12/20/2023,https://www.linkedin.com/jobs/view/3788680603,0,https://media.licdn.com/dms/image/C510BAQHq7dnji3N96A/company-logo_100_100/0/1630626269907/webologix_logo?e=2147483647&v=beta&t=-U61EoZyGDGw9ytxl6VFxI512bFtxn8DoxmEP8-ehm8,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Role: Senior SQL Server Developer</strong></p><p><strong>Location: NYC, NY / Jersey City, NJ / Dallas, TX</strong></p><p><strong>Experience- 8+ yrs</strong></p><p><strong>Type of hiring- Contract, Hybrid</strong></p><p><br/></p><p><strong>Note: We are looking for a SQL Server Developer NOT a DBA.</strong></p><p><br/></p><p><strong>Job Description:</strong></p><p>We are seeking a highly skilled SQL Developer with expertise in MS SQL Server, SSRS, SQL programming, writing stored procedures, and proficiency in ETL. The ideal candidate will have a strong understanding of database concepts, query optimization, and data modeling.</p><p><strong> </strong></p><p><strong>Responsibilities:</strong></p><p>● Align Sigmoid with key Client initiatives</p><p>○ Interface daily with customers across leading Fortune 500 companies to understand</p><p>strategic requirements</p><p>● Stay up-to-date on the latest technology to ensure the greatest ROI for customer &amp; Sigmoid</p><p>○ Hands on coder with excellent understanding of SQL Programming.</p><p>○ Design and implement APIs, abstractions and integration patterns to solve challenging</p><p>distributed computing problems</p><p>○ Experience in defining technical requirements, data extraction, data transformation,</p><p>automating jobs, productionizing jobs, and exploring new technologies.</p><p>● Culture</p><p>○ Must be a strategic thinker with the ability to think unconventional / out:of:box.</p><p>○ Analytical and data driven orientation.</p><p>○ Raw intellect, talent and energy are critical.</p><p>○ Entrepreneurial and Agile : understands the demands of a private, high growth</p><p>company.</p><p>○ Should be an independent and individual contributor as well as a good team player.</p><p>● Facilitate in Technical Aspects</p><p>○ Develop, optimize, and maintain SQL queries, stored procedures, and functions for</p><p>efficient data retrieval and manipulation.</p><p>○ Troubleshoot and resolve database performance issues, bottlenecks, and data</p><p>inconsistencies.</p><p>○ Create and maintain data models, ensuring data integrity, normalization, and</p><p>performance.</p><p>○ Collaborate with cross-functional teams to gather business requirements and translate</p><p>them into technical specifications.</p><p>○ Conduct thorough testing and debugging of SQL code to ensure accuracy and reliability</p><p>○ Design and implement ETL processes for data extraction, transformation, and loading</p><p>from various sources.</p><p><strong> </strong></p><p><strong>Qualifications:</strong></p><p>● 6+ years track record of relevant work experience and a Computer Science or related technical</p><p>discipline is required.</p><p>● 6+ years of experience as a SQL Developer or similar role.</p><p>● Knowledge of other database systems such as Oracle or MySQL.</p><p>● Familiarity with MongoDB, Tabloid and Power BI.</p><p><strong> </strong></p><p><strong>Preferred Qualification:</strong></p><p>● Experience in agile methodology</p><p>● Certification in MS SQL Server or related technologies.</p><p>● Experience with version control systems.</p><p>● Familiarity with data warehousing concepts and tools</p>
</div>",No Salary Info Found,ETL Developer
"Data Engineer, Product Analytics",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3790554161,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,BeaconFire Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3788691831,0,https://media.licdn.com/dms/image/C560BAQEgZyD0JY8dTA/company-logo_100_100/0/1630645938186?e=2147483647&v=beta&t=_1a4H3IIfyJigHbi_NPBI4P5Hj_Unz3cwiUADDdNxy8,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Qualifications:</strong></p><p>• Passion for data and a deep desire to learn.</p><p>• Bachelor’s Degree in Computer Science/Information Technology, Data Analytics/Data Science, or related</p><p>discipline.</p><p>• Intermediate Python. Experience in data processing is a plus. (Numpy, Pandas, etc)</p><p>• Strong written and verbal communication skills.</p><p>• Ability to work both independently and as part of a team.</p><p><br/></p><p><strong>Responsibilities:</strong></p><p>• Collaborate with analytics team to find reliable data solutions to meet the business needs.</p><p>• Design and implement scalable ETL or ELT processes to support the business demand for data.</p><p>• Perform data extraction, manipulation, and production from database tables.</p><p>• Build utilities, user-defined functions, and frameworks to better enable data flow patterns.</p><p>• Build and incorporate automated unit tests, participate in integration testing efforts.</p><p>• Work with teams to resolve operational &amp; performance issues.</p><p>• Work with architecture/engineering leads and other teams to ensure quality solutions are implemented, and engineering best practices are defined and adhered to.</p><p><br/></p><p>Location: Remote to start</p><p><br/></p><p>Salary: $65,000.00 to $80,000.00 /year</p><p><br/></p><p>BeaconFire is an e-verified company, and we provide H1B visa sponsorship to all qualified internationalcandidates.</p>
</div>",$65000.00- $80000.00,ETL Developer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791625342,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Join our growing Engineering team!<br/><br/></strong>This Jobot Job is hosted by Mike Duffy<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $100,000 - $140,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>We are rapidly growing equipment finance company with over 25 years in business!<br/><br/>The Data Engineer will be responsible for building data-driven analytics tools that are used across the entire organization to improve decision making.<br/><br/>The Data Engineer should have 3+ years of experience with Python, ETL, and SQL<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Excellent pay &amp; benefits!</li><li> 100% remote flexibility!</li><li> Room for growth!</li><li> Outstanding company culture!<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.</li><li> Has demonstrated proficiency in designing and developing data marts in Snowflake schema.</li><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL Server, NoSQL, Kafka using AWS or AZURE Big Data technologies.</li><li> Use troubleshooting skills to identify and correct root cause of workflow failures based on error log outputs and environmental conditions.</li><li> Use SQL to examine, filter, and aggregate data in Microsoft SQL Server.</li><li> Experience working with data transformation processing.</li><li> Anticipate, identify, and solve issues concerning data management to improve data quality.</li><li> Experience working with Microsoft BI and Microsoft SQL server.</li><li> Perform POCs on new technology, architecture patterns.</li><li> Must have Experience with at least one Columnar MPP Cloud data warehouse (Snowflake /Azure Synapse / Redshift)</li><li> Design of complex physical data models, projects and cloud-based data lake constructs including SQL/NoSQL database systems. Leads the creation of integrated data views based on business or analytics requirements.</li><li> Design, implement, and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems and business requirements.</li><li> Experience in ETL tools like DBT is nice to have.</li><li> Experience with version control and DevOps platforms such as AZURE DevOps, GitHub, GitLab</li><li> Experience with CI/CD Pipelines and SDLC best practices.</li><li> Experience using Agile methods and project management tools like Jira preferred.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Software Engineering, Information Technology, or a related field.</li><li> Minimum of 3 years of experience in a data engineer or similar role.</li><li> Strong knowledge of Python, ETL, SQL, data integration, and data pipelines.</li><li> Experience with data architecture, data modeling, schema design, and software development.</li><li> Proficiency in data migration, transformation, and scripting.</li><li> Familiarity with machine learning models and their data needs.</li><li> Understanding of distributed systems as it pertains to data storage and computing.</li><li> Strong project management and organizational skills.</li><li> Ability to analyze problems and strategize for better solutions.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$100000- $140000,ETL Developer
SQL Developer - US Residents Only,Team Remotely Incorporation,12/25/2023,https://www.linkedin.com/jobs/view/3793403189,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,PA Consulting,12/19/2023,https://www.linkedin.com/jobs/view/3752017186,0,https://media.licdn.com/dms/image/D4E0BAQGzMvnsrZOkxA/company-logo_100_100/0/1688328174598/pa_consulting_logo?e=2147483647&v=beta&t=Ec8QVvRnf_DVjk0c5JfZAs23urJGlPyEs7bqBhsMsWM,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>We believe in the power of ingenuity to build a positive human future.<br/><br/>As strategies, technologies and innovation collide, we create opportunity from complexity.<br/><br/>Our diverse teams of experts combine innovative thinking and breakthrough use of technologies to progress further, faster. Our clients adapt and transform, and together we achieve enduring results.<br/><br/>An innovation and transformation consultancy, we are over 4000 specialists in consumer and manufacturing, defence and security, energy and utilities, financial services, government and public services, health and life sciences, and transport. Our people are strategists, innovators, designers, consultants, digital experts, scientists, engineers and technologists. We operate globally from offices across the UK, US, Netherlands and Nordics.<br/><br/>PA. Bringing Ingenuity to Life<br/><br/><strong>Job Description<br/><br/></strong><strong>Your day to day <br/><br/></strong>We’re an innovation and transformation consultancy that believes in the power of ingenuity to build a positive-human future in a technology-driven world. Our diverse teams of experts combine innovative thinking with breakthrough-technologies to progress further, faster.<br/><br/>Are you ready to harness the power of data to drive advancements in healthcare? Are you passionate about designing, building, and maintaining data infrastructure that plays a pivotal role in improving patient outcomes and shaping the future of medicine? If you're seeking a rewarding career at the intersection of healthcare and technology, we invite you to be part of our dynamic team. This is a unique, multi-year, project-based opportunity to build and grow a clinical data registry platform over many years working with a dedicated team of collaborators and customers. As a Data Engineer for our cutting-edge medical data registry, you'll be at the forefront of managing, optimizing, and expanding our data infrastructure, enabling critical insights that can positively impact patient outcomes. If you're excited about leveraging your data engineering skills to make a difference in the world of healthcare, we want to hear from you.<br/><br/><strong>Qualifications<br/><br/></strong>Minimum qualifications:<br/><br/><br/><ul><li>Advanced SQL and Python</li><li>Expertise in the design and construction of Big Data Lakes and Data Warehouses capable of ingesting, standardizing, and serving billions of data rows spanning diverse datasets ranging from tens to hundreds</li><li>Experience building dynamic, metadata driven pipelines and analyses</li><li>Building and managing fully automated data pipelines (ETL, ELT, ELTL) including:</li><ul><li>Designing and building data interfaces to source systems</li><li>Combining and transforming data into the appropriate format for storage</li><li>Developing data sets for analytics purposes</li><li>Developing pipelines that can handle common issues/errors in a robust and automated way</li></ul><li>Cloud experience in Azure, AWS or GCP<br/><br/></li></ul>Preferred qualifications:<br/><br/><br/><ul><li>Spark / PySpark experience highly preferable</li><li>Working in Agile and DevOps environments</li><li>Basic Python, Bash, or PowerShell for automation</li><li>Data modelling – Kimball, Data Vault, Star/Snowflake schema, Query-first etc.</li><li>Data visualisation in Power BI, Tableau, Qlik or similar</li><li>Architecting Data Platforms - designing BI/MI/Analytics solutions using Big Data, Relational or Streaming technologies</li><li>One or more of the following certifications:</li><ul><li>Microsoft Certified: Azure Data Engineer Associate</li><li>AWS Certified Data Analytics - Specialty</li><li>GCP Professional Data Engineers<br/><br/><br/></li></ul></ul><strong>Additional Information<br/><br/></strong>Life At PA encompasses our peoples' experience at PA. It's about how we enrich peoples’ working lives by giving them access to unique people and growth opportunities and purpose led meaningful work.<br/><br/>We believe diversity fuels ingenuity. Diversity of thought brings exciting perspectives; diversity of experience brings a wealth of knowledge, and diversity of skills brings the tools we need. When we bring people together with diverse backgrounds, identities, and minds, embracing that difference through an inclusive culture where our people thrive; we unleash the power of diversity – bringing ingenuity to life. We are dedicated to supporting the physical, emotional, social and financial well-being of our people.<br/><br/>The Salary for this role is between $90,000 - $110,000
      </div>",$90000- $110000,ETL Developer
Informatica Cloud Developer,Venusgeo Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3784414551,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
React Front-end Developer (Data Visualization) (63458BR),Harvard Kennedy School,12/19/2023,https://www.linkedin.com/jobs/view/3756726114,0,https://media.licdn.com/dms/image/C4D0BAQGz7JtcRoH-Hg/company-logo_100_100/0/1631329665234?e=2147483647&v=beta&t=CyhirmGqDcSzFKc5weJJRZTc0zV3DwetSSOUmsPll34,"Cambridge, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Position Description<br/><br/></strong><strong>About the Growth Lab &amp; Our Tools <br/><br/></strong>Located at the Harvard Kennedy School of Government, the Growth Lab works to understand the dynamics of economic growth and to translate those insights into more effective policy making in developing countries. The Lab disrupts the conventional research setup by embedding a diverse software Digital Development &amp; Design team alongside faculty and fellows, to build open-access web applications that translate and disseminate the Growth Lab’s cutting-edge economic research to improve the livelihoods of people on a global scale. We believe that user-friendly software can be a vital channel to effectively interpret complex concepts and to better understand the world.<br/><br/>The Growth Lab’s Viz Hub , is an online portfolio of data analysis and visualization platforms built in-house by the Digital Development &amp; Design team. Our flagship platform, The Atlas of Economic Complexity , delivers the ability to discover new economic growth opportunities for every country. Our award-winning platform, Metroverse , allows users to explore urban growth opportunities for over 1000 worldwide. In addition to these tools, the team has built over 30 additional software products, prototypes and digital storytelling features. Our digital tools have been cited in major media outlets and are relied upon across the Harvard community and by policymakers, journalists, and leaders in international development.<br/><br/>As a front-end developer you’ll have the best of both worlds: all the benefits of being part of a world-class research institution combined with the autonomy and agility of a small, growing software team.<br/><br/>General Responsibilities<br/><br/>In this role you will be tasked with building, enhancing, and maintaining the front-end codebase of our flagship tools, The Atlas of Economic Complexity and Metroverse. These tools are built with React, TypeScript, and GraphQL and require proficiency in these frameworks. Responsibilities will include:<br/><br/><br/><ul><li> Leading the front-end development of major Atlas and Metroverse data visualizations and UI/UX components within large, existing codebases </li><li> Leading aspects of quality standard development and testing that promotes code that is reliable, readable, maintainable, well-documented </li><li> Collaborating closely with design, backend and product team members to scope new feature requests and articulate relevant trade-offs </li><li> Participating in various phases of feature development, including requirements analysis, design, testing, brainstorming and sprint planning meetings </li><li> Executing technical troubleshooting and bug fixes </li><li> Maintaining up-to-date documentation for all relevant front-end aspects </li><li> Helping to optimize our Google Analytics <br/><br/></li></ul>You will also work with a wide assortment of interesting data sets to build brand new, innovative tools at the Lab. This will involve responsibilities such as:<br/><br/><br/><ul><li> Leading the development of front-end frameworks and standards that adhere with the Growth Lab’s high performance standards and design aesthetic </li><li> Building custom and dynamic web-based data visualizations </li><li> Planning and accommodating for various mediums, screen sizes and device types </li><li> Occasionally presenting aspects of your work at staff meetings and Harvard events <br/><br/></li></ul><strong> Please note: This a hybrid position and we can consider candidates who want to work primarily remote, with the expectation to be able to come to our campus in Cambridge, MA 2-3 times per month for meetings and events. <br/><br/></strong><strong>Basic Qualifications<br/><br/><br/></strong><ul><li>Minimum of two years’ post-secondary education or relevant work experience<br/><br/></li></ul><strong>Additional Qualifications And Skills<br/><br/><br/></strong><ul><li> At least 2 years of active React development experience through academics and/or previous employment positions </li><li> Demonstrated experience using modern HTML, CSS and JavaScript </li><li> Demonstrated experience building interactive data visualizations <br/><br/></li></ul>Additional Preferred Requirements:<br/><br/><br/><ul><li> Experience with GraphQL and/or REST API frameworks </li><li> Experience with TypeScript, Node, and command line </li><li> Strong understanding of browser rendering behaviors and performance, including mobile development best practices </li><li> Familiarity with source code control systems for collaboration (GitFlow, Github Flow or similar) </li><li> Awareness of website accessibility standards </li><li> Ability to proactively confront ambiguity with good judgment and mature problem-solving skills </li><li> Excited to explore and learn new technologies and innovative practices in data visualization development </li><li> Experience working within an Agile software development cycle </li><li> Comfortable and willing to communicate technical concepts to non-technical audiences </li><li> Interested in economic and social development issues <br/><br/></li></ul><strong>Certificates and Licenses<br/><br/><br/></strong><ul><li>Completion of Harvard IT Academy specified foundational courses (or external equivalent) preferred<br/><br/></li></ul><strong>Working Conditions<br/><br/><br/></strong><ul><li>Work is performed in an office setting<br/><br/></li></ul><strong>Additional Information<br/><br/></strong><strong>Please note</strong>: As part of the interview process, applicants should be prepared to undertake an online technical challenge and demo samples of personal or professional work that best demonstrates relevant capabilities.<br/><br/><strong> This position is a fully benefits-eligible term appointment ending one year from date of hire, with possibility of renewal. <br/><br/></strong>Learn more about our work culture and see yourself at Harvard Kennedy School.<br/><br/>We regret that the Harvard Kennedy School does not provide visa sponsorship.<br/><br/>Harvard University requires pre-employment reference and background checks.<br/><br/>Harvard University is committed to supporting a healthy, sustainable learning and working environment.<br/><br/><strong> Please note: This a hybrid position and we can consider candidates who want to work primarily remote, with the expectation to be able to come to our campus in Cambridge, MA 2-3 times per month for meetings and events. <br/><br/></strong>The health of our workforce is a priority for Harvard University. With that in mind, we strongly encourage all employees to be up-to-date on CDC-recommended vaccines.<br/><br/><strong>Salary Range:</strong> $74,200 - $126,200<br/><br/>Note: Starting salaries typically fall in the lower half of the salary range; however, they are ultimately determined by the scope of the position, the candidate's relevant experience, and internal equity.<br/><br/><strong>Benefits<br/><br/></strong>We invite you to visit Harvard’s Total Rewards website to learn more about our outstanding benefits package, which may include:<br/><br/><br/><ul><li>Paid Time Off: 3-4 weeks of accrued vacation time per year (3 weeks for support staff and 4 weeks for administrative/professional staff), 12 accrued sick days per year, 12.5 holidays plus a Winter Recess in December/January, 3 personal days per year (prorated based on date of hire), and up to 12 weeks of paid leave for new parents who are primary care givers. </li><li>Health and Welfare: Comprehensive medical, dental, and vision benefits, disability and life insurance programs, along with voluntary benefits. Most coverage begins as of your start date. </li><li> Work/Life and Wellness: Child and elder/adult care resources including on campus childcare centers, Employee Assistance Program, and wellness programs related to stress management, nutrition, meditation, and more. </li><li>Retirement: University-funded retirement plan with contributions from 5% to 15% of eligible compensation, based on age and earnings with full vesting after 3 years of service. </li><li>Tuition Assistance Program: Competitive program including $40 per class at the Harvard Extension School and reduced tuition through other participating Harvard graduate schools. </li><li>Tuition Reimbursement: Program that provides 75% to 90% reimbursement up to $5,250 per calendar year for eligible courses taken at other accredited institutions. </li><li> Professional Development: Programs and classes at little or no cost, including through the Harvard Center for Workplace Development and LinkedIn Learning. </li><li>Commuting and Transportation: Various commuter options handled through the Parking Office, including discounted parking, half-priced public transportation passes and pre-tax transit passes, biking benefits, and more. </li><li> Harvard Facilities Access, Discounts and Perks: Access to Harvard athletic and fitness facilities, libraries, campus events, credit union, and more, as well as discounts to various types of services (legal, financial, etc.) and cultural and leisure activities throughout metro-Boston. <br/><br/></li></ul><strong>Job Function<br/><br/></strong>Information Technology<br/><br/><strong>Department Office Location<br/><br/></strong>USA - MA - Cambridge<br/><br/><strong>Job Code<br/><br/></strong>I0757P Applications Professional III<br/><br/><strong>Work Format<br/><br/></strong>Hybrid (partially on-site, partially remote)<br/><br/><strong>Sub-Unit<br/><br/></strong><strong> Salary Grade <br/><br/></strong>057<br/><br/><strong>Department<br/><br/></strong>Center for International development - Growth Lab<br/><br/><strong>Union<br/><br/></strong>00 - Non Union, Exempt or Temporary<br/><br/><strong>Time Status<br/><br/></strong>Full-time<br/><br/><strong>Pre-Employment Screening<br/><br/></strong>Education, Identity<br/><br/><strong>Commitment to Equity, Diversity, Inclusion, and Belonging<br/><br/></strong><strong>Harvard Kennedy School’s Mission and Commitment to Diversity, Equity, and Anti-Racism<br/><br/></strong>At Harvard Kennedy School, fostering a diverse and inclusive community where everyone feels they belong is a matter of basic fairness consistent with our core values as an institution. It is also essential to our mission of improving public policy and leadership—because recruiting the best people and creating an environment where they can thrive make us better at what we do, because we learn more from people with different perspectives, and because we work in diverse groups and serve diverse societies.<br/><br/>Learn more about Harvard Kennedy School’s commitment to Diversity Equity, and Anti-Racism.<br/><br/><strong>EEO Statement<br/><br/></strong>We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.
      </div>",$74200- $126200,ETL Developer
Data Center Engineer,Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3732385209,0,https://media.licdn.com/dms/image/C4D0BAQG16gpXzS14DQ/company-logo_100_100/0/1630499898593/cloudflare_logo?e=2147483647&v=beta&t=JnWbIHRMM7IEd6GKOBdDcOcAwe8GlG6X05cH_ptu3Rc,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world’s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine’s Top Company Cultures list and ranked among the World’s Most Innovative Companies by Fast Company.<br/><br/>We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!<br/><br/><strong> Data Center Operations Engineer </strong> <strong><strong>About the department<br/><br/></strong></strong>In this role, you will be focused on maintaining the Clou dflare global network. You 'll work closely with Cloudflare’s SRE (Site Reliability Engineering) team, Network Engineering team, Network Deployment Engineering team and with various vendors and partners (including hardware vendors, datacenter and network providers, and ISPs) to maintain and improve our global infrastructure. You will further be responsible for the development and implementation of consistent processes and visibility measurements for consistent and effective management of our infrastructure. This is a highly visible position that requires deep technical understanding of datacenter infrastructure, networking (physical), and basic experience with data analysis and project management.<br/><br/>To be successful in this position, you should have excellent technical skills, communication skills, and be able to navigate a range of challenges and constraints (e.g. schedule adherence, time zones, and cultures). You will have the opportunity to (literally) build a faster, safer Internet for our millions of users and the billions of web surfers that visit their sites each month.<br/><br/><strong>Who You Are<br/><br/></strong>You will thrive in a hypergrowth engineering environment and be self driven with a keen attention to detail. You will come with a deep technical understanding of Data Center colocation environments, network architecture and server technologies. You will be used to working through partners to support infrastructure delivery to a number of remote locations. You will have had experience managing operational environments, and used to developing new approaches to improve delivery efficiency or operational stability.<br/><br/><strong>What You'll Do<br/><br/></strong><ul><li> Collaborating with internal teams (Infrastructure, Network Engineering and SRE). Create documentation and manage remote contractors to complete datacenter tasks, working with hardware manufacturers, datacenter and network providers, logistics partners and other service providers in support of our 300+ datacenter locations </li><li> Maintain Data Center environment operational availability </li><li> Creating and maintaining documentation, plans, SOP’s, MOP’s etc. </li><li> Support and configure network infrastructure where required </li><li> Providing feedback to internal teams to support internal tools and external vendor partnerships <br/><br/><br/></li></ul><strong>Required Experience<br/><br/></strong><ul><li> Minimum of 5 yrs of Linux systems administration </li><li> Experience with Juniper, Cisco and DWDM network equipment </li><li> Experience managing and instructing remote contractors </li><li> Familiarity with work required to stand up infrastructure in remote colocation facilities </li><li> Experience running and improving operational processes, including automation tooling, in a rapidly changing environment </li><li> Familiarity with day-to-day tasks and projects common to Data Center Operations (deployment, migration, decommissioning etc.) </li><li> Comfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA </li><li> Incident management <br/><br/><br/></li></ul><strong>Other Responsibilities May Include<br/><br/></strong><ul><li> Aggressively seek opportunities to introduce cutting-edge technology and automation solutions that are effective, efficient and scalable in order to improve our ability to deploy and maintain our global infrastructure </li><li> Assist with the definition, documentation and implementation of consistent processes across all region </li><li> Limited travel <br/><br/><br/></li></ul><strong>Examples Of Desirable Skills, Knowledge And Experience<br/><br/></strong><ul><li> Bachelor’s degree; technical background in engineering, computer science, or MIS </li><li> Direct experience executing on complex data center/infrastructure projects </li><li> Previous experience installing / maintaining data center (and other IT) infrastructure and DCIM tools </li><li> Experience running and improving operational processes in a rapidly changing environment </li><li> Strong verbal and written communication skills, problem-solving skills, attention to detail, and interpersonal skills </li><li> Must be proactive with proven ability to learn fast and execute on multiple tasks simultaneously </li><li> Ability to manage MS excel and Google spreadsheets </li><li> Comfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA </li><li> Must be a team player <br/><br/><br/></li></ul><strong>Bonus Points<br/><br/></strong><ul><li> Multi-lingual; experience working with infrastructure in multiple countries </li><li> Comfortable with remote “lights-out” and out-of-band access to data center resources </li><li> Linux certifications (RHCSA etc.) </li><li> Network certifications (CCNA, JNCIA or higher) <br/><br/><br/></li></ul><strong>Compensation<br/><br/></strong>Compensation may be adjusted depending on work location.<br/><br/><ul><li>For Colorado-based hires: Estimated annual salary of $ 111,000 - $ 135,000 .</li><li>For New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $ 135,000 - $ 165,000 </li><li>For Bay Area-based hires: Estimated annual salary of $ 142,000 - $ 174,000 .<br/><br/><br/></li></ul><strong>Equity<br/><br/></strong>This role is eligible to participate in Cloudflare’s equity plan.<br/><br/><strong>Benefits<br/><br/></strong>Cloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S.<br/><br/><strong>Health &amp; Welfare Benefits<br/><br/></strong><ul><li>Medical/Rx Insurance</li><li>Dental Insurance</li><li>Vision Insurance</li><li>Flexible Spending Accounts</li><li>Commuter Spending Accounts</li><li>Fertility &amp; Family Forming Benefits</li><li>On-demand mental health support and Employee Assistance Program</li><li>Global Travel Medical Insurance<br/><br/><br/></li></ul><strong>Financial Benefits<br/><br/></strong><ul><li>Short and Long Term Disability Insurance</li><li>Life &amp; Accident Insurance</li><li>401(k) Retirement Savings Plan</li><li>Employee Stock Participation Plan<br/><br/><br/></li></ul><strong>Time Off<br/><br/></strong><ul><li>Flexible paid time off covering vacation and sick leave</li><li>Leave programs, including parental, pregnancy health, medical, and bereavement leave<br/><br/><br/></li></ul><strong>What Makes Cloudflare Special?<br/><br/></strong>We’re not just a highly ambitious, large-scale technology company. We’re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.<br/><br/><strong>Project Galileo</strong> : We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare’s enterprise customers--at no cost.<br/><br/><strong> Athenian Project </strong> : We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.<br/><br/><strong>Path Forward Partnership</strong> : Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.<br/><br/><strong>1.1.1.1</strong> : We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here’s the deal - we don’t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.<br/><br/>Sound like something you’d like to be a part of? We’d love to hear from you!<br/><br/>This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.<br/><br/>Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.<br/><br/>Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.
      </div>",No Salary Info Found,ETL Developer
Data Engineer (56664BR),Harvard Medical School,12/19/2023,https://www.linkedin.com/jobs/view/3675208445,0,https://media.licdn.com/dms/image/C4E0BAQFpnx840JxXEA/company-logo_100_100/0/1631308066635?e=2147483647&v=beta&t=dgBeR-KouCeNkr3fa_zvFiUj-bERsWzPhCIobukAijo,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Position Description<br/><br/></strong>The Center for Computational Biomedicine (CCB) is a new center within the Blavatnik Institute at Harvard Medical School. Our mission is to provide cutting-edge computational capabilities, data analysis, and data integration technologies to support medical and biological research within the Medical School. Based at the Harvard Medical School Longwood Campus, we are part of a vibrant community of scientists, physicians, and engineers whose goal is to advance the boundaries of knowledge and improve patient care. The working environment combines the best features of a startup (fast pace, flexibility, flat hierarchies) with those of one of the leading medical schools (excellent benefits, outstanding opportunities for learning, great resources, name recognition).<br/><br/>CCB is looking for an individual to join the Data and Analytic Platforms Group, a group of engineers and scientists developing data warehousing and analytic solutions in support of epidemiology, healthcare economics, machine learning, and basic science research.<br/><br/>The Group works to reduce the burden on faculty by developing centrally managed and shareable data solutions to be used across research silos. We curate very large public and private healthcare utilization (insurance claims, electronic health record), multi-omics, environmental exposure, and social determinants data sets, provision access to those curated data sets, and develop analytic frameworks to accelerate reproducible academic research on top of them. Collectively these data sets contain information relating to hundreds of millions of patients.<br/><br/>This position reports to the Director of the CCB Data and Analytic Platforms Group. Primary responsibilities will include designing and implementing relational database architecture (schema, indexing, stored procedures, ETL processes, etc.) to warehouse multi-terabyte data sets in Microsoft SQL Server. This will include periodically evaluating various query performance metrics to ensure real-time availability to the research community and recommending modifications to the underlying database platform to resolve any identified issues. The bulk of this design work will be left up with the candidate, while a small portion will involve refactoring (or strategically deciding to abandon) existing ETL / indexing strategies. The data sets will be staged into a combination of proprietary schemas as well as the open-source i2b2 data model.<br/><br/>Additional opportunities will be available for the candidate to interact with individual scientific research teams to help improve their workflows.<br/><br/><strong>Basic Qualifications<br/><br/><br/></strong><ul><li>Minimum of seven years’ post-secondary education or relevant work experience <br/><br/></li></ul><strong>Additional Qualifications And Skills<br/><br/><br/></strong><ul><li>Bachelor’s Degree in Computer Science or related degree preferred. At least 5 years experience as a software systems architect, including experience developing solutions with both relational database systems and at least one of the following languages: Java, Python, R. </li><li>Master’s Degree in a related field (Computer Science / Electrical Engineering, Bioinformatics, Statistics, Data Science, etc.) preferred. </li><li>Excellent communication skills, both written and oral</li><li>Experience with Microsoft SQL Server or cloud-based data warehousing technologies</li><li>Experience designing and maintaining multi-terabyte analytic relational databases, including index and query optimization</li><li>Experience orchestrating and optimizing Extract-Transform-Load (ETL) processes for multi- terabyte data warehouses</li><li>Comfort doing basic system administration in a Linux environment Comfort doing basic system administration in a Windows environment Experience with relational database index optimization</li><li>Experience with containerized (Docker or Singularity) workflows/paradigms</li><li>Experience with non-relational database systems (graph, key/value, document, array data stores) Experience with the R statistical computing platform</li><li>Experience with Java Experience with Python</li><li>Experience with high-performance computing</li><li>Comfort independently exploring distributed computing and database technologies and generating executive reports</li><li>Experience with public cloud platforms (AWS, Azure, Google Cloud)<br/><br/></li></ul><strong>Additional Information<br/><br/></strong>This is a 12-month term appointment with the possibility of renewal contingent on funding.<br/><br/>The health of our workforce is a priority for Harvard University. With that in mind, we strongly encourage all employees to be up-to-date on CDC-recommended vaccines.<br/><br/>Please note that we are currently conducting a majority of interviews and onboarding remotely and virtually. We appreciate your understanding.<br/><br/>Harvard University offers an outstanding benefits package including:<br/><br/><br/><ul><li>Time Off: 3 - 4 weeks paid vacation, paid holiday break, 12 paid sick days, 12.5 paid holidays, and 3 paid personal days per year. </li><li>Medical/Dental/Vision: We offer a variety of excellent medical plans, dental &amp; vision plans, all coverage begins as of your start date. </li><li>Retirement: University-funded retirement plan with full vesting after 3 years of service. </li><li>Tuition Assistance Program: Competitive tuition assistance program, incredibly affordable classes directly at the Harvard Extension School, and discounted options through participating Harvard grad schools. </li><li>Transportation: Harvard offers a 50% discounted MBTA pass as well as additional options to assist employees in their daily commute. </li><li>Wellness options: Harvard offers programs and classes at little or no cost, including stress management, massages, nutrition, meditation, and complementary health services. </li><li>Harvard access to athletic facilities, libraries, campus events, and many discounts throughout metro Boston. <br/><br/></li></ul>The Harvard Medical School is not able to provide visa sponsorship for this position.<br/><br/>Not ready to apply? Join our Talent community to keep in touch and learn about future opportunities!<br/><br/>( https://www.gem.com/form?formID=16341e35-cbc6-4904-88a3-09b35763307e <strong>)<br/><br/></strong><strong>Job Function<br/><br/></strong>Information Technology, Research<br/><br/><strong>Department Office Location<br/><br/></strong>USA - MA - Boston<br/><br/><strong>Job Code<br/><br/></strong>I1359P IT Data Architect Prof V<br/><br/><strong>Work Format<br/><br/></strong>Remote<br/><br/><strong>Sub-Unit<br/><br/></strong><strong> Salary Grade <br/><br/></strong>059<br/><br/><strong>Department<br/><br/></strong>Center for Computational Biomedicine<br/><br/><strong>Union<br/><br/></strong>00 - Non Union, Exempt or Temporary<br/><br/><strong>Time Status<br/><br/></strong>Full-time<br/><br/><strong>Pre-Employment Screening<br/><br/></strong>Criminal, Identity<br/><br/><strong>Schedule<br/><br/></strong>35 hrs. per week | Monday - Friday | 9:00 am - 5:00 pm<br/><br/><strong>Commitment to Equity, Diversity, Inclusion, and Belonging<br/><br/></strong>We are committed to cultivating an inclusive workplace culture of faculty, staff, and students with diverse backgrounds, styles, abilities, and motivations. We appreciate and leverage the capabilities, insights, and ideas of all individuals. Harvard Medical School Mission and Community Values<br/><br/><strong>EEO Statement<br/><br/></strong>We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability status, protected veteran status, gender identity, sexual orientation, pregnancy and pregnancy-related conditions, or any other characteristic protected by law.
      </div>",No Salary Info Found,ETL Developer
Data Platform Engineer,GSK,12/19/2023,https://www.linkedin.com/jobs/view/3787660573,0,https://media.licdn.com/dms/image/C4E0BAQE52m4AbEhxCw/company-logo_100_100/0/1663675238924/glaxosmithkline_logo?e=2147483647&v=beta&t=6Td8hCQOgB4Yx1roeAvIKbaMn-ru_w3eZThfb-FZ_Jc,"Cambridge, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Site Name:</strong> USA - California - San Francisco, Cambridge 300 Technology Square, London The Stanley Building, Seattle Sixth Ave<br/><br/><strong>Posted Date:</strong> Dec 18 2023<br/><br/>At GSK, we want to supercharge our data capability to better understand our patients and accelerate our ability to discover vaccines and medicines. The Onyx Research Data Platform organization represents a major investment by GSK R&amp;D and Digital &amp; Tech, designed to deliver a step-change in our ability to leverage data, knowledge, and prediction to find new medicines. We are a full-stack shop consisting of product and portfolio leadership, data engineering, infrastructure and DevOps, data / metadata / knowledge platforms, and AI/ML and analysis platforms, all geared toward:<br/><br/><li>Building a next-generation, metadata- and automation-driven data experience for GSK’s scientists, engineers, and decision-makers, increasing productivity and reducing time spent on “data mechanics” </li><li>Providing best-in-class AI/ML and data analysis environments to accelerate our predictive capabilities and attract top-tier talent. </li><li>Aggressively engineering our data at scale, as one unified asset, to unlock the value of our unique collection of data and predictions in real-time.</li>Automation of end-to-end data flows: Faster and reliable ingestion of high throughput data in genetics, genomics, and multi-omics, to extract value of investments in new technology (instrument to analysis-ready data in <li>Enabling governance by design of external and internal data:  with engineered practical solutions for controlled use and monitoring </li><li>Innovative disease-specific and domain-expert specific data products: to enable computational scientists and their research unit collaborators to get faster to key insights leading to faster biopharmaceutical development cycles. </li><li>Supporting e2e code traceability and data provenance: Increasing assurance of data integrity through automation, integration </li><li>Improving engineering efficiency: Extensible, reusable, scalable, updateable, maintainable, virtualized traceable data and code would be driven by data engineering innovation and better resource utilization. <br/><br/></li>We are looking for a skilled and experienced <strong>Data Platform Engineer I </strong>to join our growing team. Data Platform Engineers take full ownership of delivering high-performing, high-impact data platform as products, and services, from a description of a problem customer Data Engineers are trying to solve all the way through to final delivery (and ongoing monitoring and operations). They are standard bearers for software engineering and quality coding practices within the team and are expected to mentor more junior engineers; they may even coordinate the work of more junior engineers on a large project. They devise useful metrics ensuring their services are meeting customer demand, having an impact, and iterate to deliver and improve on those metrics in an agile fashion.<br/><br/>A <strong>Data Platform Engineer I </strong>should have awareness of the most common tools (languages, libraries, etc) within their specialization. They should be constantly seeking feedback and guidance to further develop their technical skills and expertise and should take feedback well from all sources in the name of development.<br/><br/><strong><strong>Why You</strong>?<br/><br/></strong><strong>Basic Qualifications<br/><br/></strong>We are looking for professionals with these required skills to achieve our goals:<br/><br/><br/><ul><li>Bachelor's degree in computer science, Software Engineering, or related discipline.</li><li>Experience with standard components for cloud-based data pipelines including ingestion, transformation, and orchestration. </li><li>Experience with Standard components for publishing data to file-based, relational, and other sorts of data storage.  </li><li>Experience with Standardized physical storage and search / indexing systems.  </li><li>Experience with Standard API architectures and tooling for QA / evaluation.  </li><li>Provide L3 support to existing tools / services / pipelines.<br/><br/><br/></li></ul><strong>Preferred Qualifications:<br/><br/></strong>If you have some of the following characteristics, it would be a plus:<br/><br/><br/><ul><li>Master's degree in computer science, Software Engineering with 0-2 Years of experience.</li><li>Schema and governance management (data + metadata + versioning + provenance + access control)    </li><li>Experience using at least one common programming language (e.g., Python, Scala, Java), including toolchains for documentation and testing</li><li>Experience with common data engineering tooling like Spark, data warehousing, ETL tools, workflow tools.</li><li>Exposure to Infrastructure/Configuration as Code tools and techniques</li><li>Exposure to modern software development tools / ways of working (e.g. git/GitHub, devops tools, …)</li><li>Exposure to tools, techniques, etc relevant to their specialization area (e.g. AI/ML, DevOps, Data Platforms)<br/><br/><br/></li></ul>#GSKOnyx<br/><br/>The annual base salary for new hires in this position ranges from $92,251 to $124,810 taking into account a number of factors including work location, the candidate’s skills, experience, education level and the market rate for the role. In addition, this position offers an annual bonus and eligibility to participate in our share based long term incentive program which is dependent on the level of the role. Available benefits include health care and other insurance benefits (for employee and family), retirement benefits, paid holidays, vacation, and paid caregiver/parental and medical leave.<br/><br/>Please visit GSK US Benefits Summary to learn more about the comprehensive benefits program GSK offers US employees.<br/><br/><strong>Why Us?<br/><br/></strong>GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.<br/><br/>Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.<br/><br/>If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).<br/><br/>GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.<br/><br/><strong>Important notice to Employment businesses/ Agencies<br/><br/></strong>GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.<br/><br/>Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK’s compliance to all federal and state US Transparency requirements. For more information, please visit GSK’s Transparency Reporting For the Record site.<br/><br/>
</div>",$92251- $124810,ETL Developer
Data Engineer,Hub Technology Group,12/20/2023,https://www.linkedin.com/jobs/view/3785032850,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Hybrid Work - Need Sr. ETL Informatica developer in Boston MA,Steneral Consulting,12/20/2023,https://www.linkedin.com/jobs/view/3789037119,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
"Back End-Java Developer(Data Engineer)-Assistant Vice President-Irving, TX(Hybrid)",WorkatHome-JobBoard,12/25/2023,https://www.linkedin.com/jobs/view/3793148588,0,https://media.licdn.com/dms/image/C560BAQEQofZqkor6vg/company-logo_100_100/0/1630643992501?e=2147483647&v=beta&t=vN7nqG7QwrW37U1r0M5PgN7G06F5nmOVI2MFvi5XRA0,"Irving, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>Citi's Institutional Clients Group (ICG, visit us at ) comprised of diverse, talented professionals located in more than 100 countries, jurisdictions and territories globally. ICG Operations and Technology develops innovative solutions and provide exceptional service to our clients in full partnership with our product teams. ICG O&amp;T features a diverse, inclusive team of professionals in approximately 90 countries around the globe. Institutional operations group is responsible for the management and execution of transactions for Markets, Credit Risk, Security Services, Information Services, Private Bank, Treasury and Trade Solutions and Operation Controls and reporting. The technology arm of ICG engaged in the application development and support for various lines of businesses. We are focused on building a cross-functional team of talented individuals, creating a unique platform to deliver products that will pioneer the industry through technical innovation and creativity. Our mission as a business focused technology organization is to provide best-in-class products and services to our global clients.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Identify data and information needs for wholesale lending business of ICG</li><li>Deliver solutions to automate data model creation and transformations and partner with model engineering team to deliver Data Driven solutions</li><li>Automate the build model generation Software Development Lifecycle to merge, build and release models as code</li><li>Partner with Data Architects to produce JSON, AVRO and Java versions of Models produced by Data Architects using Magic Draw</li><li>Define processes and rationalize target state architecture, socialize with key stakeholders and conduct walkthrough</li><li>Merge data model changes from different workstreams and generate model change report</li><li>Automate data model deployment and manage version control in bit bucket or central model repository</li><li>Upload the data model to data catalog services</li><li>Develop scripts to reduce manual work and automate the model delivery process</li><li>Participate in requirement engineering and working groups and collaborate with business leads, operations, SMEs, technologists and governance teams</li><li>Collaborate with Enterprise, Sector and Federated architecture team and adopt recommendations</li><li>Incorporate data standards and implement governance model</li><li>Develop data flows, ownership matrixes and data lineage<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><strong> MUST Have: <br/><br/></strong><ul><li>3-5 years of demonstrable hands-on experience in Java Coding</li><li>Test driven development by setting up automated testing</li><li>Continuous Integration and Continuous Deployment Practice</li><li>Experience in modelling and transforming data to meet best-practice data standards for Operational Data Stores, Big Data platforms, and Reporting &amp; Visualization</li><li>Analytical and problem solver, excellent verbal, written and presentation skills</li><li>Excellent influencing, meeting organization, facilitation skill</li><li>Self-Starter with keen interest in learning new products and skills<br/><br/></li></ul><strong>NICE To Have<br/><br/></strong><ul><li>Experience in building complex API driven distributed IT systems.</li><li>Product knowledge in commercial banking, capital and investment banking and markets</li><li>Expertise in Data Management methodologies involving architecture, modeling, storage, security</li><li>Prior experience in data integration, interoperability, and data quality solutions</li><li>Knowledge of modeling and architecture tools such as Magic Draw, Erwin, Enterprise Architect etc.<br/><br/></li></ul><strong>Education<br/><br/></strong><ul><li>Bachelor's degree/University degree or equivalent experience<br/><br/></li></ul>This job description provides a high-level review of the types of work performed. Other job-related duties may be assigned as required.<br/><br/><strong>Job Family Group<br/><br/></strong>Technology<br/><br/><strong>Job Family<br/><br/></strong>Applications Development<br/><br/><strong>Time Type<br/><br/></strong>Full time<br/><br/><strong> Primary Location: <br/><br/></strong>Irving Texas United States<br/><br/><strong> Primary Location Salary Range: <br/><br/></strong>$107,120.00 - $160,680.00<br/><br/>Citi is an equal opportunity and affirmative action employer.<br/><br/>Qualified applicants will receive consideration without regard to their race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran.<br/><br/>Citigroup Inc. and its subsidiaries (""Citi"") invite all qualified interested applicants to apply for career opportunities. If you are a person with a disability and need a reasonable accommodation to use our search tools and/or apply for a career opportunity review <strong> Accessibility at Citi </strong>.<br/><br/>View the "" <strong>EEO is the Law</strong> "" poster. View the <strong>EEO is the Law Supplement</strong> .<br/><br/>View the <strong>EEO Policy Statement</strong> .<br/><br/>View the <strong>Pay Transparency Posting</strong>
</div>",$107120.00- $160680.00,ETL Developer
"Full-Time Hybrid : Azure Data Engineer in Dallas, TX",VBeyond Corporation,12/20/2023,https://www.linkedin.com/jobs/view/3785060615,0,https://media.licdn.com/dms/image/C560BAQG2W6BoqD8MNg/company-logo_100_100-alternative/0/1630661708817/vbeyond_corporation_logo?e=2147483647&v=beta&t=VV1ljd0iANG57gvLY1_YKfrVpBg0BP93mzRLnLxi9xY,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Vbeyond Corporation, is seeking the following. Apply via Dice today!<br/><br/><strong>Azure Data Engineer<br/><br/></strong><strong>Dallas, TX (Hybrid 2 Days in Office, 3 Days Remote)<br/><br/></strong><strong>Full-Time Permanent<br/><br/></strong><strong>Duties &amp; Responsibilities<br/><br/></strong><ul><li>Working on data model designs and ERD documentation to support new data sets and systems implemented around the organization. </li><li>In-depth analysis of existing data load, analytics, and visualization code to ensure accuracy of data flow and resolution of anomalies. </li><li>Identifying operational data gaps and recommending data solutions to address those gaps in a secure, performant and reliable manner.</li><li>Working from requests stored in a managed backlog, research and enhance specifications to develop or significantly modify data sourcing, storage and provisioning needs. Develop and/or modify effective, defect free source code that meets business requirements and team standards, as verified through peer code reviews.</li><li>Working through Agile sprints, participating in, and often leading, paired programming and code reviews.</li><li>Leveraging concepts in test driven development and unit test case development to execute on all levels of testing (System, Integration, and Regression). </li><li>Provisioning workflows, data pipelines, extracts, ETL and integrations.<br/><br/></li></ul><strong>Qualifications, Skills And Experience<br/><br/></strong><strong>Must have skills:<br/><br/></strong><ul><li>5-7 years of demonstrated professional software or data engineering experience with specialization in ETL, data wahousing and business intelligence.</li><li>Intimate knowledge of and working experience with Microsoft Azure Data Factory, SSIS and Azure DevOps</li><li>Intimate knowledge of the SQL Server stack (2016+) and Transact SQL (TSQL)</li><li>Proficient in data engineering concepts, languages, and tools; ability to develop on multiple platforms. </li><li>Proficient in data transformation, ETL methodology</li><li>Proficient in TSQL procedural coding, analysis, DML and DDL scripting</li><li>Proficient with contemporary data file formats such as JSON and unstructured data.</li><li>Experience with relational database modeling, star schemas and Data Warehousing </li><li>Working knowledge of Agile data engineering concepts and processes, such as CICD, pipelines, backlog tracking, burndown metrics, and incremental delivery.</li><li>Strong collaboration, prioritization, and adaptability skills required</li><li>Excellent interpersonal and communication skills</li><li>Must be proactive and self-driven, demonstrated initiative and be a logical thinker. </li><li>Be a positive influence on a team of skilled data engineers <br/><br/></li></ul><strong>Nice To Have Skills<br/><br/></strong><ul><li>Working knowledge of Python and modeling datasets for dashboards for BI visualization tools such as Power BI / SSRS / Tableau is a plus. (not mandatory)</li><li>Experience with NoSQL/Non-relational databases are a plus, such as blob and Azure file tables<br/><br/></li></ul><strong>Academics Qualifications<br/><br/></strong><ul><li>Recognized with a Bachelor's/Master's degree in Computer Science/Information Technology<br/><br/></li></ul>Full-Time Hybrid : Azure Data Engineer in Dallas, TX
      </div>",No Salary Info Found,ETL Developer
Database Developer,Ria Money Transfer,12/19/2023,https://www.linkedin.com/jobs/view/3784453087,0,https://media.licdn.com/dms/image/C4D0BAQFOLMjEUQ3TDg/company-logo_100_100/0/1630514301775/ria_financial_logo?e=2147483647&v=beta&t=wMph3ZAj4cQoClyODwBZkx5Gv9AGlBXoSFTW_-y41Gg,"Irving, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>We are seeking an experienced SQL Database/Backend Developer to design, develop, and maintain our company's database systems. The ideal candidate will have a strong background in SQL and database design principles, as well as experience in database administration, maintenance, and performance tuning. The SQL Database Developer will work closely with our software developers and business analysts to ensure that our database systems meet the needs of the business.<br/><br/>As a company whose mission is to be the most progressive and inclusive money transfer business in the world, Ria delivers highly reliable payment services to our customers. With locations in over 402k locations in 165 countries, we have adopted the true identity of what it means to be multicultural. Our commitment to future growth is ingrained in everything we do, from global expansion and partnerships to our persistent focus on the ultimate customer experience.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Design and implement database structures using SQL</li><li>Develop and maintain database queries, stored procedures, and views</li><li>Optimize database performance through query and index optimization</li><li>Ensure data accuracy and integrity by implementing appropriate data validation and error handling</li><li>Work with software developers to integrate database functionality into software applications</li><li>Collaborate with business analysts to understand and document business requirements</li><li>Develop data migration and data integration strategies</li><li>Perform database maintenance activities such as backups, restores, and disaster recovery</li><li>Stay current with new database technologies and industry trends</li><li>A thorough understanding of relational database theory and practice</li><li>Analytical thinking and adept at problem-solving</li><li>Strong communication skills</li><li>A bachelor’s degree in computer science or a related field is required, although strong database experience might be substituted in some cases</li><li>Knowledge of major enterprise database programs, including Microsoft SQL Server, Oracle or IBM DB2, is required; professional certifications such as Microsoft Certified Database Administrator (MCDA) or Oracle Database Administrator Certified Professional (ODACP) are a plus – strong preference for Microsoft technologies (SQL Server 2008R2 thru 2017, as well as Microsoft’s Business Intelligence Suite of reporting services)</li><li>Experience in Internet technologies also is valuable</li><li>Very strong understanding of Indexes and keys (Primary, foreign, constraints, clustered, simple, pros/cons), views, stored procedures, functions, security, transactions, normalization/denormalization, bulk operations, SSIS, triggers, temp tables</li><li>Professional history with JSON, XML and/or other serialized formats</li><li>NET development experience in C#<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Bachelor's degree in computer science, Information Technology, or a related field.</li><li>5+ years of experience in SQL database development.</li><li>Proficient in SQL and relational database concepts.</li><li>Familiarity with database design principles and best practices.</li><li>Experience with database administration, maintenance, and performance tuning.</li><li>Strong problem-solving and analytical skills.</li><li>Excellent communication and collaboration skills.</li><li>Ability to work independently as well as in a team environment.</li><li>Knowledge of ETL (extract, transform, load) tools and processes is a plus.</li><li>Experience in .Net c# development.<br/><br/></li></ul>Pursuant to the California Pay Transparency Act, below is a summary of compensation elements for this role.<br/><br/>Benefits: Our package includes medical, dental, vision insurance, 401K, employee stock options, paid time off, HSA/FSA, short-term/long-term disability, tuition assistance, growth opportunities, and much more. Salary: The range in California for this position is $90,000 - $120,000. Actual starting compensation may vary based upon geographic location, work experience, and skills.<br/><br/>Ria values diversity and is proud to be an equal opportunity employer. We provide equal opportunities to all employees and applicants, regardless of race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local laws.<br/><br/>
</div>",$90000- $120000,ETL Developer
"Senior Data Engineer, DevX and Platform-Dallas, Austin, or San Antonio, TX",H-E-B,12/19/2023,https://www.linkedin.com/jobs/view/3508877623,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Operational Controls SQL Developer (On-site),Shellpoint Mortgage Servicing,12/19/2023,https://www.linkedin.com/jobs/view/3755850443,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
ETL / SQL Developer,Ripple Logics,12/19/2023,https://www.linkedin.com/jobs/view/3784435302,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
"Senior Software Engineer, Full Stack (Enterprise Data)",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788646264,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Plano, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong><ul><li>Job Title: Senior Software Engineer, Full Stack (Enterprise Data)** **About us:** Are you passionate about technology and solving complex business problems? At Capital One, we are a diverse group of makers, thinkers, and doers who aim to meet real customer needs. As a Full Stack Software Engineer, you will have the opportunity to be part of a major transformation within Capital One and work with emerging technologies. **Job Description:** In this role, you will support an enterprise-wide data management initiative and a data governance application for managing digital assets. This application will be a centralized repository of metadata that will facilitate the navigation, discovery, and change management of digital assets. You will collaborate with Agile teams to design, develop, test, implement, and support technical solutions in full-stack development. Your work will contribute to delivering robust cloud-based solutions that provide powerful experiences for millions of Americans, helping them achieve financial empowerment. **Key Responsibilities:** - Collaborate with Agile teams to design, develop, test, implement, and support technical solutions in full-stack development. - Stay updated with the latest tech trends, experiment with new technologies, and participate in internal and external technology communities. - Collaborate with product managers to deliver robust cloud-based solutions for a seamless user experience. - Utilize programming languages like Python, JavaScript, and Node.js, as well as AWS tools and services, to drive innovation. **Required Qualifications:** - Bachelor’s Degree. - At least 4 years of experience in software engineering. **Preferred Qualifications:** - 5+ years of experience with Python. - 3+ years of experience with AWS. - 3+ years of experience in open-source frameworks. - 2+ years of experience in Agile practices. **How to Apply:** Please submit your application through our website [insert link]. **Note:** At this time, Capital One will not sponsor a new applicant for employment authorization for this position. **Benefits:** Capital One offers a comprehensive set of health, financial, and other benefits that support your total well-being. You can learn more about our benefits on the Capital One Careers website. **Equal Opportunity Employer:** Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We value individuals from all backgrounds and walks of life. All qualified applicants will receive consideration for employment without regard to sex, race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable laws. **Accommodation:** If you require an accommodation during the application process, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. Your information will be kept confidential and used only to provide needed reasonable accommodations. **Technical Support:** For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com. **Note:** This job ad is for a position within Capital One Financial. Please be aware that any job posted in Canada is for Capital One Canada, in the United Kingdom is for Capital One Europe, and in the Philippines is for Capital One Philippines Service Corp. (COPSSC).</li></ul>
</div>",No Salary Info Found,ETL Developer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789087486,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Sr. Data Engineer (Hybrid),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788646179,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Plano, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Job Advertisement: Senior Data Engineer Location: Plano, Texas, United States of America Are you a driven individual looking to join our team of passionate data engineers at Capital One? We are creating the next generation of data products and capabilities, and we need your expertise. Responsibilities: - Build data pipeline frameworks to automate high-volume and real-time data delivery. - Develop data APIs and delivery services to support critical operational and analytical applications. - Transform complex analytical models into scalable, production-ready solutions. - Continuously integrate and ship code into our on premise and cloud environments. - Develop applications using modern technology stack such as Scala, Spark, Postgres, Angular JS, and NoSQL. - Collaborate with Product Owners and customers in an agile environment to deliver data products. Basic Qualifications: - Bachelor's Degree. - At least 4 years of experience in application development. Preferred Qualifications: - Master's Degree. - 6+ years of experience in application development (Python, SQL, Scala, or Java). - Experience with big data technologies, public cloud platforms (AWS, Microsoft Azure, Google Cloud), distributed data/computing tools, real-time data and streaming applications, NoSQL implementation, and data warehousing. - Experience with UNIX/Linux and Agile engineering practices. Salary: - New York City (Hybrid On-Site): $161,900 - $184,800 for Senior Data Engineer. - Salary for candidates hired in other locations will be based on the specific location and will be communicated in the offer letter. Benefits: We offer a comprehensive and competitive set of health, financial, and other benefits that support your total well-being. Learn more on the Capital One Careers website. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. Application Process: Applications for this role will be accepted for a minimum of 5 business days. Note: Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We do not discriminate based on sex, race, age, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, veteran status, or any other basis prohibited under applicable laws. If you require an accommodation during the application process, please contact Capital One Recruiting. Your information will be kept confidential and used only to provide necessary accommodations. For technical support or questions about the recruiting process, please email Careers@capitalone.com. Please be aware that Capital One Financial comprises different entities depending on the country. Positions posted in Canada are for Capital One Canada, positions in the UK are for Capital One Europe, and positions in the Philippines are for Capital One Philippines Service Corp. (COPSSC). Thank you for considering a career at Capital One. We look forward to receiving your application.
      </div>",$161900- $184800,ETL Developer
Senior Data Services Engineer,Motion Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3790930797,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
"Analytics Engineer, Data Insights",MERU,12/25/2023,https://www.linkedin.com/jobs/view/3599301708,0,https://media.licdn.com/dms/image/C4E0BAQEVuf3UK2EhgQ/company-logo_100_100/0/1631333559352?e=2147483647&v=beta&t=KDydjKATbpF7A3q6-c3kxeDG9KTxggW0DkHeCIqNdcw,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><u>Meet the Company:</u></strong></p><p>We are MERU. A values-driven, impact-oriented team dedicated to fixing companies. We provide advisory services and data analytics support to middle-market companies ($50M - $2B in annual sales), and our clients include private equity firms, credit funds, investment banks, and law firms. We bring deep turnaround experience, a group of veteran operators, and an incentive-aligned approach to any situation. MERU was founded by professionals from Alvarez &amp; Marsal and McKinsey and has seen rapid growth in the five-plus years since its founding.</p><p><br/></p><p><strong><u>The MERU Way &amp; Valuing Our Team:</u></strong></p><p>We're Partners, not consultants. When you join MERU, you will help our clients solve their most pressing problems, supported by a team of people who will challenge you, support you, and inspire you.</p><p><br/></p><p>In order to be Partners, we don't silo people into just one functional area of the business, instead advancing our team's capabilities by providing training for every service that MERU offers. Additionally, we don't just focus on technical skills but also leadership style and soft skills, so MERU team members not only know what it means to manage a client engagement but to lead a team to success. In training team members to be well-rounded individuals, we can deliver an overall higher impact to clients, allowing each individual the ability to gain experience in diligence, turnarounds, interim management, data science, and more.</p><p><br/></p><p>To aid this career advancement and development, MERU provides an internal Coach to each team member in order to guide and maintain their professional development plan goals. Unlike most Firms, we actually focus on the achievement of those goals for each individual team member, providing opportunities that would not usually be offered.</p><p><br/></p><p>Finally, MERU values personal time, only traveling when necessary, in order to celebrate and respect your personal life. We believe that by encouraging and mandating balance, it will lead to happier and longer-tenured team members.</p><p><br/></p><p>When you come to MERU, you come to further your career and maintain your entrepreneurial spirit, never losing sight of the desire to provide meaningful impact, solutions, and value to clients. Learn more about our colleagues’ core characteristics and culture here: https://wearemeru.com/meru-way/</p><p><br/></p><p><strong><u>Responsibilities: </u></strong></p><ul><li>Demonstrates ownership of individual workstreams with minimal supervision from senior team members, with the ability to coach junior team members on the engagement</li><li>Complete ownership for end-to-end process of engaging stakeholders for design sessions and requirements gathering and solution build​</li><li>Produces high quality, production level code, balances on-time delivery with long-term sustainability</li><li>Proactively communicates progress and roadblocks to senior team members on an ongoing basis; proactively develops solutions to the roadblocks</li><li>Contributes to proposal development (i.e., assistance with analysis/presentation, etc.) and proactively identifies ways to improve the proposal quality (i.e., research, package case studies, etc.)</li><li>Assists Partners in preparation for pitches and attends as required</li><li>Proactively identifies ways to improve proposal quality</li><li>Supports in the development of Firm Contribution areas, such as Recruiting, Professional Development, Marketing, etc.</li></ul><p><br/></p><p><strong><u>Qualifications:</u></strong></p><ul><li><strong>3+ years of business intelligence or data analytics experience</strong></li><li><strong>Previous experience in data and analytics consulting or a client-facing role, required</strong></li><li>Bachelor’s degree from a top university, required</li><li>Strong knowledge and delivery experience with Tableau, Power BI, Qlik, or any other data visualization tools</li><li>Working knowledge of ETL tools like Power Query, Azure Data Factory, FiveTran, Stitch, Alteryx, and languages like SQL, Python, or R</li><li>Relevant certifications associated with business intelligence tools, and enthusiasm to learn new tools and technologies and attain certifications</li><li>Experience in mentoring junior analysts and leading cross-functional teams to deliver data products</li><li>Demonstrated ability to interact and work collaboratively with junior and senior team members, senior management, and other stakeholders or professionals</li><li>Experience in independently managing deliverables with little oversight</li><li>Effective communication skills to explain technical concepts to a non-technical audience or senior executives</li><li>“Roll up your sleeves” mentality and willingness to complete any task if needed, no matter the role</li><li>Ability to assist with internal firm initiatives (e.g., marketing, client pitches)</li><li>Willingness to travel up to 20%</li><li>Ability to work full time in an office and remote environment; physically able to sit/stand at a computer and work in front of a computer screen for significant portions of the workday</li><li>Authorization to work in the United States</li><li>Commitment to living MERU’s values and core characteristics</li></ul><p><br/></p><p><strong><u>Overview of MERU Service Offerings: </u></strong></p><p><br/></p><p>Data Insights:</p><p>Work with companies at all stages of their digital transformation journey to automate reporting processes, build scalable data platforms, and leverage predictive analytics to transform data from a liability into an asset. Services include Data Discovery and Analysis, Data Prep and Integration, Self-Service Analytics, Data Visualization and Reporting, Data Science and Advanced Analytics, and Strategy Enablement.</p><p><br/></p><p>Performance Improvement:</p><p>Help companies identify and achieve their full potential by leveraging a value-focused approach to driving sustainable margin expansion impact. Services include MERU 360° Assessment, Transformation Plan Development, Chief Transformation Officer placement, Cash Cycle and Working Capital Optimization, and Implementation Performance Management.</p><p><br/></p><p>Turnaround &amp; Restructuring:</p><p>Partner with clients during uncertain times to help stabilize operations and rapidly triage the causes of financial distress, charting a path back to long-term sustainability. Services include Interim Management, Turnaround Plan Development and Execution, Liquidity Management, Stakeholder Negotiations, Strategic Alternatives Assessment, Bankruptcy, Insolvency, and Case Management.</p><p><br/></p><p>Transaction Services:</p><p>Partner with private equity firms across the investment lifecycle, from due diligence to portfolio value creation and exit planning. Services include Due Diligence, Pre-Close Planning, Post-Close Implementation, and Exit Planning.</p><p><br/></p><p><strong><u>Salary Range:</u></strong><u> </u></p><p>$105,000 – $155,000. In addition to benefits, MERU also offers an extremely competitive bonus program that is based on firm contribution efforts and performance.</p><p><br/></p><p><strong><u>Voluntary Inclusion:</u></strong></p><p>It is MERU’s policy to provide and promote equal opportunity in employment, compensation, and other terms and conditions of employment without discrimination because of race, color, sex, sexual orientation, family medical history or genetic information, political affiliation, military service, pregnancy, marital status, family status, religion, national origin, age or disability or any other non-merit based factor in accordance with all applicable laws and regulations.</p><p><br/></p><p><strong><u>Unsolicited Resumes from Third-Party Recruiters:</u></strong></p><p>Please note that we do not accept unsolicited resumes from third-party recruiters unless such recruiters are engaged to provide candidates for a specified opening. Any employment agency, person, or entity that submits an unsolicited resume does so with the understanding that MERU will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person, or entity.</p>
</div>",$50- $2,ETL Developer
Data Analyst/Data Engineer,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791623745,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Extremely flexible work environment<br/><br/></strong>This Jobot Job is hosted by Alexandra Cohen<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $65,000 - $80,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>Play a critical role with a cloud-based technology company that is helping vulnerable populations. This is a fantastic opportunity to learn from senior leaders and have your hands in a mix of work, including data migrations, data analysis, and automation.<br/><br/>In this role, you will work with multiple teams to review and manipulate data from customer requests. You also review and perform ETL operations using Azure Data Factory/Apache Nifi to support onboarding of new clients. The role will perform tasks related to data migration, data analysis, automation, and other activities, offering variety of experience and opportunity for advancement.<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> 10% annual bonus </li><li> 401(k) match</li><li> Medical, dental, vision</li><li> On-site fitness center</li><li> Start-of-the-art tools and technologies</li><li> Generous PTO package, holidays, sick days, volunteer days, and parental leave</li><li> Professional development opportunities </li><li> Flexible work environment (you will be ATL-based, but can be heavily remote)</li><li> Opportunity to make a significant impact in the affordable housing sector<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Troubleshoot and provide corrective actions to query performance. </li><li> Perform data manipulation request using TSQL and Powershell scripts. </li><li> Perform data migrations for new clients. </li><li> Troubleshoot and resolve operational environment issues after data migrations. </li><li> Develop tools as needed to support database consistency and quality across databases.</li><li> Contribute as a technical resource, helping maintain databases, ADF pipelines, Nifi flows and other data infrastructure.</li><li> Participate in responding to tenant requests, supporting the client services, and implementation teams. </li><li> Collaborate with developers to ensure best practices are adhered and followed.</li><li> Collaborate with team members as well as operates individually to execute all phases of complex data migration projects.<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li> 2+ years of professional SQL experience </li><li> 1+ years in writing TSQL scripts preferred</li><li> 1+ years of Azure cloud experience preferred </li><li> Experience with writing Powershell scripts a ""plus""</li><li> Knowledgeable in Azure SQL Server Databases</li><li> Knowledgeable in Apache Nifi is a ""plus </li><li> Ability to work cross-functionally with other teams</li><li> Willingness to learn (and be trained)</li><li> BS/MS degree or equivalent in Computer Science, Data/Analytics, Information Systems, or related field or 2 years of Microsoft SQL Server experience.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$65000- $80000,ETL Developer
Data Engineer,Robert Half,12/19/2023,https://www.linkedin.com/jobs/view/3788193038,0,https://media.licdn.com/dms/image/D560BAQFP6-a3z7Fm8Q/company-logo_100_100/0/1696341221977/robert_half_international_logo?e=2147483647&v=beta&t=bEiN5BCeElOLCcC8_YBaV9u7oNwig23-OSsa-qGORvI,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Are you a data wizard with a passion for transforming raw data into actionable insights? Do you want to work on cutting-edge data engineering projects, leveraging the latest technologies and making a real impact? If you're ready to dive into a world of data-driven innovation, we want YOU to be part of our dynamic team!<br/><br/><strong>🚀 The Role<br/><br/></strong>As a Data Engineer, you'll be the architect of our data infrastructure, responsible for designing and building the foundation upon which our analytics and data-driven insights rely. You'll work in a collaborative and agile environment, alongside a team of experts who are passionate about data and innovation.<br/><br/><strong>📊 What You'll Do<br/><br/></strong><ul><li>Design, develop, and maintain robust data pipelines and ETL processes.</li><li>Optimize and ensure the scalability, reliability, and performance of our data systems.</li><li>Collaborate with data scientists, analysts, and stakeholders to understand data requirements.</li><li>Implement data security and privacy best practices.</li><li>Stay current with emerging data technologies and trends.<br/><br/></li></ul><strong>Requirements<br/><br/></strong>🔑 Requirements:<br/><br/><ul><li>Proficiency in programming languages like Python, Java, or Scala.</li><li>Strong knowledge of SQL and relational databases.</li><li>Experience with big data technologies such as Hadoop, Spark, or Kafka.</li><li>Familiarity with cloud platforms (AWS, GCP, Azure).</li><li>Strong problem-solving and analytical skills.</li><li>Excellent communication and collaboration abilities.<br/><br/></li></ul>Data E<br/><br/>Technology Doesn't Change the World, People Do.®<br/><br/>Robert Half is the world’s first and largest specialized talent solutions firm that connects highly qualified job seekers to opportunities at great companies. We offer contract, temporary and permanent placement solutions for finance and accounting, technology, marketing and creative, legal, and administrative and customer support roles.<br/><br/>Robert Half works to put you in the best position to succeed. We provide access to top jobs, competitive compensation and benefits, and free online training. Stay on top of every opportunity - whenever you choose - even on the go.<br/><br/>All applicants applying for U.S. job openings must be legally authorized to work in the United States. Benefits are available to contract/temporary professionals, including medical, vision, dental, and life and disability insurance. Hired contract/temporary professionals are also eligible to enroll in our company 401(k) plan. Visit<br/><br/>© 2024 Robert Half. An Equal Opportunity Employer. M/F/Disability/Veterans. By clicking “Apply Now,” you’re agreeing to
      </div>",No Salary Info Found,ETL Developer
AWS Data Engineer,Intellectt Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788188147,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Center Engineer,Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3732380840,0,https://media.licdn.com/dms/image/C4D0BAQG16gpXzS14DQ/company-logo_100_100/0/1630499898593/cloudflare_logo?e=2147483647&v=beta&t=JnWbIHRMM7IEd6GKOBdDcOcAwe8GlG6X05cH_ptu3Rc,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world’s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine’s Top Company Cultures list and ranked among the World’s Most Innovative Companies by Fast Company.<br/><br/>We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!<br/><br/><strong> Data Center Operations Engineer </strong> <strong><strong>About the department<br/><br/></strong></strong>In this role, you will be focused on maintaining the Clou dflare global network. You 'll work closely with Cloudflare’s SRE (Site Reliability Engineering) team, Network Engineering team, Network Deployment Engineering team and with various vendors and partners (including hardware vendors, datacenter and network providers, and ISPs) to maintain and improve our global infrastructure. You will further be responsible for the development and implementation of consistent processes and visibility measurements for consistent and effective management of our infrastructure. This is a highly visible position that requires deep technical understanding of datacenter infrastructure, networking (physical), and basic experience with data analysis and project management.<br/><br/>To be successful in this position, you should have excellent technical skills, communication skills, and be able to navigate a range of challenges and constraints (e.g. schedule adherence, time zones, and cultures). You will have the opportunity to (literally) build a faster, safer Internet for our millions of users and the billions of web surfers that visit their sites each month.<br/><br/><strong>Who You Are<br/><br/></strong>You will thrive in a hypergrowth engineering environment and be self driven with a keen attention to detail. You will come with a deep technical understanding of Data Center colocation environments, network architecture and server technologies. You will be used to working through partners to support infrastructure delivery to a number of remote locations. You will have had experience managing operational environments, and used to developing new approaches to improve delivery efficiency or operational stability.<br/><br/><strong>What You'll Do<br/><br/></strong><ul><li> Collaborating with internal teams (Infrastructure, Network Engineering and SRE). Create documentation and manage remote contractors to complete datacenter tasks, working with hardware manufacturers, datacenter and network providers, logistics partners and other service providers in support of our 300+ datacenter locations </li><li> Maintain Data Center environment operational availability </li><li> Creating and maintaining documentation, plans, SOP’s, MOP’s etc. </li><li> Support and configure network infrastructure where required </li><li> Providing feedback to internal teams to support internal tools and external vendor partnerships <br/><br/><br/></li></ul><strong>Required Experience<br/><br/></strong><ul><li> Minimum of 5 yrs of Linux systems administration </li><li> Experience with Juniper, Cisco and DWDM network equipment </li><li> Experience managing and instructing remote contractors </li><li> Familiarity with work required to stand up infrastructure in remote colocation facilities </li><li> Experience running and improving operational processes, including automation tooling, in a rapidly changing environment </li><li> Familiarity with day-to-day tasks and projects common to Data Center Operations (deployment, migration, decommissioning etc.) </li><li> Comfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA </li><li> Incident management <br/><br/><br/></li></ul><strong>Other Responsibilities May Include<br/><br/></strong><ul><li> Aggressively seek opportunities to introduce cutting-edge technology and automation solutions that are effective, efficient and scalable in order to improve our ability to deploy and maintain our global infrastructure </li><li> Assist with the definition, documentation and implementation of consistent processes across all region </li><li> Limited travel <br/><br/><br/></li></ul><strong>Examples Of Desirable Skills, Knowledge And Experience<br/><br/></strong><ul><li> Bachelor’s degree; technical background in engineering, computer science, or MIS </li><li> Direct experience executing on complex data center/infrastructure projects </li><li> Previous experience installing / maintaining data center (and other IT) infrastructure and DCIM tools </li><li> Experience running and improving operational processes in a rapidly changing environment </li><li> Strong verbal and written communication skills, problem-solving skills, attention to detail, and interpersonal skills </li><li> Must be proactive with proven ability to learn fast and execute on multiple tasks simultaneously </li><li> Ability to manage MS excel and Google spreadsheets </li><li> Comfortable handling basic program management responsibilities (prioritization, planning, scheduling, status reporting) such as JIRA </li><li> Must be a team player <br/><br/><br/></li></ul><strong>Bonus Points<br/><br/></strong><ul><li> Multi-lingual; experience working with infrastructure in multiple countries </li><li> Comfortable with remote “lights-out” and out-of-band access to data center resources </li><li> Linux certifications (RHCSA etc.) </li><li> Network certifications (CCNA, JNCIA or higher) <br/><br/><br/></li></ul><strong>Compensation<br/><br/></strong>Compensation may be adjusted depending on work location.<br/><br/><ul><li>For Colorado-based hires: Estimated annual salary of $ 111,000 - $ 135,000 .</li><li>For New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $ 135,000 - $ 165,000 </li><li>For Bay Area-based hires: Estimated annual salary of $ 142,000 - $ 174,000 .<br/><br/><br/></li></ul><strong>Equity<br/><br/></strong>This role is eligible to participate in Cloudflare’s equity plan.<br/><br/><strong>Benefits<br/><br/></strong>Cloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S.<br/><br/><strong>Health &amp; Welfare Benefits<br/><br/></strong><ul><li>Medical/Rx Insurance</li><li>Dental Insurance</li><li>Vision Insurance</li><li>Flexible Spending Accounts</li><li>Commuter Spending Accounts</li><li>Fertility &amp; Family Forming Benefits</li><li>On-demand mental health support and Employee Assistance Program</li><li>Global Travel Medical Insurance<br/><br/><br/></li></ul><strong>Financial Benefits<br/><br/></strong><ul><li>Short and Long Term Disability Insurance</li><li>Life &amp; Accident Insurance</li><li>401(k) Retirement Savings Plan</li><li>Employee Stock Participation Plan<br/><br/><br/></li></ul><strong>Time Off<br/><br/></strong><ul><li>Flexible paid time off covering vacation and sick leave</li><li>Leave programs, including parental, pregnancy health, medical, and bereavement leave<br/><br/><br/></li></ul><strong>What Makes Cloudflare Special?<br/><br/></strong>We’re not just a highly ambitious, large-scale technology company. We’re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.<br/><br/><strong>Project Galileo</strong> : We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare’s enterprise customers--at no cost.<br/><br/><strong> Athenian Project </strong> : We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.<br/><br/><strong>Path Forward Partnership</strong> : Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.<br/><br/><strong>1.1.1.1</strong> : We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here’s the deal - we don’t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.<br/><br/>Sound like something you’d like to be a part of? We’d love to hear from you!<br/><br/>This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.<br/><br/>Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.<br/><br/>Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.
      </div>",No Salary Info Found,ETL Developer
SQL Developer,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3790099589,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3766608708,0,https://media.licdn.com/dms/image/C4D0BAQFPP1NRP4F5dQ/company-logo_100_100/0/1656657978597/tata_consultancy_services_logo?e=2147483647&v=beta&t=Ao4Ihtw2eg1ymYGPB7E4AEHoNQ83oX6bP1DrQIiqR1s,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<ul><li>The ETL Engineer performs design, development and implementation of integration processes for both the Enterprise Data lake, Data Warehouse and Applications</li><li>Analyzes requirements and existing resources to create efficient database and integration designs that meet company IT standards.</li><li>Works with project and business analyst leads to develop and clarify in-depth technical requirements.</li><li>Participates in all phases of the integration development lifecycle, including unit testing, quality assurance(QA) and ongoing support.</li><li>Helps with Production support as needed</li></ul>
</div>",No Salary Info Found,ETL Developer
Sr Data Engineer,The Fountain Group,12/19/2023,https://www.linkedin.com/jobs/view/3784094967,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Graph Database Developer,Enru Logistics and Postal Optimization,12/19/2023,https://www.linkedin.com/jobs/view/3785382631,0,https://media.licdn.com/dms/image/C560BAQGRBjLVJ2G2QQ/company-logo_100_100/0/1677673914327/enruio_logo?e=2147483647&v=beta&t=l0NKZ4oombs_cbmBb4LYBd2f0owUcpBoyTGfKBRA4a4,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Enru™ Logistics and Postal Optimization </strong>is about to do for logistics what we did for co-mail: optimize it, through our proprietary, digital-first technology and strategic network of consolidation warehouses. </p><p><br/></p><p><strong>Enru </strong>partners with shippers, mailers, carriers, and drivers to gather crucial, real-time data through proprietary technology to efficiently and predictably deliver mail and shipments via our optimized supply chain network. We keep things moving in ways never before possible. Our team is growing rapidly, apply today to get your career moving with Enru! </p><p><br/></p><p><strong>Summary: Enru Logistics and Postal Optimization is looking to hire a Software Architect to support our engineering and development efforts. <em><u>This role sits hybrid in our Atlanta, GA office. </u></em></strong>Our state-of-the-art logistics optimization software as a service company is seeking a highly motivated and skilled architect to join our team. This is an exciting opportunity for a recent graduate or early career individual to gain hands-on experience in the field of logistics technology and software development. If you are passionate about software engineering and want to be a part of a team that is revolutionizing the logistics industry, we encourage you to apply. </p><p><br/></p><p><strong>Key Responsibilities: </strong> </p><ul><li>Work in concert with software engineering leader on technology design and implementation needs </li><li>Lead design discussions, ideation and concept generation to solve problems and document new designs </li><li>Maintain diagrams, data flows, and relationships in how systems are connected </li><li>Work across engineering and team leads to identify best practices and patterns, work with team to ensure designs adhere to designs </li><li>Ensure solutions are holistic in design and consider error conditions and are secure </li><li>Identify re-use patterns for modules, calculations, and other critical functions to ensure maintainability and modularity of solutions </li><li>Apply development experience, automation, Linux, OO Concepts, Performance Tuning, best practices in building and maintaining software systems </li><li>Partner with DevOPS engineers around monitoring opportunities and solution </li><li>Work with Software Leaders to define security and other development/design standards </li><li>Understand and differentiate when to apply various design patterns such as event driven, query/response, and others </li><li>Partner with 3rd parties to jointly deliver technical solutions to enable business objectives </li><li>Support daily standups, identify and manage dependencies and tracking deliverables in an Agile development environment </li><li>Identify and drive data driven decisions </li><li>Partner across organizations to understand data, solve problems and build working relationships </li><li>Develop and maintain system design documentation, architecture diagrams and other artifacts </li><li>Differentiate between availability needs and costs to apply balance </li><li>Understand and apply concepts behind authentication vs authorization, integration with SSO for internal and external facing applications and services </li><li>Lead vendor data integrations, establish integration strategies and standards </li><li>Provide guidance for team around security best practices, apply in designs and patterns a security first approach </li></ul><p> </p><p><strong>Qualifications &amp; Skills:</strong> </p><ul><li>Bachelor degree in Computer Science, Software Engineering or equivalent degree </li><li>5+ years of relevant job experience, inclusive of the following: </li><li>Software development experience, application of object-oriented design concepts, code reuse and other modularization techniques </li><li>Awareness of open-source projects/libraries/tools. </li><li>Experience with UML sequence diagrams or other methods to communicate how modules interact with a larger system </li><li>Practical application of Azure (preferred), AWS and/or Google cloud services and configuration </li><li>Experience with Kafka, Azure Event Hub or other pub/sub event driven architectures </li><li>Experience with Docker/Containerization of workloads </li><li>Knowledge with Kubernetes </li><li>Experience with development and/or architecture experience with building/running SaaS platforms </li><li>Working knowledge of databases, data, data quality best practices </li><li>Ability to follow company policies and understand any rules or regulations governing the work being completed </li><li>Ability to understand the impact this role has on our department or company </li><li>Good communication skills, both verbal and written </li><li>Good collaboration and time management skills </li><li>Ability to communicate effectively with diverse groups of people </li><li>Energetic and eager to tackle new projects and ideas </li><li>Linux command line experience (bash, csh, zsh, etc.) and ssh </li><li>Experience with a programming language like Python, Bash and others </li><li>Ability to understand complex problems and data </li><li>Proficient computer skills, including Microsoft Office Suite (Word, PowerPoint, Excel) and the ability to learn additional programs as needed </li><li>Willingness to work extremely hard and go above and beyond in a fast-paced, high-growth startup environment. </li></ul><p> </p><p><strong>ESG Statement: </strong>We strive to make our world better by utilizing ingenuity and technology to minimize our environmental impact, cultivating a business that recognizes the intrinsic value of diversity and inclusion, and requiring accountability, transparency, and integrity in everything we do. </p><p>Want to learn more about Enru? Connect with us on LinkedIn! www.linkedin.com/company/enruio and Check out our website here: www.enru.io</p>
</div>",No Salary Info Found,ETL Developer
Data Platform Engineer - Experienced - Remote | WFH,Get It Recruit - Information Technology,12/20/2023,https://www.linkedin.com/jobs/view/3785056779,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"Norcross, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Clinician Nexus empowers health care organizations to cultivate thriving clinician teams through cutting-edge technology products, workforce and compensation analytics, and streamlined workflow solutions. Supported by extensive technical expertise and industry-leading data, we pioneer innovative approaches to help clients plan, educate, and engage their clinical workforce at every stage of the lifecycle. Our commitment is to provide outstanding guidance and support, allowing our clients to focus on shaping the future of health care.<br/><br/>As a Data Platform Engineer, your primary responsibility is to craft, advance, and maintain the infrastructure and systems essential for managing and optimizing data as a crucial enterprise asset. In this role, you'll create and maintain tooling, abstractions, and services, enabling enterprise users to meticulously oversee the entire lifecycle of their data product. This involves efficient collection, storage, processing, and retrieval of data, while upholding stringent standards for security, governance, and data quality. Proficiency in programming languages such as Python, Scala, Java, and SQL is essential, along with expertise in diverse data storage technologies, including databases, data lakes, and data warehouses, as well as streaming architectures and service layer technologies.<br/><br/>Your skill set should extend to data integration, ETL processes, ELT, Restful/GRPC services, streaming, and the construction of robust data pipelines. As a Data Platform Engineer, your overarching objective is to enable enterprise product teams to deliver quality data products that drive business insight and value to our customers. This includes building tooling and services that connect data sources to data consumers, ensuring accessibility, structural integrity, and reliability of data to fulfill analytical and business imperatives.<br/><br/><strong>Primary Accountabilities<br/><br/></strong>Collaborate with data platform architects to design and specify platform tooling, services, and integrations.<br/><br/>Build data lake and lake house architectures.<br/><br/>Construct streaming data architectures to support data platform tooling and services.<br/><br/>Collaborate with software teams to integrate streaming and batch architectures with software products.<br/><br/>Collaborate with data scientists, analysts, and business stakeholders to MVP optimal solutions.<br/><br/>Collaborate with data governance teams and data platform architects to build governance into technical solutions.<br/><br/>Maintain systems and services that provide transparency and observability into our critical systems.<br/><br/>Implement and promote engineering and architectural patterns, perform code reviews, and collaborate in architectural reviews.<br/><br/>Collaborate with product team data engineers and architects to MVP data products, maintain data models, and promote data modeling best practice.<br/><br/>Provide technical leadership and mentorship to product and data engineers, guiding their growth and professional development and enabling their ability to use platform tooling and services.<br/><br/>Lead by example through hands-on contributions to designing, coding, and troubleshooting complex data systems.<br/><br/>Identify and address performance bottlenecks and optimization opportunities within data pipelines, databases, and processing frameworks.<br/><br/>Optimize data processing workflows to improve efficiency and reduce latency.<br/><br/>Lead efforts to diagnose and resolve data-related incidents in a timely manner.<br/><br/>Participate in the grooming of stories.<br/><br/>Be responsible for tasking towards the completion of stories.<br/><br/>Mentor junior members of the team and guide them on best practices.<br/><br/>Participate in design.<br/><br/>Be responsible for the quality of code and participate in code reviews of others' products.<br/><br/>Integrate code with the team's DevOps plan and implementation.<br/><br/><strong>Knowledge, Skills, And Abilities<br/><br/></strong>Minimum Required Qualifications:<br/><br/>5+ years of relevant experience.<br/><br/>Degree in Computer Science, Software Engineering, Information Systems, Information Technology, or a related computer degree or equivalent experience. Master’s degree is a plus.<br/><br/>Proficiency in one object or object/functional programming language, preferably Python, Scala, or Java.<br/><br/>Knowledge of common object and object/functional design patterns (Builder, factory, façade, context, etc.).<br/><br/>Proficiency with Apache Spark.<br/><br/>Knowledge of data lake and lake house design principles, OLTP design principles, document data stores, and graph databases.<br/><br/>Proficiency in building ELT/ETL patterns in a distributed compute system, preferably Databricks.<br/><br/>Proficiency with common data quality tooling and the design of configurable systems to front end that tooling.<br/><br/>Proficiency with common systems and data observability tooling.<br/><br/>Knowledge of standard practices of the Software Development Lifecycle (SDLC).<br/><br/>Proficiency in standard SDLC concepts and tooling, including unit and integration testing frameworks like Pytest, IDE features like debugging, testing practices like mocking, CI/CD tooling like Github actions, build tooling (poetry), GIT.<br/><br/>Proficiency in creating and using basic Restful or GRPC services.<br/><br/>Proficiency in message bus and streaming technologies and understanding common event stream architectures.<br/><br/>Knowledge of the health care industry is a plus.<br/><br/><strong>Salary, Benefits, And Perks<br/><br/></strong>The base salary range for this position is $96,000 - $160,000 annually. Actual salaries may vary depending on factors such as academic achievements, skills, and experience. The listed range is just one component of the total rewards package offered to candidates.<br/><br/>Competitive total rewards package.<br/><br/>Medical and dental coverage at no premium cost for employees.<br/><br/>401(k) and profit-sharing retirement plans.<br/><br/>Flexible spending accounts.<br/><br/>Generous paid time off (PTO).<br/><br/>Federal and company holidays.<br/><br/>Gender-neutral parental leave.<br/><br/>Bereavement and pet leave.<br/><br/>Continuing education and professional accreditation sponsorship.<br/><br/>Life and AD&amp;D insurance.<br/><br/>Short- and long-term disability.<br/><br/>Employee assistance program.<br/><br/>Mental health support program.<br/><br/>Additional perks.<br/><br/><strong>Work Environment<br/><br/></strong>Flex/Remote, minimal travel (0-10% annually). Must be physically able to perform the essential functions of the job.<br/><br/>SullivanCotter Holdings (Clinician Nexus, SCH Services, SullivanCotter) is an Equal Employment Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law or marital status.<br/><br/>Employment Type: Full-Time
      </div>",$96000- $160000,ETL Developer
Data Engineer (DE),Zortech Solutions,12/24/2023,https://www.linkedin.com/jobs/view/3787251275,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,"Phoenix Staff, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789019676,0,https://media.licdn.com/dms/image/C560BAQFS4ZNlu_xRdA/company-logo_100_100/0/1660709194786/phoenix_staff_logo?e=2147483647&v=beta&t=v9MgqTey08e5HuF3bTNlfj1Lwgy0bS9KkQs2j4tkqBY,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Title:</strong> Data Engineer <br/> <strong>Location:</strong> Remote </p><p><br/> The Data Engineer role offers tremendous opportunities for advancement. We are seeking a highly skilled and industrious individual who can independently initiate tasks, manage multiple responsibilities efficiently, and produce outcomes swiftly in a dynamic work setting. The ideal candidate must be a collaborative team member who possesses a history of crafting high-performance applications for sizable corporate clients. Possess expertise in agile product development practices, and a proven history of prioritizing and meeting project deadlines with dedication and a strong sense of urgency. Reporting directly to the Director of Engineering, this role is a valuable addition to our client's organization.</p><p><strong><br/> Your role:</strong></p><ul><br/><li>Designing, developing, testing, deploying, and maintaining applications to support business requirements.</li><li>Developing and enhancing data solutions.</li><li>Designing relational schemas for persisting complex business objects.</li><li>Performing ETL (Extract, Transform, Load) processes for customer data integration.</li><li>Implementing validation and mitigation strategies to handle invalid incoming data.</li><li>Facilitating data exchange between CDI's user-facing application and backend pricing optimization science solutions.</li><li>Managing versioning of database schemas and stored procedures.</li><li>Creating visualizations for analytics and reporting.</li><li>Collaborating closely with both the Engineering and Science departments to create cohesive data-centric solutions.</li><li>Exporting data to Excel, consolidating disparate data sources, and implementing defense mechanisms to address and reduce the impact of data quality issues and inconsistencies.</li><li>Providing expertise in transitioning from a document store to a relational database.</li><li>Troubleshooting and resolving technical issues through debugging.</li><li>Estimating the level of effort required for user stories and tasks.</li><li>Active participation in Agile/SCRUM processes and ceremonies. What you've got:</li><li>Bachelor's Degree in Computer Science, or equivalent.</li><li>A minimum of 5 years' experience in software development.</li><li>Strong teamwork and effective communication skills.</li><li>Proficiency and experience in the following areas: Agile Development Methodology, Relational Databases (e.g., SQL Server, Postgres), Document stores (e.g., MongoDB), Python, database query performance optimization, database versioning and migration, ETL, Git, Object-Relational Mapping (ORM), and performance optimization and debugging.</li><li>Demonstrated initiative in identifying and addressing technology-related issues and opportunities, actively contributing to the business's success.</li><li>Strong interpersonal, written, and verbal communication skills.</li><li>Proven experience working effectively in a team-oriented, collaborative environment.</li><li>Ability to create and maintain technical documentation. </li><li>Local to Scottsdale, AZ would be a huge plus for 1-2 days of weekly whiteboarding.</li><li>Google Cloud</li><li>CI/CD Build and Release Pipelines</li><li>Jira</li><li>C#</li><li>HTML and JavaScript</li><li>Security, SSO (Single Sign-On), SSL (Secure Sockets Layer)</li><li>SaaS (Software-as-a-Service)</li><li>Experience in the Retail Industry</li></ul><br/><p><br/> To find more great tech-centric jobs, please visit www.phoenixstaff.com.</p>
</div>",No Salary Info Found,ETL Developer
Engineer I-Marketing (Data ),Microchip Technology Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3787622459,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
"ONSITE JOB: Hiring Data Engineer GCP , Phoenix, AZ","Conch Technologies, Inc",12/19/2023,https://www.linkedin.com/jobs/view/3788118349,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,SnapX.ai,12/19/2023,https://www.linkedin.com/jobs/view/3790031494,0,https://media.licdn.com/dms/image/C560BAQGrI5ZAgEOJ2Q/company-logo_100_100/0/1630666773263/snapxplatform_com_logo?e=2147483647&v=beta&t=ZLMq0RgwhdqNpuxZa98IYOgvdQbNVWudgbncPkkl5SY,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Dear Partner, Good morning,greetings from Snaprecruit LLC!<br/><br/>Submission you please review the below role,If you are available.<br/><br/><br/><br/>AWS, AWS Redshift and infrastructure, AWS Data Lake Formation and Glue components, data security, SQL, and Python</p>
</div>",No Salary Info Found,ETL Developer
Data Center Engineer,Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3732382790,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,E-Solutions,12/20/2023,https://www.linkedin.com/jobs/view/3790807805,0,https://media.licdn.com/dms/image/D4D0BAQHxBWPl28ZenQ/company-logo_100_100/0/1696854753424/e_solutions_inc_logo?e=2147483647&v=beta&t=MtCyEjXxS0OJFfRfwzD6OrCf1E2S_4jONsoDefE70kU,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Position: Data Engineer (More than 10+ Years of exp)</strong></p><p><strong>Location: Scottsdale AZ (day 1 onsite)</strong></p><p><strong>Duration: Contract/Fulltime</strong></p><p> </p><p><strong>Job description:</strong></p><p><strong> </strong></p><p><strong>Must have skill set: <em>Java, Scala, S3, Glue, Redshift , AWS</em></strong></p><p><strong> </strong></p><p>10-15 years of IT experience focusing on enterprise data architecture and management.</p><p>• Experience in Conceptual/Logical/Physical Data Modeling &amp; expertise in Relational and Dimensional Data Modeling</p><p>• Experience with Databricks &amp; on Prem , Structured Streaming, Delta Lake concepts, and Delta Live Tables required</p><p>• Experience with Spark scala and java programming</p><p>• Data Lake concepts such as time travel and schema evolution and optimization</p><p>• Structured Streaming and Delta Live Tables with Databricks a bonus</p><p>• Experience leading and architecting enterprise-wide initiatives specifically system integration, data migration, transformation, data warehouse build, data mart build, and data lakes implementation / support</p><p>• Advanced level understanding of streaming data pipelines and how they differ from batch systems</p><p>• Formalize concepts of how to handle late data, defining windows, and data freshness</p><p>• Advanced understanding of ETL and ELT and ETL/ELT tools such as Data Migration Service etc</p><p>• Understanding of concepts and implementation strategies for different incremental data loads such as tumbling window, sliding window, high watermark, etc.</p><p>• Familiarity and/or expertise with Great Expectations or other data quality/data validation frameworks a bonus</p><p>• Familiarity with concepts such as late data, defining windows, and how window definitions impact data freshness</p><p>• Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design performance optimization)</p><p>• Indexing and partitioning strategy experience</p><p>• Debug, troubleshoot, design and implement solutions to complex technical issues</p><p>• Experience with large-scale, high-performance enterprise big data application deployment and solution</p><p>• Architecture experience in AWS environment a bonus</p><p>• Familiarity working with Lambda specifically with how to push and pull data, how to use AWS tools to view data for processing massive data at scale a bonus</p><p>• Experience with Gitlabs and CloudWatch and ability to write and maintain gitlabs for supporting CI/CD pipelines</p><p>• Experience working with AWS Lambdas for configuration and optimization and experience with S3</p><p>• Familiarity with Schema Registry, message formats such as Avro, ORC, etc.</p><p>• Ability to thrive in a team-based environment</p><p>• Experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior level of management</p>
</div>",No Salary Info Found,ETL Developer
Data Engineer,FinTech LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785602219,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Data Engineer,Trident Consulting,12/20/2023,https://www.linkedin.com/jobs/view/3785060493,0,https://media.licdn.com/dms/image/C560BAQHxvk-OnZLPhw/company-logo_100_100/0/1630648727513/tridentconsulting_logo?e=2147483647&v=beta&t=DGQYNdJtIXZkH9t9de9tZahTTepSjgClhDkTrVp6X1w,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Title: Data Engineer<br/><br/></strong><strong>Type: Contract <br/><br/></strong><strong>Location: Scottsdale, AZ (onsite day 1)<br/><br/></strong><strong>Experience: 8+ years<br/><br/></strong><strong>""Data Engineering and Analytics<br/><br/></strong><strong>Key Responsibilities<br/><br/></strong>Build frameworks for data ingestion pipeline for a variety of data sources: batch and real-time<br/><br/>Participate in technical decisions<br/><br/>Design, develop, test, and maintain data processing pipelines<br/><br/>Design and build scalable, reliable data infrastructure with paramount focus on data quality, security, and privacy techniques<br/><br/><strong>Required Skills<br/><br/></strong>Proficient in Java, Python or Scala<br/><br/>Cloud experience<br/><br/>Experience with relational SQL and NoSQL databases<br/><br/>Experience with Spark, Kafka<br/><br/>Strong analytical and communication skills: verbal and written.
      </div>",No Salary Info Found,ETL Developer
Lead Data Engineer & Data Engineer || Fulltime only,Diverse Lynx,12/20/2023,https://www.linkedin.com/jobs/view/3785088141,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
"Data Science Analyst (Strong Python Skill) (Bangkok based, relocation provided)",Agoda,12/25/2023,https://www.linkedin.com/jobs/view/3791650239,0,https://media.licdn.com/dms/image/C4D0BAQGBa_7QNZNwpw/company-logo_100_100/0/1656643826660/agoda_logo?e=2147483647&v=beta&t=5V7q9sl3YFGW99Fa_-fGJ8jjK_dhtppZ8mxz8836vy4,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Agoda<br/><br/></strong>Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.<br/><br/><strong> Get to Know our Team: <br/><br/></strong>The Supply Equity Platform (SEP) team sits within the Product Supply team at Agoda Bangkok. We work closely with the sales department (Partner Services) to identify and optimize growth opportunities on accommodations supply for the company and to set up experiments to measure and implement changes. The projects SEP team works on directly impact Agoda’s bottom line and have long lasting structural impact to the business. We cover a range of topics including resource and product optimization. We collaborate with multiple departments and produce high quality results backed up by experimentation and data. Utilizing powerful tools and possessing an end-to-end view of how Agoda works, the SEP offers a team of learning and experience that will push you (and Agoda) into new territory.<br/><br/><strong> In this Role, you’ll get to:  <br/><br/></strong><ul><li> Manage complex analytics processes and algorithms to ensure their continued smooth operation, identifying root causes and debugging them where needed. </li><li> Use and analyze data from multiple large-scale data warehouses and understand data flows across the entire organization. </li><li>Identify, support, and lead projects aimed at improving the operations of our automated systems (e.g. root cause detection, anomaly detection, performance analysis)</li><li>Develop automated infrastructure supporting business intelligence at a global level as well as the analytics processes supporting them</li><li>Drive new analytical initiatives and projects aimed at improving resource and product optimization. <br/><br/></li></ul><strong>What you’ll Need to Succeed:<br/><br/></strong><ul><li>Experience in big data cleaning and wrangling as well as simple analytical processing (SQL is a must).</li><li>Have 3 years working experience in Python for data analysis.</li><li>A basic understanding of statistics and data, and the ability to implement this understanding in complex business situations</li><li>The ability to visualize and understand complex data flows, pipelines, and processes. </li><li>⁠A hacker’s mindset – the ability to build simple but clever and elegant solutions to new problems within significant resource, operational and time constraints through deep understanding of the business, creative problem solving, and a wide range of expertise in data, analytics, automation, programming, and prototyping</li><li>Either Bachelor’s degree in Computer Science or Bachelor’s degree in a quantitative discipline with extensive programming experience<br/><br/></li></ul><strong> Must-Have Skill: <br/><br/></strong><ul><li> Experience with complex analytics and statistical/machine learning techniques using R/Python/Spark. </li><li> Experience building automated analytical processes and functionality. <br/><br/></li></ul>#telaviv #jerusalem #IT #ENG #4 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #sydney #melbourne #perth #toronto #vancouver #montreal #prague #Brno #Ostrava #cairo #alexandria #giza #estonia #paris #berlin #munich #hamburg #stuttgart #cologne #frankfurt #budapest #bali #dublin #telaviv #milan #rome #venice #florence #naples #turin #palermo #bologna #osaka #malta #amsterdam #oslo #warsaw #krakow #alrayyan #riyadh #jeddah #mecca #medina #singapore #seoul #barcelona #madrid #stockholm #zurich #taipei #tainan #taichung #kaohsiung #bangkok #Phuket #istanbul #london #manchester  #edinburgh #hcmc #hanoi #lodz #wroclaw #poznan #katowice #rio #salvador #newdelhi #bangalore #bandung #yokohama #nagoya #okinawa #fukuoka #jerusalem #IT #4 #bangalore #delhi #hyderabad #pune #singapore #beijing #shanghai #shenzhen #tokyo #seoul #hongkong #taipei #kualalumpur #jakarta #hochiminh #hochiminhcity #manila #instanbul #makati #dubai #riyadh #gurgaon #noida<br/><br/><strong>Equal Opportunity Employer <br/><br/></strong>At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.<br/><br/>We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .<br/><br/>To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.<br/><br/>
</div>",No Salary Info Found,ETL Developer
Data Quality Analyst,Aston Carter,12/25/2023,https://www.linkedin.com/jobs/view/3793428297,0,https://media.licdn.com/dms/image/D4E0BAQGfPcCYR-BJKA/company-logo_100_100/0/1688582713106/aston_carter_logo?e=2147483647&v=beta&t=0x_nsq8b9vOidbm9PvA6fXqLf4YGUl_ZU7UlVZyuCoQ,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Data Quality Analyst II is responsible for identifying data quality issues, analyzing impact, recommending solutions, and monitoring results. The Data Quality Analyst II will regularly create and communicate actionable analyses to internal stakeholders. This role will develop and implement a data quality framework by creating standard data quality metrics, setting baselines, and targets. The Data Quality Analyst II will also be responsible for duplicate record management. Must possess both strong technical skills as well as a passion for using data to positively impact change in our community. Job Description:<br/><br/><ul><li>Develop methodology for data quality (completeness and accuracy) metrics, set baselines and targets, and build accessible reports and Tableau dashboards for internal teams.</li><li>Regularly analyze data to identify data quality issues, research issues to assess the frequency, depth, and potential causes.</li><li>Recommend concise and actionable solutions for identified data quality issues.</li><li>Remediate data quality issues.</li><li>Build reports to monitor corrective actions and provide timely feedback to internal staff and CIE partners to continuously address data quality concerns.</li><li>Provide monthly snapshots with executive summary for communication to senior leadership.</li><li>Perform descriptive and predictive analyses to evaluate key strategic questions, interpret, and contextualize findings; create presentations to synthesize complex analyses into actionable summaries and tangible recommendations.</li><li>Create compelling and reader-friendly infographics, tables, graphs, maps and other presentation visuals to communicate complex ideas, issues and trends gleaned from statistical reports.</li><li>Manipulate data using Excel to create tables and graphs and is comfortable using Pivot Tables to further analyze datasets.</li><li>Utilize appropriate technical writing skills when preparing narrative statistical summaries.</li><li>Proofread and double-check department work to avoid errors or mistakes.</li><li>Adhere to all department policies, practices and procedures related to data use, maintenance, and privacy.</li><li>Develop or contribute training material to support internal teams in understanding data quality standards, risks, and best practices Qualifications:</li><li>4+ years of experience with data analysis, writing comprehensive reports, research projects, and/or quality assurance.</li><li>1+ years of experience building and monitoring business intelligence dashboards in Tableau or similar data visualization tool.</li><li>1+ years of experience writing complex SQL queries, working with stored procedures, and/or database administration activities.</li><li>1+ years of experience with supervising a team is preferred.</li><li>A focus on the growth and well-being of people and the communities to which they belong.</li><li>A positive attitude, desire to learn and grow and aspirations to lead.</li><li>Candidate must demonstrate solid mathematical ability, analytic thinking, and effective oral and written communication of quantitative findings. Experience writing programs or scripts in at least one statistical or mathematical package or computer programming language is required.</li><li>Expert proficiency with Microsoft Office Suite required, including advanced Excel functions.</li><li>Experience with reporting tools, such as SQL Management Studio, Tableau, SPSS, and ArcGIS.</li><li>Experience with Salesforce CRM or another CRM tool preferred.</li><li>Familiarity with a variety of the field’s concepts, practices and procedures, including database technologies, and researching and recommending methods to proactively manage data and data quality.</li><li>Must have excellent attention to detail, ability to multi-task, and strong organizational, and project management skills.</li><li>Excellent oral and written communication skills that support effective working relationships with a diverse group of individuals both internal and external to the organization.<br/><br/></li></ul>About Aston Carter:<br/><br/>Please Note: Scammers are posing as Aston Carter. We'll never contact you via Gmail, Telegram, or WhatsApp and we'll never solicit money from you.<br/><br/>At Aston Carter, we’re dedicated to expanding career opportunities for the skilled professionals who power our business. Our success is driven by the talented, motivated people who join our team across a range of positions – from recruiting, sales and delivery to corporate roles. As part of our team, employees have the opportunity for long-term career success, where hard work is rewarded and the potential for growth is limitless. Established in 1997, Aston Carter is a leading staffing and consulting firm, providing high-caliber talent and premium services to more than 7,000 companies across North America. Spanning four continents and more than 200 offices, we extend our clients’ capabilities by seeking solvers and delivering solutions to address today’s workforce challenges. For organizations looking for innovative solutions shaped by critical-thinking professionals, visit [AstonCarter.com.](AstonCarter.com) Aston Carter is a company within Allegis Group, a global leader in talent solutions. The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law. If you would like to request a reasonable accommodation, such as the modification or adjustment of the job application process or interviewing process due to a disability, please call 888-237-6835 or email [astoncarteraccommodation@astoncarter.com](mailto:%20astoncarteraccommodation@astoncarter.com) for other accommodation options. However, if you have questions about this position, please contact the Recruiter located at the bottom of the job posting. The Recruiter is the sole point of contact for questions about this position.
      </div>",No Salary Info Found,ETL Developer
SQL Developer,Calpine,12/19/2023,https://www.linkedin.com/jobs/view/3787644141,0,https://media.licdn.com/dms/image/C560BAQGwMZQTMqgO2A/company-logo_100_100/0/1631398138821?e=2147483647&v=beta&t=sWe2cRHj-o8bFOOhYQgqirAAiW4sWaHT387r5XEBQ7I,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Calpine Corporation is America's largest generator of electricity from natural gas and geothermal resources with operations in competitive power markets. Its fleet of 76 power plants in operation and one under construction represents nearly 26,000 megawatts of generation capacity. Through wholesale power operations and its retail businesses, Calpine serves customers in 22 states, Canada and Mexico. Its clean, efficient, modern and flexible fleet uses advanced technologies to generate power in a low-carbon and environmentally responsible manner.<br/><br/>The company was established on the premise that a strong commitment to the environment is inextricably linked to excellence in power generation and corporate responsibility. Since its founding in 1984, Calpine has led the power industry in its unwavering commitment to environmental stewardship. In addition, its renewable geothermal plants use steam generated deep below the earth's surface to produce clean, renewable electricity.<br/><br/><strong>Job Summary (includes but is not limited to the following, other duties may be assigned)<br/><br/></strong><ul><li>This is not a fully remote position. <br/><br/></li></ul>The SQL Developer is responsible for supporting the Retail Platform team by developing SQL solutions leveraging Microsoft technology platforms. Use of SQL Server database, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS), SQL Server Reporting Services (SSRS), and Power BI will be required.<br/><br/><strong>Job Responsibilities<br/><br/></strong><ul><li>Working with Microsoft SQL Stack e.g. SQL Server 2016 or higher, SSAS, SSIS, SSRS, MDM, Power BI. </li><li>Use of data model concepts, master data management, operational process, SDLC, project management, data profiling, data cleansing/de-duplication processes. </li><li>Create and maintain DAX and MDX queries and perform performance tuning on SSAS. </li><li>Implement data warehousing and associated architecture. </li><li>Data migration with source database to target database mapping. </li><li>Database design with multidimensional modeling. </li><li>Working directly with the business clients. </li><li>Extensive use of written and oral communication skills, particularly the ability to synthesize complex issues/scenarios into easy-to-understand concepts. </li><li>Works closely with the business team, development team, analysis team, and the users to enhance quality and product delivered. </li><li>Responsible for precisely communicating impact, status, priority, progress, and road blocks to management</li><li>Provides guidance in terms of priority and ownership of issues and requests. <br/><br/></li></ul><strong>Job Requirements<br/><br/></strong><ul><li>Undergraduate degree in information systems, computer science, other technical/science degree, or equivalent work experience and technical training is required. </li><li>3+ years of direct experience as a SQL Developer. </li><li>Experience in managing software requests, projects, and internal customers. </li><li>Experience with every phase of the System Development Life Cycle. </li><li>Experience with being the technical liaison between the business users and development. </li><li>Experience with Azure DevOps is desired. </li><li>1 to 2 years of retail energy related experience is highly desired. </li><li>Strong written and verbal communication skills. </li><li>Strong analytical and critical thinking skills. </li><li>Good inter-personal skills combined with a willingness to listen</li><li>Self-motivated, goal oriented, and possess the initiative to learn independently. </li><li>Analytical, advanced decision-making skills, and problem solving abilities. </li><li>Must demonstrate a positive, customer-focused attitude. </li><li>Must be well organized and detail oriented</li><li>Ability to convey technical information in a clear and concise manner to other less technically oriented customers. </li><li>Ability to manage multiple duties at the same time. </li><li>Advanced Proficiency in the Microsoft Office suite and Office 365</li><li>Demonstrated ability to work in ambiguous situations and across organizational boundaries. </li><li>Sitting and standing for long periods of time. <br/><br/></li></ul><strong>Microsoft SQL Technologies<br/><br/></strong><ul><li>Microsoft SQL Server stack (Reporting Services, Integration Services, Analysis Services and Power BI). <br/><br/></li></ul><strong>Relational Database Management Systems<br/><br/></strong><ul><li>Microsoft SQL Server 2016 or newer. <br/><br/></li></ul><strong>Salary Information - Position is eligible for annual bonus.<br/><br/></strong>Salary Range $77,250.10 to $113,943.15<br/><br/><strong>Additional Calpine Information<br/><br/></strong><ul><li>Equal Opportunity Employer of Minorities, Females, Protected Veterans, and Individuals with Disabilities. </li><li>Calpine is committed to Equal Employment Opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment and need special assistance or an accommodation to use our website or to apply for a position, please send an e-mail with your request to hrrecruitment@calpine.com. Determination on requests for reasonable accommodation are made on case-by-case basis. <br/><br/></li></ul>Please view Equal Employment Opportunity Posters provided by OFCCP here<br/><br/>Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities<br/><br/>The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)
      </div>",$77250.10- $113943.15,ETL Developer
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789762711,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Senior Oracle Database Developer,"Data Intelligence, LLC",12/19/2023,https://www.linkedin.com/jobs/view/3764321370,0,https://media.licdn.com/dms/image/C560BAQFl46m5rYOFOw/company-logo_100_100/0/1631380861055?e=2147483647&v=beta&t=qOvibjC3knnc76MjvKxHV93DjM1wQkZy5-UPxLx-dFQ,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Data Intelligence, LLC (DI) is searching for a full time Senior Oracle Database Developer in the San Diego area. This is a hybrid position.</p><p><br/></p><p><strong>Required Skills/Experience</strong></p><ul><li>Minimum 5 years hands on PL/SQL programming experience</li><li>Must be able to use and understand most of the commands form the sample list below</li><li>Write Packages</li><li>Procedures</li><li>Functions</li><li>Exception Blocks</li><li>Understand Case and Decode</li><li>Object Types</li><li>Table Arrays</li><li>Regular Expression functions</li><li>Bulk collect</li><li>Use of Cursors</li><li>Pipe Row</li><li>Sub-queries</li><li>Loop structures</li><li>Merge</li><li>Views</li><li>Analytical functions (First_value, Lag, Lead, etc.)</li><li>Experience with JSON objects</li><li>Ability to analyze and trance code, familiar with object-oriented programming</li><li>Must have experience in a Linux environment</li><li>At least a ""secret level"" security clearance</li></ul><p><br/></p><p><strong>Desired Skills/Experience</strong>Hands on database administrator (DBA) Experience</p><ul><li>Oracle Database Certificates</li><li>Experience working with Oracle in AWS GovCloud</li></ul><p><br/></p><p><br/></p><p> Data Intelligence, DI is an established small business that has supported the critical missions of our government clients since 2005. We provide full life cycle system development, systems engineering, cybersecurity, and supporting analytical and logistics support to C4ISR and other complex systems. We are an equal opportunity employer that offers competitive salaries, comprehensive benefits, a team-oriented environment, and opportunities for advancement. Our excellent employee retention record reflects our employee focus. We work with Veteran’s organization to proactively hire those who have served our country. We offer medical, dental and vision insurance, 401k, PTO and 11 paid holidays.</p><p><br/></p><p>Data Intelligence is an Equal Opportunity/Affirmative Action employer. All qualified applicants will receive consideration for employment without regard to race, age, color, religion, creed, sex, sexual orientation, gender identity, national origin, disability, or protected Veteran status.</p>
</div>",No Salary Info Found,ETL Developer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765472151,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
"Electrical Engineer, Command and Data Handling Architect",General Atomics,12/19/2023,https://www.linkedin.com/jobs/view/3639927083,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Developer SQL,ALLY Energy,12/19/2023,https://www.linkedin.com/jobs/view/3790342031,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
CI Data Analyst,Eaton,12/19/2023,https://www.linkedin.com/jobs/view/3766732316,0,https://media.licdn.com/dms/image/C4E0BAQFlHTyFXVYarg/company-logo_100_100/0/1630597759539/eaton_logo?e=2147483647&v=beta&t=EvGycDnRc0YENXF-evyXoQa1WDgkajbQnckCEdqoiV0,"Tijuana, Baja California, Mexico","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Eaton’s division is currently seeking a CI Data Analyst.<br/><br/><strong>What You’ll Do<br/><br/></strong><strong>Primary Function:<br/><br/></strong>Will work closely with the operations service department, to improve current data analysis, reporting, presentation, and standardization of data for the Operations team.<br/><br/>Build and maintain decision support tools, identify opportunities to increase productivity at all levels of the organization. Should be able to connect sources of data as MFGPRO, ORACLE and MS Office and not limited to others (UBISENSE, Thinkworkx, AI)<br/><br/>This position will work directly with CI in a support role to drive improvement in our manufacturing operations, including the operations services team (program management, automation, i4.0, manufacturing engineering and maintenance).<br/><br/>These functions may include, but are not limited to cost improvement activities, process development, new business development, creation and deployment of division wide manufacturing strategies and new initiatives.<br/><br/>This position will also monitor project portfolio performance within the business units or functional areas. The position drives continuous improvement while utilizing the framework of the Eaton Business System (EBS) and the Continuous Improvement Framework (CIF).<br/><br/><strong>Essential Functions<br/><br/></strong>Migrate current reporting process of Excel, Power Point and Word to Power BI<br/><br/>Development of data collection process and data management system.<br/><br/>Standardize and narrow current dashboards and power apps.<br/><br/>Maintain and support current systems, apps, or dashboards with high utilization culture in the organization. Evolve those systems so they can be embracing as standard in all regions.<br/><br/>Upgrade CI SharePoint with latest information from the plant, monthly.<br/><br/>Be the champion of Best Practices exchange activities for digital solutions. Monitor and distribute improvements generated by teams of manufacturing experts to all regional manufacturing sites.<br/><br/><strong>Qualifications<br/><br/></strong><ul><li> Bachelor’s degree in engineering from an accredited institution is required</li><li> English, able to communicate verbally</li><li> Minimum 3 years of manufacturing operations experience is required.</li><li> Minimum 2 years of proven experience working with Power BI &amp; Apps.</li><li> Good knowledge in Share Point and Power Automate</li><li> SQL Server (only for connection with PowerApps)</li><li> Knowledge on developments using Power Platform o Dynamics 365</li><li> Knowledge of cloud data base: SQL Azure, SQL Data Warehouse</li><li> Proven experience of data analysis and data base</li><li> Manufacturing knowledge of equipment and process skills</li><li> ERP Knowledge (preferable MFGPRO, Oracle).</li><li> Financial skills and business acumen.<br/><br/><br/></li></ul>Solid interpersonal skills effective in building strategic relationships, team building, and ability to interact and influence through all levels of the organization<br/><br/><strong>Skills<br/><br/></strong><strong>Preferred Specialized Knowledge (not required to be qualified for position):<br/><br/></strong><ul><li> Advanced degree in engineering or business management from an accredited institution.</li><li> Trainings or Certifications in Microsoft Azure</li><li> Trainings or Certifications in MS teams, Office 365, Share Point etc.</li><li> Training or certifications on Data bases</li><li> Autocad</li><li> Previous lean manufacturing experience, CI basic tools knowledge</li><li> Experience and exposure to numerous manufacturing operations.</li><li> Strong business understanding of financials statements and impacts on P&amp;L.</li><li> Strong presentation and communication skills and experiences with global cultures.</li><li> Ability to think both tactically as well as strategically<br/><br/><br/></li></ul>We are committed to ensuring equal employment opportunities for job applicants and employees. Our recruitment processes use balanced selection criteria and avoid unlawful discrimination against applicants on the basis of their age, colour, disability, marital status, national origin, gender, gender identity, genetic information, race or racial origin, religion, sexual orientation or any other status protected or required by law.<br/><br/>]]&gt;<br/><br/>
</div>",No Salary Info Found,ETL Developer
Insurance - Data Analyst - REMOTE,Wahve LLC,12/20/2023,https://www.linkedin.com/jobs/view/3790963546,0,https://media.licdn.com/dms/image/D560BAQHLpAj4KcNwxw/company-logo_100_100/0/1689949451872/wahve_logo?e=2147483647&v=beta&t=ijNXVviKcnM87hQBvAX-WppSZZwnFb7A4YL9Fiqr6Zk,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><em>Put your Insurance Experience to work - FROM HOME!<br/><br/></em></strong>At <strong>Wahve</strong>, we value significant insurance experience and want to revolutionize the way people think about <strong><em>phasing into</em> <em>retirement</em></strong> by offering qualified candidates the opportunity to continue their career working from home. As we say - <strong><em>retire from the office but not from work</em></strong>. Our unique platform provides you with <em>real</em> work/life balance and allows you to customize your own work schedule while continuing to utilize your insurance expertise in <strong><em>a remote, long-term position</em></strong>.<br/><br/><strong>What You’ll Love About Wahve<br/><br/></strong>We created a welcoming place to work with friendly and professional leadership. We are known for the great care we take with our staff and our clients. We are passionate and determined about delivering the best customer service, preserving insurance industry knowledge, and making a difference by the work that we do.<br/><br/><strong>What We Are Seeking<br/><br/></strong>We have assignments available to help our <em>insurance industry</em> clients in <strong>Data Analyst positions. Responsibilities include:<br/><br/></strong><ul><li>Build and maintain data warehouse, new reports, and ad hoc reports. </li><li>Work with user groups to identify reporting issues/enhancements and document business requirements. </li><li>Will serve as a member of a project team and/or work independently on projects. </li><li>Support and train internal users as needed. </li><li>Compile and prepare data for customer analysis. </li><li>Experience in C#, Visual Studio, JavaScript, CSS, and current web technologies such as .NET, ASP, JSON, and XML. </li><li>Experience with ANY of the following technologies: SQL Server Reporting Services (SSRS), SSIS Reporting, Power BI, Dynamics CRM, Dynamics GP, Share point, Excel, Power Query, Power Pivot. </li><li>Ability to compile data results and author commentary on industry studies is a plus. </li><li>Insurance or financial services industry experience required. <br/><br/></li></ul><strong>TO BECOME A WORK-AT-HOME VINTAGE EXPERT, WE REQUIRE<br/><br/></strong><ul><li>25 years of full-time work experience</li><li>Experience working in a data analysis role in the insurance or financial services industry - required<br/><br/></li></ul><strong>Benefits Of Becoming a Wahve Vintage Expert<br/><br/></strong><ul><li>Retire from the office but not from work. </li><li>Eliminate the office stress and the commute. </li><li>Choose the work you would like to do now. </li><li>Customize your schedule - full or part time. </li><li>Continue to earn an income. </li><li>Utilize your years of insurance industry knowledge. </li><li>Be part of our dynamic yet virtual team environment and connect with other experienced insurance professionals like yourself!<br/><br/></li></ul><strong>How To Get Started<br/><br/></strong>Click <strong><em>APPLY NOW</em></strong> to complete our simple preliminary profile. Be sure to include your preferred contact information as one of our Qualification Specialists will connect with you promptly.<br/><br/><strong>WE LOOK FORWARD TO MEETING YOU!</strong>
</div>",No Salary Info Found,ETL Developer
Junior Data Engineer (US),Fitness Matrix Inc,12/25/2023,https://www.linkedin.com/jobs/view/3793120666,0,https://media.licdn.com/dms/image/D4E0BAQGmk8ZefBUxLg/company-logo_100_100/0/1698352894604/fitness_matrix_inc_logo?e=2147483647&v=beta&t=72cgj7Ot5k670-7oCMGX7QoHQoicVzzbGuWzPstPuXw,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Junior Data Engineer (US) - Onsite<br/><br/></strong><strong>Full-time<br/><br/></strong><strong>$66K - $77K per annum<br/><br/></strong><strong>1+ Year Experience Required<br/><br/></strong><strong>Introduction:<br/><br/></strong>FitnessMatrixInc is a unique approach to health and wellness that is based on the principle of bio-individuality. This means that we believe that everyone is different and has their own unique needs and challenges. We will work with you to understand your biochemistry and develop a personalized plan that is right for you.<br/><br/><strong>Position Summary<br/><br/></strong>Join the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.<br/><br/><strong>Key Responsibilities include:<br/><br/></strong><ul><li>Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. </li><li>Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency </li><li>Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency </li><li>Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data </li><li>Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently </li><li>Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation </li><li>Create/maintain documentation for data processes, data flows, and system configurations </li><li>Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness <br/><br/></li></ul><strong>Characteristics of this role:<br/><br/></strong><ul><li>Team Player: Willing to teach, share knowledge, and work with others to make the team successful. </li><li>Communication: Exceptional verbal, written, organizational, presentation, and communication skills. </li><li>Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. </li><li>Attention to detail: Systematically and accurately research future solutions and current problems. </li><li>Strong work ethic: The innate drive to do work extremely well. </li><li>Passion: A drive to deliver better products and services than expected to customers. <br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><ul><li>2+ years of programming experience in languages such as Python, Java, SQL </li><li>2+ years of experience with ETL tools and database management (relational, non-relational) </li><li>2+ years of experience in data modeling techniques and tools to design efficient scalable data structures </li><li>Skills in data quality assessment, data cleansing, and data validation <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Knowledge of big data technologies and cloud platforms </li><li>Experience with technologies like PySpark, Databricks, and Azure Synapse. <br/><br/></li></ul><strong>Education<br/><br/></strong>Bachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience<br/><br/><strong>Why should we work with Fitness Matrix?<br/><br/></strong>Fitness Matrix Inc is the leading provider of holistic and multidimensional health and wellness services. We offer a comprehensive approach to health and wellness. We take into account all aspects of your life, from your physical fitness and nutrition to your mental, emotional, and spiritual well-being. We use the latest science and technology to develop our programs and services. We are constantly innovating and finding new ways to help our clients achieve their goals. We offer a variety of programs and services to meet your needs and budget.<br/><br/>
</div>",$66- $77,ETL Developer
Data Analyst / Software Developer - Remote | WFH,Get It Recruit - Information Technology,12/20/2023,https://www.linkedin.com/jobs/view/3785023314,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"Fort Washington, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a reputable consulting firm based in Pennsylvania, is actively seeking dynamic individuals to join our team. We specialize in providing innovative Information Technology (IT) and Consulting services to FDA-regulated life sciences companies, focusing on program/project management, process analysis, automated business process improvements, data analytics, and implementation of IT solutions.<br/><br/><strong>Job Responsibilities<br/><br/></strong>As a Business/Data Analyst and Software Developer at QSE7, you will play a pivotal role in delivering exceptional services to our pharmaceutical, consumer healthcare, and medical device clients. Your responsibilities will include:<br/><br/>Assessing and enhancing key quality and compliance business processes.<br/><br/>Facilitating cross-functional ideation and voice-of-customer (VOC) sessions to identify improvement opportunities.<br/><br/>Analyzing current-state data and designing future-state data models.<br/><br/>Automating business processes using Microsoft SharePoint, Power Apps, and Power Automate.<br/><br/>Developing sophisticated data analytics reports with Microsoft BI and Tableau.<br/><br/>Analyzing data to identify trends and recommending proactive solutions.<br/><br/>Providing project management services, including documentation, risk mitigation, and status communication.<br/><br/>Collaborating with cross-functional teams to ensure timely issue resolution.<br/><br/><strong>Qualifications / Experience<br/><br/></strong>B.A. or B.S. degree required.<br/><br/>Deep technical expertise in Microsoft Excel, SharePoint, PowerApps, Power Automate, and Power BI; VBA programming skills a plus.<br/><br/>3-to-5 years of professional work experience; experience in the life sciences or other federally regulated industry is a significant plus.<br/><br/>Quantitative data analysis experience.<br/><br/>Excellent verbal and written communication skills.<br/><br/>Leadership and motivation skills.<br/><br/>Ability to work independently and collaboratively in a problem-solving environment.<br/><br/>Efficient provision of consulting services from a remote home office.<br/><br/><strong>About QSE7<br/><br/></strong>Founded in 2016, our company is dedicated to offering intuitive and high-quality IT and Consulting services to FDA-regulated life sciences companies. Our commitment lies in bringing automation and efficiency to our clients' processes through comprehensive solutions based on Microsoft technologies, including Excel, MS Teams, SharePoint, Power BI, and Power Automate.<br/><br/>Join our team and be part of an organization that values innovation, collaboration, and excellence. Apply now to contribute your skills and expertise to our mission of enhancing efficiency in the life sciences industry.<br/><br/>Employment Type: Full-Time
      </div>",No Salary Info Found,ETL Developer
Data Engineer,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3790367661,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        A national pharmaceutical company is looking for a fulltime Data Engineer to join their team. This company, based in Philadlphia, is transforming lives and reinventing healthcare as they tackle society’s most pressing health issues.<br/><br/>In this role, you will help build out a data platform, support clinical trials, and deliver patient and drug data. The ideal candidate will feel comfortable jumping into a fast moving and critical project. If you want to join an organization making a difference in the world, while also working on a fast-paced, exciting team, then this is an opportunity you do not want to miss! Required Skills &amp; Experience<br/><br/><ul><li>Bachelor’s Degree in Computer Science/Engineering or a related field or similar experience </li><li>3+ years experience <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Experience working in the pharmaceutical industry </li><li>Concepts of Microservices </li><li>Spark <br/><br/></li></ul>What You Will Be Doing Tech Breakdown<br/><br/><ul><li>Python </li><li>SQL </li><li>AWS </li><li>ETL <br/><br/></li></ul>Daily Responsibilities<br/><br/><ul><li>100% Hands On <br/><br/></li></ul>Applicants must be currently authorized to work in the US now and in the future. This position cannot support any sponsorship or C2C requirements at this time.<br/><br/><strong>Posted By:</strong> Nicole McCafferty
      </div>",No Salary Info Found,ETL Developer
"Staff Data Engineer, Data Products (Contract)",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3759867882,0,https://media.licdn.com/dms/image/C560BAQH0xjWQVXJr6w/company-logo_100_100/0/1630660955481/sofi_logo?e=2147483647&v=beta&t=FVZG0dNVAhdZ-W3Op_NDxjxwWCaIzunudLIIydaqJQI,"Claymont, DE","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Employee Applicant Privacy Notice<br/><br/></strong><strong>Who we are:<br/><br/></strong>Shape a brighter financial future with us.<br/><br/>Together with our members, we’re changing the way people think about and interact with personal finance.<br/><br/>We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. <strong>Join us to invest in yourself, your career, and the financial world.<br/><br/></strong><strong>Team: <br/><br/></strong>SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.<br/><br/><strong>Role:<br/><br/></strong>A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.<br/><br/><strong>What you’ll do:<br/><br/><br/></strong><ul><li>Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.</li><li>Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,</li><li>Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.<br/><br/><br/></li></ul><strong>What you’ll need:<br/><br/><br/></strong><ul><li>A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;</li><li>Over 8 years of experience in data engineering and analytics technical strategy. </li><li>Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..</li><li>Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP</li><li>Strong in Python and/or another data centric language. </li><li>Thorough knowledge of data modeling, database design, data architecture principles, and data operations.</li><li>Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.</li><li>Experience in the Fintech industry is advantageous.<br/><br/><br/></li></ul><em><strong>Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.<br/><br/></strong></em><strong>Compensation And Benefits<br/><br/></strong>The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.<br/><br/>To view all of our comprehensive and competitive benefits, visit our <strong>Benefits at SoFi </strong>page!<br/><br/>SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.<br/><br/>The Company hires the best qualified candidate for the job, without regard to protected characteristics.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.<br/><br/>New York applicants: Notice of Employee Rights<br/><br/>SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.<br/><br/>Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.<br/><br/><strong>Internal Employees<br/><br/></strong>If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.
      </div>",No Salary Info Found,ETL Developer
Data Engineer (Talend),Customers Bank,12/19/2023,https://www.linkedin.com/jobs/view/3756320725,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Senior Database Developer,Insight Global,12/19/2023,https://www.linkedin.com/jobs/view/3790042873,0,https://media.licdn.com/dms/image/C560BAQGUNIyRZFaj0g/company-logo_100_100/0/1657049194702/insight_global_logo?e=2147483647&v=beta&t=65QggNo-i3wIk_ezT2qv-ZFA-ghXBrhWbLT1WK3zZ14,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Database Developer </p><p><br/></p><p>Description </p><p>The Database Developer will be an active member of the Enterprise Data Services team supporting all aspects of data throughout the firm. This position will play a key role in designing, implementing, and maintaining database solutions. Proficiency in Microsoft SQL, SSIS, SSRS, and T-SQL is essential for success in this role. </p><p><br/></p><p>Responsibilities </p><p> Develop, implement, and maintain robust Extract, Transform, Load (ETL) processes using SQL Server Integration Services (SSIS) to facilitate seamless data integration across diverse systems. </p><p> Collaborate closely with business analysts and end-users to understand data requirements and ensure accurate representation in the integration process. </p><p> Work with source systems to extract and transform data into a format suitable for loading into the target database, ensuring data quality and integrity throughout the process. </p><p> Implement error handling and logging mechanisms within the ETL processes to facilitate quick identification and resolution of issues, ensuring data consistency. </p><p> Continuously optimize and enhance existing ETL processes to accommodate evolving business needs, improve performance, and reduce data load times. </p><p> Collaborate with cross-functional teams to identify opportunities for automation in data integration processes, streamlining workflows and improving efficiency. </p><p> Conduct thorough testing of ETL processes to validate data accuracy and troubleshoot any anomalies, ensuring the reliability of integrated data sets. </p><p> Design and develop SSRS reports to meet business reporting needs. </p><p> Collaborate with stakeholders to understand reporting requirements and deliver insightful reports. </p><p> Be an escalation point for any reporting or data integration operational issues. </p><p><br/></p><p>Requirements </p><p> Bachelor’s degree in computer science, business administration, information technology, or related field preferred. </p><p> 5+ years working with SQL Server and related technologies. </p><p> Strong proficiency in development of T-SQL Script writing, testing, and debuging in large software application systems. </p><p> Proven capability in developing SSIS Projects, with a preference for experience in transmitting JSON objects to a REST API. </p><p> Strong verbal and written communication skills. </p><p> Strong problem solving and critical thinking skills. </p><p>Nice to Haves </p><p> Experience with CozyRoc SSIS toolset </p><p> Experience with Azure DevOps Source Control </p><p> Experience with PowerShell </p><p> Experience with IntApp Integration Builder </p><p> Experience with diagramming databases and environments (Erwin, Visio, etc.)</p>
</div>",No Salary Info Found,ETL Developer
ETL Developer (must live in Philly area to qualify),"Liberty Personnel Services, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3755159641,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
SQL Server BI Developer,"Liberty Personnel Services, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3737585426,0,https://media.licdn.com/dms/image/C4D0BAQHWiMsOZMSj5A/company-logo_100_100/0/1631302210691?e=2147483647&v=beta&t=p9ZoyWf9trkRrK_ERp9edKNUYDKwpQAGdhpMU19-QrI,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Job Details:<br/><br/>SQL Server BI Developer<br/><br/>My client is seeking a mid-level developer mainly focusing on maintaining SQL Server tasks related to data management, repository and warehouse. This person should have an advanced knowledge of SSIS/SSRS/SSAS tools. They will be working with the development team to provide support for database objects. The ideal candidate will maintain data integrity between different environments and provide support for the build and deployment processes.<br/><br/>Please feel free to reach out to paul@libertyjobs.com with a resume to be considered for this role or call 610-941-6300 x115.<br/><br/>Paul Yaeger<br/><br/>www.linkedin.com/in/paulpjyaeger<br/><br/>paul@libertyjobs.com<br/><br/>
</div>",No Salary Info Found,ETL Developer
Jr PL/SQL Database Developer,"Liberty Personnel Services, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3790916768,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
SQL Developer,ASRC Federal,12/20/2023,https://www.linkedin.com/jobs/view/3784028695,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,ETL Developer
Junior Data Engineer (US),Fitness Matrix Inc,12/25/2023,https://www.linkedin.com/jobs/view/3793120666,0,https://media.licdn.com/dms/image/D4E0BAQGmk8ZefBUxLg/company-logo_100_100/0/1698352894604/fitness_matrix_inc_logo?e=2147483647&v=beta&t=72cgj7Ot5k670-7oCMGX7QoHQoicVzzbGuWzPstPuXw,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Junior Data Engineer (US) - Onsite<br/><br/></strong><strong>Full-time<br/><br/></strong><strong>$66K - $77K per annum<br/><br/></strong><strong>1+ Year Experience Required<br/><br/></strong><strong>Introduction:<br/><br/></strong>FitnessMatrixInc is a unique approach to health and wellness that is based on the principle of bio-individuality. This means that we believe that everyone is different and has their own unique needs and challenges. We will work with you to understand your biochemistry and develop a personalized plan that is right for you.<br/><br/><strong>Position Summary<br/><br/></strong>Join the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.<br/><br/><strong>Key Responsibilities include:<br/><br/></strong><ul><li>Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. </li><li>Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency </li><li>Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency </li><li>Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data </li><li>Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently </li><li>Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation </li><li>Create/maintain documentation for data processes, data flows, and system configurations </li><li>Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness <br/><br/></li></ul><strong>Characteristics of this role:<br/><br/></strong><ul><li>Team Player: Willing to teach, share knowledge, and work with others to make the team successful. </li><li>Communication: Exceptional verbal, written, organizational, presentation, and communication skills. </li><li>Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. </li><li>Attention to detail: Systematically and accurately research future solutions and current problems. </li><li>Strong work ethic: The innate drive to do work extremely well. </li><li>Passion: A drive to deliver better products and services than expected to customers. <br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><ul><li>2+ years of programming experience in languages such as Python, Java, SQL </li><li>2+ years of experience with ETL tools and database management (relational, non-relational) </li><li>2+ years of experience in data modeling techniques and tools to design efficient scalable data structures </li><li>Skills in data quality assessment, data cleansing, and data validation <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Knowledge of big data technologies and cloud platforms </li><li>Experience with technologies like PySpark, Databricks, and Azure Synapse. <br/><br/></li></ul><strong>Education<br/><br/></strong>Bachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience<br/><br/><strong>Why should we work with Fitness Matrix?<br/><br/></strong>Fitness Matrix Inc is the leading provider of holistic and multidimensional health and wellness services. We offer a comprehensive approach to health and wellness. We take into account all aspects of your life, from your physical fitness and nutrition to your mental, emotional, and spiritual well-being. We use the latest science and technology to develop our programs and services. We are constantly innovating and finding new ways to help our clients achieve their goals. We offer a variety of programs and services to meet your needs and budget.<br/><br/>
</div>",$66- $77,Data Integration Engineer
Cloud Data Engineer,Talener,12/19/2023,https://www.linkedin.com/jobs/view/3748836564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
ETL Data Engineer,Zortech Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3788124368,0,https://media.licdn.com/dms/image/C4E0BAQFLYN9bJoNeQg/company-logo_100_100/0/1630602268967?e=2147483647&v=beta&t=VbFirFeWDqzftzmA-xuL4-Rh3UkhihCRtFcB66Ze6Cg,"Georgia, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Note for full time candidates: (Visa Independent Only for FTE)<br/><br/></strong><strong>Role: ETL Data Engineer<br/><br/></strong><strong>Location: Augusta GA (100% Onsite)<br/><br/></strong><strong>Duration: C2C/Fulltime<br/><br/></strong><strong>Job Description<br/><br/></strong><ul><li>Strong hands-on coding experience with 6 to 8 years of experience in ETL </li><li>Hands on exp. on SQL/PL SQL </li><li>Strong hands-on Experience using Azure cloud </li><li>Hands on exp. on Data cloud platforms like Snowflake </li><li>Ability to plan and own the work packets and with minimal supervision or direction is highly desired</li></ul>
</div>",No Salary Info Found,Data Integration Engineer
Senior Analytics Engineer,Netflix,12/19/2023,https://www.linkedin.com/jobs/view/3754706960,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer (L4) - Security,Netflix,12/19/2023,https://www.linkedin.com/jobs/view/3771170809,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer,Accroid Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788129009,0,https://media.licdn.com/dms/image/D4D0BAQGz_di1atu9CQ/company-logo_100_100/0/1683292700129/accroid_inc_logo?e=2147483647&v=beta&t=OvupgW0oZWw8oodQiV4pXMO4DTI0u9OdLiuevK1eX9s,"Ankeny, IA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Onsite<br/><br/></strong><strong>Data Engineer <br/><br/></strong><ul><li>Build and maintain data pipelines utilizing Databricks and ADLS.</li><li>Collaborate with cross-functional teams to understand and fulfill data requirements.</li><li>Deliver outputs that align with defined specifications and meet business objectives.</li><li>Provide expertise in data engineering and contribute to the overall success of data-related projects.</li></ul>
</div>",No Salary Info Found,Data Integration Engineer
Data Engineer,Blackstone Talent Group,12/19/2023,https://www.linkedin.com/jobs/view/3790357905,0,https://media.licdn.com/dms/image/C560BAQHAFlnQg3firg/company-logo_100_100/0/1657148420727/blackstonetalentgroup_logo?e=2147483647&v=beta&t=RR2QR8qXLbGf4EMMe1qv0MfDEW6BsTugoFERHF1Nxgg,Washington DC-Baltimore Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>We are looking for a <strong>Data Engineer </strong>to join our team of experts to assist with building state-of-the-art data platforms for the client's premier data analytics platform.</p><p><br/></p><p><strong>Responsibilities:</strong></p><p>The Data Engineer will support data collection, ingestion, validation, and loading of optimized data in the appropriate data stores. They work on a team made up of analyst(s), developer(s), data scientist(s), and product leads, and everyone on the team collaborates in support of a specific mission. Working directly with the analyst(s) and the product lead, the data engineer identifies and implements solutions for the data requirements, including building pipelines to collect data from disparate, external sources and implementing rules to validate that expected data is received, cleansed, transformed, massaged and in an optimized output format for the data store. </p><p><br/></p><p>The Data Engineer performs validation and analytics corresponding with client requirements and evolves solutions through automation, optimizing performance with minimal human involvement. As pipelines are executed, the data engineer monitors their status, and performance, and troubleshoots issues while working on improvements to ensure the solution is the very best version to address the customer need. </p><p><br/></p><p><strong>Required Skills:</strong></p><ul><li><strong>Clearance: Secret or Top Secret Clearance</strong></li><li>6+ years of experience with SQL</li><li>6+ years of experience developing data pipelines using modern Big Data ETL technologies like NiFi or StreamSets</li><li>6+ years of experience with a modern programming language such as Python or Java</li><li>6 years of experience working in a big data and cloud environment</li><li>Documented experience with AWS, EC2, S3, and/or RDS</li></ul><p><br/></p><p><strong>Preferred Skills:</strong></p><ul><li>3 years of experience working in an agile development environment</li><li>Ability to quickly learn technical concepts and communicate with multiple functional groups</li><li>Ability to display a positive, can-do attitude to solve the challenges of tomorrow</li><li>Possession of excellent verbal and written communication skills</li><li>Preferred experience at the respective command with an understanding of analytical and data paint points and challenges across the J-Codes.</li></ul><p></p>
</div>",No Salary Info Found,Data Integration Engineer
Security Analytics Engineer (L4),Netflix,12/19/2023,https://www.linkedin.com/jobs/view/3771763243,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer,ASCENDING Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3790307654,0,https://media.licdn.com/dms/image/C4D0BAQG4H6mBuWVGQw/company-logo_100_100/0/1631372273839/ascendingllc_logo?e=2147483647&v=beta&t=HqSlWBYB2Htxq8mAj5GFZEzDCI-FyaW7xdBt4yqDPEo,"Fairfax, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Full-time, 100% Remote<br/><br/>Available for W-2 or 1099 Individual. <br/><br/></strong>Our client, one of the largest Amazon Web Services (AWS) partners for data services, is looking for a true Mid level Big Data Engineer to contribute to join their team of technologists to build and contribute to large-scale, innovative projects. Technological and career growth opportunities are a natural and every day part of the working environment.<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Analyze system requirements and design responsive algorithms and solutions.</li><li>Use big data and cloud technologies to produce production quality code.</li><li>Engage in performance tuning and scalability engineering.</li><li>Work with team, peers and management to identify objectives and set priorities.</li><li>Perform related SDLC engineering activities like sprint planning and estimation.</li><li>Work effectively in small agile teams.</li><li>Provide creative solutions to problems.</li><li>Identify opportunities for improvement and execute.<br/><br/></li></ul><strong>Requirements:<br/><br/></strong><ul><li>Minimum 4 years of proven professional experience working in the IT industry.</li><li>Bachelor's in Computer Science or related domain.</li><li>Experience with cloud based Big Data technologies.</li><li>Experience with big data technologies like Hadoop, Spark and Hive.</li><li>AWS experience (S3 and EMR).</li><li>Proficiency in Hive / Spark SQL / SQL. Experience with Spark.</li><li>Experience with one or more programming languages like Scala &amp; Python &amp; Java.</li><li>Ability to push the frontier of technology and independently pursue better alternatives.<br/><br/></li></ul>Thanks for applying!<br/><br/>Powered by JazzHR<br/><br/>Hv70rUP3Sg
      </div>",No Salary Info Found,Data Integration Engineer
Data Engineer (L5),Netflix,12/19/2023,https://www.linkedin.com/jobs/view/3755880784,0,https://media.licdn.com/dms/image/C4E0BAQEVb0ZISWk8vQ/company-logo_100_100/0/1631355051964?e=2147483647&v=beta&t=_82G5gJfq-rmofKHPHZOMBYvtHfTF8Z2qA_zAUvcVV4,United States,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Netflix, our mission is to entertain the world. With 200+ million paid members in over 190 countries on millions of devices; enjoying TV series, documentaries, and feature films across a wide variety of genres and languages - Netflix is reinventing entertainment from end to end. We are revolutionizing how shows and movies are produced, pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet, and continuously improving the end-to-end user experience with Netflix across their member journey.<br/><br/>We pride ourselves on using data to inform our decision-making as we work towards our mission. This requires curating data across various domains such as Growth, Finance, Product, Content, and Studio. All of this data collection and curation is made possible thanks to the amazing Data Engineers of Netflix who bring this data to life.<br/><br/>Data Engineering at Netflix is a role that requires building systems to process data efficiently and modeling the data to power analytics. These solutions can range from batch data pipelines that bring to life business metrics to real-time processing services that integrate with our core product features. In addition, we require our Data Engineers to have a rich understanding of large distributed systems on which our data solutions rely. Candidates should have knowledge across several of these skill sets and usually need to be deep in at least one. As a Data Engineer, you also need to have strong communication skills since you will need to collaborate with business, engineering, and data science teams to enable a culture of learning. Learn more about the work of data engineers at Netflix.<br/><br/>Location of work: We are considering candidates who are willing to relocate to Los Gatos, California, as well as fully-remote candidates (remote in the US with occasional visits to Los Gatos) depending on the team your skills are most aligned with.<br/><br/>Who are you?<br/><br/><br/><ul><li>You strive to write elegant code, and you're comfortable with picking up new technologies independently</li><li>You are proficient in at least one major programming language (e.g. Java, Scala, Python) and comfortable working with SQL</li><li>You enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine learning models</li><li>You have a strong background in at least one of the following: distributed data processing or software engineering of data services, or data modeling</li><li>You are familiar with big data technologies like Spark or Flink and comfortable working with web-scale datasets</li><li>You have an eye for detail, good data intuition, and a passion for data quality</li><li>You appreciate the importance of great documentation and data debugging skills</li><li>You relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedback</li><li>You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks<br/><br/><br/></li></ul>Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000.<br/><br/>Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.<br/><br/>Netflix is a unique culture and environment. Learn more here.
      </div>",$150000- $750000,Data Integration Engineer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791621839,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Join our growing Engineering team!<br/><br/></strong>This Jobot Job is hosted by Mike Duffy<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $100,000 - $140,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>We are rapidly growing equipment finance company with over 25 years in business!<br/><br/>The Data Engineer will be responsible for building data-driven analytics tools that are used across the entire organization to improve decision making.<br/><br/>The Data Engineer should have 3+ years of experience with Python, ETL, and SQL<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Excellent pay &amp; benefits!</li><li> 100% remote flexibility!</li><li> Room for growth!</li><li> Outstanding company culture!<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.</li><li> Has demonstrated proficiency in designing and developing data marts in Snowflake schema.</li><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL Server, NoSQL, Kafka using AWS or AZURE Big Data technologies.</li><li> Use troubleshooting skills to identify and correct root cause of workflow failures based on error log outputs and environmental conditions.</li><li> Use SQL to examine, filter, and aggregate data in Microsoft SQL Server.</li><li> Experience working with data transformation processing.</li><li> Anticipate, identify, and solve issues concerning data management to improve data quality.</li><li> Experience working with Microsoft BI and Microsoft SQL server.</li><li> Perform POCs on new technology, architecture patterns.</li><li> Must have Experience with at least one Columnar MPP Cloud data warehouse (Snowflake /Azure Synapse / Redshift)</li><li> Design of complex physical data models, projects and cloud-based data lake constructs including SQL/NoSQL database systems. Leads the creation of integrated data views based on business or analytics requirements.</li><li> Design, implement, and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems and business requirements.</li><li> Experience in ETL tools like DBT is nice to have.</li><li> Experience with version control and DevOps platforms such as AZURE DevOps, GitHub, GitLab</li><li> Experience with CI/CD Pipelines and SDLC best practices.</li><li> Experience using Agile methods and project management tools like Jira preferred.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Software Engineering, Information Technology, or a related field.</li><li> Minimum of 3 years of experience in a data engineer or similar role.</li><li> Strong knowledge of Python, ETL, SQL, data integration, and data pipelines.</li><li> Experience with data architecture, data modeling, schema design, and software development.</li><li> Proficiency in data migration, transformation, and scripting.</li><li> Familiarity with machine learning models and their data needs.</li><li> Understanding of distributed systems as it pertains to data storage and computing.</li><li> Strong project management and organizational skills.</li><li> Ability to analyze problems and strategize for better solutions.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$100000- $140000,Data Integration Engineer
Data Engineer,Proven Recruiting,12/21/2023,https://www.linkedin.com/jobs/view/3760795548,0,https://media.licdn.com/dms/image/C560BAQG1WSkkWHu85g/company-logo_100_100/0/1657560807678/proven_recruiting_logo?e=2147483647&v=beta&t=6BYTJvA8GhqtC21wPu2OfbNK4TVrc0ttTFTHBB3vmLQ,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Sr. Data Engineer<br/><br/></strong><strong>What you'll do:<br/><br/></strong><ul><li>Redesign data architecture to support new data initiatives </li><li>Gather requirements from the business enterprise wide to address business requirements </li><li>Make data more reliable and accessible to stakeholders </li><li>Design and craft modern data and analytics platforms <br/><br/><br/></li></ul><strong>Requirements:<br/><br/></strong><ul><li>7+ years of experience as Data Engineer </li><li>Experience deploying production systems into the cloud </li><li>Experience with Airflow, AWS, Astronomer, Domo, DBT <br/><br/><br/></li></ul>#IND3<br/><br/><strong>What does this position pay?<br/><br/></strong>Compensation is determined by several factors which may include skillset, experience level, and geographic location.<br/><br/>The expected range for this role is $135,000 to $145,000 per year. Please note this range is an estimate and actual pay may vary based on qualifications and experience.<br/><br/>
</div>",$135000- $145000,Data Integration Engineer
Data Engineer,Braintrust,12/19/2023,https://www.linkedin.com/jobs/view/3789766635,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
"Senior Software Engineer, Data Solutions-Dallas, Austin, or San Antonio, TX",H-E-B,12/19/2023,https://www.linkedin.com/jobs/view/3483760921,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Associate Analytics Engineer,NexusLeap,12/19/2023,https://www.linkedin.com/jobs/view/3784428116,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer,Visa,12/19/2023,https://www.linkedin.com/jobs/view/3790090038,0,https://media.licdn.com/dms/image/C560BAQEP8_eM4zW8bw/company-logo_100_100/0/1630663392691/visa_logo?e=2147483647&v=beta&t=TzxC8Eby4Etg1Y4aK9Ul8pUVAccJ4Do5GJP4uVtlOBY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.<br/><br/>When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.<br/><br/><strong>Join Visa: A Network Working for Everyone.<br/><br/></strong><strong>Job Description<br/><br/></strong>Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area.<br/><br/>Visa AI as a Service (VAIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, VAIaS automates the updates to data, models, and applications. Combined with strong AI governance, VAIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!<br/><br/>This position is for a Data Engineer with solid development experience who will focus on creating new capabilities for Visa AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.<br/><br/>You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.<br/><br/>This position will be based in Austin, TX. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li> Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions</li><li> Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards</li><li> Responsibilities span all phases of solution development including:</li><li> Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved</li><li> Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner<br/><br/></li></ul>This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.<br/><br/><strong>Qualifications<br/><br/></strong>Basic Qualifications:<br/><br/><ul><li> Bachelors degree, OR 3+ years of relevant work experience<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li> 2 or more years of work experience</li><li> Exposure to leading-edge areas such as Machine Learning, Big Data, Distributed Systems or SRE. </li><li> Experience in at least one of the following: Golang, Java, or C/C++, Spark</li><li> Familiarity with web service standards and related patterns (REST, gRPC)</li><li> Experience implementing solutions for low-latency, distributed services using open standard technologies. <br/><br/></li></ul><strong>Additional Information<br/><br/></strong><strong>Work Hours:</strong> Varies upon the needs of the department.<br/><br/><strong>Travel Requirements:</strong> This position requires travel 5-10% of the time.<br/><br/><strong>Mental/Physical Requirements:</strong> This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.<br/><br/>Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.<br/><br/>Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.<br/><br/><strong>U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 89,600.00 to 114,300.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.</strong>
</div>",No Salary Info Found,Data Integration Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789086619,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Senior Data Engineer,Incedo Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3788682248,0,https://media.licdn.com/dms/image/C4D0BAQEzqnAdsML8AQ/company-logo_100_100/0/1656661706797/incedo_inc_logo?e=2147483647&v=beta&t=lTHWgZfnEyk0Gwvr1BTpOPP3jxHm4Xl-INBATyFxapM,"Austin, Texas Metropolitan Area","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title: Senior Data Engineer</strong></p><p><strong>Full time </strong></p><p><strong>Location: Charlotte NC, and Austin TX, or Fort Mills, SC. </strong></p><p><br/></p><p> <strong>AWS Data Engineer (Spark, AWS, Glue) </strong></p><p><br/></p><p><strong>Must Skill:</strong></p><p>- Work with development teams and other project leaders/stakeholders to provide technical solutions that enable business capabilities</p><p>- Design and develop data applications using big data technologies (AWS, Spark) to ingest, process, and analyze large disparate datasets</p><p>- Build robust data pipelines on Cloud using AWS Glue, Aurora Postgres, EKS, Redshift, PySpark, Lambda, and Snowflake.</p><p>- Build Rest based Data API using Python / C#, EKS, Lambda.</p><p>- Build the infrastructure required for optimal extraction, transformation, and loading of data from various data sources using SQL and AWS ‘big data’ technologies.</p><p>- Work with data and analytics experts to strive for greater functionality in our data systems.</p><p>- Implement architectures to handle large scale data and its organization</p><p>- Execute strategies that inform data design and architecture partnering with enterprise standard</p><p>- Work across teams to deliver meaningful reference architectures that outline architecture principles and best practices for technology advancement</p><p></p>
</div>",No Salary Info Found,Data Integration Engineer
Data Engineer,AtkinsRéalis,12/20/2023,https://www.linkedin.com/jobs/view/3785085485,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer,"VMC Soft Technologies, Inc",12/20/2023,https://www.linkedin.com/jobs/view/3788678633,0,https://media.licdn.com/dms/image/C560BAQFYJzWt3lrZxw/company-logo_100_100/0/1638373652009?e=2147483647&v=beta&t=HcBXf5MuP4MnSHIjz8gEQQP0vWkkqiOw1Tpihg4GwOY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title: Data Engineer</strong></p><p><strong>Location: Austin, TX</strong></p><p><strong>Contract: W2 Only</strong></p><p><br/></p><p><strong>Job Description,</strong></p><p>- Fluency in Advanced SQL (complex joins, stored procedures, subqueries, window functions, performance optimization, etc.), Snowflake, Python.</p><p>- Provide analytical reporting and analytics to the operations team and external partners.</p><p>- Ability to operate in a fast paced, rapidly changing environment.</p><p>- Ability to rapidly learn and adapt to business changes.</p><p>- Excellent communication, project management, and presentation skills</p><p>- Create and maintain reports, create and manage data models, leverage data across complex hierarchies using multiple data sources.</p><p>- Leverage process improvement techniques to drive improvements in data quality.</p><p>Perform testing to support system implementations and upgrades</p><p><br/></p><p><strong>Note: This is a W2 Contract. So, candidates must work on VMC SOFT TECH Payroll. For Immediate response please reach out to me at sai2@galaxyitech.com</strong></p><p><br/></p><p><strong>Thanks</strong></p><p><strong>SAII</strong></p><p><strong>480-992-9904</strong></p><p></p>
</div>",No Salary Info Found,Data Integration Engineer
Junior Data Scientist - US Residents Only,Team Remotely Incorporation,12/25/2023,https://www.linkedin.com/jobs/view/3793154087,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Business Data Analyst,SPECTRAFORCE,12/21/2023,https://www.linkedin.com/jobs/view/3791473634,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765469445,0,https://media.licdn.com/dms/image/D560BAQFsPZUT0bTpJg/company-logo_100_100/0/1689000656484/bdo_usa_logo?e=2147483647&v=beta&t=-M1FfX9Kow8d2drx-DmltN3u3liHKtB3vVhqpNf3A8Q,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>Job Summary:<br/><br/></strong>This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.<br/><br/><strong>Job Duties<br/><br/></strong><ul><li> Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS </li><li> Listens to client needs to align solution with business requirements and delivery schedule </li><li> Creates written functional and technical designs </li><li> Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers </li><li> Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions </li><li> Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles </li><li> Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency) </li><li> Assists with implementation of data governance programs and best practices </li><li> Performs the cleaning and transforming of data from source systems into analytics models </li><li> Implements models to support data visualizations and integrations </li><li> Assists with implementing DevOps, DataOps and MLOps methodologies on projects </li><li> Writes custom integration logic in applicable programming languages </li><li> Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle </li><li> Assists clients with licensing, security, and cost estimation of solutions </li><li> Performs code reviews to ensure adherence to standards </li><li> Works directly with clients and team members to establish secure data analytics platforms and infrastructure </li><li> Contributes to successful deployments of developed solutions and integration of DevOps tools </li><li> Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools </li><li> Builds client relationships during project execution, effectively becoming a trusted advisor of the client </li><li> Participates in support activities for existing software solutions </li><li> Other duties as assigned <br/><br/><br/></li></ul><strong>Supervisory Responsibilities<br/><br/></strong><ul><li> Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product <br/><br/><br/></li></ul><strong>Education<br/><br/></strong><strong>Qualifications, Knowledge, Skills and Abilities:<br/><br/></strong><ul><li> High School Diploma or GED equivalent, required </li><li> Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred <br/><br/><br/></li></ul><strong>Experience<br/><br/></strong><ul><li> Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required </li><li> One (1) or more years of experience technically leading development projects, preferred </li><li> One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred <br/><br/><br/></li></ul><strong>Software<br/><br/></strong><ul><li> Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required </li><li> Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required </li><li> Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred </li><li> Experience with one (1) or more of the following computer languages, preferred:</li><ul><li> C# </li><li> Python </li><li> Java </li><li> Scala </li></ul><li> Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred </li><li> Experience with Git and DevOps deployment technologies, preferred </li><li> Experience with Linux, preferred </li><li> Experience with one (1) or more of the following, preferred:</li><ul><li> Data Lake Medallion Architecture </li><li> Batch and/or streaming data ingestion into a data lake </li><li> AI Algorithms/Machine Learning </li><li> Automation tools such as UiPath, Alteryx, etc. </li><li> Computer Vision based AI technologies <br/></li></ul></ul><strong>Other Knowledge, Skills &amp; Abilities<br/><br/></strong><ul><li> Ability to work with a high degree of professionalism and autonomy </li><li> Excellent verbal and written communication skills </li><li> Solid organizational skills, especially the ability to meet project deadlines with a focus on details </li><li> Ability to successfully multi-task while working independently or within a group environment </li><li> Ability to work in a deadline-driven environment, and handle multiple projects simultaneously </li><li> Ability to interact effectively with people at all organizational levels of the Firm </li><li> Ability to effectively interact with a team of professionals and delegating work assignments, as needed </li><li> Ability to build and maintain strong relationships with internal and client personnel </li><li> Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel <br/><br/><br/></li></ul><strong>Keywords:</strong> Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL<br/><br/>Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.<br/><br/>California Range: $111,000 - $152,000<br/><br/>Colorado Range: $111,000 - $152,000<br/><br/>New York City/ Valhalla Range: $111,000 - $152,000<br/><br/>Washington Range: $111,000 - $152,000<br/><br/><strong>About Us<br/><br/></strong>BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.<br/><br/><ul><li>Unparalleled partner-involvement </li><li>Deep industry knowledge and participation</li><li>Geographic coverage across the U.S.</li><li>Cohesive global network </li><li>Focused capabilities across disciplines<br/><br/><br/></li></ul>BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.<br/><br/>BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best &amp; Brightest Companies to Work For and more.<br/><br/><strong>Some Examples Of Our Total Rewards Offerings Include<br/><br/></strong><ul><li>Competitive pay and eligibility for an annual performance bonus. </li><li>A 401k plan plus an employer match</li><li>Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one</li><li> Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays </li><li>Paid Parental Leave</li><li>Adoption Assistance</li><li>Firm paid life insurance</li><li>Wellness programs</li><li>Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance <br/><br/><br/></li></ul>Above offerings may be subject to eligibility requirements.<br/><br/>Click here to find out more!<br/><br/>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.<br/><br/>""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""<br/><br/>
</div>",$111000- $152000,Data Integration Engineer
Lead Data Engineer,GoodRx,12/19/2023,https://www.linkedin.com/jobs/view/3771699983,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Senior Site Reliability Engineer - Data Infrastructure (Seattle),ByteDance,12/19/2023,https://www.linkedin.com/jobs/view/3752620479,0,https://media.licdn.com/dms/image/C560BAQGA-1ynUGnhlA/company-logo_100_100/0/1630658803864/bytedance_logo?e=2147483647&v=beta&t=qwdwRFbcyeowsgkldY71siWXFEeKM3RGpMQlkJFP9T4,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong>Founded in 2012, ByteDance's mission is to inspire creativity and enrich life. With a suite of more than a dozen products, including TikTok, Helo, and Resso, as well as platforms specific to the China market, including Toutiao, Douyin, and Xigua, ByteDance has made it easier and more fun for people to connect with, consume, and create content.<br/><br/>Why Join Us<br/><br/>Creation is the core of ByteDance's purpose. Our products are built to help imaginations thrive. This is doubly true of the teams that make our innovations possible.<br/><br/>Together, we inspire creativity and enrich life - a mission we aim towards achieving every day.<br/><br/>To us, every challenge, no matter how ambiguous, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always.<br/><br/>At ByteDance, we create together and grow together. That's how we drive impact - for ourselves, our company, and the users we serve.<br/><br/>Join us.<br/><br/>Our data infrastructure Site Reliability Engineering (SRE) team is a pioneer in innovation. We seamlessly merge software development and infrastructure operations to design, build, and manage large-scale, highly distributed systems.<br/><br/>We take pride in overseeing one of the industry's most extensive cloud infrastructures. As software development evolves, building systems from a mix of components has become the new standard. In this era, SRE takes a central role. This role demands the ability to design, develop, and operate these components, transforming them into cloud-managed, scalable, and reliable elements. Our professionals play a critical role as connectors, ensuring the seamless integration of these diverse components to deliver high-performing systems.<br/><br/>Our dynamic SRE field is about actively shaping the future of technology, not just keeping pace with it. We contribute significantly to the next chapter of data infrastructure. We're currently in the process of building global teams around the world. Join us today and embark on this transformative journey!<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li> Participate in and enhance the complete service lifecycle, from inception and design, through development, capacity planning, launch reviews, deployment, operation, and refinement.</li><li> Design and implement software platforms and monitoring frameworks to govern service-oriented architecture (SOA) efficiently, automatically, and intelligently.</li><li> Develop and manage components of cloud-managed data infrastructure, encompassing technologies such as Kubernetes, Redis, MySQL, Flink, and more.</li><li> Establish sustainable mechanisms for scaling systems, such as automation, to drive enhancements in reliability, efficiency, and velocity.</li><li> Provide sustainable user support, manage incident responses, and conduct blameless postmortems as part of our ongoing efforts to improve our systems.<br/><br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science or a related technical field with 5+ years of experience</li><li> Experience programming in one of the following Languages: C, C++, Java, Python, Go, and Rust</li><li> Familiar with Unix/Linux system internals, networking, and distributed systems</li><li> [Preferred] Experience in MySQL, Redis, Ngnix, Kubernetes, Docker, OpenStack, Hadoop, Spark, Flink, etc.</li><li> [Preferred] Experience in designing and analyzing large-scale distributed systems</li><li> [Preferred] Strong skills in problem solving and communication<br/><br/><br/></li></ul>ByteDance is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At ByteDance, our mission is to inspire creativity and enrich life. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.<br/><br/>ByteDance Inc. is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at dataecommerce.accommodations@bytedance.com<br/><br/><br/><br/><strong>Job Information:<br/><br/></strong><strong>【For Pay Transparency】Compensation Description (annually)<br/><br/></strong>The base salary range for this position in the selected city is $177688 - $266000 annually.<br/><br/>Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.<br/><br/>Our Company Benefits Are Designed To Convey Company Culture And Values, To Create An Efficient And Inspiring Work Environment, And To Support Our Employees To Give Their Best In Both Work And Life. We Offer The Following Benefits To Eligible Employees:<br/><br/>We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&amp;D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care.<br/><br/>Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability.<br/><br/>We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.
      </div>",$177688- $266000,Data Integration Engineer
"Systems Development Engineer, MVP DBS Analytics",Amazon Web Services (AWS),12/19/2023,https://www.linkedin.com/jobs/view/3703174524,0,https://media.licdn.com/dms/image/C560BAQER_QnUTXrPJw/company-logo_100_100/0/1670264051233/amazon_web_services_logo?e=2147483647&v=beta&t=tI5mZm2XR_yMnLD5LQNmk8dQtVwGevKFXUHJlb8I_wE,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Note: This position requires that the candidate selected be a US Citizen have an active TS/SCI security clearance with polygraph. In compliance with the U.S. government requirement that employees of its contractors, and employees who work on or in connection with U.S government contracts must receive the COVID-19 vaccine, this position may require that the candidate selected be fully vaccinated against COVID-19. A person is considered fully vaccinated by completing the full regimen of the COVID-19 vaccine (two doses for Pfizer or Moderna and one dose for Johnson &amp; Johnson).<br/><br/>This is an excellent opportunity to join Amazon's world class technical team in Denver, CO Seattle, WA, Crystal City, VA or Herndon, VA, working with some of the best and brightest engineers and technical managers while also developing your skills and furthering your career within one of the most innovative and progressive technology companies anywhere.<br/><br/>Amazon Web Service is building some of the largest distributed systems in the world. Amazon's Analytics offerings like ElasticSearch, QuickSight, Glue, Athena, LakeFormation, EMR, and RedShift are massively scaled services that make up a critical piece of the internet today.<br/><br/>A successful Engineer joining the team will do much more than write code and triage problems. They will work with Amazon's largest and most demanding customers to address specific needs across a full suite of services. They will dive deeply into technical issues and work relentlessly to improve the customer experience. The ideal candidate will...<br/><br/>Be great fun to work with. Our company credo is ""Work hard. Have fun. Make history"". The right candidate will love what they do and instinctively know how to make work fun.<br/><br/>Have strong Linux &amp; Networking background. The ideal candidate will have deep experience working with Linux, preferably in a large scale, distributed environment. You understand networking technology and how servers and networks inter-relate. You regularly take part in deep-dive troubleshooting and conduct technical post-mortem discussions to identify the root cause of complex issues.<br/><br/>Think Big. The ideal candidate will build and deploy solutions across thousands of devices. You will strive to improve and streamline processes to allow for work on a massive scale.<br/><br/>Arlington, VA: This role will sit in our new headquarters in Northern Virginia, where Amazon will invest $2.5 billion dollars, occupy 4 million square feet of energy efficient office space, and create at least 25,000 new full-time jobs. Our employees and the neighboring community will also benefit from the associated investments from the Commonwealth including infrastructure updates, public transportation improvements, and new access to Reagan National Airport. By working together on behalf of our customers, we are building the future one innovative product, service, and idea at a time. Are you ready to embrace the challenge? Come build the future with us.<br/><br/>The pay range for this position in Colorado is $129,2k -174,8k yr; however, base pay offered may vary depending on job-related knowledge, skills, and experience. A sign-on bonus and restricted stock units may be provided as part of the compensation package, in addition to a full range of medical, financial, and/or other benefits, dependent on the position offered. This information is provided per the Colorado Equal Pay Act. Base pay information is based on market location. Applicants should apply via Amazon's internal or external careers site.<br/><br/>We are open to hiring candidates to work out of one of the following locations:<br/><br/>Denver, CO, USA | Seattle, WA, USA<br/><br/><strong>Basic Qualifications<br/><br/></strong><ul><li> 2+ years of non-internship professional software development experience</li><li> 1+ years of designing or architecting (design patterns, reliability and scaling) of new and existing systems experience</li><li> 7+ years of administrative experience in networking, storage systems, operating systems and hands-on systems engineering experience</li><li> Knowledge of systems engineering fundamentals (networking, storage, operating systems)</li><li> Experience programming with at least one modern language such as C++, C#, Java, Python, Golang, PowerShell, Ruby<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li> Experience with PowerShell (preferred), Python, Ruby, or Java</li><li> Experience working in an Agile environment using the Scrum methodology<br/><br/></li></ul>Amazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.<br/><br/>Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $103,400/year in our lowest geographic market up to $201,200/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information, please visit https://www.aboutamazon.com/workplace/employee-benefits. Applicants should apply via our internal or external career site.<br/><br/><br/><strong>Company</strong> - Amazon Development Center U.S., Inc.<br/><br/>Job ID: A2437023
      </div>",$2.5- $1292,Data Integration Engineer
Insurance - Data Analyst - REMOTE,Wahve LLC,12/20/2023,https://www.linkedin.com/jobs/view/3790962880,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Scientist: 23-03226,"Akraya, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3785019600,0,https://media.licdn.com/dms/image/C560BAQHvgNZ-eiCxhA/company-logo_100_100/0/1657039456688/akraya_inc_logo?e=2147483647&v=beta&t=AHdRQ4MG2nO9Rvl1T2vaAAhc8tviIumRzQfk43TvMZ8,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Primary Skills: Data Science , Data analytics ,Machine Learning, Algorithm , Data pipelines, Data Visualization, Tableau , Python , Java, Scala, Statistical background, AWS, Azure<br/><br/>Contract Type: W2 Only<br/><br/>Duration: 18+ Months (Possible Extension)<br/><br/>Location: Seattle, WA<br/><br/>Pay Range:$80.00 - $85.00 Per Hour<br/><br/><ul><li> TALK to a recruiter NOW: CONTACT Gowtham at (408) 512-2369<br/><br/></li></ul>Grow your network by interacting with people.<br/><br/><strong>Job Responsibilities<br/><br/></strong>Looking for a lead data scientist to join our Ad Platforms team in Seattle. You will be responsible for driving innovation and applying machine learning to boost advertising efforts for client's online properties. This includes developing algorithms, analyzing large-scale data, and collaborating with cross-functional teams. Must have 5-8 years of experience, strong statistical and analytical skills, and proficiency in Python and data visualization tools.<br/><br/><strong>Job Requirements<br/><br/></strong><ul><li> 6+ years of hands-on experience in machine learning and advanced analytics. Experience in the advertising domain is preferred.</li><li> Solid understanding of Client technologies, mathematics and statistics.</li><li> Proficient with Python, Java, Scala , large scale Client/DL platforms and processing tech stack.</li><li> Passion to understand the ad business and apply accurate research study according to the business scenario, and seek innovation opportunities to enhance business effectiveness.</li><li> Passion for technology, open to interdisciplinary work, and experience in building data-driven services and applications.</li><li> Proven track record of thriving in a fast-paced, data-driven, collaborative and iterative applied research environment is required.</li><li> CALL NOW: Gowtham at (408) 512-2369 </li></ul><li><br/><br/></li><strong>About Akraya<br/><br/></strong>Akraya is an award-winning IT staffing firm and the staffing partner of choice for many leading companies across the US. Akraya was recently voted as a <strong>2021 Best Staffing Firm to Temp for</strong> by Staffing Industry Analysts and voted by our employees and consultants as a <strong>2022 Glassdoor Best Places to Work</strong>.
      </div>",$80.00- $85.00,Data Integration Engineer
Data Engineer- REMOTE (W2 & Benefits provided) - 4239,Braintrust,12/20/2023,https://www.linkedin.com/jobs/view/3790533491,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Analyst,Motion Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3774941037,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Our client, <strong>a global broadcast media and entertainment company,</strong> is actively looking for a <strong>Data Analyst</strong> to join their News Group's Business Intelligence team based out of <strong>Seattle!</strong> This role is fully remote however must be comfortable working PST hours.<br/><br/><ul><li>This is a 1 year initial contract position***<br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li>Dimensional modeling: Craft and implement robust dimensional models for diverse datasets, including structured and semistructured data</li><li>Leverage advanced SQL skills to query and manipulate data efficiently in AWS Athena and other relevant platforms</li><li>Develop and optimize data processing workflows using Pyspark</li><li>Engage in investigative data analysis to identify and resolve data-related challenges, including stakeholder requests and data integrity/accuracy</li><li>Work closely with a team of 3, partner teams, and stakeholder groups to understand business requirements to provide valuable insights</li><li>Continuously assess and enhance existing processes, employing innovative approaches to optimize data pipelines and improve overall system efficiency</li><li>Thoroughly document data models, queries, and processes</li><li>Conduct rigorous testing of data solutions to uphold data standards and ensure the reliability of analytical outputs<br/><br/></li></ul><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>Bachelor's degree in a quantitative field such as Applied Mathematics, Statistics, Computer Science, MIS, or related field OR equivalent work experience</li><li>7+ years of experience with reporting packages, databases, and ETL frameworks</li><li>3+ years of experience with data analysis and database management</li><li>Strong SQL querying skills</li><li>Strong experience with dimensional modeling</li><li>Pyspark experience is a HUGE PLUS (can be trained on if necessary)</li><li>Strong experience with Excel (Pivot Tables and Macros)<br/><br/></li></ul><strong>Posted By:</strong> Jillian Reagan
      </div>",No Salary Info Found,Data Integration Engineer
"Data Engineer, Google Customer Solutions",Google,12/23/2023,https://www.linkedin.com/jobs/view/3790696258,0,https://media.licdn.com/dms/image/C4D0BAQHiNSL4Or29cg/company-logo_100_100/0/1631311446380?e=2147483647&v=beta&t=5bmvSDVt4i-ECxTU43yiS4iXUM4inJiG-e9PHOUlxx0,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This role may also be located in our Playa Vista, CA campus.<br/><br/>Note: By applying to this position you will have an opportunity to share your preferred working location from the following: <strong>Redwood City, CA, USA; Ann Arbor, MI, USA; Chicago, IL, USA; New York, NY, USA; Los Angeles, CA, USA; San Francisco, CA, USA</strong>.<strong>Minimum qualifications:<br/><br/></strong><ul><li>Bachelor’s degree or equivalent practical experience.</li><li>2 years of experience in software development in one or more general purpose programming languages (e.g., Java, C/C++, C#, Python, etc.), including experience with SQL.</li><li>Experience in data pipeline development and business communication.</li><li>Experience in relational/non-relational databases, API development (e.g. REST), or backend system design.<br/><br/></li></ul><strong>Preferred qualifications:<br/><br/></strong><ul><li>Master’s degree in Business, Statistics, Mathematics, Economics, Engineering, or Applied Science, or a related field.</li><li>Ability to work with stakeholders to provide technical solutions to business challenges.</li><li>Excellent project management skills and ability to prioritize tasks.</li><li>Basic proficiency in and passion for data analysis.<br/><br/></li></ul><strong>About The Job<br/><br/></strong>The Revenue Strategy and Operations (RSO) team is the strategic and operational arm of Google Customer Solutions (GCS) and is responsible for setting priorities and then driving implementation.<br/><br/>Within RSO, the Engineering team is responsible for creating technical solutions to support and maximize traction with Google's advertisers. We lead the design, planning, and operations, using a scalable and analytical programmatic approach to drive business initiatives through our products, in collaboration with cross-functional teams across Sales, Marketing, Product, and Engineering.<br/><br/>When our millions of advertisers and publishers are happy, so are we! Our Google Customer Solutions (GCS) team of entrepreneurial, enthusiastic and client-focused members are the ""human face"" of Google, helping entrepreneurs both individually and broadly build their online presence and grow their businesses. We are dedicated to growing the unique needs of advertising companies. Our teams of strategists, analysts, advisers and support specialists collaborate closely to spot and analyze customer needs and trends. In collaboration, we create and implement business plans broadly for all types of businesses.<br/><br/>The US base salary range for this full-time position is $93,500-$135,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.<br/><br/>Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Design, build, deploy, and improve data pipelines and applications using standard and Google-specific software development tools. This may include ensuring reliable backends, building pipelines to aggregate data from multiple sources, or enhancing performance of existing tools and services.</li><li>Analyze problems and develop solutions, while identifying dependencies and resolving issues to drive implementation. Make technical contributions, including writing and reviewing design documents, tests, and code.</li><li>Provide subject-matter expertise and utilize comprehensive knowledge of Google's relevant technologies, principles, practices, and coding standards.</li><li>Collaborate with cross-functional users and stakeholders to identify pain points and devise innovative technical solutions.<br/><br/><br/></li></ul>Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .
      </div>",$93500- $135000,Data Integration Engineer
Data Analyst,Vaco,12/22/2023,https://www.linkedin.com/jobs/view/3786752257,0,https://media.licdn.com/dms/image/D4E0BAQETVFSdIzK4cw/company-logo_100_100/0/1688588535509/vaco_logo?e=2147483647&v=beta&t=KN3VUnnqFSwt02YHwldNK4wEkN8Drmn8Q0gqsxv6-AU,"Los Angeles County, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<br/><strong>Quick Notes:</strong><ul><li>1-2 years of experience desired</li><li>Industry exp preferred</li><li>Senior in Excel, mid-level in SQL, understanding of Python</li><li>Not moving towards Data Science anytime soon, but they are open to use Python day-to-day if they prefer</li><li>Doing most of the Data visualizations in Excel (not a tool)</li><li>Will have 5 clients they do analytics for. Working with Account Managers to give them the data analysis for clients, sometimes will have to speak with clients on call.<br/><br/></li></ul><strong>Job Description:</strong> <br/><br/><strong>Business Data Analyst</strong> <br/><br/>The Analyst will provide analytical support to the sales, marketing, and business development departments. They will focus on performance and optimization of our key client accounts. They will collect and analyze data, and then apply mathematical models and statistics to guide key decisions and management. <br/>Core responsibilities include optimizing campaigns, preparing and interpreting data and reporting, and reviewing key performance indicators (KPIs) to provide suggestions and guidance. The analyst will also support the product and engineering teams, as well as executive management, in building and evaluating tools and software. <br/><strong>RESPONSIBILITIES</strong><ul><li>Compile, analyze and interpret performance data to best optimize advertiser campaigns.</li><li>Build and evaluate mathematical models and optimization approaches towards maximizing advertiser's return on investment (ROI).</li><li>Analyze data across our marketplace to uncover opportunities for growth and efficient allocation of resources.</li><li>Work with engineering and product teams to prototype, build, and evaluate the MediaAlpha platform's optimization tools.</li><li>Help clients build, execute and optimize campaigns, measure and present results.</li><li>Provide consultative and strategic marketing guidance for clients.</li><li>Build templates and tools to improve efficiency and efficacy of analysis and optimizations.<br/></li></ul><strong>REQUIREMENTS</strong><ul><li>Strong analytical ability and attention to detail</li><li>Experience synthesizing large data sets.</li><li>Capacity to think critically and creatively, identify problems, and propose solutions.</li><li>Strong written and verbal communication skills.</li><li>Self-starter who can take initiative on projects, work to scale existing processes and implement new ones.</li><li>Strong Excel proficiency (pivot tables, vlookups, data manipulation).</li><li>Strong proficiency with statistical and financial concepts (e.g., confidence intervals and ROI).</li><li>Experience using programming/scripting languages for data analysis and mathematical modeling preferred (SQL, Python, R, Stata, etc.).</li><li>2+ years of work experience in an analytical role.</li><li>B.S. required, must be in a quantitative discipline (e.g., economics, finance, engineering, math or statistics).</li></ul>
</div>",No Salary Info Found,Data Integration Engineer
Data Engineer,UCLA Health,12/19/2023,https://www.linkedin.com/jobs/view/3788430276,0,https://media.licdn.com/dms/image/C560BAQHyuBEO4-qOOw/company-logo_100_100/0/1630668765070/ucla_health_logo?e=2147483647&v=beta&t=2-jEcz0aRJMHdE2Xz-zakZTu9Z9ZeVYHwXDELtsvui4,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Under general supervision of the manager of DGIT Data Operations, the Database Engineer will be responsible for installation, configuration, database design, pipeline building, migration, capacity planning, performance tuning, security and recovery among other tasks. In this role, you will: monitor daily ETLs as well as developing new and enhancing existing ETL packages build data pipelines with process in place to ensure data quality and conform to the best industry practice of data governance maintain all VM servers as well as MS SQL Servers on premises, and MS Azure admin tasks function as a Database engineer for DGIT Data Operations, with the mindset of securing and backing up all databases on a regular cadence work closely with our business partners and collaborate with other team members on monthly financial report releases work closely with other DGIT groups to collaborate on existing or new server configurations provide general technical support in the areas of database engineering, logical and physical data model design be expected to work on, maintain, and manage multiple projects simultaneously over an extended period of time, collaborate with developers and appropriately prioritizing tasks and regularly showing progress backfill ETL developers and DBAs as needed. In this role, you will be required to be on site at least 6 days per quarter. Salary offers are determined based on various factors including, but not limited to, qualifications, experience, and equity. The full annual salary range for this position is $78,800 - $175,000. The target salary range that the University reasonably expects to pay for this position is between the minimum and the midpoint of the salary range.
      </div>",$78800- $175000,Data Integration Engineer
"Data Scientist I, Revenue",Tinder,12/19/2023,https://www.linkedin.com/jobs/view/3757776367,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer,University of Southern California,12/19/2023,https://www.linkedin.com/jobs/view/3500265434,0,https://media.licdn.com/dms/image/C4E0BAQHatTfEv4Af6w/company-logo_100_100/0/1631312619853?e=2147483647&v=beta&t=SMp5VNiFDNwEqti49w8FPl5yYzg-RYxhNB3IEE0jqZI,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The University of Southern California, founded in 1880, is located in the heart of downtown and is the largest private employer in the City of Los Angeles. As an employee of USC, you will be a part of a world-class research university and a member of the “Trojan Family.”<br/><br/>USC University Advancement is seeking a collaborative <strong>Data Engineer</strong> to design, build, and launch new data models to provide intuitive analytics to customers. Reporting to the Executive Director of Business Intelligence, the Data Engineer will move data from our Data Warehouse Systems into downstream databases and data marts for analysis. This is a hybrid position based in our downtown Los Angeles office (USC Tower).<br/><br/>USC values diversity and is committed to equal opportunity in employment. USC University Advancement is committed to fostering a diverse, equitable, and inclusive culture in which all advancement staff and our stakeholders have the opportunity to connect, belong, and grow while supporting the USC’s mission, values, and goals.<br/><br/><strong>Job Accountabilities<br/><br/></strong><ul><li>Architect, build, and launch new data models that provide intuitive analytics to your customers</li><li>Design, build and launch extremely efficient &amp; reliable data pipelines to move data (both large and small amounts) from our Data Warehouse Systems into downstream databases and data marts for analysis</li><li>Develop strategies to extract, resolve, and unify information of various types from numerous disparate data sources and integrate cohesively with external business applications</li><li>Collaborate with a cross-functional team of client leads, application developers, operations engineers, and architects to translate complex product requirements into technical specs and design requirements</li><li>Optimize performance and cost efficiency of cloud-based processes across multiple cloud environments (AWS, Azure, GCP)</li><li>Design, build and deploy ETL and data management processes with reliable error/exception handling and rollback framework</li><li>Provide production support for data load jobs and develop customized query to generate automatic periodic reports</li><li>Build applications writing SQL/Python scripts to manipulate data and/or writing specific instructions for off-shore programmers to write the scripts</li><li>Provide daily monitoring, management, troubleshooting, and issue resolution to existing and new data solutions and systems’ interfaces affected by them.</li><li>Develop high quality, reliable, and fault-tolerant data solutions based on internal and external customers/users’ requirements, applying best practices and new trends/technologies all along the solution lifecycle.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>2+ years of overall experience developing cloud-native data solutions on Azure/AWS (Must have a solid understanding of cloud concepts: Storage, Compute, Network and Managed Services)</li><li>Broad knowledge of different database technologies beyond RDBMS, vendor/solution capabilities in data management and reporting/analytics – data federation, big data, data quality, Business Intelligence, etc., and writing complex SQL queries in a data warehouse environment</li><li>3+ years of experience programming in PowerShell and C#</li><li>3+ years of experience in SQL, data transformations, statistical analysis, and troubleshooting across more than one Database Platform (Cassandra, MySQL, Snowflake, PostgreSQL, Redshift, Azure SQL Warehouse, etc.).</li><li>3+ years of experience designing and building solutions utilizing various Cloud services such as EC2, S3, EMR, Kinesis, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API gateway, etc.</li><li>Experience with one or more relevant tools (Sqoop, Flume, Kafka, Oozie, Hue, Zookeeper, HCatalog, Solr, Avro, SSIS)</li><li>Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto)</li><li>Experience with AWS ecosystem (Data Lake Formation, Glue, Data Pipelines, EC2, Redshift, S3, Glacier, DynamoDB, Lambda, etc.)<br/><br/></li></ul><strong>Documentation And Additional Information<br/><br/></strong>To apply, please include a resume and cover letter.<br/><br/>The annual base salary range for this position is $96,739.35 - $110,000. When extending an offer of employment, the University of Southern California considers factors such as (but not limited to) the scope and responsibilities of the position, the candidate’s work experience, education/training, key skills, internal peer equity, federal, state, and local laws, contractual stipulations, grant funding, as well as external market and organizational considerations.<br/><br/>USC has excellent benefits, including health benefits for staff &amp; their family with access to the renowned university medical network; retirement plans with employer contributions once you meet Program’s eligibility; tuition benefits for staff &amp; their family; central Los Angeles location with easy access to commuter trains, buses &amp; free tram pick up services.<br/><br/>The University of Southern California values diversity and is committed to equal opportunity in employment.<br/><br/>Minimum Education: Bachelor's degree Minimum Experience: 3 years Minimum Field of Expertise: Direct knowledge and experience in data modeling, data warehousing and reporting. Project management experience for complex projects. Demonstrated organizational, critical thinking, interpersonal, planning, problem solving, and business analytical skills. Able to work at a high functional and technical level.
      </div>",$96739.35- $110000,Data Integration Engineer
"Senior Data Engineer, Python (Remote) – 3988",HIRECLOUT,12/19/2023,https://www.linkedin.com/jobs/view/3552098262,0,https://media.licdn.com/dms/image/D560BAQEUsd6ajmP3ZQ/company-logo_100_100/0/1692307270312/hireclout_logo?e=2147483647&v=beta&t=kDQYCBte9Oh2m6Jk-2ULaGzxOUOXb-by0e3YXpr_WEY,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        HireClout<br/><br/>What You Will Be Doing<br/><br/><ul><li>Design and support an innovative Data Platform </li><li>Create data models that can not only be utilized by the entire company, but that’s relevant and important to the entire company </li><li>Gain information on data collection efficiencies through collaboration with data analysts and contribute to the further automation of manual tasks </li><li>Identify, extract, assess, manipulate, and analyze internal and external data from multiple sources including transactional and reference data </li><li>Closely interact with data scientists and analysts to build pipelines and warehousing solutions <br/><br/></li></ul>What You Will Need<br/><br/><ul><li>Experience with Python </li><li>Experience with Data Pipelines </li><li>Experience with Snowflake, Spark, Airflow, or Kinesis <br/><br/></li></ul>Nice to Have<br/><br/><ul><li>Apache Storm, Apache Kafka, or Apache Nifi experience </li><li>Experience with Flink, Cassandra, MariaDB, and ElasticSearch </li><li>Experience with a technology like Redis, Redshift, Athena, BigQuery, DBT, or Presto <br/><br/></li></ul>Why Us<br/><br/><strong>Benefits And Perks<br/><br/></strong><ul><li>Competitive Salary: $100,000 – $200,000 <br/><br/></li></ul>Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.<br/><br/>This position does not offer sponsorship.<br/><br/><strong>REF: JOB-3988<br/><br/></strong>Share this job<br/><br/>First name<br/><br/>Last name<br/><br/>Email<br/><br/>Attach resume*<br/><br/><ul><li> Job type: Permanent </li><li> Location: </li><li> Date posted: Posted 12 months ago </li><li>Salary:$100000 - $200000 per Year<br/><br/></li></ul>
</div>",$100000- $200000,Data Integration Engineer
Data Engineer,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3790370222,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Burbank, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Looking for someone with a strong background working as a data engineer pulling and extracting data, as well as building pipelines &amp; distributed systems. The ideal candidate will have strong experience with Python, PySpark, SQL, and AWS.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>Experience with Python programming </li><li>Experience with PySpark </li><li>Strong AWS experience </li><li>Comfortable working within several SQL databases </li><li>Experience with one or more data warehousing technology <br/><br/></li></ul>What You Will Be Doing<br/><br/>Tech Breakdown<br/><br/><ul><li>50% Building Pipelines with PySpark </li><li>50% Data cleaning and integration <br/><br/></li></ul>Daily Responsibilities<br/><br/><ul><li>100% Hands On <br/><br/></li></ul>The Offer<br/><br/><ul><li>Competitive base salary and equity offered <br/><br/></li></ul><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical &amp; Dental Insurance </li><li>Health Savings Account (HSA) </li><li>401(k) with 3% match </li><li>Unlimited Paid Time Off </li><li>Pre-tax Commuter Benefit </li><li>Unlimited remote access </li><li>Flexible work from home schedule (onsite 2-3 days/month) </li><li>On-site Gym <br/><br/></li></ul>Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Julie Bennett
      </div>",No Salary Info Found,Data Integration Engineer
"Data Engineer, Product Analytics",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3725959368,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.<br/><br/>Data Engineer, Product Analytics Responsibilities:<br/><br/><ul><li>Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems</li><li>Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve</li><li>Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way</li><li>Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership</li><li>Design, build and launch new data models and visualizations in production, leveraging common development toolkits</li><li>Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries</li><li>Support existing processes running in production and implement optimized solutions with limited guidance</li><li>Define and manage SLA for data sets in allocated areas of ownership<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.</li><li>2+ years of work experience in data engineering</li><li>Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy</li><li>Experience working with terabyte to petabyte scale data<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data Integration Engineer
Data and Platform Engineer,"Honda of America Mfg., Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3790802092,0,https://media.licdn.com/dms/image/C4E0BAQHJzoYpgeuWkw/company-logo_100_100/0/1631310920236?e=2147483647&v=beta&t=sPSFxpdwUEU0KcluhRMcpvXucMepm76QmsROz96EVLo,"Torrance, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Workstyle: </strong>Hybrid (20% onsite)<br/><br/><strong>Preferred onsite location: </strong>Torrance, OH or Marysville, OH<br/><br/>The <strong>Data and Platform Engineer</strong> plays a crucial role in designing, developing, and maintaining scalable and reliable data platforms to support the organization's data needs. With a propensity of action over analysis , they are responsible for ensuring efficient data ingestion, storage, processing, and retrieval, as well as providing data integration solutions to enable effective data analysis and reporting. This role requires a strong understanding of data engineering concepts, data management, and programming languages to deliver innovative data solutions while respecting governance principles like responsible AI and data privacy.<br/><br/><strong>Data Integration And Transformation<br/><br/></strong><ul><li>Develop and implement data integration solutions to enable seamless data movement across various systems and platforms.</li><li>Implement efficient data workflows, data pipelines, and ETL processes to accommodate structured and unstructured data from various sources to ensure the timely delivery of high-quality data.</li><li>Define data models and build data hierarchy structures to support AI/ML model integrations that are reliable and scalable.</li><li>Transform and cleanse data to ensure accuracy, consistency, and integrity.</li><li>Collaborate with data analysts and data scientists to understand data requirements and deliver tailored solutions.</li><li>Troubleshoot and resolve data integration issues in a timely manner.<br/><br/></li></ul><strong>Data Platform Development And Maintenance<br/><br/></strong><ul><li>Design, develop, and maintain scalable data platforms that support data ingestion, storage, processing, and retrieval.</li><li>Collaborate with cross-functional teams to ensure data platforms meet the organization's evolving data requirements.</li><li>Regularly monitor the data platform's performance, identifying and resolving any issues or bottlenecks<br/><br/></li></ul><strong>Data Quality, Governance And Security<br/><br/></strong><ul><li>Implement and enforce data quality and governance assurance policies, ensuring compliance with relevant data protection regulations and industry best practices.</li><li>Develop and maintain data security measures, including access controls, encryption, and data anonymization techniques.</li><li>Monitor data usage and access patterns, proactively identifying and mitigating potential security risks.</li><li>Collaborate with the IT and cybersecurity teams to address data-related vulnerabilities and incidents.</li><li>Perform data profiling, data validation, and data cleansing activities to ensure data.accuracy and completeness.</li><li>Collaborate with stakeholders to identify and resolve data quality issues.</li><li>Define and monitor data quality metrics to measure and improve data quality over time.</li><li>Conduct regular audits and reviews to ensure adherence to data quality standards.</li><li>Ensure data governance and compliance standards, including responsible AI principles and data privacy, are adhered to during data integration and transformation processes.<br/><br/></li></ul><strong>Performance Optimization<br/><br/></strong><ul><li> Identify and implement performance optimization strategies for data platforms and processes. </li><li> Optimize database design, data structures, and query performance to enhance data retrieval speed. </li><li> Monitor and analyze data processing and query performance metrics, taking proactive actions to optimize their performance. </li><li> Collaborate with infrastructure and network teams to ensure optimal data platform performance. </li><li> Conduct regular performance testing and tuning activities and optimize data platforms for performance, reliability, and security. <br/><br/></li></ul><strong>Documentation And Knowledge Sharing<br/><br/></strong><ul><li> Document data platform architecture, data models, data flows, and technical specifications. </li><li> Create and maintain comprehensive documentation of data engineering processes and workflows. </li><li> Share knowledge and best practices with team members and stakeholders. </li><li> Provide training and support to users on data engineering tools and technologies. </li><li> Contribute to the development and enhancement of data engineering standards and guidelines. </li><li> Continuously research, evaluate and implement emerging technologies and best practices in data engineering to drive innovation. </li><li> BS in Technical discipline such as Computer Science, Information Systems, Computer Engineering or a related field. Proven experience as a Data Engineer, Database Developer, or relevant experience and certifications are welcome in lieu of a degree. <br/><br/></li></ul><strong>Minimum Experience<br/><br/></strong><ul><li> Strong understanding of data engineering principles, data management, and data modeling concepts. </li><li> Proficient in programming languages such as Python, Java, or Scala, with experience in database query languages (e.g., SQL). </li><li> Experience with cloud-based data platforms (e.g., AWS, Azure, GCP) and associated services (e.g., S3, Redshift, BigQuery). </li><li> Familiarity with data integration techniques, ETL frameworks (e.g., Apache Spark), and workflow management tools (e.g., Airflow). </li><li> Experience with data streaming and real-time data processing frameworks (e.g., Kafka, Apache Flink, AWS Kinesis, etc). </li><li> Familiarity with machine learning and AI techniques for data analysis and prediction. </li><li> Understanding of data security, encryption, privacy, and compliance requirements. </li><li> Excellent problem-solving and analytical skills, with the ability to optimize data processing pipelines for performance and efficiency. </li><li> Strong communication skills, with the ability to effectively collaborate with cross-functional teams and explain complex technical concepts to non-technical stakeholders. <br/><br/></li></ul><strong>Other Job-specific Skills<br/><br/></strong><ul><li> Experience with data engineering tools and frameworks such as Apache Airflow, Apache NiFi, Talend, etc. </li><li> Experience with Data science tools such as Open Data Hub (Seldon, Prometheus, Dataiku, IBM Watson Studio, etc) </li><li> Deep learning - machine learning that is a neural network with three or more layers, which helps to “learn” from large amounts of data. </li><li> Cloud/big data tools (ex. blob storage, Redshift, Kafka, Hadoop, Spark, Hive etc.). </li><li> Experience with containerization technologies such as Docker or Kubernetes.</li></ul>
</div>",No Salary Info Found,Data Integration Engineer
Data Engineer,STAND 8 Technology Services,12/20/2023,https://www.linkedin.com/jobs/view/3773569628,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Cloud Data Engineer/Developer,Talener,12/25/2023,https://www.linkedin.com/jobs/view/3757621969,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
"Data Engineer, FinTech",Amazon,12/24/2023,https://www.linkedin.com/jobs/view/3756689531,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Jr. Data Engineer,Brooksource,12/19/2023,https://www.linkedin.com/jobs/view/3790347614,0,https://media.licdn.com/dms/image/C4D0BAQEpBYagiK3vWA/company-logo_100_100/0/1631310603864?e=2147483647&v=beta&t=QFWW3W6lJWmWobT1e3ga2p8it00G9tpnQUu4zQBd94Y,Dallas-Fort Worth Metroplex,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Jr. Data Engineer</strong></p><p><strong>DFW (Hyrbid)</strong></p><p><strong>6-12 Month Contract To Hire (Upskilling Program)</strong></p><p><br/></p><p><strong><u> Why you’ll love this job</u></strong></p><ul><li>Our data engineers are powering the capability to make decisions using data to improve operations and our customer and employee experience.</li><li>You will help enable data engineering solutions.</li><li>You will be part of a team that innovates.</li><li>This role is a part of the Data Engineering and Analytics team within our Technology group. You’ll bring your data engineering, collaboration and analytics skills to help cultivate a data driven culture by designing and delivering analytics solutions and making data analytics easier and more effective.</li></ul><p> </p><p><strong><u>Responsibilities</u></strong></p><ul><li>Work closely with source data application teams and product owners to design, implement and support analytics solutions that provide insights to make better decisions</li><li>Implement data migration and data engineering solutions using Azure products and services: (Azure Data Lake Storage, Azure Data Factory, Azure Functions, Event Hub, Azure Stream Analytics, Azure Databricks, etc.) and traditional data warehouse tools.</li><li>Perform multiple aspects involved in the development lifecycle – design, cloud engineering (Infrastructure, network, security, and administration), ingestion, preparation, data modeling, testing, CICD pipelines, performance tuning, deployments, consumption, BI, alerting, prod support.</li><li>Provide technical leadership and collaborate within a team environment as well as work independently.</li><li>Be a part of a DevOps team that completely owns and supports their product</li><li>Implement batch and streaming data pipelines using cloud technologies</li><li>Leads development of coding standards, best practices and privacy and security guidelines.</li><li>Mentors others on technical and domain skills to create multi-functional teams</li></ul><p> </p><p><strong><u>Qualifications</u></strong></p><ul><li>Bachelor's degree in Computer Science, Computer Engineering, Technology, Information Systems (CIS/MIS), Engineering or related technical discipline, or equivalent experience/training</li><li>1 years software solution development using agile, DevOps, operating in a product model that includes designing, developing, and implementing large-scale applications or data engineering solutions</li><li>1 years data analytics experience using SQL</li><li>1 year of cloud development and data lake experience (prefer Microsoft Azure) including Azure EventHub, Azure Data Factory, Azure Databricks, Azure DevOps, Azure Blob Storage, Azure Data Lake, Azure Power Apps and Power BI.</li><li>Combination of Development, Administration &amp; Support experience in several of the following tools/platforms required:</li><li>Scripting: Python, Spark, Unix, SQL</li><li>Data Platforms: Teradata, Cassandra, MongoDB, Oracle, SQL Server, ADLS, Snowflake, Azure Data Explorer. Administration skills a plus</li><li>Azure Cloud Technologies: Azure Data Factory, Azure Databricks, Azure Blob Storage, Azure Data Lake, Azure Power Apps and Azure Functions</li><li>CI/CD: GitHub, Jenkins, Azure DevOps, Terraform</li><li>BI Analytics Tool Stack - Cognos, Tableau, Power BI, Alteryx, Denodo, and Grafana</li><li>Data Warehousing: DataStage, Informatica</li><li>Data Governance and Privacy: Informatica Axon and EDC, BigID</li></ul><p> </p><p><strong><u>Nice-to-Have</u></strong></p><p>· 1+ years software solution development using agile, dev ops, product model that includes designing, developing, and implementing large-scale applications or data engineering solutions.</p><ul><li>1+ years data analytics experience using SQL</li><li>1 years full-stack development experience, preferably in Azure</li><li>1 years of cloud development and data lake experience (prefer Microsoft Azure) including Azure EventHub, Azure Data Factory, Azure Functions, ADX, ASA, Azure Databricks, Azure DevOps, Azure Blob Storage, Azure Data Lake, Azure Power Apps and Power BI.</li><li>Airline Industry Experience</li></ul><p></p>
</div>",No Salary Info Found,Data Integration Engineer
"(USA) Senior, Data Engineer",Walmart,12/19/2023,https://www.linkedin.com/jobs/view/3790381527,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
"Senior Data Engineer, DevX and Platform-Dallas, Austin, or San Antonio, TX",H-E-B,12/19/2023,https://www.linkedin.com/jobs/view/3508877623,0,https://media.licdn.com/dms/image/C560BAQGIrljxfWRNtQ/company-logo_100_100/0/1660516154560/heb_logo?e=2147483647&v=beta&t=7OeSirhtE-hma6Hj7wvHqAUyPWJlA1JJIjUWT_wFzGk,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Since H-E-B Digital Technology's inception, we've been investing heavily in our customers' digital experience, reinventing how they find inspiration from food, how they make food decisions, and how they ultimately get food into their homes. This is an exciting time to join H-E-B Digital--we're using the best available technologies to deliver modern, engaging, reliable, and scalable experiences to meet the needs of our growing audience. If you enjoy taking on new challenges, working in a rapidly changing environment, learning new skills, and applying it all to solve large and impactful business problems, we want you as part of our team.<br/><br/>Our Partners thrive The H-E-B Way. In the <strong>Senior Data Engineer, DevX </strong> that means you have a...<br/><br/>HEART FOR PEOPLE... you can organize multiple engineers, negotiate solutions, and provide upward communication<br/><br/>HEAD FOR BUSINESS... you consistently demonstrate and uphold the standards of coding, infrastructure, and process<br/><br/>PASSION FOR RESULTS... you're capable of high-velocity contributions in multiple technical domains<br/><br/><strong>What you will do:<br/></strong><ul><li> Develop solutions to build and continuously improve monitoring and observability for data pipelines and data platform </li><li> Build data platform components using hybrid cloud services (AWS, GCP, and Azure) </li><li> Implement features to improve data platform performance and security continuously </li><li> Build Real-time data streaming tools and associated experience </li><li> Create self-service tools and experience for all enterprise data engineering teams <br/><br/></li></ul><strong>Project you will impact:<br/></strong><ul><li> Build a data platform that can handle petabytes of data and help running advanced analytics workloads </li><li> Improve the data quality and consumer experience for 100K+ enterprise data consumer <br/><br/></li></ul><strong>Who you are:<br/></strong><ul><li> Hands-on experience in Cloud and data pipelines. </li><li> Expert in SQL, and experienced programmer in one or more than one of the languages such as Python, Java, or Scala. </li><li> Understanding of Big Data and Hybrid Cloud infrastructure. Experienced in more than one of the technologies such as Kafka, Kubernetes, Spark, Databricks, AWS EMR, S3, Data warehouses (Snowflake, Teradata), AWS and GCP Cloud services </li><li> Experienced in cloud administration and infrastructure as a code (Terraform, Cloud Formation, Ansible, Chef) is a plus </li><li> Experienced in DevOps tools such as GitLab CI/CD, and Jenkins. </li><li> Up to date on the latest technology developments. Should be able to evaluate and propose new tooling/solutions for data platforms. </li><li> Excellent written, oral communication and presentation skills. </li><li> Understanding of MLOps and Data Engineering <br/><br/></li></ul><strong>Bonus:<br/></strong><ul><li> Databricks or Spark Certifications </li><li> DevOps Certifications </li><li> Cloud certifications (AWS Preferred)</li></ul>
</div>",No Salary Info Found,Data Integration Engineer
Data Engineer - Data Ventures,Walmart Luminate,12/19/2023,https://www.linkedin.com/jobs/view/3705427831,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer,SnapX.ai,12/19/2023,https://www.linkedin.com/jobs/view/3790035374,0,https://media.licdn.com/dms/image/C560BAQGrI5ZAgEOJ2Q/company-logo_100_100/0/1630666773263/snapxplatform_com_logo?e=2147483647&v=beta&t=ZLMq0RgwhdqNpuxZa98IYOgvdQbNVWudgbncPkkl5SY,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Dear Partner, Good morning,greetings from Snaprecruit LLC!<br/><br/>Submission you please review the below role,If you are available.<br/><br/><br/> </p> <p><strong>Role description: </strong></p> <p>The Data Engineer will participate on data management aspects of client engagements to deliver as well as contribute to and foster a high-performance collaborative workplace. </p> <p> </p> <p>A Data Engineer will: </p> <p>- Independently execute projects through design, implementation, automation, and maintenance of large-scale enterprise ETL processes for a global client </p> <p>- Develop repeatable and scalable code that processes client data in an automated and efficient manner to ensure data availability in the platform is as real-time as possible. </p> <p>- Act as an expert data resource within the team </p> <p>- Manage the process of data delivery on teams by overseeing other Data Engineers and Analysts to deliver on-time, accurate, high-value, robust data solutions across multiple clients, solutions, and industry sectors </p> <p>- Build trust-based working relationships with peers and clients across local and global teams </p> <p>- Implement best practices and collaborate in the design of effective streamlined processes for a complex global solutions group </p> <p>- Leverage industry best practices including proper use of source control, code reviews, data validation and testing </p> <p>- Contribute to the automation capabilities of the team. </p> <p>- Comply with and uphold all Mastercard internal policies and external regulations </p> <p> </p> <p>Minimum job requirements: </p> <p>- Bachelor's degree in a quantitative field (e.g., Computer Science, Statistics, Econometrics, Engineering, Mathematics, Operations Research). </p> <p>- Excellent English quantitative, technical, and communication (oral/written) skills; is an excellent listener </p> <p>- Expertise and hands-on experience with Microsoft SQL Server and Python </p> <p>- Proven self-motivated leader with experience working in multiple teams spread across several geographies </p> <p>- Demonstrated excellent skills in the ability to innovate, think critically and disaggregate problems. Able to provide oversight, validation and quality control to own and teamwork product </p> <p>- Skilled at balancing multiple projects and differing project priorities </p> <p>- Flexible to work with global offices across several time zones </p> <p> </p> <p>Relevant fields of educational study: </p> <li>Computer Science, Statistics, Econometrics, Engineering, Mathematics, Operations Research </li><br/> <p> </p>
</div>",No Salary Info Found,Data Integration Engineer
Data Engineer (Python/SQL),"RealPage, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3750654473,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Sr. Data Integration Engineer,NTT DATA Services,12/19/2023,https://www.linkedin.com/jobs/view/3790400818,0,https://media.licdn.com/dms/image/D4E0BAQFGbJcePCYbQw/company-logo_100_100/0/1698840606005/ntt_data_americas_logo?e=2147483647&v=beta&t=iv5QKLmDD_5oWjT4ExAtWK-jaEeiBVnk30tIuUWykXg,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Sr. Data Integration Engineer - 23-03367<br/><br/>100% REMOTE<br/><br/>3Mths Duration (Possible Extension)<br/><br/>W2 or C2C<br/><br/></strong>NTT DATA Services strives to hire exceptional, innovative and passionate individuals who want to grow with us. If you want to be part of an inclusive, adaptable, and forward-thinking organization, apply now.<br/><br/>We are currently seeking a Sr. Data Integration Engineer to join our team.<br/><br/><strong>Job Description<br/><br/></strong>You will be part of the product which plays a pivotal role in the direction NTT DATA Services is taking with the cloud technologies.<br/><br/><strong>Open<br/><br/></strong><ul><li>You are expected to make significant, direct and high-quality contributions to the product that lead to increased market share and customer happiness.</li><li>As part of the NTT DATA Services Insurance Analytics Development Team, you will:</li><li>Design, develop, and maintain high-performance and scalable APIs, including the design of new features and enhancements to existing functionality.</li><li>Defining and implementing Open API designs for containerized architecture using Continuous Integration/Continuous Deployment (CI/CD) tooling using GitHub Actions / Azure DevOps, and related technologies.</li><li>Write automated feature and regression tests as part of daily development.</li><li>Play an active hands-on role across the entire software development life cycle, including helping to deliver software into production.</li><li>Interact with globally distributed teams and technical leaders driving architecture and technical roadmap planning.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>6&amp;plus; years experience with Open API design and development using python preferably FastAPI web framework and ElasticSearch</li><li>3&amp;plus; years of experience of object-oriented coding for designing and implementing microservices.</li><li>Solid understanding of RESTful API design principles.</li><li>Experience in implementing API security best practices.</li><li>Experience working with open-source software and tools (Redis, Kafka, ElasticSearch etc)</li><li>General cloud architecture experience with a major cloud provider (AWS, Azure, GCP) Preferred Azure.</li><li>Experience with building production grade products for cloud Marketplace.</li><li>Experience with version control systems (e.g., Git) and CI/CD pipelines using Azure<br/><br/></li></ul><strong>Devops<br/><br/></strong><ul><li>Experience in gRPC based services is a bonus</li><li>Documentation and white-boarding skills.</li><li>Strong communication and collaboration abilities.</li><li>Practices, Principles, Techniques</li><li>Continuous Integration/Continuous Deployment (CI/CD)</li><li>Release Communication and Collaboration</li><li>Follow coding best practices.</li><li>TDD (Test Driven Development, especially with respect to CI/CD and DevOps<br/><br/></li></ul><strong>About NTT DATA Services<br/><br/></strong>Where required by law, NTT DATA provides a reasonable range of compensation for specific roles. The starting hourly range for this remote role is <strong>$60 to $71.</strong> This range reflects the minimum and maximum target compensation for the position across all US locations. Actual compensation will depend on several factors, including the candidate's actual work location, relevant experience, technical skills, and other qualifications. This position may also be eligible for incentive compensation based on individual and/or company performance.<br/><br/>This position is eligible for company benefits that will depend on the nature of the role offered. Company benefits may include medical, dental, and vision insurance, flexible spending or health savings account, life, and AD&amp;D insurance, short-and long-term disability coverage, paid time off, employee assistance, participation in a 401k program with company match, and additional voluntary or legally required benefits<em>.<br/><br/></em>NTT DATA Services is a recognized leader in IT and business services, including cloud, data and applications, headquartered in Texas. As part of NTT DATA, a $30 billion trusted global innovator with a combined global reach of over 80 countries, we help clients transform through business and technology consulting, industry and digital solutions, applications development and management, managed edge-to-cloud infrastructure services, BPO, systems integration and global data centers. We are committed to our clients' long-term success. Visit nttdata.com or LinkedIn to learn more.<br/><br/>NTT DATA Services is an equal opportunity employer and considers all applicants without regarding to race, color, religion, citizenship, national origin, ancestry, age, sex, sexual orientation, gender identity, genetic information, physical or mental disability, veteran or marital status, or any other characteristic protected by law. We are committed to creating a diverse and inclusive environment for all employees. If you need assistance or an accommodation due to a disability, please inform your recruiter so that we may connect you with the appropriate team.
      </div>",$60- $71,Data Integration Engineer
Azure Data Engineer,Akkodis,12/19/2023,https://www.linkedin.com/jobs/view/3788163742,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer III - Remote | WFH,Get It Recruit - Information Technology,12/25/2023,https://www.linkedin.com/jobs/view/3787808700,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"La Mesa, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a dynamic and innovative team seeking a skilled Data Engineer III to join us remotely. At our company, we value collaboration, creativity, and a passion for transforming data into meaningful insights. If you thrive in a fast-paced, agile environment and are excited about building solutions that make a real impact, we invite you to explore this opportunity.<br/><br/><strong>Responsibilities<br/><br/></strong>Design and implement features in collaboration with a diverse team of engineers, product owners, data analysts, and business partners using Agile/Scrum methodology.<br/><br/>Develop programs and systems that translate data into meaningful information for analysis.<br/><br/>Build ETL/ELT jobs and workflows to integrate data from various sources.<br/><br/>Install continuous pipelines of filtered information for data analysts/scientists.<br/><br/>Construct data workflows using SQL Server Integration Services (SSIS), Microsoft Azure (Azure Data Factory, Storage Accounts, Synapse), and Databricks.<br/><br/>Collaborate with business stakeholders and product engineering teams to analyze business problems and implement solutions.<br/><br/>Document software architecture, create roadmap plans, and assist in the design, implementation, and maintenance of complex solutions.<br/><br/>Build systems that collect, manage, and convert raw data into usable information for business analysts.<br/><br/>Ensure data accessibility for evaluation and optimization.<br/><br/><strong>Qualifications<br/><br/></strong>Required:<br/><br/>Master's degree in computer science, systems engineering, or a related technical discipline (preferred).<br/><br/>5 years of experience as a Data Engineer/Administrator or in a similar role.<br/><br/>6 additional years of relevant experience may substitute for education.<br/><br/><strong>Preferred<br/><br/></strong>Proficiency in back-end data organization using SQL scripts and SSIS.<br/><br/>Experience with Microsoft Azure, Databricks, and Python or other scripting languages in data pipelines.<br/><br/>Familiarity with Microsoft Power BI.<br/><br/>Ability to work independently and provide technical and non-technical support to multiple users.<br/><br/>Capable of working under pressure, handling multiple tasks simultaneously.<br/><br/>Occasional overtime and weekend availability may be required.<br/><br/><strong>Salary Range<br/><br/></strong>Experience providing services to the federal government is preferred.<br/><br/>Target salary range: $165,001 - $175,000. The estimate displayed represents the typical salary range for this position based on experience and other factors.<br/><br/><strong>COVID Policy<br/><br/></strong>We prioritize the health and safety of our team members. While we do not require COVID-19 vaccinations or boosters, we adhere to customer site vaccination requirements when work is performed at a customer site.<br/><br/>Employment Type: Full-Time
      </div>",$165001- $175000,Data Integration Engineer
"Data Engineer - Data Science Solution, Privacy, and Ethics (JRD)",Johnson & Johnson,12/24/2023,https://www.linkedin.com/jobs/view/3792749486,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765472151,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
"Data Conversion Developer, Senior Associate",PwC,12/19/2023,https://www.linkedin.com/jobs/view/3749933940,0,https://media.licdn.com/dms/image/D4D0BAQH3qXh7nyImoQ/company-logo_100_100/0/1697100791441/pwc_logo?e=2147483647&v=beta&t=egwzMH-OEEIdbRMowwJcaDKwrISS95b4zQiwpJJhhyw,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Specialty/Competency: </strong>Functional &amp; Industry Technologies<br/><br/><strong>Industry/Sector: </strong>Not Applicable<br/><br/><strong>Time Type: </strong>Full time<br/><br/><strong>Travel Requirements: </strong>Up to 80%<br/><br/>A career within Functional and Industry Technologies services will provide you with the opportunity to build secure and new digital experiences for customers, employees, and suppliers. We focus on improving apps or developing new apps for traditional and mobile devices as well as conducting usability testing to find ways to improve our clients’ user experience. Our team helps clients transform their business through enabling technologies across marketing, finance and operations in the functional areas such as Maximo and PowerPlant.<br/><br/>To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.<br/><br/><strong>Responsibilities<br/><br/></strong>As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:<br/><br/><ul><li>Use feedback and reflection to develop self awareness, personal strengths and address development areas.</li><li>Delegate to others to provide stretch opportunities, coaching them to deliver results.</li><li>Demonstrate critical thinking and the ability to bring order to unstructured problems.</li><li>Use a broad range of tools and techniques to extract insights from current industry or sector trends.</li><li>Review your work and that of others for quality, accuracy and relevance.</li><li>Know how and when to use tools available for a given situation and can explain the reasons for this choice.</li><li>Seek and embrace opportunities which give exposure to different situations, environments and perspectives.</li><li>Use straightforward communication, in a structured way, when influencing and connecting with others.</li><li>Able to read situations and modify behavior to build quality relationships.</li><li>Uphold the firm's code of ethics and business conduct.<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><strong><strong>Minimum Degree Required:<br/><br/></strong></strong>Bachelor Degree<br/><br/><strong>Minimum Years Of Experience<br/><br/></strong>4 years<br/><br/><strong>Preferred Qualifications<br/><br/></strong><strong><strong>Degree Preferred:<br/><br/></strong></strong>Master Degree<br/><br/><strong>Certification(s) Preferred<br/><br/></strong>Azure Data Engineer Associate<br/><br/>Databricks Certified Data Engineer Associate<br/><br/><strong>Preferred Fields Of Study<br/><br/></strong>Computer and Information Science, Computer Engineering, Computer Management, Management Information Systems, Information Technology<br/><br/><strong>Preferred Knowledge/Skills<br/><br/></strong>Demonstrates a thorough level of abilities with, and/or a proven record of success as both an individual contributor and team member, identifying and addressing client needs:<br/><br/><ul><li>Supports in data analysis techniques to assess source data structures, identify mapping requirements, and define transformation rules for data conversion into Maximo;</li><li>Leads Maximo's modules and functionalities related to Asset Management and Work Order Management and IBM Maximo, including its data structures, configuration settings, and integration capabilities;</li><li>Identifies relational databases, preferably experience in working with databases commonly used in Maximo, such as IBM DB2, Oracle, Microsoft SQL Server, along with familiarity with Maximo's Integration Framework (MIF) and its capabilities for data integration and conversion;</li><li>Supports in designing and implementing data extraction, transformation, and loading processes for Maximo data conversion; </li><li>Showcases understanding in SQL and database querying languages to extract and manipulate data from source systems along with understanding ETL tools and methodologies commonly used in Maximo data conversion;</li><li>Identifies technologies commonly used with Maximo, including web services (SOAP, RESTful APIs), XML, JSON, and other relevant data exchange formats;</li><li>Supports in pipeline architecture and development using one of the tools such as Azure ADF, AWS Glue, SSIS, DataBricks (multiple preferred);</li><li>Utilizes data cleansing techniques and methodologies to ensure the integrity and accuracy of converted data in Maximo;</li><li>Developes data cleansing functional business rules as per Maximo Business Object (MBO) definitions for source to Maximo conversion requirements;and comprehensive testing plans and executing validation processes to verify the accuracy and integrity of converted data in Maximo; </li><li>Customizes Maximo options, such as Automation Scripts, Java Customizations, Database Configuration, or Application Designer, to support data conversion requirements;</li><li>Identifies integrations within Maximo with other enterprise systems, such as ERP systems, GIS systems, or asset management systems. Knowledge of integration patterns, data synchronization, and data exchange protocols; and,</li><li>Showcases work experience as a Data Engineer, Data Architect or similar role, along with experience in programming languages including Python, PySpark, Scala, SQL. <br/><br/></li></ul>Learn more about how we work: https://pwc.to/how-we-work<br/><br/>PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.<br/><br/>All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.<br/><br/>For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.<br/><br/>Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines<br/><br/>For positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https://pwc.to/payrange-v1-advisoryseniorassociate<br/><br/>
</div>",No Salary Info Found,Data Integration Engineer
Principal Data Scientist,Intuit,12/19/2023,https://www.linkedin.com/jobs/view/3739158009,0,https://media.licdn.com/dms/image/C560BAQFTpF8uneqScw/company-logo_100_100/0/1661446146222/intuit_logo?e=2147483647&v=beta&t=iftV6ZuJ3UG8jC5zwm-gE8RPaVtk4cAhvGG4aXrt6AA,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>Intuit is hiring a <strong>Principal Data Scientist</strong> to join our Intuit AI team.<br/><br/>Come join our collaborative and creative group of data scientists and machine learning engineers and build models that directly affect hundreds of thousands of our customers. In this role you will be building and deploying machine learning models using both analytical algorithms and deep learning approaches. We are waiting for you to join us and do the best work of your life.<br/><br/><strong>What You'll Bring<br/><br/></strong><ul><li>PhD/MS in Engineering Mathematics, Statistics, Theoretical/Computational Physics, or related field</li><li>Solid knowledge of statistical techniques</li><li>3+ years as either a lead in a data science role or in a management position in data science</li><li>Strong communication skills and proven experience as an influencer at the executive level</li><li>Hands-on programming experience in one or more of: ML, NLP, Statistics, or Optimization</li><li>6+ years’ experience manipulating large datasets and using databases (e.g. R, SQL, S-Plus, etc.)</li><li>6+ years’ experience with a general-purpose programming language (e.g. Python, Scala, etc.)<br/><br/></li></ul><strong>Strongly Preferred<br/><br/></strong><ul><li>PhD in Engineering Mathematics, Statistics, Theoretical/Computational Physics, or related field</li><li>Expert knowledge and hands-on experience in one or more of: ML, NLP, Statistics, or Optimization</li><li>Expert knowledge and hands-on experience with ML pipelines, processes, and design patterns</li><li>Proven track record of influencing business leaders to shape mission critical projects </li><li>Proven track record of leading team to successful delivery of ML solutions</li><li>Strong interpersonal and communication skills in order to effectively contribute to technical teams and make presentations to a variety of technical and business personnel<br/><br/></li></ul><strong>How You Will Lead<br/><br/></strong><ul><li>Practices excellent leadership and communication skills to influence and lead teams and to evangelize data science across the organization</li><li>Leads team’s work in one or more of: ML, NLP, Statistics, or Optimization, performs hand-on work in these domains. </li><li>Weighs ROI considerations of general and tailored capabilities for projects in the team</li><li>Creates new capabilities that solve critical business problems </li><li>Pushes the boundaries of ML by developing foundational methods and novel applications from state-of-the-art ML technologies and industry trends </li><li>Influences business leaders to shape mission critical projects </li><li>Creates multi-year vision that connects product strategy with technology strategy</li><li>Drives architecture decisions, influences and contributes to ML platform architecture and strategy </li><li>Leads team and partners to the successful delivery and integration of ML solutions </li><li>Conducts design reviews, holds teams to technical and operational rigor. </li><li>Acts as an advisor in overseeing and mentoring the work of colleagues towards the building of a vibrant practice community</li></ul>
</div>",No Salary Info Found,Data Integration Engineer
Data Analyst,TEKsystems,12/20/2023,https://www.linkedin.com/jobs/view/3788626864,0,https://media.licdn.com/dms/image/D4E0BAQFLrODAdU8Mdw/company-logo_100_100/0/1688568814937/teksystems_logo?e=2147483647&v=beta&t=oUxSISiI6GoLA1ohGI74ZDRCRqtO7-AJ3HQb3Iu_Rnk,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Description <br/><br/>Data Analyst (for EHR data migration)<br/><br/><ul><li>ideal candidate has 4 – 10 years experience (but open to up to 15 years)</li><li> This position will support with EHR migration from Cerner to SmartCare (by Streamline)<br/><br/><br/></li></ul> Job Duties <br/><br/><ul><li> Data Analyst job duties for a large data migration– analysis, requirements gathering, compliance, etc. Data entry, data processing, data integrity,</li><li> Responsible for the analysis, compliance, integration, aggregation and management of data – i.e. patient information, clinical measures, registries, and determinants</li><li> Data Systems and Process Management - Assure all data processes supported or defined by the EHR comply with guidance from regulatory agencies and acts</li><li> Support the development and maintenance of Clinical Data Security, Handling, and Compliance Procedures</li><li> Provide support, analysis, guidance, feedback and recommendations to colleagues, organizational leadership, clinical staff and clinical systems vendors on data, business intelligence,</li><li> Act as initial point of contact for issues regarding population health systems</li><li> Collect all required issue data for problem analysis and resolution<br/><br/><br/></li></ul> Additional Skills &amp; Qualifications <br/><br/>NICE TO HAVE:<br/><br/><ul><li> Reporting Tools – Tableau, BusinessObjects, DA2/CCL</li><li> Database Tools – Snowflake</li><li> Programming languages – Python</li><li> Bachelor's degree in computer science or related field</li><li> Knowledge of the regulatory (standards, compliance, etc.) environment related to EHR implementations (Joint Commission, OSHPD, HIPAA, etc.)<br/><br/><br/></li></ul> About TEKsystems <br/><br/>We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.<br/><br/>The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.
      </div>",No Salary Info Found,Data Integration Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083991,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $160,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$160000- $173000,Data Integration Engineer
Data Visualization Developer,Vaco,12/20/2023,https://www.linkedin.com/jobs/view/3785095175,0,https://media.licdn.com/dms/image/D4E0BAQETVFSdIzK4cw/company-logo_100_100/0/1688588535509/vaco_logo?e=2147483647&v=beta&t=KN3VUnnqFSwt02YHwldNK4wEkN8Drmn8Q0gqsxv6-AU,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Data Virtualization Developer Our client is looking for a seasoned data visualization programmer with strong UX/UI design experience to develop new interactive tools that advance their clients' understanding and adoption of their offerings. The ideal candidate will be able to share a relevant portfolio of interactive tools for consideration.<br/><br/>What You'll Contribute: o Develop interactive tools that enable their client end-users to visually explore and download industry benchmarking data provided through a variety of dimensions of interest. o Refine existing ""business case in a box"" ROI calculators developed in Tableau to make them more intuitive and visually appealing. o Liaise with product management to understand business requirements and high-level specifications and translate them into technical requirements. o Work closely with software and Web development teams that will embed interactive tools in their website, ensuring tool designs marry well with Web pages and satisfy corporate branding requirements. o Rapid, iterative prototyping of tools to solicit and incorporate stakeholder feedback, including clients and end-users. o Participate in user testing prior to finalizing designs.<br/><br/>Requirements: Experienced developer of interactive data visualization applications for business users. Specific requirements:<br/><br/>Minimum 3 years experience with data visualization tools including Tableau, Plotly or equivalent. o Able to share/demonstrate a relevant portfolio of interactive tools developed by the candidate for consideration o UX/UI design experience, with emphasis on designing interactive, intuitive and informative tools for business users. o Proficient in writing database queries to feed data visualization views. o Experience embedding visualization into Web applications, taking account of accessibility requirements. o Ability to manage workloads and meet project deadlines. o Experience with one or more general purpose programming languages including but not limited to: Java, JavaScript, Python, Swift and/or Ruby. o Experience with data visualization libraries, such as D3.js or Vega. o Solid communication skills; ability to communicate effectively with team and interact with users to understand their requirements and respond to their issues. o Works well in a team of diverse skills (user experience, engineering, product).
      </div>",No Salary Info Found,Data Integration Engineer
"Data Scientist, Mid",Booz Allen Hamilton,12/20/2023,https://www.linkedin.com/jobs/view/3789000813,0,https://media.licdn.com/dms/image/D560BAQFONzmexEjnKQ/company-logo_100_100/0/1688152881727/booz_allen_hamilton_logo?e=2147483647&v=beta&t=WObdLZdWUtVerjHd32dAqEjay9aR9sBz2AI2Y4tN_44,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Number: R0187217<br/><br/></strong>Data Scientist, Mid<br/><br/><strong>The Opportunity: <br/><br/></strong>As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors—from fraud detection to cancer research to national intelligence—we need you to help find the answers in the data.<br/><br/>On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide teammates and lead the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used. Work with us as we use data science for good.<br/><br/>Join us. The world can’t wait.<br/><br/><strong>You Have:<br/><br/></strong><ul><li>3+ years of experience with data science, data analytics, machine learning, or statistics, including in a management or advisory role</li><li>Experience with object-oriented programming languages, including Python, C++, Java, or R</li><li>Experience with identifying and analyzing data sets to meet customer requirements</li><li>Experience with preparing customer data for models, including merging and aggregating data, handling anomalies, balancing, and feature selection</li><li>Knowledge of Cloud services, including AWS, Azure, or Google Cloud</li><li>Ability to help interpret model results and communicate them clearly through compelling data visualizations</li><li>Ability to obtain a security clearance</li><li>Bachelor’s degree<br/><br/><br/></li></ul><strong>Nice If You Have:<br/><br/></strong><ul><li>Experience with supervised and unsupervised machine learning techniques, including neural networks, decision trees, logistic regressions, or dimension reduction</li><li>Experience with data engineering and data science tools, including Databricks, ElasticSearch, Apache NiFi, or StreamSets</li><li>Experience with enterprise DataOps, DevSecOps, and MLOps processes to operationalize and monitor data science models</li><li>Experience with Agile development</li><li>Experience with CI/CD, including Git, Jenkins, and Docker</li><li>Knowledge of procedural SQL language, including PL/pgSQL</li><li>Ability to explain analytic and model findings to non-technical audiences<br/><br/><br/></li></ul><strong>Clearance:<br/><br/></strong>Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.<br/><br/><strong>Create Your Career: <br/><br/></strong><strong>Grow With Us <br/><br/></strong>Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.<br/><br/><strong>A Place Where You Belong <br/><br/></strong>Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time.<br/><br/><strong>Support Your Well-Being<br/><br/></strong>Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.<br/><br/><strong>Your Candidate Journey<br/><br/></strong>At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.<br/><br/><strong>Compensation<br/><br/></strong>At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.<br/><br/>Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.<br/><br/><strong>Work Model<br/><br/></strong>Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.<br/><br/><ul><li>If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.</li><li>If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.<br/><br/><br/></li></ul><strong>EEO Commitment<br/><br/></strong>We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.
      </div>",$73100.00- $166000.00,Data Integration Engineer
Principal Data Scientist,Precision Point Staffing,12/20/2023,https://www.linkedin.com/jobs/view/3790453008,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Junior Data Engineer (US),Fitness Matrix Inc,12/25/2023,https://www.linkedin.com/jobs/view/3793120666,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Junior Data Engineer ( US Only),VPNforAndroid,12/25/2023,https://www.linkedin.com/jobs/view/3793149558,0,https://media.licdn.com/dms/image/D4D0BAQGxr6JHWQfm7Q/company-logo_100_100/0/1703085942357/vpnforandroid_logo?e=2147483647&v=beta&t=FLkefdBzaEfaC6oa-y9v-dapg0lzP3ry6mLYT0ugty4,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong>Junior Data Engineer ( US Only)- Full-time remote work <br/><br/></strong><strong>Years of experience: </strong>1+<br/><br/><strong>Salary:</strong> $55K to $65K<br/><br/>VPNforAndroid is a leading provider of virtual private network (VPN) services. We help people stay safe online by encrypting their internet traffic and routing it through our secure servers. This lets you browse the web privately and securely, even on public Wi-Fi networks.<br/><br/><strong>Position Summary<br/><br/></strong>Join the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.<br/><br/><strong>Key Responsibilities include:<br/><br/></strong>Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation.<br/><br/>Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency<br/><br/>Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency<br/><br/>Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data<br/><br/>Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently<br/><br/>Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation<br/><br/>Create/maintain documentation for data processes, data flows, and system configurations<br/><br/>Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness<br/><br/><strong>Characteristics of this role:<br/><br/></strong>Team Player: Willing to teach, share knowledge, and work with others to make the team successful.<br/><br/>Communication: Exceptional verbal, written, organizational, presentation, and communication skills.<br/><br/>Creativity: Ability to take written and verbal requirements and come up with other innovative ideas.<br/><br/>Attention to detail: Systematically and accurately research future solutions and current problems.<br/><br/>Strong work ethic: The innate drive to do work extremely well.<br/><br/>Passion: A drive to deliver better products and services than expected to customers.<br/><br/><strong>Required Qualifications<br/><br/></strong>2+ years of programming experience in languages such as Python, Java, SQL<br/><br/>2+ years of experience with ETL tools and database management (relational, non-relational)<br/><br/>2+ years of experience in data modeling techniques and tools to design efficient scalable data structures<br/><br/>Skills in data quality assessment, data cleansing, and data validation<br/><br/><strong>Preferred Qualifications<br/><br/></strong>Knowledge of big data technologies and cloud platforms<br/><br/>Experience with technologies like PySpark, Data Bricks, and Azure Synapse.<br/><br/><strong>Education<br/><br/></strong>Bachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience<br/><br/><strong>Why join VPNforAndroid?<br/><br/></strong>VPNforAndroid isn't just a company; it's a mission to democratize online privacy and security. Join our passionate team and make a real impact on millions of users worldwide. We offer a thrilling blend of cutting-edge VPN technology, a collaborative environment, and the chance to shape the future of online freedom.<br/><br/>Become part of a dynamic team driven by innovation and a shared passion. We push boundaries with the latest tools and techniques, constantly evolving to stay ahead of the curve. And while we're serious about our mission, we don't take ourselves too seriously. We believe in a fun and supportive culture where collaboration thrives and laughter rings out (even virtually!).<br/><br/>Beyond the perks like competitive compensation, comprehensive benefits, and flexible work arrangements, what truly sets us apart is the opportunity to grow alongside a company on the rise. We invest in our people, providing ample chances to learn, hone your skills, and advance your career.<br/><br/>Ready to make a difference in a fun, fast-paced environment? Dive into the world of VPNforAndroid and let's redefine online security together. We can't wait to hear from you!<br/><br/>
</div>",$55- $65,Data Integration Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765471243,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Analyst,Accroid Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788130081,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Sr/Engineer-Data Science & Analytics - 90261266 - Philadelphia,Amtrak,12/19/2023,https://www.linkedin.com/jobs/view/3784453205,0,https://media.licdn.com/dms/image/C4D0BAQFFA5eXL3C_Bw/company-logo_100_100/0/1630519023586/amtrak_logo?e=2147483647&v=beta&t=KJai3kunau8ncxW5qOX4HXYZRHXSVzTb7YROjNsSGI8,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Your success is a train ride away!<br/><br/></strong>As we move America’s workforce toward the future, Amtrak connects businesses and communities across the country. We employ more than 20,000 diverse, energetic professionals in a variety of career fields throughout the United States. The safety of our passengers, our employees, the public and our operating environment is our priority, and the success of our railroad is due to our employees.<br/><br/><strong>Are you ready to join our team?<br/><br/></strong>Our values of ‘Do the Right Thing, Excel Together and Put Customers First’ are at the heart of what matters most to us, and our Core Capabilities, ‘Building Trust, Accountability, Effective Communication, Customer Focus, and Proactive Safety &amp; Security’ are what every employee needs to know and do to be most impactful at Amtrak. By living the Amtrak values, focusing on our capabilities, and actively embracing and fostering diverse ideas, backgrounds, and perspectives, together we will honor our past and make Amtrak a company of the future.<br/><br/><strong> This position is a tiered position. Incumbents will have a position level assigned based on their skills and experience, and in alignment with position development plans. Position placement is at Amtrak’s sole and absolute discretion. <br/><br/></strong><strong>Summary Of Duties<br/><br/></strong>The Engineer Data Science &amp; Analytics is responsible for data storage, processing, and analysis to provide information for the development of data-driven scopes of work for maintenance activities. This role will be responsible for collaborating with colleagues in the Research, Analytics &amp; Test Group and other key stakeholders to develop new tools for the visualization and analysis of infrastructure condition data.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li>Develop and implement graphical display and analytical software used by the Engineering Department for condition monitoring, work planning, and degradation analysis.</li><li>Collaborate with Senior Engineer Data Management &amp; Analytics to expand database and analysis capabilities of AssetWise software. </li><li>Collaborate with Manager Engineering Track Geometry Improvements to analyze curve data and develop recommendations for curve modifications.</li><li>Collaborate with Research &amp; Development Group to research and assess new software tools for data analysis. </li><li>Assist in providing technical, logistical, and administrative support to ensure the successful completion of assigned project tasks within scope, schedule and budget. </li><li>May be called upon to assist in inspections utilizing track geometry and catenary measurement cars.</li><li>May be called upon to assist in field inspections.<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>Bachelor of Science Degree in Civil/Transportation/Mechanical/Computer Engineering, or equivalent work experience and training in position of similar capacity.</li><li>Must be able to interface with all levels of employees and both external and internal customers.</li><li>Must be skilled and experienced with MS Office, creating spreadsheets, presentations, memorandums, and utilizing other applications to perform job functions.</li><li>Demonstrated effective communication skills both written and verbal.</li><li>Must become qualified in Roadway Worker Protection, AMT-2, NORAC/GCOR operating rules, and MW100 and maintain these qualifications.</li><li>Ability to learn and understand the use of software such as Matlab, Python, Bentley AssetWise, GeoDrive, PowerBI, Survey123, ArcGIS, ESRI, and Bentley Microstation.<br/><br/></li></ul><strong>MIMINUM KSA (Knowledge, Skills, And Abilities)<br/><br/></strong><ul><li>Must have excellent communication skills, both verbal and written</li><li>Understands how to collaborate with various work groups<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>3-6 years of relevant experience preferred </li><li>Familiarity with Matlab and/or Python coding languages </li><li>Experience with railroad construction, design, and maintenance</li><li>Experience with railroad operations<br/><br/></li></ul><strong>Work Environment<br/><br/></strong><ul><li>Up to 10% travel<br/><br/></li></ul><strong>Communications And Interpersonal Skills<br/><br/></strong>Must have excellent oral and written communication skills.<br/><br/>The salary/hourly range is $86,500 - $111,996 for the Engineer position and $103,700 - $134,460 for the Sr Engineer position. Pay is based on several factors including but not limited to education, work experience, certifications, internal equity, etc. Depending on an employee’s assigned worksite or location, Amtrak may consider a geo-pay differential to be applied to the employee’s base salary. Amtrak may offer additional incentive and pay programs to recognize and reward our employees, including a short-term incentive bonus based upon factors such as individual and company performance that is commensurate with the level of the position and/or long-term incentive plan compensation. In addition to your salary, Amtrak offers a comprehensive benefit package that includes health, dental, and vision plans; health savings accounts; wellness programs; flexible spending accounts; 401K retirement plan with employer match; life insurance; short and long term disability insurance; paid time off; back-up care; adoption assistance; surrogacy assistance; reimbursement of education expenses; Public Service Loan Forgiveness eligibility; Railroad Retirement sickness and retirement benefits; and rail pass privileges. Learn more about our benefits offerings here .<br/><br/><strong>Requisition ID:</strong>160551<br/><br/><strong>Posting Location(s):</strong>Pennsylvania<br/><br/><strong>Job Family/Function:</strong>Engineering<br/><br/><strong>Relocation Offered:</strong>Yes<br/><br/><strong>Travel Requirements:</strong>Up to 25%<br/><br/><strong>You power our progress through your performance.<br/><br/></strong>We want your work at Amtrak to be more than a job. We want your career at Amtrak to be a fulfilling experience where you find challenging work, rewarding opportunities, respect among colleagues, and attractive compensation. Amtrak maintains a culture that values high performance and recognizes individual employee contributions.<br/><br/>Amtrak is committed to a safe workplace free of drugs and alcohol. All Amtrak positions requires a pre-employment background check that includes prior employment verification, a criminal history check and a pre-employment drug screen.<br/><br/>Candidates who test positive for marijuana will be disqualified, regardless of any state or local statute, ordinance, regulation, or other law that legalizes or decriminalizes the use or possession of marijuana, whether for medical, recreational, or other use. Amtrak's pre-employment drug testing program is administered in accordance with DOT regulations and applicable law.<br/><br/>In accordance with DOT regulations (49 CFR<br/><br/><ul><li>40.25), Amtrak is required to obtain prior drug and alcohol testing records for applicants/employees intending to perform safety-sensitive duties for covered Department of Transportation positions. If an applicant/employee refuses to provide written consent for Amtrak to obtain these records, the individual will not be permitted to perform safety-sensitive functions.<br/><br/></li></ul>In accordance with federal law governing security checks of covered individuals for providers of public transportation (Title 6 U.S.C.<br/><br/><ul><li>1143), Amtrak is required to screen applicants for any permanent or interim disqualifying criminal offenses.<br/><br/></li></ul>Note that any education requirement listed above may be deemed satisfied if you have an equivalent combination of education, training and experience.<br/><br/>Amtrak is an EOE/Affirmative Action Minority/Female employer, and we welcome all to apply. We consider candidates regardless of race/color, religion, sex (including pregnancy, childbirth and related conditions), national origin/ethnicity, age, disability (intellectual, mental and physical), veteran status, marital status, ancestry, sexual orientation, gender identity and gender expression, genetic information, citizenship or any other personal characteristics protected by law.<br/><br/>
</div>",$86500- $111996,Data Integration Engineer
Data Engineer,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3790367661,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer,Hyperloop Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3788678577,0,https://media.licdn.com/dms/image/D4E0BAQE5-wtGV9fWBQ/company-logo_100_100/0/1683619007636/hyperlooprecruitment_logo?e=2147483647&v=beta&t=4GRFib2T7ZuyTWESWmNt0g2NBzu40ZTgn23wPDBKEO8,"North Wales, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Data Engineer/Science<br/><br/></strong><strong>Circa 70k<br/><br/></strong><strong>North Wales<br/><br/></strong><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>The Client<br/><br/></strong>We’re representing a multi-billion pound Data Analytics and Software house who’re experience a period of high growth. They’re revolutionising their channel bringing new insights to their tracking software and work with the main players in global performance.<br/><br/>The role sits in the R&amp;D channel and at the crossover of software, hardware, data science and AI. You’ll help come up with new solutions to hard problems, create novel products and support the dev team in building and maintaining core software.<br/><br/>We’re looking for a hybrid Data Science/Engineer to join the team as their first specialist Data employee to leverage the extensive data volume we harvest<br/><br/><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>The Role<br/><br/></strong>As the companies first Data Specialist you’ll be confident working autonomously and help shape the companies Data profile. The role offers the chance to really shape the long term direction of the Data Dept with your decision making influential to the companies plans to scale<br/><br/><strong>Requirements<br/><br/></strong><ul><li>Strong coding skills, Python, Java </li><li>AWS experience</li><li>Ability to create data pipelines and storage in AWS</li><li>Ability to analyse large data sets and present findings</li><li>(nice to have) AI skills<br/><br/></li></ul><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>Benefits<br/><br/></strong><ul><li>Competitive salary, contributory pension scheme</li><li>Hybrid working.</li><li>International travel available</li><li>20% bonus scheme</li><li>Electric Vehicle Salary Sacrifice scheme (after 6 months of joining)<br/><br/></li></ul><strong>AWS - Python - AI - CICD</strong>
</div>",No Salary Info Found,Data Integration Engineer
Lead Data Engineer (FinOps),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788644595,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Analyst / Software Developer - Remote | WFH,Get It Recruit - Information Technology,12/20/2023,https://www.linkedin.com/jobs/view/3785023314,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"Fort Washington, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a reputable consulting firm based in Pennsylvania, is actively seeking dynamic individuals to join our team. We specialize in providing innovative Information Technology (IT) and Consulting services to FDA-regulated life sciences companies, focusing on program/project management, process analysis, automated business process improvements, data analytics, and implementation of IT solutions.<br/><br/><strong>Job Responsibilities<br/><br/></strong>As a Business/Data Analyst and Software Developer at QSE7, you will play a pivotal role in delivering exceptional services to our pharmaceutical, consumer healthcare, and medical device clients. Your responsibilities will include:<br/><br/>Assessing and enhancing key quality and compliance business processes.<br/><br/>Facilitating cross-functional ideation and voice-of-customer (VOC) sessions to identify improvement opportunities.<br/><br/>Analyzing current-state data and designing future-state data models.<br/><br/>Automating business processes using Microsoft SharePoint, Power Apps, and Power Automate.<br/><br/>Developing sophisticated data analytics reports with Microsoft BI and Tableau.<br/><br/>Analyzing data to identify trends and recommending proactive solutions.<br/><br/>Providing project management services, including documentation, risk mitigation, and status communication.<br/><br/>Collaborating with cross-functional teams to ensure timely issue resolution.<br/><br/><strong>Qualifications / Experience<br/><br/></strong>B.A. or B.S. degree required.<br/><br/>Deep technical expertise in Microsoft Excel, SharePoint, PowerApps, Power Automate, and Power BI; VBA programming skills a plus.<br/><br/>3-to-5 years of professional work experience; experience in the life sciences or other federally regulated industry is a significant plus.<br/><br/>Quantitative data analysis experience.<br/><br/>Excellent verbal and written communication skills.<br/><br/>Leadership and motivation skills.<br/><br/>Ability to work independently and collaboratively in a problem-solving environment.<br/><br/>Efficient provision of consulting services from a remote home office.<br/><br/><strong>About QSE7<br/><br/></strong>Founded in 2016, our company is dedicated to offering intuitive and high-quality IT and Consulting services to FDA-regulated life sciences companies. Our commitment lies in bringing automation and efficiency to our clients' processes through comprehensive solutions based on Microsoft technologies, including Excel, MS Teams, SharePoint, Power BI, and Power Automate.<br/><br/>Join our team and be part of an organization that values innovation, collaboration, and excellence. Apply now to contribute your skills and expertise to our mission of enhancing efficiency in the life sciences industry.<br/><br/>Employment Type: Full-Time
      </div>",No Salary Info Found,Data Integration Engineer
Lead Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788695810,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Integration Engineer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791621839,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Join our growing Engineering team!<br/><br/></strong>This Jobot Job is hosted by Mike Duffy<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $100,000 - $140,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>We are rapidly growing equipment finance company with over 25 years in business!<br/><br/>The Data Engineer will be responsible for building data-driven analytics tools that are used across the entire organization to improve decision making.<br/><br/>The Data Engineer should have 3+ years of experience with Python, ETL, and SQL<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Excellent pay &amp; benefits!</li><li> 100% remote flexibility!</li><li> Room for growth!</li><li> Outstanding company culture!<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.</li><li> Has demonstrated proficiency in designing and developing data marts in Snowflake schema.</li><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL Server, NoSQL, Kafka using AWS or AZURE Big Data technologies.</li><li> Use troubleshooting skills to identify and correct root cause of workflow failures based on error log outputs and environmental conditions.</li><li> Use SQL to examine, filter, and aggregate data in Microsoft SQL Server.</li><li> Experience working with data transformation processing.</li><li> Anticipate, identify, and solve issues concerning data management to improve data quality.</li><li> Experience working with Microsoft BI and Microsoft SQL server.</li><li> Perform POCs on new technology, architecture patterns.</li><li> Must have Experience with at least one Columnar MPP Cloud data warehouse (Snowflake /Azure Synapse / Redshift)</li><li> Design of complex physical data models, projects and cloud-based data lake constructs including SQL/NoSQL database systems. Leads the creation of integrated data views based on business or analytics requirements.</li><li> Design, implement, and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems and business requirements.</li><li> Experience in ETL tools like DBT is nice to have.</li><li> Experience with version control and DevOps platforms such as AZURE DevOps, GitHub, GitLab</li><li> Experience with CI/CD Pipelines and SDLC best practices.</li><li> Experience using Agile methods and project management tools like Jira preferred.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Software Engineering, Information Technology, or a related field.</li><li> Minimum of 3 years of experience in a data engineer or similar role.</li><li> Strong knowledge of Python, ETL, SQL, data integration, and data pipelines.</li><li> Experience with data architecture, data modeling, schema design, and software development.</li><li> Proficiency in data migration, transformation, and scripting.</li><li> Familiarity with machine learning models and their data needs.</li><li> Understanding of distributed systems as it pertains to data storage and computing.</li><li> Strong project management and organizational skills.</li><li> Ability to analyze problems and strategize for better solutions.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$100000- $140000,Big Data Engineer
Senior Data Engineer (GCP Platform) (R-15496),Dun & Bradstreet,12/20/2023,https://www.linkedin.com/jobs/view/3785602179,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Big Data Engineer,Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3767948511,0,https://media.licdn.com/dms/image/C4D0BAQFPP1NRP4F5dQ/company-logo_100_100/0/1656657978597/tata_consultancy_services_logo?e=2147483647&v=beta&t=Ao4Ihtw2eg1ymYGPB7E4AEHoNQ83oX6bP1DrQIiqR1s,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<ul><li>Having 10 years of professional experience fields of software Analysis, Design, Development, Deployment and Maintenance of software and Big Data applications. </li><li> Experience in Big data Implementation with strong experience on major components of Iceberg, Tableau, Kafka, Superset, Druid, Hive metastore, apache, ranger, security, AWS </li><li> Experience in creating iceberg tables and loading the data from different file formats. </li><li> Good Experience in Data importing and exporting to Hive and HDFS with Sqoop. </li><li> Experience in using Producer and Consumer API’s of Apache Kafka. </li><li> Skilled in integrating Kafka with Spark streaming for faster data processin g. </li><li> Experience in using Spark Streaming programming model for Real-time data processing. </li><li> Experience dealing with the file formats like text files, Sequence files, JSON, Parquet, ORC. </li><li> Extensively used Apache Kafka to collect the logs and error messages across the cluster. </li><li> Excellent knowledge and understanding of Distributed Computing and Parallel processing frameworks. </li><li>Experienced with Analytics with Hive Megastore.</li><li> Experience with Superset, Druid. </li><li> Experience working with EC2 (Elastic Compute Cloud) cluster instances, setup data buckets on S3 (Simple Storage Service), setting up EMR (Elastic MapReduce). </li><li> Good experience working on Tableau and enabled the JDBC/ODBC data connectivity from those to Hive Metastore. </li><li> Good with version control systems like GIT. </li><li> Strong knowledge on UNIX/LINUX commands. </li><li> Adequate Knowledge on Python scripting Language. </li><li> Adequate knowledge of Scrum, Agile and Waterfall methodologies. </li><li> Highly motivated and committed to the highest levels of professionalism. </li><li> Exhibited strong written and oral communication skills. Rapidly learn and adapt quickly to emerging new technologies and paradigms.</li></ul>
</div>",No Salary Info Found,Big Data Engineer
"Senior Software Engineer, Data Solutions-Dallas, Austin, or San Antonio, TX",H-E-B,12/19/2023,https://www.linkedin.com/jobs/view/3483760921,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer,Braintrust,12/19/2023,https://www.linkedin.com/jobs/view/3789766635,0,https://media.licdn.com/dms/image/C560BAQHbQYFSQsK__A/company-logo_100_100/0/1630511738029/usebraintrust_logo?e=2147483647&v=beta&t=KwbYjG0MdxQVYAijRBYsSuBn-w2onHZNpCmM31LViso,"Austin, Texas Metropolitan Area","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality.<br/><br/><strong>About The Hiring Process<br/><br/></strong>The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match.<br/><br/>Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies.<br/><br/><strong>JOB TYPE:</strong> Direct Hire/ FTE Position (no agencies/C2C - see notes below)<br/><br/><strong>LOCATION:</strong> Work from anywhere - Anytime | No timezone overlap required<br/><br/><strong>SALARY RANGE</strong> $110,000 – $130,000 /yr<br/><br/><strong>ESTIMATED DURATION:</strong> 40/week - long term<br/><br/><strong>EXPERIENCE:</strong> 3-4 years<br/><br/><strong>BRAINTRUST JOB ID:</strong> 11526<br/><br/>The Opportunity<br/><br/><strong>Required Skills<br/><br/></strong><ul><li> T-SQL (DDL, Stored Proces, Views, CTEs, etc) </li><li> VCS (Git, SVN, etc) <br/><br/></li></ul><strong>Bonus Skills<br/><br/></strong><ul><li> Candidates with a CPA/CFA or other financial services background are preferred. </li><li> Candidates who understand web technologies and can program in other languages in addition to SQL will be preferred. JavaScript/ES6/NodeJS preferred. </li><li> VS Code, SSMS, and other IDEs. </li><li> CI/CD experience with integrating database changes into deployment models. <br/><br/></li></ul>What You'll Be Working On<br/><br/><ul><li>This is a FTE position and is only open to US-based candidates**<br/><br/></li></ul>InvestEdge is seeking a database specialist with expert knowledge in relational data modeling, querying, and data analysis.<br/><br/>This role requires expert knowledge of working with MSSQL and Postgres databases, and can write complex queries, stored procedures, and views.<br/><br/><strong>The Candidate<br/><br/></strong><ul><li> has likely worked as a senior data developer or data architect role, and also understands database administration concepts such as indexing strategies, backup and fault-tolerance strategies, and how to organize and secure data at rest. </li><li> have a background in financial services and understand how financial markets work. </li><li> Has a CPA/CFA with the ability to write advanced SQL should be a shoe-in. <br/><br/></li></ul>This role will work with InvestEdge's senior data architect to implement new solutions as well as improve existing ones. Also, the role will be working with large data sets and large database footprints and should understand concepts such as performance tuning, SQL Injection, and data security best practices.<br/><br/>In addition to an emphasis on data manipulation and storage, the candidate will also work on other aspects of the application including UX and middle-tier concerns relating to the presentation, use, and manipulation of data. The ideal candidate is a well-rounded developer that is comfortable in any layer of the application, even as their focus is data and the persistence of that data.<br/><br/><strong>Roles And Responsibilities<br/><br/></strong><ul><li> Work with the senior data architect to implement data routines in a financial services environment. </li><li> Create new queries, views, and stored procedures for a large existing relational data set. </li><li> Debug and troubleshoot logical issues in database code. </li><li> Debug and troubleshoot performance issues in database code. </li><li> Serve as a subject matter expert on a large in-house enterprise database model. </li><li> Understand the business domain of the application. </li><li> Work in an Agile environment on a cross-functional team. <br/><br/></li></ul><strong>Apply Now!<br/><br/></strong><strong>Notes<br/><br/></strong>Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.<br/><br/>Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
      </div>",$110000- $130000,Big Data Engineer
"Data Engineer with Python, Kube, Big Data, AlgoCD and AirFlow",Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3767919413,0,https://media.licdn.com/dms/image/C4D0BAQFPP1NRP4F5dQ/company-logo_100_100/0/1656657978597/tata_consultancy_services_logo?e=2147483647&v=beta&t=Ao4Ihtw2eg1ymYGPB7E4AEHoNQ83oX6bP1DrQIiqR1s,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<ul><li>Experience in monitoring and troubleshooting large scale data platforms, data pipelines, complex backend services</li><li> Able to effectively communicate incidents, coordinate incident responses, document/manage runbooks, set up processes to support other software engineering teams and data analysts</li><li> Experience in managing large datasets</li><li> Experience in creating Kubernetes configurations, managing services in Kubernetes, building docker images</li><li> Demonstrate good understanding &amp; troubleshooting Spark jobs</li><li> Experience in developing/maintaining automation tools in programming/scripting languages like Python</li><li> Demonstrate good understanding in Big data eco-systems such as HDFS, Kafka, SQL etc.</li><li> Experience in using IT automation tools such as AlgoCD, and job orchestrator systems such as AirFlow, Jenkins</li><li> Experience in cloud based environment (AWS/GCP etc.) is a big plus.</li><li> Experience in monitoring tools such as Splunk, Prometheus/Grafana is a big plus.</li><li> Experience with Full-Stack web development (React, Django etc.) is a big plus.<br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li> Support large scale data pipelines and backend services by monitoring and troubleshooting/recovering incidents</li><li> Manage large volume datasets in Spark and Hadoop environments using scripts and automation</li><li> Build and operate data management infra services</li><li> Automate build, deployment, and monitoring</li><li> Participate at an onCall &amp; release turn</li><li> Taking an oncall turn including weekend coverage<br/><br/></li></ul>
</div>",No Salary Info Found,Big Data Engineer
Associate Analytics Engineer,NexusLeap,12/19/2023,https://www.linkedin.com/jobs/view/3784428116,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer,Visa,12/19/2023,https://www.linkedin.com/jobs/view/3790090038,0,https://media.licdn.com/dms/image/C560BAQEP8_eM4zW8bw/company-logo_100_100/0/1630663392691/visa_logo?e=2147483647&v=beta&t=TzxC8Eby4Etg1Y4aK9Ul8pUVAccJ4Do5GJP4uVtlOBY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.<br/><br/>When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.<br/><br/><strong>Join Visa: A Network Working for Everyone.<br/><br/></strong><strong>Job Description<br/><br/></strong>Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area.<br/><br/>Visa AI as a Service (VAIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, VAIaS automates the updates to data, models, and applications. Combined with strong AI governance, VAIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!<br/><br/>This position is for a Data Engineer with solid development experience who will focus on creating new capabilities for Visa AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.<br/><br/>You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.<br/><br/>This position will be based in Austin, TX. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li> Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions</li><li> Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards</li><li> Responsibilities span all phases of solution development including:</li><li> Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved</li><li> Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner<br/><br/></li></ul>This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.<br/><br/><strong>Qualifications<br/><br/></strong>Basic Qualifications:<br/><br/><ul><li> Bachelors degree, OR 3+ years of relevant work experience<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li> 2 or more years of work experience</li><li> Exposure to leading-edge areas such as Machine Learning, Big Data, Distributed Systems or SRE. </li><li> Experience in at least one of the following: Golang, Java, or C/C++, Spark</li><li> Familiarity with web service standards and related patterns (REST, gRPC)</li><li> Experience implementing solutions for low-latency, distributed services using open standard technologies. <br/><br/></li></ul><strong>Additional Information<br/><br/></strong><strong>Work Hours:</strong> Varies upon the needs of the department.<br/><br/><strong>Travel Requirements:</strong> This position requires travel 5-10% of the time.<br/><br/><strong>Mental/Physical Requirements:</strong> This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.<br/><br/>Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.<br/><br/>Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.<br/><br/><strong>U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 89,600.00 to 114,300.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.</strong>
</div>",No Salary Info Found,Big Data Engineer
"Senior Software Engineer, Data Science Platform",NVIDIA,12/19/2023,https://www.linkedin.com/jobs/view/3789792672,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer,AtkinsRéalis,12/20/2023,https://www.linkedin.com/jobs/view/3785085485,0,https://media.licdn.com/dms/image/D4E0BAQENGaGvdO3TOw/company-logo_100_100/0/1695059107065/atkinsrealis_logo?e=2147483647&v=beta&t=97_WWS0g7kyFfGgXfDApNXY-v0y8Brbx7XxsaTAebUE,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Why join us? <br/><br/></strong>We are hiring! The <strong>Data Engineer</strong> is an integral part of our Community &amp; Intermodal Infrastructure Mountain Team. This is an entry-level position and is based out of <strong>Austin, TX</strong>.<br/><br/><strong>About Us<br/><br/></strong>AtkinsRéalis is one of the world’s most respected design, engineering and project management consultancies. AtkinsRéalis has been providing infrastructure planning, engineering, construction, environmental consulting, urban planning, architecture, and program management services to public and private clients across the United States for more than 50 years. AtkinsRéalis has the depth and breadth of expertise to respond to the most technically challenging and time-critical infrastructure projects and the urgent transition to a low-carbon economy.<br/><br/><strong>How will you contribute to the team?<br/><br/></strong><ul><li>Adept analytic skills including knowledge of MS Excel, PowerBI and other business analysis and intelligence software</li><li>Strong written communication skills including prior experience in MS Word and MS PowerPoint</li><li>Strong verbal communication skills</li><li>Focus on customer service<br/><br/></li></ul><strong>What will you contribute? <br/><br/></strong><ul><li>EXPERIENCE: Business analytics from one or more prior internships; basic understanding of engineering practices such as CAD</li><li>EDUCATION: Bachelor of Science in Engineering</li><li>SPECIAL SKILLS: MS Excel, PowerBI, PowerPoint</li><li>PROFESSIONAL REGISTRATIONS: None required<br/><br/></li></ul><strong>What We Offer At AtkinsRéalis<br/><br/></strong>As an Intern, you will enjoy a host of developmental benefits which includes:<br/><br/><ul><li>Competitive salary</li><li>Hands-on experience with industry leaders</li><li>Support and mentorship from various professionals throughout the business</li><li>Career and educational exploration opportunities such as Client Site Visits, Weekly Lunch &amp; Learns, &amp; various virtual and/or in-person activities<br/><br/></li></ul>As a Full-Time employee, you may enjoy a robust rewards package which includes:<br/><br/><ul><li>Opportunity to work on various projects of various sizes</li><li>Competitive salary</li><li>Flexible work schedules</li><li>Group Insurance</li><li>Retirement Savings Plan with employer match</li><li>Employee Assistance Program (EAP)</li><li>Learning and development programs, training, career opportunities and a highly regarded tuition reimbursement program<br/><br/></li></ul><strong>Expected compensation range is between $70,000 - $78,000 annually/hourly depending on skills, experience, and geographical location. <br/><br/></strong><strong>If this sounds like you and you would like to expand your career with us, apply today! <br/><br/></strong>AtkinsRéalis Is An Equal Opportunity, Drug-free Employer Committed To Diversity In The Workplace. EOE/Minorities/Females/Vet/Disability. Please Review AtkinsRéalis Equal Opportunity Statement Here<br/><br/>https://careers.atkinsrealis.com/equal-opportunities-statement<br/><br/>Upon acceptance of an offer, all candidates must go through a drug screen test and background check. AtkinsRéalis is a federal contractor which mandates a satisfactory background screening report and drug test that supersedes state laws.<br/><br/><strong>AtkinsRéalis cares about your privacy</strong> and are committed to protecting your privacy. Please consult our Privacy Notice on our Careers site to know more about how we collect, use and transfer your Personal Data. By submitting your personal information to AtkinsRéalis, you confirm that you have read and accept our Privacy Notice.<br/><br/><strong>Note To Staffing And Direct Hire Agencies<br/><br/></strong>In the event a recruiter or agency who is not on our preferred supplier list submits a resume/candidate to anyone in the company, AtkinsRéalis family of companies, we explicitly reserve the right to recruit and hire the candidate(s) at our discretion and without any financial obligation to the recruiter or agency. https://careers.atkinsrealis.com/recruitment-agencies<br/><br/>#URR222
      </div>",$70000- $78000,Big Data Engineer
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791628110,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Python Data Engineer,Synechron,12/20/2023,https://www.linkedin.com/jobs/view/3788676786,0,https://media.licdn.com/dms/image/C4D0BAQF-kdmTYpOKFg/company-logo_100_100/0/1663673608492/synechron_logo?e=2147483647&v=beta&t=srG-HyAPgRmdiRELy-32e05tZFPYByEm48tZ92tcIg4,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><u>Role:</u></strong> Python Data Engineer</p><p><strong><u>Work Location</u>: </strong>New York, New York, United States</p><p><strong><u>Contact</u>:</strong> Sachin.s@synechron.com</p><p><br/></p><p><strong><u>Our Challenge:</u></strong></p><p>We are looking for strong Python Developer with strong background in data engineering and integration experience.</p><p><br/></p><p><strong><u>The Role</u></strong></p><p><strong><u>Responsibilities:</u></strong></p><ul><li>Integration Engineer responsible for daily support and project-based development of credit risk management systems.</li><li>ETL developers are responsible for designing and creating the data warehouse and all related extraction, transformation and load of data functions.</li><li>This is an opportunity to gain experience in risk management processing using new technologies.</li></ul><p><br/></p><p><strong><u>Requirements:</u></strong></p><p><strong><u>You are:</u></strong></p><ul><li>5+ years of full-time development experience using Python.</li><li>Experience building data pipelines using Azure Data Factory and Databricks.</li><li>Experience with Python application frameworks (Django, Flask, Pyramid, Tornado).</li><li>Experience with Python testing and code analysis tools (Pytest, Pylint).</li><li>Strong SQL skills.</li><li>Familiarity with SSIS.</li><li>Strong troubleshooting skills.</li><li>On-point communication skills.</li></ul><p><br/></p><p><strong><u>Education:</u></strong></p><ul><li>Bachelor’s degree in computer science or finance.</li></ul><p><br/></p><p><strong><u>We can offer you:</u></strong></p><ul><li>A highly competitive compensation and benefits package</li><li>A multinational organization with 45 offices in 19 countries and the possibility to work abroad.</li><li>Laptop and a mobile phone</li><li>10 days of paid annual leave (plus sick leave and national holidays)</li><li>Maternity &amp; Paternity leave plans</li><li>A comprehensive insurance plan including medical, dental, vision, life insurance, and long-/short-term disability (plans vary by region)</li><li>Retirement savings plans</li><li>A higher education certification policy</li><li>Commuter benefits (varies by region)</li><li>Extensive training opportunities, focused on skills, substantive knowledge, and personal development.</li><li>On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses</li><li>Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups</li><li>Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms.</li><li>A flat and approachable organization</li><li>A truly diverse, fun-loving and global work culture</li></ul><p><br/></p><p><strong><u>SYNECHRON’S DIVERSITY &amp; INCLUSION STATEMENT</u></strong></p><p>Diversity &amp; Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.</p>
</div>",No Salary Info Found,Big Data Engineer
Cloud Data Engineer,Talener,12/19/2023,https://www.linkedin.com/jobs/view/3748836564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
"Staff Data Engineer, Data Products (Contract)",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3759870591,0,https://media.licdn.com/dms/image/C560BAQH0xjWQVXJr6w/company-logo_100_100/0/1630660955481/sofi_logo?e=2147483647&v=beta&t=FVZG0dNVAhdZ-W3Op_NDxjxwWCaIzunudLIIydaqJQI,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Employee Applicant Privacy Notice<br/><br/></strong><strong>Who we are:<br/><br/></strong>Shape a brighter financial future with us.<br/><br/>Together with our members, we’re changing the way people think about and interact with personal finance.<br/><br/>We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. <strong>Join us to invest in yourself, your career, and the financial world.<br/><br/></strong><strong>Team: <br/><br/></strong>SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.<br/><br/><strong>Role:<br/><br/></strong>A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.<br/><br/><strong>What you’ll do:<br/><br/><br/></strong><ul><li>Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.</li><li>Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,</li><li>Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.<br/><br/><br/></li></ul><strong>What you’ll need:<br/><br/><br/></strong><ul><li>A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;</li><li>Over 8 years of experience in data engineering and analytics technical strategy. </li><li>Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..</li><li>Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP</li><li>Strong in Python and/or another data centric language. </li><li>Thorough knowledge of data modeling, database design, data architecture principles, and data operations.</li><li>Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.</li><li>Experience in the Fintech industry is advantageous.<br/><br/><br/></li></ul><em><strong>Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.<br/><br/></strong></em><strong>Compensation And Benefits<br/><br/></strong>The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.<br/><br/>To view all of our comprehensive and competitive benefits, visit our <strong>Benefits at SoFi </strong>page!<br/><br/>SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.<br/><br/>The Company hires the best qualified candidate for the job, without regard to protected characteristics.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.<br/><br/>New York applicants: Notice of Employee Rights<br/><br/>SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.<br/><br/>Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.<br/><br/><strong>Internal Employees<br/><br/></strong>If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.
      </div>",No Salary Info Found,Big Data Engineer
Cloud Data Engineer - Hadoop / Snowflake / Azure,M&T Bank,12/19/2023,https://www.linkedin.com/jobs/view/3660638420,0,https://media.licdn.com/dms/image/C4D0BAQFdBokFRoHX4g/company-logo_100_100/0/1631340952916?e=2147483647&v=beta&t=ZDBu1XKQVJspTTO9al1GBSiDfG_fWy-aQlg0RX9Er4I,"Buffalo, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><em>This role </em><em>follows </em><em>a hybrid work schedule; offering the flexibility to work remotely two days a week, while providing the opportunity for onsite and in person collaboration the other three days.<br/></em></strong><ul><li>This position is available in either Buffalo, NY or Wilmington, DE**<br/><br/></li></ul><strong>About The Team<br/><br/></strong>Our team is on a mission of unleashing the power of data to support decision making. Our team builds enduring data products, provides platforms to access &amp; derive insights from data, enables confidence in decision making with appropriate data governance, delivers actionable insights through use of data science and activates value for the business by innovatively solving problems with data. We love translating data, insights, and anecdotes into action, we operate with a sense of urgency, have a startup mentality, build data analytic products at scale, and innovate solutions on behalf of our customers. We work hard but value the need for downtime to unplug and recharge. We embrace our differences and view them as a key driver of innovation. We are Data@M&amp;T<br/><br/><strong>Role Overview: <br/><br/></strong>This team transforms data assets into business insights by delivering information for consumption thru the building of data pipelines that contain Data processing, Data Enrichment, Data Storage, Data Provisioning/Consumption, Data Archival, Data Quality, Data Lineage, Data Security, and other related capabilities.<br/><br/>As part of the Finance Domain, the role focuses on supporting Profitability and Regulatory Reporting.<br/><br/><strong>Area(s) of Focus: All Success with Rely on Cross Group Communication and Planning<br/></strong><ul><li>Improve Cross Domain Solutions: Reduce duplicated solutions and cost while improving cross domain communication and collaboration.</li><li>Realize Business Needs: Assess future Domain needs and work closely with other groups to bring those needs to realization.</li><li>Development Efficiency: Provide business with a competitive edge by improving our speed to market and cost to deliver.</li><li>Domain Migration to Cloud: Working with the Cloud &amp; Modernization group the Domains will need to Scope, Size and Plan their Migration to Cloud.</li><li>Modernizing Code and Designs: Fully Automated Deployments for ALL changes, Improved Defensive Coding, Automated Testing, Automated Code Scanning, and More.</li><li>Enable Business Agility: Designs and Solutions focusing on enabling the business for rapid change, enabling agility while operating in control.<br/><br/></li></ul><strong>The successful candidate will have:<br/></strong><ul><li>Minimum of an Associate degree and 5 years’ systems analysis/application development experience, or in lieu of a degree, a combined minimum of 7 years’ higher education and/or work experience</li><li>Experience with Agile Methodology</li><li>An ability to build out data products &amp; product enhancements from idea through to launch</li><li>Strong collaboration with technology partners and customers on feature requirements and prioritization</li><li>A team player mindset with an ability to thrive and effectively communicate in a fast-paced, constantly evolving environment<br/><br/></li></ul><strong>Tech Stack:<br/></strong><ul><li>Snowflake on Azure</li><li>Hadoop</li><li>Informatica</li><li>Automic</li><li>Unix shell scripting</li><li>SQL</li><li>Python<br/><br/></li></ul><strong>Required Technology Skills<br/></strong><ul><li>In-Depth Knowledge of SQL and Other Database Solutions – preferable in Hadoop</li><li>Experience in big-data technologies, such as: Hive, Impala, Kudu</li><li>Programming skillsets in at least one of these languages: Java, Scala, Python</li><li>Experience in Unix/Linux operating systems, with scripting experience</li><li>Experience in data pipeline development, monitoring, and support</li><li>Cloud computing (Azure, AWS or equivalent)</li><li>Experience in Cloud data platforms (Snowflake, Databricks) <br/><br/></li></ul><strong>Preferred Technology Skills<br/></strong><ul><li>Informatica (or equivalent) tools: PowerCenter, BDM, Big Data Manager, Data Quality</li><li>CA Automic or equivalent job scheduling tool experience</li><li>Realtime processing like Spark streaming, Kafka</li><li>Experience working with multiple file structures – Mainframe, Flat files, Json, XML’s<br/><br/></li></ul><strong>Preferred Other skills:<br/></strong><ul><li>Agile (such as JIRA), Source code repository (Git, Bitbucket, etc.) CI/CD tools (Jenkins, Teamcity, etc.)</li><li>Business acumen, familiarity with banking concepts</li><li>Strong analytical skills, ability to tackle nontrivial business requests<br/><br/></li></ul><strong>Company:<br/><br/></strong><strong>At M&amp;T Tech,</strong> we’re a team of makers, doers, and builders, working to create the most advanced technology solutions in banking. We’re not your stereotypical suit and tie bankers: We’re an innovative team of leading tech experts, pushing boundaries, and taking risks. We’re building an agile team of the most skilled and creative, workers to solve complex problems, architecting solutions, writing high-performance software, and charting our new path, all to make the lives of our customers, and the communities that we serve, better. Join us and be part of something new as we build tomorrow’s bank, today.<br/><br/><strong>M&amp;T Bank</strong> is a Top 20 US bank holding company and one of the best performing and financial stable regional banks in the country, we offer our technology employees a wide range of performance-based career development opportunities. We have a strong commitment to our customers and the communities we serve, and we continue to grow with a focus on the future. So, when looking to advance your career, look to M&amp;T. Grow with us.<br/><br/>Hiring Immediately.<br/><br/>We support our team members with generous benefits.<br/><ul><li>Competitive compensation</li><li>Health, welfare, and retirement benefits</li><li>401(k) match at 5%</li><li>Work-life balance and flexible work arrangements</li><li>Start with 25 days PTO plus 12 paid holidays<br/><br/></li></ul>#Cloud #Snowflake #Azure #Hadoop #BDM #DataEngineer #EDS #EnterpriseDataServices #Engineer #Data #Bigdata #SoftwareEngineer<br/><br/>#DICE<br/><br/>M&amp;T Bank is committed to fair, competitive, and market-informed pay for our employees. The pay range for this position is $90,855.45 - $151,425.75 Annual (USD). The successful candidate’s particular combination of knowledge, skills, and experience will inform their specific compensation.<br/><br/><strong>Location:<br/><br/></strong>Buffalo, New York, United States of America<br/><br/>
</div>",$90855.45- $151425.75,Big Data Engineer
"Data Engineer, Technical Lead (Python, LLM's)",McGregor Boyall,12/19/2023,https://www.linkedin.com/jobs/view/3790303994,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data and Analytics Engineer,Jetty,12/19/2023,https://www.linkedin.com/jobs/view/3788131758,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer,BeaconFire Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3788691831,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Snowflake Data Engineer,Capgemini,12/20/2023,https://www.linkedin.com/jobs/view/3785037830,0,https://media.licdn.com/dms/image/D4D0BAQH7wERIbu2fvQ/company-logo_100_100/0/1702673452642/capgemini_logo?e=2147483647&v=beta&t=NBnhHRGoBlo-42X39edX25CaIyU2ED_clduyxHli004,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Title: Snowflake Data Engineer</strong></p><p><strong>Location: New York, NY</strong></p><p><br/></p><p><strong>Required Skills</strong></p><ul><li>2 years of experience in Snowflake.</li><li>5 years of experience in software development process or maintenance projects.</li><li>At least 4 years of experience in Design and architecture review.</li><li>Hands on in complex SQL python and data modeling.</li><li>Hands on experience creating Snowflake procedures UDFs.</li><li>Relevant experience with Splunk, Azure, Event Grid, Sailpoint and IDM integration.</li><li>Hands on experience in data loading into Snowflake from diverse sources.</li><li>Experience with semi structured data type.</li><li>Experience in building Enterprise DW Data Lake Provision and administer Snowflake corporate cloud infrastructure hosted on public cloud preferably on Azure Provision and manage cloud infrastructure using Terraform Cloud Formation tools.</li><li>Strong communication and Analytical skills.</li><li>Experience working in, and desire to work in, a Global delivery environment.</li><li>Good to have experience in ETL tool.</li></ul><p><br/></p><p><strong>Life at Capgemini</strong></p><p>Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:</p><ul><li>Flexible work</li><li>Healthcare including dental, vision, mental health, and well-being programs</li><li>Financial well-being programs such as 401(k) and Employee Share Ownership Plan</li><li>Paid time off and paid holidays</li><li>Paid parental leave</li><li>Family building benefits like adoption assistance, surrogacy, and cryopreservation</li><li>Social well-being benefits like subsidized back-up child/elder care and tutoring</li><li>Mentoring, coaching and learning programs</li><li>Employee Resource Groups</li><li>Disaster Relief</li></ul><p><br/></p><p><strong>About Capgemini</strong></p><p>Capgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.</p><p>Get The Future You Want | www.capgemini.com</p><p><br/></p><p><strong>Disclaimer</strong></p><p>Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.</p><p>This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.</p><p>Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.</p><p>Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law</p><p><br/></p><p><strong><span class=""ql-cursor""> </span>Salary Transparency</strong></p><p>Capgemini discloses salary range information in compliance with state and local pay transparency obligations. The disclosed range represents the lowest to highest salary we, in good faith, believe we would pay for this role at the time of this posting, although we may ultimately pay more or less than the disclosed range, and the range may be modified in the future. The disclosed range takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to, geographic location, relevant education, qualifications, certifications, experience, skills, seniority, performance, sales or revenue-based metrics, and business or organizational needs. At Capgemini, it is not typical for an individual to be hired at or near the top of the range for their role. The base salary range for the tagged location is $80420 - $106050 /yearly.</p><p>This role may be eligible for other compensation including variable compensation, bonus, or commission. Full time regular employees are eligible for paid time off, medical/dental/vision insurance, 401(k), and any other benefits to eligible employees. </p><p>Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.</p>
</div>",$80420- $106050,Big Data Engineer
Sr Data Developer,Synechron,12/20/2023,https://www.linkedin.com/jobs/view/3788674633,0,https://media.licdn.com/dms/image/C4D0BAQF-kdmTYpOKFg/company-logo_100_100/0/1663673608492/synechron_logo?e=2147483647&v=beta&t=srG-HyAPgRmdiRELy-32e05tZFPYByEm48tZ92tcIg4,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Overview</strong></p><p>As a Data Developer, you will be responsible for supporting business intelligence and reporting initiatives. You will use your engineering skills and experience with ETL concepts to create data structures for reporting systems and develop data exchanges and integrations between various platforms. You should also be able to optimize existing and new data processes. While not required, experience within the Capital Markets/Investment Banking domain is preferred.</p><p><strong>JOB: Data Developer</strong></p><p><strong>Location: NYC NY</strong></p><p><br/></p><p><strong>Additional Information – New York Only* </strong></p><p><strong>The base salary for this position will vary based on geography and other factors. </strong></p><p><strong>In accordance with New York law, the base salary for this role if filled within New York is $125k-$145k/year &amp; benefits (see below). </strong></p><p><br/></p><p><strong>Responsibilities</strong></p><ul><li>Participate in all phases of the data solutions development lifecycle</li><li>Engage with the core data team in the design of efficient processes to load and manage data, data quality assessments to ensure that the quality of the source data will meet the information requirements, and development of business rules, data mappings, and transformation rules</li></ul><p><strong>Requirements</strong></p><p>You are:</p><ul><li>Bringing 8+ years of experience to the team (a must!)</li><li>Highly experienced in ETL concepts, data mapping &amp; transformation rules, and developing real-time, API-based data ingestion and integration solutions using leading iPaaS offerings</li><li>An expert in developing scheduled batch processes for data integration using leading ETL tools</li><li>Experienced in MDM (Master Data Management) / EDL (Enterprise Data Lake)</li><li>Very knowledgeable in SQL</li><li>Well-versed in MS SQL Server platform</li><li>Highly understanding of RDBMS concepts</li><li>Experience in developing stored procedures, functions, and scripts</li><li>Experienced in database/query performance optimization (indexing, query tuning, troubleshooting performance problems)</li><li>Experienced in data modeling/database design</li></ul><p>It would be great if you also had:</p><ul><li>Experience working with BIG data and unstructured data sources (AWS)</li><li>Experience with Databricks and Airflow</li><li>Experience with both iPaaS and on-prem ETL platforms like Mulesoft, Informatica</li><li>Familiarity with Salesforce</li><li>Experience within the Capital Markets/Investment Banking domains</li></ul><p><strong>We Can Offer You</strong></p><ul><li>A highly competitive compensation and benefits package</li><li>A multinational organization with 45 offices in 19 countries and the possibility to work abroad</li><li>Laptop and a mobile phone</li><li>10 days of paid annual leave (plus sick leave and national holidays)</li><li>Maternity &amp; Paternity leave plans</li><li>A comprehensive insurance plan including: medical, dental, vision, life insurance, and long-/short-term disability (plans vary by region)</li><li>Retirement savings plans</li><li>A higher education certification policy</li><li>Commuter benefits (varies by region)</li><li>Extensive training opportunities, focused on skills, substantive knowledge, and personal development</li><li>On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses </li><li>Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups </li><li>Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms</li><li>A flat and approachable organization</li><li>A truly diverse, fun-loving and global work culture</li></ul><p><br/></p><p><br/></p><p><strong>Diversity &amp; Inclusion</strong> are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs.</p><p>All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.</p>
</div>",$125- $145,Big Data Engineer
Senior Data Engineer,CareerAddict,12/25/2023,https://www.linkedin.com/jobs/view/3791672621,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Sr. Data Engineer,Alliant Credit Union,12/19/2023,https://www.linkedin.com/jobs/view/3772773871,0,https://media.licdn.com/dms/image/C4E0BAQHfseg71MQgig/company-logo_100_100/0/1630630417167/alliant_credit_union_logo?e=2147483647&v=beta&t=BVoF7QHB3YUkmugWVZKJgl1vS_ItSbAQe6AXYqb3qW8,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Start a Rewarding Career with Alliant <br/><br/></strong>In this role, you will provide continuous build-up and operation of an enterprise-class modern data environment, which may include various components within the Azure, Hadoop, SQL server, and Informatic stack. Works with AI/ML, LLM technologies encompassed within the cloud and on-prem data management technology stack while also having knowledge and capabilities as a systems developer. Coordinates, designs, builds, and integrates complex application technology solutions, aligned to architectural standards and definitions and ensures IT services are delivered effectively and efficiently.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Development, operation and support of modern data environments (AI/ML, LLM) such as new concepts, practices, and approaches. </li><li> Design, build, deploy and maintain data pipelines using modern data tools on batch and streaming data in relational and non-relational databases in cloud and on-prem. </li><li> Collaborate with different teams on infrastructure setup, testing, monitoring, tuning/optimizing, troubleshooting and maintenance. </li><li> Collaborate with development and strategy teams on component and software vendor services in the cloud and on-prem, recommendation, installation and management of cloud-native and on prem jobs. </li><li> Collaborate with the data teams in technical investigations, development, and prototypes and corporate IT function around integrating data management ecosystem(s) with critical enterprise systems. </li><li> Develop and manage data management testing activities and create roadmaps for ongoing data management technology and growth. </li><li> Perform capacity monitoring and capacity planning on infrastructure and cloud resources. </li><li> Manage activities through the implementation and maintenance of security and governance components across various data protocols. </li><li> Participate in the design and implementation of a disaster recovery strategy for modern data components and the alignment activities with pertinent audit and compliance activities. </li><li> Provide input and develop new processes and standards in support of the organization's business/functional short-term strategies. </li><li> Address data-related problems in regard to systems integration, compatibility, and multiple-platform integration. </li><li> Support existing data pipelines on-prem, cloud and business engineering extract. </li><li> Provide technical support to meet application service level agreements. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><strong> Education: <br/><br/></strong><ul><li> Bachelors Degree - Computer Science or Related - Minimum <br/><br/></li></ul><strong>Years Of Experience<br/><br/></strong><ul><li> 5 Years - Data warehouse, data lake, cloud technology or related - Minimum </li><li> 3 Years - AI/ML, LLM - Preferred <br/><br/></li></ul><strong>In Lieu Of Education<br/><br/></strong><ul><li> 8 years - Data warehouse, data lake, cloud technology <br/><br/></li></ul><strong>You Will Benefit From<br/><br/></strong><ul><li> Competitive medical, dental, and free vision benefits </li><li> Paid parental leave </li><li> Competitive compensation plan </li><li> Gym memberships discounts </li><li> Generous PTO and banking holidays off </li><li> Tuition reimbursement </li><li> 401k with immediate employer match and vesting <br/><br/></li></ul>Adhere to and ensure compliance of all business transactions with policy and process of the Bank Secrecy Act. Ensures compliance with all applicable state and federal laws, company procedures and policies. Maintains integrity and ethics in all actions and conversations with or regarding credit union members and their accounts; complies with Privacy Act directives.<br/><br/>The responsibilities listed do not contain a comprehensive listing of activities, duties or responsibilities that are required of the employee for this position. Duties, responsibilities and activities may change at any time with or without notice.
      </div>",No Salary Info Found,Big Data Engineer
Senior Data Engineer,StoneX Group Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3752008137,0,https://media.licdn.com/dms/image/C560BAQHNOwyGAUk1ag/company-logo_100_100/0/1670595447279/stonex_group_inc_logo?e=2147483647&v=beta&t=iufYLHptzqOLqlQMDo78FOVbORwcV2wjMMTUOF7K-N4,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>The Data Platform Team looks to raise the level and productivity of data engineering and data science by building, scaling, and supporting our big data infrastructure with an emphasis on simple and efficient solutions on top of complex distributed data stores. As a contributing senior data engineer, you will assist in architecting, designing, and implementing components within our cloud data platform expanding our data assets while continuously improving the architecture and processes around our daily operations.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Create cloud and big data technical design recommendations for developing and integrating new software and system technologies – from the physical layer through to the virtual layer – per written specifications; test, evaluate, engineer, implement and support said technologies. </li><li> Review, influence and contribute to new and evolving design, architecture, standards, and methods for operating and contributing to services within our big data ecosystem. </li><li> Add to our existing business and data models. Reviews existing designs and processes to highlight more efficient ways to complete existing workload more effectively through industry perspectives. </li><li> Drive technical innovation and efficiency in infrastructure operations through automation by assisting in improvements to continuous integration, continuous deployment and </li><li> Create cloud and big data technical design recommendations for developing and integrating new software and system technologies – from the physical layer through to the virtual layer – per written specifications; test, evaluate, engineer, implement and support those technologies </li><li> Collaborates with technical teams and utilizes system expertise to deliver technical solutions, continuously learning and evolving big data skillsets. </li><li> Monitors and evaluates overall strategic data infrastructure; tracks system efficiency and reliability; identifies and recommends efficiency improvements and mitigates operational vulnerabilities. Respond to and resolve emergent service problems. Design solutions using automation and self-repair rather than relying on alarming and human intervention <br/><br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Pursuing a Bachelor’s degree or relevant work experience in Computer Science, Mathematics, Electrical Engineering or related technical discipline. </li><li> 5-7 years experience developing software in a professional environment (preferably financial services but not required) </li><li> Exposure to Docker/Containers, microservices, distributed systems architecture, Kubernetes, and cloud computing preferably Azure. </li><li> Comfortable with core programming concepts and techniques (e.g. concurrency, memory management) </li><li> ETL tooling like Airflow and Databricks. </li><li> Experience in supporting API Gateways and building and consuming REST APIs along with other distribution technologies. </li><li> Familiarity with Financial Systems architecture/ecosystems, Real Time Market Data messaging and FIX Protocol a huge plus. </li><li> Foundational knowledge of data structures, algorithms, and designing for performance. </li><li> Competent in one of the following programming languages: Java, C# or Python (preferred) and willingness to learn and adopt new languages as necessary </li><li> Experience in database technology like MSSQL and one of key value and document databases like MongoDb, Redis, Dynamo Db, Casandra. </li><li> Monitoring/Observability concepts and tooling: APM, Distributed Tracing, Grafana, Splunk, Prometheus. </li><li> Excellent communications skills and the ability to work with subject matter expert to extract critical business concepts. </li><li> Ability to work and potentially lead in an Agile methodology environment.</li></ul>
</div>",No Salary Info Found,Big Data Engineer
Senior Azure Data Engineer,CareerAddict,12/19/2023,https://www.linkedin.com/jobs/view/3788415496,0,https://media.licdn.com/dms/image/C4E0BAQHQUo3YFS080Q/company-logo_100_100/0/1630594573373/career_addict_logo?e=2147483647&v=beta&t=hlZnAyyIVBvbBfiOiJmKLhmpwyazTzU_0eCdWkhqD1E,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        *We are unable to sponsor for this permanent Full time role*<br/><br/>*Position is bonus eligible*<br/><br/>Prestigious Global Firm is currently seeking a Senior Azure Data Engineer. Candidate will drive the data integration solutions in terms of design, build and deployment, DevOps with best-in-class data models, data quality and data architecture standards Candidate will possess strong data capabilities in terms of data analysis, data models, and hands on expertise in crafting and deploying data pipes using Azure data platform and tools, as well as enterprise ETL tool Talend, leveraging its DQ, DI and Data Catalogue features.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Accountable for the technical leadership regarding the data integration solutions and delivery. Ensuring a sound and best in class design, with enterprise implementation, deployment and operational meets the technical quality standards</li><li>Responsible for planning and coordinating in carving out the needed dev/test environments, as well as defining and managing code branching/config strategies supporting concurrent releases</li><li>Works with Data and Enterprise architecture team to define the data integration design/coding/deployment/operational standards and technology stack</li><li>Responsible for data operations, in terms of scheduling, successful execution, and reconciliation of the data pipes in production</li><li>Works collaboratively with other dev teams to guide and review their deliverables against the set standards</li><li>Works collaboratively with Data Analytics, applications, DBA, and cloud operations teams to ensure end to end integrity and usage of data assets.</li><li>Provides inputs in shaping DevOps and DataOps practices</li><li>Partners with internal and external data experts to infuse innovation with focus on cross training and upskilling the existing teams.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Bachelor's degree in data, computer science or relevant discipline.</li><li>8+ years of experience in ETL, ELT and data engineering</li><li>At least 3+ years of working experience on Azure data platforms</li><li>Experience working in agile delivery, Jira usage and other agile delivery best practices</li><li>Data architecture, Data Modeling, and data visualization experience is a plus</li><li>Ability to interact with business, other teams to create data mapping documents, ETL architecture/design artifacts, performance improvements, improve delivery&amp; operational excellence.</li><li>8+ years of end-to-end implementation experience of deploying enterprise data warehouse, data mart and data lake solutions</li><li>3+ years of working experience with Azure data solutions including but not limited to ADLS, Data Bricks, ADF, Synapse etc</li><li>Azure ADLS/Databricks administration experience</li><li>5+ years of Implementation and maintenance experience with Talend DI, DQ capabilities</li><li>Demonstrable understanding of Data Governance, and enabling technical tools and technologies</li><li>Certification in Azure cloud stack, Talend Data Integration Certified Administrator/Developer will be a plus</li></ul>
</div>",No Salary Info Found,Big Data Engineer
Lead Data Engineer,Burtch Works,12/19/2023,https://www.linkedin.com/jobs/view/3740458573,0,https://media.licdn.com/dms/image/D560BAQGI80kVo4t7hg/company-logo_100_100/0/1698938235961/burtch_works_logo?e=2147483647&v=beta&t=LxsQJgb0mJ-H9yqdcajlHGKjF2bVmSqlKjUQ61OHZE0,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Our client, a leader in the hospitality industry, is looking for a <strong>Lead Data Engineer</strong> to provide technical expertise and leadership in delivering end to end data pipelines. This role will impact the teams advanced analytics capabilities and drive innovation and decision-making across the organization.</p><p><br/></p><p><strong>Responsibilities:</strong></p><ul><li>Build and maintain real-time data pipelines</li><li>Collaborate with the greater analytics organization to prepare data for modeling</li><li>Lead a team of Data Engineers and delegate tasks</li><li>Architect, implement, and maintain data warehouse and database systems for efficient data storage, retrieval, and analysis using Snowflake.</li><li>Act as a subject matter expert on data-related projects and communicate effectively with non-technical stakeholders.</li></ul><p><br/></p><p><strong>Qualifications:</strong></p><ul><li>Bachelors degree in a STEM field preferred (Masters is a plus)</li><li>5+ Years experience in Data Engineering, 2+ years with leadership responsibilities a plus</li><li>Experience working with Snowflake as well as ETL tools like Matillion or DBT</li><li>Proven experience working with Cloud Architectures (Azure is a plus)</li><li>Expertise with Python and SQL</li></ul><p><br/></p><p>Work Environment: Hybrid Tuesday-Thursday</p><p><br/></p><p>Compensation: $130,000-$150,000</p><p><br/></p><p><strong><em>KeyWords: </em></strong><em>Matillion, DBT, Snowflake, Data Engineer, Azure, AWS, Cloud, SQL, Python, ETL</em></p>
</div>",$130000- $150000,Big Data Engineer
"Software Engineer, Growth Data Engineering",Stripe,12/19/2023,https://www.linkedin.com/jobs/view/3790401364,0,https://media.licdn.com/dms/image/C560BAQF1NNJs-2xA5g/company-logo_100_100/0/1630643399686/stripe_logo?e=2147483647&v=beta&t=tI9GyVnhsOBvz9U5RjoHzoAhzy6WdPOe4YP1KSodzT4,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Who we are<br/><br/><strong>About Stripe<br/><br/></strong>Stripe is a financial infrastructure platform for businesses. Millions of companies—from the world’s largest enterprises to the most ambitious startups—use Stripe to accept payments, grow their revenue, and accelerate new business opportunities. Our mission is to increase the GDP of the internet, and we have a staggering amount of work ahead. That means you have an unprecedented opportunity to put the global economy within everyone’s reach while doing the most important work of your career.<br/><br/><strong>About The Team<br/><br/></strong>Stripe is the best software platform for running an internet business. We handle billions of dollars every year for hundreds of thousands of businesses around the world. One third of Americans bought something on Stripe in the last year.<br/><br/>With all this data, the Growth Data Engineering team is looking for talented data-minded engineers to help us manage business critical data leveraged across the entire organization. If you are passionate about data, excited about designing data pipelines and data-driven user experiences, and motivated by having an outsized impact on the business, we want to hear from you.<br/><br/>What you’ll do<br/><br/>Every record in our data warehouse is vitally important for the businesses that use Stripe, so we’re looking for people with a strong background in data engineering and analytics to help us scale while maintaining correct and complete data. You’ll be working with a variety of internal teams across Growth, Sales, Marketing, and Data Science to help them solve their data needs. Your work will provide teams with visibility into how Stripe’s Growth organization is performing and how we can deliver a better experience to Stripe's customers.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Identify data needs for Growth, Sales, and Marketing teams, understand their specific operational and reporting requirements, and build efficient and scalable data products &amp; pipelines to enable data-driven decisions across Stripe</li><li>Design, develop, and own data pipelines, models, and products that power Stripe’s Growth, Sales, and Marketing teams</li><li>Help the Data Science team apply and generalize statistical and econometric models on large datasets to empower more intelligent decision making among our Growth &amp; Go-to-Market teams</li><li>Develop strong subject matter expertise and manage the SLAs for both data pipelines and full stack web applications that support the Growth &amp; Go-to-Market organizations at Stripe</li><li>Build Stripe's Customer Engagement Data Service - collecting, curating, mastering, enriching, and presenting a single view of user interactions with Stripe for consumption by data applications across the company</li><li>Build and refine Stripe's data foundations - infrastructure, pipelines, and tools to enable Growth, Sales, and Marketing teams at Stripe - working with Scala, Spark, and Airflow</li><li>Design and build client libraries and frameworks to log events and accurately track the behavior of users interacting with our logged-out user interfaces such as Stripe.com</li><li>Refine our existing data marts that help the Sales and Marketing organization at Stripe forecast the future potential performance of the business, and reliably measure their ongoing attainment toward targets</li><li>Build data pipelines that track key GTM product metrics, and measure the impact of different GTM strategies employed by teams in the field</li><li>Integrate different parts of our experimentation infrastructure at Stripe, to enable full-funnel measurement and personalization of experiences spanning from Stripe.com into product</li><li>Our stack spans tools in Spark, Scala, Python, SQL, Presto, Airflow, AWS, Java, Go, and React<br/><br/><br/></li></ul>Who you are<br/><br/>We’re looking for someone who meets the minimum requirements to be considered for the role. If you meet these requirements, you are encouraged to apply. The preferred qualifications are a bonus, not a requirement.<br/><br/><strong>Minimum Requirements<br/><br/></strong><ul><li>3+ years of experience in a Data Engineering or Software Engineering role, with a focus on building data pipelines, or applications powered by big data.</li><li>A strong engineering background and are interested in data</li><li>Prior experience with writing and debugging data pipelines using a distributed data framework (Spark / Hadoop / Pig etc)</li><li>An inquisitive nature in diving into data inconsistencies to pinpoint issues, and resolve deep rooted data quality issues</li><li>Knowledge of a scientific computing language (such as Scala or Python) and SQL</li><li>Experience with full stack development languages such as Java or Go, and front-end frameworks such as React</li><li>The ability to communicate cross-functionally, derive requirements and architect shared datasets<br/><br/><br/></li></ul>Hybrid work at Stripe<br/><br/>Our Chicago, Dublin, and Singapore teams spend at least 50% of their time in their local offices. We believe that more in-person interactions will contribute to better results for our employees and Stripe. Increased office time allows for improved collaboration, efficiency, and informal learning opportunities, fostering a stronger community and building our culture. We will apply the insights gained from these initial three locations to continue refining our hybrid approach.<br/><br/>Pay and benefits<br/><br/>The annual salary range for this role in the primary location is C$130,100 - C$176,000. This range may change if you are hired in another location. For sales roles, the range provided is the role’s On Target Earnings (“OTE”) range, meaning that the range includes both the sales commissions/sales bonuses target and annual base salary for the role. This salary range may be inclusive of several career levels at Stripe and will be narrowed during the interview process based on a number of factors, including the candidate’s experience, qualifications, and specific location. Applicants interested in this role and who are not located in the primary location may request the annual salary range for their location during the interview process.<br/><br/>Specific benefits and details about what compensation is included in the salary range listed above will vary depending on the applicant’s location and can be discussed in more detail during the interview process. Benefits/additional compensation for this role may include: equity, company bonus or sales commissions/bonuses; retirement plans; health benefits; and wellness stipends.
      </div>",$130100- $176000,Big Data Engineer
Staff Data Engineer,Kin Insurance,12/19/2023,https://www.linkedin.com/jobs/view/3763328086,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
"Lead Data Engineer (AWS, Azure, GCP)",CapTech,12/19/2023,https://www.linkedin.com/jobs/view/3751644354,0,https://media.licdn.com/dms/image/D4E0BAQEzvZZT9k7tQg/company-logo_100_100/0/1688216361303/captechconsulting_logo?e=2147483647&v=beta&t=wV_XeINYC7gUtPXYwqonUqAssSaid9KiHLw1Hxp4Z7Q,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>CapTech is an award-winning consulting firm that collaborates with clients to achieve what’s possible through the power of technology. At CapTech, we’re passionate about the work we do and the results we achieve for our clients. From the outset, our founders shared a collective passion to create a consultancy centered on strong relationships that would stand the test of time. Today we work alongside clients that include Fortune 100 companies, mid-sized enterprises, and government agencies, a list that spans across the country.<br/><br/><strong>Job Description<br/><br/></strong>CapTech Data Engineering consultants enable clients to build and maintain advanced data systems that bring together data from disparate sources in order to enable decision-makers. We build pipelines and prepare data for use by data scientists, data analysts, and other data systems. We love solving problems and providing creative solutions for our clients. Cloud Data Engineers leverage the client’s cloud infrastructure to deliver this value today and to scale for the future. We enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other developers, architects, and our clients. <br/><br/>The Value You Deliver (or What You’ll Do)<br/><br/><ul><li>Be trusted advisor to customers with best practices, methodologies, and technologies to implement data engineering solutions. </li><li>Design, implement, and maintain modern data pipelines to deliver optimal solutions utilizing appropriate cloud technologies. </li><li>Partner with product owners and business SMEs to analyze customer requirements and provide a supportable and sustainable engineered solution. </li><li>Provide technical leadership and collaborate within and across teams to ensure that the overall technical solution is aligned with the customer needs. </li><li>Stay current with the latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Experience building/operating highly available distributed systems of data extraction, ingestion, and processing large data sets </li><li>5+ years of experience delivering data engineering solutions on cloud platform </li><li>5+ years of experience implementing modern designs using at least one cloud-based solution/platform (AWS, Azure, GCP) </li><li>Advanced level proficiency with at least one ETL / Data Orchestration technology (Azure Data Factory, SSIS, Informatica, Alteryx, Ab Initio, Pentaho, Talend, Matillion) </li><li>Experience cloud-based data warehousing and data lake solutions like Snowflake, Redshift, Databricks </li><li>5+ years of experience with SQL or NoSQL database (PostgreSQL, MySQL, SQL server, Oracle, Aurora, Presto, BigQuery) </li><li>Expertise with SQL, database design/structure and data structure (star, snowflake schemas, de/normalized designs) </li><li>5+ years of experience with at least one programming language (Python, Java, R, C / C# / C++, Shell) </li><li>Familiarity with one or more DevOps tools (git, Jenkins, CI/CD, Jira) </li><li>Fundamental understanding of big data, open source, and data streaming concepts </li><li>Ability to think strategically and provide recommendations utilizing traditional and modern architectural components based on business needs    </li><li>Experience providing technical leadership and mentoring other engineers in data engineering space </li><li>Cloud certification on any platform a plus <br/><br/></li></ul><strong>Additional Information<br/><br/></strong>We want everyone at CapTech to be able to envision a lasting and rewarding career here, which is why we offer a variety of career paths based on your skills and passions. You decide where and how you want to develop, and we help get you there with customizable career progression and a comprehensive benefits package to support you along the way. Alongside our suite of traditional benefits encompassing generous PTO, health coverage, disability insurance, paid family leave and more, we’ve launched extended benefits to help meet our employees’ needs.<br/><br/><ul><li>CapFlex – Employee-first mentality that supports a remote and hybrid workforce and empowers daily flexibility while servicing our clients</li><li>Learning &amp; Development – Programs offering certification and tuition support, digital on-demand learning courses, mentorship, and skill development paths</li><li>Modern Health –A mental health and well-being platform that provides 1:1 care, group support sessions, and self-serve resources to support employees and their families through life’s ups and downs</li><li>Carrot Fertility –Inclusive fertility and family-forming coverage for all paths to parenthood – including adoption, surrogacy, fertility treatments, pregnancy, and more – and opportunities for employer-sponsored funds to help pay for care</li><li>Fringe –A company paid stipend program for personalized lifestyle benefits, allowing employees to choose benefits that matter most to them – ranging from vendors like Netflix, Spotify, and GrubHub to services like student loan repayment, travel, fitness, and more</li><li>Employee Resource Groups – Employee-led committees that embrace and incorporate diversity and inclusion into our day-to-day operations</li><li>Philanthropic Partnerships – Opportunities to engage in partnerships and pro-bono projects that support our communities. </li><li>401(k) Matching – Generous matching and no vesting period to help you continue to build financial wellness<br/><br/></li></ul>CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace. For more information about our Diversity, Inclusion and Belonging efforts, click HERE. As part of this commitment, CapTech will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact Laura Massa directly via email lmassa@captechconsulting.com.<br/><br/>At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.<br/><br/>
</div>",No Salary Info Found,Big Data Engineer
Senior Data Engineer,Singleton Group,12/19/2023,https://www.linkedin.com/jobs/view/3790329724,0,https://media.licdn.com/dms/image/D560BAQFfh-74VLvh5Q/company-logo_100_100/0/1690147229506/singletonrecruiting_logo?e=2147483647&v=beta&t=6IMF0TCnEWiXk-OIqlPLm3sYE_xw0IgF_h3okQ0-C74,Greater Chicago Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Singleton is searching for a Senior Data Engineer. The ideal candidate will be able to provide technical leadership, and push forward end to end data solutions that will support advanced analytics functionality.</p><p><br/></p><p>We would describe this role as remote-ish. While the work can be largely done remotely, there is a requirement of being in office in the Chicago area 3 business days per month.</p><p><br/></p><p><strong>Skills We Believe Will Make a Candidate Successful:</strong></p><p><br/></p><ul><li>4+ years experience in data engineering roles</li><li>Expertise with Databricks and Spark.</li><li>An understanding of the best practices around data engineering in an Azure cloud-based environment</li><li>Demonstrated ability to solve complex technical problems and build scalable data pipelines</li></ul>
</div>",No Salary Info Found,Big Data Engineer
Sr. Data Engineer II,RED SKY Consulting,12/19/2023,https://www.linkedin.com/jobs/view/3790402405,0,https://media.licdn.com/dms/image/C4D0BAQE1mFi6GLSFqA/company-logo_100_100/0/1647890522808/red_sky_consulting_logo?e=2147483647&v=beta&t=2s7X1ZU2iyn6xw4gSs0Y14xZp3pjZwESU0NQMuZocKQ,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title: Sr. Data Engineer II - 2809</strong></p><p><strong> </strong></p><p><strong> Location: Hybrid Onsite 3x / Week in Chicago, IL </strong></p><p><strong> </strong></p><p><strong> Type: Direct Hire </strong></p><p><strong> </strong></p><p><strong> Bottom Line / In a Nutshell: </strong></p><ul><li>8+ years of end-to-end implementation experience of deploying enterprise data warehouse, data mart and data lake solutions</li><li>8+ years of experience in ETL, ELT and data engineering</li><li>5+ years of Implementation and maintenance experience with Talend DI, DQ capabilities</li><li>3+ years of working experience with Azure data solutions including but not limited to ADLS, Data Bricks, Azure Data Factory, Synapse etc</li><li>Certification in Azure cloud stack, Talend Data Integration Certified Administrator/Developer will be a plus </li></ul><p><strong>Job Description: </strong></p><p> </p><p> Owns and drives our data integration solutions in terms of design, build and deployment, DevOps with best-in-class data models, data quality and data architecture standards </p><p> Possesses strong data capabilities in terms of data analysis, data models, and hands on expertise in crafting and deploying data pipes using Azure data platform and tools, as well as enterprise ETL tool Talend, leveraging its DQ, DI and Data Catalogue features. </p><p> </p><p> <strong>Essential Functions:</strong></p><ul><li>Accountable for the technical leadership regarding the data integration solutions and delivery. Ensuring a sound and best in class design, with enterprise implementation, deployment and operational meets the technical quality standards</li><li>Responsible for planning and coordinating in carving out the needed dev/test environments, as well as defining and managing code branching/config strategies supporting concurrent releases</li><li>Works with Data and Enterprise architecture team to define the data integration design/coding/deployment/operational standards and technology stack</li><li>Responsible for data operations, in terms of scheduling, successful execution, and reconciliation of the data pipes in production </li><li>Works collaboratively with other dev teams to guide and review their deliverables against the set standards</li><li>Works collaboratively with Data Analytics, applications, DBA, and cloud operations teams to ensure end to end integrity and usage of data assets.</li><li>Provides inputs in shaping K&amp;E DevOps and DataOps practices</li><li>Partners with internal and external data experts to infuse innovation with focus on cross training and upskilling the existing teams.</li><li>Fosters and promotes heathy working relationships across the board to propagate end-to-end value of data.</li></ul><p><strong>Qualifications &amp; Requirements:</strong></p><p> </p><p> <strong><em>Education, Work Experience, Skills</em></strong></p><ul><li>Bachelor’s degree in data, computer science or relevant discipline.</li><li>8+ years of experience in ETL, ELT and data engineering</li><li>At least 3+ years of working experience on Azure data platforms</li><li>Experience working in agile delivery, Jira usage and other agile delivery best practices</li><li>Data architecture, Data Modeling, and data visualization experience is a plus</li><li>Ability to interact with business, other teams to create data mapping documents, ETL architecture/design artifacts, performance improvements, improve delivery &amp; operational excellence.</li></ul><p><strong>Technologies/Software:</strong></p><ul><li>8+ years of end-to-end implementation experience of deploying enterprise data warehouse, data mart and data lake solutions</li><li>3+ years of working experience with Azure data solutions including but not limited to ADLS, Data Bricks, ADF, Synapse etc</li><li>Azure ADLS/Databricks administration experience</li><li>5+ years of Implementation and maintenance experience with Talend DI, DQ capabilities</li><li>Demonstrable understanding of Data Governance, and enabling technical tools and technologies</li></ul><p><strong>Certificates, Licensures, Registrations:</strong></p><ul><li>Certification in Azure cloud stack, Talend Data Integration Certified Administrator/Developer will be a plus </li></ul><p><strong>THIS IS A GREAT OPPORTUNITY WITH A FIRST-CLASS COMPANY</strong></p><p> </p><p> <strong>Sr. Data Engineer II </strong></p><p> </p><p> <strong>&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;</strong> </p><p> </p><p> <strong>RED SKY Career Opportunities at: redskyconsulting.co/career-portal</strong></p><p> </p><p> <strong>&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt; </strong></p><p> </p><p> <strong>Sr. Data Engineer II</strong></p>
</div>",No Salary Info Found,Big Data Engineer
Senior Data Engineer,System1,12/24/2023,https://www.linkedin.com/jobs/view/3744704288,0,https://media.licdn.com/dms/image/C4D0BAQHLu6mGz4AYlA/company-logo_100_100/0/1630571994808/system1co_logo?e=2147483647&v=beta&t=gLnBWRpODwlJfxi-VZLalOL3S-robz68jW10i698fLc,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        System1 is one of the largest customer acquisition companies in the world whose growth depends heavily on a very talented data engineering team. The <strong>Sr.</strong><strong>Data Engineering</strong> team at System1 is focused on building frameworks, processes, and automation to ensure smooth running data pipelines and infrastructure. We process billions of records per day, for the benefit of multiple business functions like business intelligence, data science &amp; machine learning, traffic quality and analytics. You would be working in a fast-paced environment where system scalability, reliability, usability, efficiency are the goals. Come join us!<br/><br/><strong>The Role You Will Have<br/><br/></strong><ul><li>Designing and developing data processing infrastructure.</li><li>Developing new and improving existing data pipelines, extracting from external API sources or internal events.</li><li>Developing self-serve data solutions, self-correcting robust ETL pipelines.</li><li>Continuously improving monitoring and alerting coverage.</li><li>As a Sr. Engineer, this role will provide mentorship to colleagues in/outside of the immediate team.</li><li>Self-driving proof of concept for new technologies, new patterns and writing technical specifications for data architecture projects.</li><li>Identifying complex scaling bottlenecks and how to prevent them, and communicating updates to stakeholders.</li><li>Performing maintenance of existing infrastructure, investigating issues and failures.</li><li>Conducting SQL data investigations, and optimizations.</li><li>Participate in peer code reviews and produce high quality documentation<br/><br/></li></ul><strong>What You Will Bring<br/><br/></strong><ul><li>Bachelor's or Master's degree in Computer Science/Engineering.</li><li>Programming expertise in Python is required. JVM lang like Scala, Kotlin are preferred.</li><li>6+ years’ experience in Cloud ecosystems like AWS is required. GCP, Azure are preferred.</li><li>SQL expertise, and preferably SQL query optimization experience.</li><li>Database design skills, both relational and non-relational, SQL and NoSQL.</li><li>Experience with Cloud data warehouses like BigQuery, Snowflake, Redshift preferred.</li><li>High level of proficiency with modern orchestration platforms such as Airflow.</li><li>Deep understanding of data engineering fundamentals, ETL experience and analytics skills required in order to solve complex challenges across the System1 environment.</li><li>Knowledge of data engineering mechanics, flow, distribution, optimization.</li><li>Data organization, distribution, latency, observability.</li><li>Distributed big data processing and storage systems.</li><li>Kubernetes, docker, containerization strategies, Linux/UNIX would be required.</li><li>Experience with Kafka is preferred.<br/><br/></li></ul><strong>What We Have To Offer<br/><br/></strong><ul><li>Competitive salary + bonus + equity</li><li>Generous PTO + 11 company holidays</li><li>Open sick time</li><li>100% covered Medical, Dental, Vision for employees</li><li>401k with match</li><li>Health &amp; Dependent Care Flex Spending Account </li><li>Paid professional development</li><li>Leadership &amp; growth opportunities</li><li>Virtual company and team building events <br/><br/></li></ul>The U.S. base salary range for this full-time position is <strong>$159,000 - $222,000</strong> + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process. Please note that the compensation details listed in U.S. role postings reflect the base salary only, and do not include bonus, equity, or benefits.<br/><br/>System1 offers flexible work arrangements for most employees (unless they hold positions which are identified as having to be 100% onsite in Marina del Rey, CA, Bellevue, WA or Guelph, ON Canada). Most System1 full-time employees choose to work in a hybrid environment, splitting their time between working in our offices and working remotely. System1 allows fully-remote work in the following approved locations: Arizona, Colorado, Georgia, Hawaii, Minnesota, Missouri, New Jersey, New York, North Carolina, Oklahoma, Oregon, Pennsylvania, Tennessee, Texas and Virginia. Prospective U.S. employees who live outside of any of these states will need to establish residency in one of the approved states prior to employment.
      </div>",$159000- $222000,Big Data Engineer
Senior Data Engineer,Jobot,12/24/2023,https://www.linkedin.com/jobs/view/3791335662,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3790370222,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Burbank, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Looking for someone with a strong background working as a data engineer pulling and extracting data, as well as building pipelines &amp; distributed systems. The ideal candidate will have strong experience with Python, PySpark, SQL, and AWS.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>Experience with Python programming </li><li>Experience with PySpark </li><li>Strong AWS experience </li><li>Comfortable working within several SQL databases </li><li>Experience with one or more data warehousing technology <br/><br/></li></ul>What You Will Be Doing<br/><br/>Tech Breakdown<br/><br/><ul><li>50% Building Pipelines with PySpark </li><li>50% Data cleaning and integration <br/><br/></li></ul>Daily Responsibilities<br/><br/><ul><li>100% Hands On <br/><br/></li></ul>The Offer<br/><br/><ul><li>Competitive base salary and equity offered <br/><br/></li></ul><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical &amp; Dental Insurance </li><li>Health Savings Account (HSA) </li><li>401(k) with 3% match </li><li>Unlimited Paid Time Off </li><li>Pre-tax Commuter Benefit </li><li>Unlimited remote access </li><li>Flexible work from home schedule (onsite 2-3 days/month) </li><li>On-site Gym <br/><br/></li></ul>Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Julie Bennett
      </div>",No Salary Info Found,Big Data Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765470284,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Mid Level Data Engineer / Santa Monica Startup / FinTech,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789761714,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Santa Monica, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        A Series D start-up in Santa Monica is hiring a 4year Mid Level Data Engineer to join their rapidly expanding team. This company is scaling their pipelines, looking for someone who wants strong mentorship and the ability to grow within the company as well in a clear growth path to Senior/Lead. This position is fully remote but is best fit for someone who is open to traveling at least 10% of the time to Santa Monica, CA.<br/><br/>This finance company is mainly focused on empowering and investing in the entertainment space. They analyze real-time data insights into all new and existing content to educate these clients on the value of their current library as well as their future library with an influx in investments in the right areas. The tech stack for this role includes Python, PostgresSQL, PostGIS, Python, Spark/PySpark, AWS, and Airflow.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>4+ years of experience in data engineering </li><li>Exp. building out highly scalable systems </li><li>Experience in SQL &amp; SQL Databases </li><li>Application development frame (Python) </li><li>Experience working in a big-data and cloud-based environment <br/><br/></li></ul><strong>The Offer You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Time Off (PTO) </li><li>401(k) matching </li><li>Bonus </li><li>Flexible schedule <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Cassi Benson
      </div>",No Salary Info Found,Big Data Engineer
Data Engineer with Software Background,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789764446,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Burbank, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        One of the largest and most innovative digital media and entertainment companies in North America is looking to add a new member to their close knit team. Their offices are in the heart of Downtown Burbank, open to candidates who need to work remotely but have great preference to those in the Greater Los Angeles area. Looking for someone with a strong background working as a data engineer pulling and extracting data, as well as building pipelines &amp; distributed systems. The ideal candidate will have strong experience with Python, PySpark, SQL, and AWS.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>Experience with Python programming </li><li>Experience with PySpark </li><li>Strong AWS experience </li><li>Comfortable working within several SQL databases </li><li>Experience with one or more data warehousing technology <br/><br/></li></ul>What You Will Be Doing<br/><br/>Tech Breakdown<br/><br/><ul><li>50% Building Pipelines with PySpark </li><li>50% Data cleaning and integration <br/><br/></li></ul>Daily Responsibilities<br/><br/><ul><li>100% Hands On <br/><br/></li></ul>The Offer<br/><br/><ul><li>Competitive base salary and equity offered <br/><br/></li></ul><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical &amp; Dental Insurance </li><li>Health Savings Account (HSA) </li><li>401(k) with 3% match </li><li>Unlimited Paid Time Off </li><li>Pre-tax Commuter Benefit </li><li>Unlimited remote access </li><li>Flexible work from home schedule (onsite 2-3 days/month) </li><li>On-site Gym <br/><br/></li></ul>Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Cassi Benson
      </div>",No Salary Info Found,Big Data Engineer
Mid Level Data Engineer / SQL Background / Migrating to AWS and Spark/ Hybrid,Motion Recruitment Partners LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785059622,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789086620,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $160,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$160000- $173000,Big Data Engineer
Senior Analytics Engineer,Dollar Shave Club,12/20/2023,https://www.linkedin.com/jobs/view/3756918688,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Mid Level Data Engineer / Santa Monica Startup / FinTech,Motion Recruitment Partners LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785063365,0,https://media.licdn.com/dms/image/C4E0BAQGbIGAVD9Ugtg/company-logo_100_100/0/1630587145865/motion_recruitment_partners_llc_logo?e=2147483647&v=beta&t=alBjyOtSVLguJoyqNF0DXJ9Pwg7PtTJhNsISoDSt9QU,"Santa Monica, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Motion Recruitment Partners, LLC, is seeking the following. Apply via Dice today!<br/><br/>A Series D start-up in Santa Monica is hiring a 4year Mid Level Data Engineer to join their rapidly expanding team. This company is scaling their pipelines, looking for someone who wants strong mentorship and the ability to grow within the company as well in a clear growth path to Senior/Lead. This position is fully remote but is best fit for someone who is open to traveling at least 10% of the time to Santa Monica, CA.<br/><br/>This finance company is mainly focused on empowering and investing in the entertainment space. They analyze real-time data insights into all new and existing content to educate these clients on the value of their current library as well as their future library with an influx in investments in the right areas. The tech stack for this role includes Python, PostgresSQL, PostGIS, Python, Spark/PySpark, AWS, and Airflow.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>4+ years of experience in data engineering </li><li>Exp. building out highly scalable systems </li><li>Experience in SQL &amp; SQL Databases </li><li>Application development frame (Python) </li><li>Experience working in a big-data and cloud-based environment <br/><br/></li></ul><strong>The Offer You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Time Off (PTO) </li><li>401(k) matching </li><li>Bonus </li><li>Flexible schedule <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Mid Level Data Engineer / Santa Monica Startup / FinTech
      </div>",No Salary Info Found,Big Data Engineer
"Data Engineer, Data Platform",Grammarly,12/25/2023,https://www.linkedin.com/jobs/view/3656898066,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer,Deloitte,12/20/2023,https://www.linkedin.com/jobs/view/3752817620,0,https://media.licdn.com/dms/image/C560BAQGNtpblgQpJoQ/company-logo_100_100/0/1662120928214/deloitte_logo?e=2147483647&v=beta&t=KhIfaHWyu1aAgyyImEhYDprMjFP3LaMR0E7NF2MPxMY,"Arlington, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Do you want to build your brand by working for a leading consulting firm that drives eminence in the marketplace? Are you interested in leveraging your analytical skills and strategic ideas to improve mission execution? If so, Deloitte could be the place for you! Our Government and Public Services Strategy and Analytics team brings deep industry expertise, rigorous analytical capabilities and a pragmatic mindset to help solve our client's most complex business problems. Join our team and play a key role in helping to design our clients' roadmap to the future and help transform the Federal marketplace.<br/><br/><strong>Work you'll do<br/><br/></strong>The Data Analytics Architect will have overall responsibility of planning how work within different teams will integrate into one solution. The Data Analytics Architect will also have overall responsibility of being the primary representative on all architecture matters and the leading member of the Architecture Team. The Architect will:<br/><br/><ul><li>Work closely with various software development team(s) to migrate and architect data to meet client needs</li><li>Work directly with clients to validate migrated data</li><li>Work with Agile development teams to understand changes and their impacts towards data migration efforts</li><li>Leading developers, managing database administrators' workload and activities, among other tasks.</li><li>Create and manage schedules for data management (e.g. migration, integration, etc.) efforts</li><li>Build processes and scripts required to transform and stage data necessary to develop products and analyses<br/><br/></li></ul><strong>The team <br/><br/></strong>Deloitte's Government and Public Services (GPS) practice - our people, ideas, technology and outcomes-is designed for impact. Serving federal, state, &amp; local government clients as well as public higher education institutions, our team of over 15,000+ professionals brings fresh perspective to help clients anticipate disruption, reimagine the possible, and fulfill their mission promise.<br/><br/>The GPS Analytics and Cognitive (A&amp;C) offering is responsible for developing advanced analytics products and applying data visualization and statistical programming tools to enterprise data in order to advance and enable the key mission outcomes for our clients. Our team supports all phases of analytic work product development, from the identification of key business questions through data collection and ETL, and from performing analyses and using a wide range of statistical, machine learning, and applied mathematical techniques to delivery insights to decision-makers. Our practitioners give special attention to the interplay between data and the business processes that produce it and the decision-makers that consume insights.<br/><br/><strong>Qualifications<br/><br/></strong>Required:<br/><br/><ul><li>Must have an active Secret clearance</li><li>2+ years of hands-on experience with ETL/data pipeline development experience, leveraging industry-standard tools, ideally Informatica</li><li>2+ years of experience working with relational databases and data lakes, with an emphasis on data warehousing, performance tuning, and analytics use cases</li><li>Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future.<br/><br/></li></ul>Preferred:<br/><br/><ul><li>Experience integrating them into custom web applications</li><li>Data modeling and solution design experience</li><li>Familiarity programming in languages commonly used for data management and data science/statistics, such as Python</li><li>A general interest in relevant emerging technologies such as cloud-native services, and a constant thirst to further your own technical abilities</li><li>Experience working in an Agile development environment</li><li>Hands-on experience with full suite of software lifecycle tools (Confluence, Jira, Stash, Jenkins, Artifactory, etc.)</li></ul>
</div>",No Salary Info Found,Big Data Engineer
Data Engineer,Blackstone Talent Group,12/19/2023,https://www.linkedin.com/jobs/view/3790357905,0,https://media.licdn.com/dms/image/C560BAQHAFlnQg3firg/company-logo_100_100/0/1657148420727/blackstonetalentgroup_logo?e=2147483647&v=beta&t=RR2QR8qXLbGf4EMMe1qv0MfDEW6BsTugoFERHF1Nxgg,Washington DC-Baltimore Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>We are looking for a <strong>Data Engineer </strong>to join our team of experts to assist with building state-of-the-art data platforms for the client's premier data analytics platform.</p><p><br/></p><p><strong>Responsibilities:</strong></p><p>The Data Engineer will support data collection, ingestion, validation, and loading of optimized data in the appropriate data stores. They work on a team made up of analyst(s), developer(s), data scientist(s), and product leads, and everyone on the team collaborates in support of a specific mission. Working directly with the analyst(s) and the product lead, the data engineer identifies and implements solutions for the data requirements, including building pipelines to collect data from disparate, external sources and implementing rules to validate that expected data is received, cleansed, transformed, massaged and in an optimized output format for the data store. </p><p><br/></p><p>The Data Engineer performs validation and analytics corresponding with client requirements and evolves solutions through automation, optimizing performance with minimal human involvement. As pipelines are executed, the data engineer monitors their status, and performance, and troubleshoots issues while working on improvements to ensure the solution is the very best version to address the customer need. </p><p><br/></p><p><strong>Required Skills:</strong></p><ul><li><strong>Clearance: Secret or Top Secret Clearance</strong></li><li>6+ years of experience with SQL</li><li>6+ years of experience developing data pipelines using modern Big Data ETL technologies like NiFi or StreamSets</li><li>6+ years of experience with a modern programming language such as Python or Java</li><li>6 years of experience working in a big data and cloud environment</li><li>Documented experience with AWS, EC2, S3, and/or RDS</li></ul><p><br/></p><p><strong>Preferred Skills:</strong></p><ul><li>3 years of experience working in an agile development environment</li><li>Ability to quickly learn technical concepts and communicate with multiple functional groups</li><li>Ability to display a positive, can-do attitude to solve the challenges of tomorrow</li><li>Possession of excellent verbal and written communication skills</li><li>Preferred experience at the respective command with an understanding of analytical and data paint points and challenges across the J-Codes.</li></ul><p></p>
</div>",No Salary Info Found,Big Data Engineer
Data Engineer,Kearney & Company,12/19/2023,https://www.linkedin.com/jobs/view/3790345109,0,https://media.licdn.com/dms/image/C4D0BAQF6_7WsdCwmqg/company-logo_100_100/0/1631311582093?e=2147483647&v=beta&t=G5FR9nbxsXrXyuSMW9lZYvvigcpM_rJQ-k6pqY3_sW0,"Arlington, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Kearney and Company is currently seeking a Data Engineer to join our Arlington, VA team. The Data Engineer will develop pipelines for data acquisition and ingestion, enabling detailed data analytics using industry leading tools and capabilities. You will be part of a customer focused team developing productive working relationships with client personnel, delivering capabilities for the Department of Defense through agile methodology.<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Create and update data pipelines and conduct data ingesting operations</li><li>Query, discover, export, and connect dashboards/analytic models to data provided by DoD stakeholders</li><li>Develop and translate functional data requirements to assemble datasets and program related business logic</li><li>Ensure the data catalog is updated with metadata related to new data being ingested.</li><li>Maintain relationships and communicate with key client personnel to understand business operations, processes, and functions</li><li>Develop and run reconciliation scripts to support customer data and use cases</li><li>Adhere to management’s Agile Development process, including using JIRA and Slack daily</li><li>Present progress to senior stakeholders</li><li>Balance multiple projects concurrently<br/><br/></li></ul><strong>Qualifications<br/><br/></strong>Required Qualifications<br/><br/><ul><li>BA, BS or BBA degree in mathematics, engineering, computer science, or related area and at least 2 years of relevant experience</li><li>Must have at least an active Secret clearance</li><li>Prior experience as a data engineer, data architect, or data scientist</li><li>Experience with using Databricks to perform data transformations or modeling (including Databricks SQL and Delta Lake)</li><li>Intermediate knowledge of SQL and Python</li><li>Experience working with Accounting and Financial Management Data</li><li>Experience independently evaluating controls over security processes, infrastructure, network, applications and databases</li><li>Ability to provide on-site support 3-5 days a week at the Pentagon or Mark Cente<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Data engineer or data architect certification: Amazon Web Services (AWS) Certified Data Analytics - Specialty, or other related designation preferred</li><li>Experience with StreamSets</li><li>Understanding of DoD Financial Management Systems</li><li>Experience with PySpark</li><li>Experience with bash scripting</li><li>Experience with ini/cfg configuration files<br/><br/></li></ul><strong>Overview<br/><br/></strong>Exclusively focused on the Government, Kearney &amp; Company provides financial services, including auditing, consulting, and technology services. Our commitment to our employees and clients as well as to dedication and trust, critical values to our Firm, have led to Kearney’s recognition as one of the leading accounting firms in the country. Based on our employees’ feedback, we are also consistently rated a Best Place to Work. Employment at Kearney means a flexible, collaborative, and open-minded work environment. We hope it is your “first easy decision.” Learn more at www.kearneyco.com/careers.<br/><br/><strong>EEO Notice<br/><br/></strong><strong> Applicants have rights under Federal Employment Laws <br/><br/></strong>EEO Notice<br/><br/>Work location is subject to change based on client requirements.<br/><br/>Kearney &amp; Company is an Equal Opportunity Employer and will consider all qualified applicants without regard to race, color, creed, genetic information, religion, national origin, ethnicity, gender; gender identity, sexual orientation, pregnancy, childbirth or related medical condition, age, disability or handicap, servicemember status, relationship or association with a protected veteran, and any other category protected by Federal, state, or local law. Click here to learn more.<br/><br/>If you would like to request a reasonable accommodation, regarding accessibility of our website, a modification or adjustment of the job application or interview process due to a disability, please call 703-236-2391 or email accommodations@kearneyco.com. Please be advised that this contact information is for accommodation requests only and cannot be used to inquire about the status of an application.<br/><br/><strong> Family and Medical Leave Act (FMLA) <br/><br/></strong>FMLA is designed to help employees balance their work and family responsibilities by allowing them to take reasonable unpaid leave for certain family and medical reasons. Kearney &amp; Company provides eligible employees with up to 12 weeks of unpaid, job-protected leave per year. Military family leave is available for up to 26 weeks under FMLA. Click here to learn more.<br/><br/><strong> Employee Polygraph Protection Act (EPPA) <br/><br/></strong>The EPPA prohibits most private employers from using lie detector tests either for pre-employment screening or during the course of employment. Kearney &amp; Company adheres all provisions of the EPPA. Click here to learn more.
      </div>",No Salary Info Found,Big Data Engineer
Data Engineer,Tential Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3771471112,0,https://media.licdn.com/dms/image/C560BAQHnOqVlYhs_Qw/company-logo_100_100/0/1644376641769/tential_logo?e=2147483647&v=beta&t=KGNXyf8sS9RdkjXtqLM2TG9fNnJmesGJvYC4j3btUis,"Vienna, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>Modernize an On-Prem architecture migrating to Azure creating new data pipelines and contributing to architectural decisions. Develop strategies for data acquisition, and database implementation. Responsible for designing, building, integrating data from various resources, and managing big data. Solves highly complex problems; takes a broad perspective to identify solutions. Works independently.<br/><br/><strong>Requirements<br/><br/></strong><ul><li>Must have strong hands-on experience with Azure Data Factory and Databricks.</li><li>3+ years of experience in data engineering.</li><li>Experienced in sourcing, maintaining, and updating data in On-Prem and Cloud environments.</li><li>Strong SQL skills and knowledge of data warehousing and ETL best practices.</li><li>Experience designing, building and monitoring of data pipelines using Azure Data Factory.</li><li>Understands data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage.</li><li>Experience using GIT &amp; Source Control. </li><li>Some experience in developing NO SQL solutions using Azure Cosmos DB.</li><li>Bachelor’s degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience.<br/><br/><br/></li></ul><strong>Responsibilities:<br/><br/></strong><ul><li>Develop high-performance data pipelines.</li><li>Contribute to architectural decisions and system evaluations.</li><li>Build conceptual and logical data models for stakeholders and management.</li><li>Ensure data quality and continuous improvement.</li><li>Familiarity with data warehousing concepts and best practices.</li><li>Perform other duties as assigned.<br/><br/><br/></li></ul><strong>Additional Information:<br/><br/></strong><ul><li>Our client is looking for candidates local to either the VA or Pensacola (but preference is Pensacola) area but are open to Full-time remote within the United States.<br/><br/><br/></li></ul>#Dice<br/><br/>#Remote<br/><br/>
</div>",No Salary Info Found,Big Data Engineer
Junior Data Engineer,ARA,12/19/2023,https://www.linkedin.com/jobs/view/3753015172,0,https://media.licdn.com/dms/image/C4D0BAQGJaMmMeoNeEg/company-logo_100_100/0/1631356968447/ara_logo?e=2147483647&v=beta&t=PKIHrN1qBGruMbaWAB_tRq7JfyF3h3IEGh6n-wdeqGY,"Herndon, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Applied Research Associates, Inc. is looking for a successful candidate to work in cross-functional engineering and product development teams with data at all stages of the analysis lifecycle to derive actionable insights. They will utilize data to provide innovative technologies that enable the integration of tools and data, improve data ingestion, increase data scaling, and enhance data exploitation to ensure more interoperable and secure data. They will assist in identifying and developing new and innovative data models (conceptual, logical, physical) and data relationships. The candidate should be able to operationalize supervised Machine Learning (ML) algorithms, and support development of Artificial Intelligence (AI)/ML to enhance automated data analysis methods.<br/><br/><strong>Junior Data Engineer Required Qualifications<br/><br/></strong><ul><li> US citizen with an active TS/SCI security clearance</li><li> Bachelors degree</li><li> Proficiency with major data science tools and languages such as Graph DB tools, PostgreSQL/SQL, Python, and/or Git</li><li> 2 years’ experience obtaining data from multiple, disparate data sources including structured, semi-structured and unstructured data</li><li> Experience using AWS cloud technologies and open source libraries (Python, etc.)</li><li> Experience developing, verifying, and monitoring AI/ML Models<br/><br/></li></ul><strong>Junior Data Engineer Desired Qualifications<br/><br/></strong><ul><li> Demonstrated experience with cleaning, managing, optimizing performance with, and processing large volumes of data</li><li> Familiarity with industry best practices for software/hardware optimization when processing large data sets and offers experience in the following required task areas: experience with machine learning, statistical modeling, time-series forecasting, and/or geospatial analytics; experience with Hadoop, Spark, or other parallel storage/computing processes is a plus</li><li> Experience with developing data processing workflows using the Joint Enterprise Modeling and Analytics (JEMA) framework or Apache NiFi.</li><li> Knowledge of Cloud services used by the Intel Community<br/><br/></li></ul><strong>Who is ARA?<br/><br/></strong>Do you want to work for a purpose? Applied Research Associates, Inc. (aka ARA) is an employee-owned international research and engineering company. We have been providing technically superior solutions to complex and challenging problems in the physical sciences since 1979. ARA has over 2,042 employee owners and continues to grow rapidly. Together, our offices throughout the U.S. and Canada provide a broad range of technical expertise in defense, civil, and health technologies, computer software and simulation, systems analysis, environmental technologies, and testing and measurement.<br/><br/>ARA also prides itself, on having a challenging culture where innovation &amp; experimentation are the norm. The motto, “Engineering and Science for Fun and Profit” sums up the ARA experience. Employee ownership ensures you have a voice with what happens in the company. We are also very proud of our Women’s Initiative Network (WIN), whose purpose is to motivate, support, and encourage professional career development for women to maximize career and professional accomplishments.<br/><br/>To find out more about what the Intelligence, Surveillance &amp; Reconnaissance Division has to offer, visit our website at: https://www.ara.com/benefits/
      </div>",No Salary Info Found,Big Data Engineer
Data Engineer,AARP,12/19/2023,https://www.linkedin.com/jobs/view/3770536272,0,https://media.licdn.com/dms/image/C4D0BAQGrLdVnDetK2w/company-logo_100_100/0/1630512518306/aarp_logo?e=2147483647&v=beta&t=GPoqu717ZAAEG4LNm6Og7hd8S4ESP2pWTXNvKncT_lk,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>AARP Services, Inc., founded in 1999, is a wholly-owned taxable subsidiary of AARP. AARP Services manages the provider relationships for and performs quality control oversight of the wide range of products and services that carry the AARP name and are made available by independent providers as benefits to AARP’s millions of members. The provider offers currently span health products, financial products, travel and leisure products, and life event services. Specific products include Medicare supplemental insurance; credit cards, auto and home, mobile home and motorcycle insurance, life insurance and annuities; member discounts on rental cars, cruises, vacation packages and lodging; special offers on technology and gifts; pharmacy services and legal services. AARP Services also engages in new product development activities for AARP and provides certain consulting services to outside companies.<br/><br/>As the Data Engineer for the Marketing team with AARP Services, you will administer and oversee systems, tools and technologies for CRM Databases and member advertising platforms. In addition, you will design and implement data architecture including designing data pipelines, creating data models, and ensuring high performance, low latency as well as accuracy, completeness, and consistency of data.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Writes code proficiently to generate answers to analytic inquiries.</li><li>Manages the intake and output process for technical and non-technical internal audiences requesting analytic projects.</li><li>Utilizes data engineering procedures to feature engineer, move data, and produce and/or automate products, especially those including large amounts of data.</li><li>Develops reports and data visualizations to answer a broad range of questions.</li><li>Generates insights to be shared with internal customers.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Bachelor’s degree in a related field or relevant years of experience in lieu of degree</li><li>3+years of related experience; including programming and cloud platforms preferably on data management processes, data engineering, or data analytics</li><li>2+ years on Python, PySpark, Databricks, Snowflake, etc.</li><li>Data analysis experience is required</li><li>Experience with digital audience platforms preferred</li><li>Technical project management and vendor resource management experience preferred</li><li>AWS Architect and/or Cloud certifications preferred<br/><br/></li></ul><strong>Additional Requirements<br/><br/></strong><ul><li>Regular and reliable job attendance</li><li>Effective verbal and written communication skills</li><li>Exhibit respect and understanding of others to maintain professional relationships</li><li>Independent judgement in evaluation options to make sound decisions</li><li>In office/open office environment with the ability to work effectively surrounded by moderate noise<br/><br/></li></ul><strong>Flexible Work Arrangement (FWA)<br/><br/></strong>AARP observes Mondays and Fridays as telecommuting workdays, except for essential functions. Remote work and telecommuting can only be done within the United States and its territories.<br/><br/><strong>Compensation And Benefits<br/><br/></strong>AARP offers a competitive compensation and benefits package including a 401(k); 100% company-funded pension plan; health, dental, and vision plans; life insurance; paid time off to include company and individual holidays, vacation, sick, caregiving, and parental leave; performance-based and peer-based recognition; tuition reimbursement; among others.<br/><br/><strong>Equal Employment Opportunity<br/><br/></strong>AARP is an equal opportunity employer committed to hiring a diverse workforce and sustaining an inclusive culture. AARP does not discriminate on the basis of race, ethnicity, religion, sex, color, national origin, age, sexual orientation, gender identity or expression, mental or physical disability, genetic information, veteran status, or on any other basis prohibited by applicable law.
      </div>",No Salary Info Found,Big Data Engineer
Data Solutions Engineer,Analytica,12/20/2023,https://www.linkedin.com/jobs/view/3785044139,0,https://media.licdn.com/dms/image/C4E0BAQGyzLU9Qb95hw/company-logo_100_100/0/1658342420509/analytica_inc_logo?e=2147483647&v=beta&t=wF68HG0sSTrJ2mQejOakqwBKKS6YFrqcLmgQHiH6iOI,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>ANALYTICA is seeking a <strong>Data Solutions Engineer</strong>to support a federal government client in the DC metro area (Note - your work location is REMOTE). In this assignment, you will be a team member serving the client in advancing the customers use data, metadata, as well as explore new technologies to better meet those needs.<br/><br/>This is a mission that takes some serious smarts, intense curiosity and a background in developing data solutions across the data lifecycle.<br/><br/>Analytica has been recognized by Inc. Magazine as the fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. As a core member you’ll work with a diverse team of professionals to solution matters, architect nuisances, and come up with alternatives. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.<br/><br/><strong>Responsibilities include (But Are Not Necessarily Limited To):</strong></p><ul><li>Research, design, build, optimize and maintain reliable, efficient, and accessible data models, systems and pipelines/APIs etc.</li><li>Support, with guidance, the analytic and/or operational use of data.</li><li>Align closely with Enterprise partners in data science, architecture, governance, infrastructure, and security to apply standards and optimize production environments and practices.</li><li>Collaborate with business owners to optimize data collection, movement, storage, and usage to data process and data quality.</li><li>Convert concepts &amp; ideas into workable prototypes (custom or COTS products) for client reviews and acceptance.</li><li>Translate business needs into:<ul><li>data architecture solutions development within supported data systems.</li><li>data orchestration pipelines (source to target analysis &amp; recommendations), data sourcing, cleansing, augmentation and quality control processes within supported data systems.</li><li>Prototype, test and integrate new data tools (i.e. data features and functionality) as defined by the product owners and business teams</li></ul></li></ul><p>Competency and skill set will determine level of placement within the posted job family.<br/><br/><strong>Qualifications:</strong></p><ul><li>Bachelor’s degree incomputer science, information systems management or similarly related degree.</li><li>7+ years of professional data solutions development and implementation experience with:<ul><li>AWS (Glue, Athena, API Gateway)</li><li>SQL, NoSQL</li><li>Data developments with modeling tools such as Neo4J, Erwin, Embarcadero, transforming logical, physical, conceptual, reverse engineering &amp; forward engineering.</li><li>Development with Alation and/or EASparx</li><li>Data Movement tools such as Informatica &amp; others…</li><li>Unit testing</li><li>RESTful API Development</li><li>Desire and willingness to learn new data tools</li></ul></li><li>​​​Has an Agile mindset and iterative development process background<ul><li>Help promote a culture of diversity and inclusion within the department and the larger organization</li><li>Value different ideas and opinions</li><li>Listen courageously and remain curious in all that you do</li></ul></li><li>CMS data experience a must</li><li>CMS Public Trust clearance, EUA highly preferred</li></ul><p><strong>Valuable Experience:</strong></p><ul><li>AWS CDK and/or other AWS services (or comparable cloud data solutioning tools)</li><li>Experience with Git and CICD pipelines</li><li>Relational database design</li><li>Microservices / Containers (Docker, Kubernetes)</li><li>Informatica Intelligent Cloud Services (IICS)</li><li>Prior experience with CMS, preferably within clinical quality or standards area</li></ul><p><br/><strong>About</strong><strong>ANALYTICA</strong>: Analytica is a leading consulting and information technology solutions provider to public sector organizations supporting health, civilian, and national security missions. Founded in 2009 and headquartered in Bethesda, MD., the company is an established8(a) small businessthat has been recognized by<em>Inc. Magazine</em>each of the past three years as one of the 250 fastest-growing companies in the U.S. Analytica specializes in providing software and systems engineering, information management, analytics &amp; visualization, agile project management, and management consulting services. The company is appraised by the Software Engineering Institute (SEI) atCMMI® Maturity Level 3and is anISO 9001:2008 certifiedprovider.<br/><br/>As a federal contractor, Analytica is required to verify that all employees are fully vaccinated against COVID-19. If you receive an offer and are unable to get vaccinated for religious or medical reasons, you may request a reasonable accommodation.<br/><br/></p>
</div>",No Salary Info Found,Big Data Engineer
Data Engineer,Definitive Logic a ManTech Company,12/20/2023,https://www.linkedin.com/jobs/view/3785058078,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083990,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $140,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$140000- $173000,Big Data Engineer
Senior Data Engineer,AssetMark,12/23/2023,https://www.linkedin.com/jobs/view/3760885547,0,https://media.licdn.com/dms/image/D560BAQEXLjsOYiLvGg/company-logo_100_100/0/1684346917576/assetmark_logo?e=2147483647&v=beta&t=R5XiKmQsk6LmXop_xtTrwn0Zt7tXIvq8nDKsiywxD6c,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description:<br/><br/></strong><strong>AssetMark</strong> is a leading strategic provider of innovative investment and consulting solutions serving independent financial advisors. We provide investment, relationship, and practice management solutions that advisors use in helping clients achieve wealth, independence, and purpose.<br/><br/><strong>The Job/What You'll Do:<br/><br/></strong>As a Data Architect, you will play a pivotal role in shaping our data infrastructure and ensuring that data flows seamlessly through our organization. Your primary responsibilities will include:<br/><br/><ul><li>Designing, developing, and maintaining end-to-end master data pipelines that efficiently collect, process, transform, and load data from diverse sources into our data ecosystem.</li><li>Collaborating with cross-functional teams to understand business requirements and translate them into effective data architecture solutions.</li><li>Ensuring data quality, integrity, and security throughout the data lifecycle by implementing best practices and standards.</li><li>Optimizing data pipelines for performance, scalability, and reliability, and identifying opportunities for automation and process improvement.</li><li>Utilizing your expertise in SQL, Unix/Shell scripting, Python, and data processing frameworks to create and manage data transformations and integrations.</li><li>Utilizing concepts like Data warehouse, Data Lake house, Data Mess to share enterprise data strategies.</li><li>Working closely with DevOps and Engineering teams to implement continuous integration and continuous deployment (CI/CD) pipelines for data-related processes.</li><li>Staying current with industry trends and emerging technologies in data architecture and applying that knowledge to drive innovation within the organization.</li><li>Bachelor's degree in Computer Science, Information Technology, or a related field (Master's degree preferred).</li><li>A minimum of 5 years of experience in data architecture, with a proven track record of designing and deploying master data pipelines.</li><li>Proficiency in SQL for data manipulation and retrieval from relational databases.</li><li>Strong scripting skills in Unix/Shell and Python for automating data processes and transformations.</li><li>Experience with data processing frameworks such as Apache Spark, Apache Flink, or similar technologies.</li><li>Familiarity with CI/CD tools and practices for automating deployment and monitoring of data pipelines.</li><li>Excellent problem-solving skills and the ability to optimize data workflows for performance and efficiency.</li><li>Solid understanding of data modeling, data warehousing concepts, and ETL processes.</li><li>Strong communication skills to collaborate effectively with cross-functional teams and articulate complex technical concepts to non-technical stakeholders.<br/><br/><br/></li></ul><strong>Knowledge, Skills, and Abilities:<br/><br/></strong><ul><li>In-depth experience of designing and implementing information solutions.</li><li>Experience in architecture practice, tools, and methodologies.</li><li>Demonstrate the ability to work well with others and exhibit leadership.</li><li>Have a track record of remaining unbiased toward specific technologies or vendors.</li><li>Be an excellent communicator and collaborator, engaging with multiple technical and business stakeholders and leaders.</li><li>Be able to translate the information architecture contribution to business outcomes into simple briefings for use by various data-and-analytics-related roles.</li><li>Organizationally savvy, with a good understanding of the enterprise's political climate and how to navigate, influence and persuade political waters.</li><li>Ability to communicate, influence and persuade peers and leadership.</li><li>Ability to understand the long-term (""big picture"") and short-term perspectives of situations.</li><li>Ability to quickly comprehend the functions and capabilities of new technologies.</li><li>Displays intellectual curiosity and integrity.<br/><br/><br/></li></ul><strong>Education &amp; Experience:<br/><br/></strong><ul><li>7+ years to 15 years A minimum of 12+ years of experience in IT, majority in information system design. Required and</li><li>3+ years to 7 years A minimum of 5 years as a Data Architect with progressively increasing responsibility.</li><li>Bachelor's Degree Computer and Information Science Bachelor’s in computer science Required</li><li>Master's Degree Computer and Information Science MS preferred<br/><br/><br/></li></ul><em>Candidates must be legally authorized to work in the US to be considered. We are unable to provide visa sponsorship for this position.<br/><br/></em><strong>Who We Are &amp; What We Offer:<br/><br/></strong>AssetMark’s mission is centered around helping financial advisors make a difference in the lives of their clients. To help them do that, we aim to provide advisors with holistic support. We offer compelling technology that facilitates a better client experience, consulting services that ensure advisors’ businesses are running at their best and a comprehensive suite of investment solutions. AssetMark’s platform empowers advisors to provide the highest level of service possible to their clients.<br/><br/>AssetMark’s culture is driven by our mission and connected by our values; Heart, Integrity, Excellence and Respect. You will join a team that lives these values every day by doing the best and what is right in all we do and encouraging different ideas for continual success and innovation. Additionally, we offer a wide range of benefits to meet the needs of our team members and their families.<br/><br/><ul><li>Flex Time Off or Paid Time/Sick Time Off</li><li>401K – 6% Employer Match</li><li>Medical, Dental, Vision – HDHP or PPO</li><li>HSA – Employer contribution (HDHP only)</li><li>Volunteer Time Off</li><li>Career Development / Recognition</li><li>Fitness Reimbursement</li><li>Hybrid Work Schedule<br/><br/><br/></li></ul>As an Equal Opportunity Employer, AssetMark is committed to building a diverse and inclusive workplace where everyone feels valued.<br/><br/>
</div>",No Salary Info Found,Big Data Engineer
Azure DevOps/Data Engineer/ Atlanta,Motion Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3790922792,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer,Robert Half,12/19/2023,https://www.linkedin.com/jobs/view/3788193038,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
"Lead Data Engineer, Supply Chain",Chick-fil-A Corporate Support Center,12/19/2023,https://www.linkedin.com/jobs/view/3707553158,0,https://media.licdn.com/dms/image/C4E0BAQFp7YtVucYbXQ/company-logo_100_100/0/1631324166255?e=2147483647&v=beta&t=SQzjWYbXrzFjZIzpTeWdd5UV470kZgeCadHl9HnirCM,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        As a part of the Chick-fil-A Supply Chain Data Services team, the Supply Chain Data Engineer will design and implement necessary analytics infrastructure on technically complex projects, focusing on developing solutions to data modeling and/or analytics technology needs. They must be able to quickly develop mastery of the needed subject across any line of business for which they are responsible. The role must have strong analytical and data modeling skills, a deep understanding of database technology and data use within analytic platforms, and they must have strong programming skills with SQL and/or Python<br/><br/>This role will directly support our Chick-fil-A Supply Chain data foundation, focusing on transforming data for business and analytic needs. The data engineer plays an essentail role, providing the business with the visibility required to manage our complex business. The ability to collaborate well with both IT and business partners to achive goals is also essential.<br/><br/>This role is also responsible to educate others about the use of key data assets and help drive overall data literacy.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Exhibits wide latitude in aligning business stakeholders and IT to translate business logic into scalable data and analytic solutions on complex projects</li><li>Enable a modern data architecture and/or referencing the need to build data models in support of advanced analytical models and systems</li><li>Develops ETL pipelines for general business consumption, establishing patterns for repeatable, scalable ETL work that others can leverage in their work</li><li>Develops tool, data, and analytics best practices for the SC analyst community and advising on their integration into operational practices</li><li>Designs specific tool implementations, understanding both Tableau and Alteryx performance (including server) and cloud compute performance requirements and expectations</li><li>Owns and is accountable for data model and code quality and any relevant documentation</li><li> Monitor data quality by:</li><li>Establishing concise data quality measurements</li><li>Developing automated models, dashboards and workflows necessary to track data quality</li><li>Researching and resolving ongoing data issues</li><li>Work closely with Data Governance Lead to follow established processes<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>3.2 GPA minimum</li><li>Bachelor’s degree in finance or a quantitative/technical discipline</li><li>Strong analytical skills</li><li>Attentiveness to details with the ability to understand business context</li><li>Ability to learn things quickly and work independently</li><li>Ability to communicate your results effectively to others</li><li>Ability to manage multiple projects and deadlines simultaneously</li><li>Proficiency in a data blending tool and a visualization tool<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li> Proficiency in Data Analysis, AWS Redshift, AWS S3, SQL, Python, Alteryx, Tableau preferred <br/><br/></li></ul><strong>Minimum Years Of Experience<br/><br/></strong>3<br/><br/><strong>Travel Requirements<br/><br/></strong>20%<br/><br/><strong>Required Level Of Education<br/><br/></strong>Bachelor's Degree<br/><br/><strong> Minimum GPA (4.0 Scale) <br/><br/></strong>3.2
      </div>",No Salary Info Found,Big Data Engineer
Hadoop and PySpark Developer,Infosys,12/19/2023,https://www.linkedin.com/jobs/view/3788411274,0,https://media.licdn.com/dms/image/D4D0BAQE7Zf1-vvfbUA/company-logo_100_100/0/1692876768583/infosys_logo?e=2147483647&v=beta&t=YVa7DOQnXWfEUBW6OoJC734Ry5EIksEedFcmoiEL8VY,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>Infosys is seeking Hadoop and PySpark Developer</strong>. The position will primarily be responsible to interface with key stakeholders and apply your technical proficiency across different stages of the Software Development Life Cycle including Requirements Elicitation, Application Architecture definition and Design. You will play an important role in creating high-level design artifacts. You will also deliver high quality code deliverables for a module, lead validation for all types of testing and support activities related to implementation, transition, and warranty. You will be part of a learning culture, where teamwork and collaboration are encouraged, excellence is rewarded, and diversity is respected and valued.<br/><br/><strong>Required Qualifications<br/><br/></strong><ul><li> Bachelor’s degree or foreign equivalent required from an accredited institution. Will also consider three years of progressive experience in the specialty in lieu of every year of education </li><li> Candidate must be located within commuting distance of Atlanta, GA or be willing to relocate to the area. This position may require travel to project locations. </li><li> At least 4 years of Information Technology experience. </li><li> Experience in end-to-end implementation of projects in Python and Spark, from Analysis, Design, Model to Coding &amp; testing and promote to production, especially Python server-side backend programming </li><li> Good understanding of OOPS concepts </li><li> Strong knowledge in Data Structures, Algorithms, Collections, Multi-threading and memory management, concurrency (GIL) </li><li> Strong knowledge and hands-on experience in SQL, Unix shell scripting </li><li> Experience in Big data ecosystem using Hadoop, Spark, Scala, Python packages and libraries for large scale data </li><li> U.S. citizens and those authorized to work in the U.S. are encouraged to apply. <br/><br/></li></ul><strong>Preferred Qualifications:<br/><br/></strong><ul><li> Sound Knowledge of Software engineering design patterns and practices </li><li> Strong understanding of Functional programming and RESTful APIs </li><li> Experience with design and implementation of ETL/ELT framework for complex warehouses/marts Knowledge of large data sets and experience with performance tuning and troubleshooting </li><li> Planning and Co-ordination skills </li><li> Good Communication and Analytical skills </li><li> Experience and desire to work in a Global delivery environment </li><li> Ability to work in teams in a diverse/ multiple stakeholder environment <br/><br/></li></ul>The job entails sitting as well as working at a computer for extended periods of time. Should be able to communicate by telephone, email or face to face. Travel may be required as per the job requirements.<br/><br/><strong>About Us<br/><br/></strong>Infosys is a global leader in next-generation digital services and consulting. We enable clients in 50 countries to navigate their digital transformation. With over four decades of experience in leading the systems and workings of global enterprises, we expertly steer our clients through their digital journey. We do it by enabling the enterprise with an AI-powered core that helps prioritize the execution of change. We also empower the business with agile digital at scale to deliver outstanding levels of performance and customer delight. Our always-on learning agenda drives their continuous improvement through building and transferring digital skills, expertise, and ideas from our innovation ecosystem.<br/><br/>To learn more about Infosys and see our perspectives in action please visit us at<br/><br/><strong>Infosys is an equal opportunity employer and all qualified applicants will receive consideration without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, spouse of protected veteran, or disability.</strong>
</div>",No Salary Info Found,Big Data Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765470292,0,https://media.licdn.com/dms/image/D560BAQFsPZUT0bTpJg/company-logo_100_100/0/1689000656484/bdo_usa_logo?e=2147483647&v=beta&t=-M1FfX9Kow8d2drx-DmltN3u3liHKtB3vVhqpNf3A8Q,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>Job Summary:<br/><br/></strong>This position will work with cutting edge technology, deliver high quality solutions across various industries, and oversee team(s) on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.<br/><br/><strong>Job Duties<br/><br/></strong><ul><li> Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS </li><li> Listens to client needs to align solution with business requirements and delivery schedule </li><li> Creates written functional and technical designs </li><li> Participates in project status and stand meetings, and assists with providing aggregated project status for project and program managers </li><li> Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions </li><li> Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles </li><li> Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency) </li><li> Assists with implementation of data governance programs and best practices </li><li> Performs the cleaning and transforming of data from source systems into analytics models </li><li> Implements models to support data visualizations and integrations </li><li> Assists with implementing DevOps, DataOps and MLOps methodologies on projects </li><li> Writes custom integration logic in applicable programming languages </li><li> Assists project managers with work breakdown structure creation, project estimation, resource staffing, workload planning and adjustments throughout the project lifecycle </li><li> Assists clients with licensing, security, and cost estimation of solutions </li><li> Performs code reviews to ensure adherence to standards </li><li> Works directly with clients and team members to establish secure data analytics platforms and infrastructure </li><li> Contributes to successful deployments of developed solutions and integration of DevOps tools </li><li> Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools </li><li> Builds client relationships during project execution, effectively becoming a trusted advisor of the client </li><li> Participates in support activities for existing software solutions </li><li> Other duties as assigned <br/><br/><br/></li></ul><strong>Supervisory Responsibilities<br/><br/></strong><ul><li> Supervises the day-to-day workload of Associates on assigned engagements to ensure that timelines and deliverables are met, and reviews work product <br/><br/><br/></li></ul><strong>Education<br/><br/></strong><strong>Qualifications, Knowledge, Skills and Abilities:<br/><br/></strong><ul><li> High School Diploma or GED equivalent, required </li><li> Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred <br/><br/><br/></li></ul><strong>Experience<br/><br/></strong><ul><li> Five (5) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required </li><li> One (1) or more years of experience technically leading development projects, preferred </li><li> One (1) or more years of consulting experience or implementation of cloud-based data analytics solutions, preferred <br/><br/><br/></li></ul><strong>Software<br/><br/></strong><ul><li> Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required </li><li> Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, required </li><li> Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred </li><li> Experience with one (1) or more of the following computer languages, preferred:</li><ul><li> C# </li><li> Python </li><li> Java </li><li> Scala </li></ul><li> Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred </li><li> Experience with Git and DevOps deployment technologies, preferred </li><li> Experience with Linux, preferred </li><li> Experience with one (1) or more of the following, preferred:</li><ul><li> Data Lake Medallion Architecture </li><li> Batch and/or streaming data ingestion into a data lake </li><li> AI Algorithms/Machine Learning </li><li> Automation tools such as UiPath, Alteryx, etc. </li><li> Computer Vision based AI technologies <br/></li></ul></ul><strong>Other Knowledge, Skills &amp; Abilities<br/><br/></strong><ul><li> Ability to work with a high degree of professionalism and autonomy </li><li> Excellent verbal and written communication skills </li><li> Solid organizational skills, especially the ability to meet project deadlines with a focus on details </li><li> Ability to successfully multi-task while working independently or within a group environment </li><li> Ability to work in a deadline-driven environment, and handle multiple projects simultaneously </li><li> Ability to interact effectively with people at all organizational levels of the Firm </li><li> Ability to effectively interact with a team of professionals and delegating work assignments, as needed </li><li> Ability to build and maintain strong relationships with internal and client personnel </li><li> Ability to encourage a team environment on engagements, and contribute to the professional development of assigned personnel <br/><br/><br/></li></ul><strong>Keywords:</strong> Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL<br/><br/>Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.<br/><br/>California Range: $111,000 - $152,000<br/><br/>Colorado Range: $111,000 - $152,000<br/><br/>New York City/ Valhalla Range: $111,000 - $152,000<br/><br/>Washington Range: $111,000 - $152,000<br/><br/><strong>About Us<br/><br/></strong>BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.<br/><br/><ul><li>Unparalleled partner-involvement </li><li>Deep industry knowledge and participation</li><li>Geographic coverage across the U.S.</li><li>Cohesive global network </li><li>Focused capabilities across disciplines<br/><br/><br/></li></ul>BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.<br/><br/>BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best &amp; Brightest Companies to Work For and more.<br/><br/><strong>Some Examples Of Our Total Rewards Offerings Include<br/><br/></strong><ul><li>Competitive pay and eligibility for an annual performance bonus. </li><li>A 401k plan plus an employer match</li><li>Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one</li><li> Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays </li><li>Paid Parental Leave</li><li>Adoption Assistance</li><li>Firm paid life insurance</li><li>Wellness programs</li><li>Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance <br/><br/><br/></li></ul>Above offerings may be subject to eligibility requirements.<br/><br/>Click here to find out more!<br/><br/>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.<br/><br/>""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""<br/><br/>
</div>",$111000- $152000,Big Data Engineer
Sr Data Engineer,The Fountain Group,12/19/2023,https://www.linkedin.com/jobs/view/3784094967,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
SW Engineer Cloud/Dashboard Analytics,NCR Atleos,12/19/2023,https://www.linkedin.com/jobs/view/3755584883,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
AWS Data Engineer,Intellectt Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788188147,0,https://media.licdn.com/dms/image/C560BAQFOYtI3qgbARA/company-logo_100_100/0/1630625069813/intellecttinc_logo?e=2147483647&v=beta&t=QjDuPUOAXTaOhbAni4QxTWKLIOJeaSPWmg-8rdZ7lJ0,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<ul><li>12+ years experience required.</li><li>Must be able to handle Data engineering operations / enhancement project with a technical consultant bend. </li><li>SQL, Python, PySpark , S3, Lambda, EMR, Glue, Athena, EC2, IAM, Redshift, DMS, Airflow, Jenkins, Snowflake. </li><li>End-to-end data solutions (ingest, storage, integration, processing, access) on AWS. </li><li>Migrate data from traditional relational database systems to AWS relational databases such as Amazon RDS, Aurora, and Redshift. </li><li>12+ years IT experience. Background and experience in data engineering/analytics. </li><li>Should have a very good hands-on experience in Cloud DB platforms (Snowflake is preferable), Building data pipelines &amp; SQL, Python for Data Engineering. </li><li>Got experience to Perform, Support and Lead all aspects of Data Engineering strategy. </li><li>Excellent root cause analysis skills. </li><li>Ensure effective data pipeline engineering, deployment, ongoing operations, and continuous improvement. </li><li>Certification in Data Engineering and/or Cloud Platforms are a plus. </li><li>Good written and verbal communication skills, and comfortable presenting findings to Sr. Management.</li></ul>
</div>",No Salary Info Found,Big Data Engineer
Senior Data Engineer,SiriusXM,12/19/2023,https://www.linkedin.com/jobs/view/3732586345,0,https://media.licdn.com/dms/image/D560BAQGZYZJBUsuzbg/company-logo_100_100/0/1700146850253/siriusxm_logo?e=2147483647&v=beta&t=mV830XuN8ytZ4D5kSWTIg2jiQLNLiCpQLTTSfAE8xhY,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Who We Are<br/><br/></strong>SiriusXM and its brands (Pandora, SXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners -- in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories and music they love wherever they are.<br/><br/>This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically-acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day.<br/><br/><strong>SiriusXM<br/><br/></strong>SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150 million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics and monetization. The Company’s advertising sales organization, which operates as SXM Media, leverages its scale, cross-platform sales organization and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through Sirius XM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers.<br/><br/><strong>How You’ll Make An Impact<br/><br/></strong>In this role you’ll join a team who designs, builds, and maintains data products that enable critical decision making across the company through experimentation. Experimentation is a key driver of the product development process, and this role will put you at the center of the platform that solves this at scale.<br/><br/><strong>What You’ll Do<br/><br/></strong><ul><li>Build flexible cloud-based data pipeline frameworks to produce statistical analyses of user outcomes</li><li>Build and improve workflow orchestration tooling to support efficient data pipelines. E.g. airflow plugins, systems integration, deployments</li><li>Build tooling to support ML workflows for statistical analysis</li><li>Build monitoring dashboards for stakeholders to better understand the health, performance, and cost of the platform</li><li>Write documentation to encourage adoption of platform tools and support users in their use</li><li>Strengthen corporate best practices around data engineering software development processes</li><li>Collaborate closely with cross-functional teams to launch new analyses in a way that’s reliable and scalable<br/><br/></li></ul><strong>What You’ll Need<br/><br/></strong><ul><li>5+ years’ experience developing data ETL pipelines and data tools in Scala and/or Python</li><li>BS/MS or above in Computer Science or relevant experience</li><li>Experience with data warehouse technologies: MapReduce, HDFS, Hive, Tez, Spark, Sqoop</li><li>Experience with streaming technologies - Kafka, Kafka Connect, KStreams, KSQL, Beam, Flink, Spark</li><li>Experience developing SQL applications of significant complexity</li><li>Experience with cloud computing - Google Cloud Platform, Amazon Web Services</li><li>Experience developing for Linux-based deployment platforms, developing scalable server-side software for deployment</li><li>Experience developing service-oriented architectures/orchestration</li><li>Experience with API design/development – RPC, REST, JSON</li><li>Experience with unit and integration testing frameworks</li><li>Experience with CI/CD, build and deployment technologies such as Jenkins</li><li>Experience with Data Visualization or Data Notebook tools (i.e Zeppelin, Tableau, etc.)</li><li>Experience working in a Cloud Environment (AWS, GCP, etc.)</li><li>Experience developing and deploying machine learning algorithms</li><li>Experience developing with additional languages - R, Scala</li><li>Experience with workflow tools – Airflow/Composer/Luigi</li><li>Experience with data serialization system - Avro, Protobuf</li><li>Interpersonal skills and ability to interact and work with staff at all levels.</li><li>Excellent written and verbal communication skills.</li><li>Ability to work independently and in a team environment.</li><li>Ability to project professionalism over the phone and in person.</li><li>Ability to handle multiple tasks in a fast-paced environment.</li><li>Commitment to “internal client” and customer service principles.</li><li>Willingness to take initiative and to follow through on projects.</li><li>Creative writing ability.</li><li>Excellent time management skills, with the ability to prioritize and multi-task, and work under shifting deadlines in a fast-paced environment.</li><li>Must have legal right to work in the U.S<br/><br/></li></ul>At SiriusXM, we carefully consider a wide range of factors when determining compensation, including your background and experience. These considerations can cause your compensation to vary. We expect the base salary for this position to be in the range of $126,000 to $145,800 and will depend on your skills, qualifications, and experience. Additionally, this role might be eligible for discretionary short-term and long-term incentives. We encourage all interested candidates to apply.<br/><br/><strong> <br/><br/></strong>Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.<br/><br/>The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.<br/><br/>R-2023-08-81
      </div>",$126000- $145800,Big Data Engineer
Senior Data Cloud Engineer,Kforce Inc,12/22/2023,https://www.linkedin.com/jobs/view/3786710170,0,https://media.licdn.com/dms/image/C4D0BAQEtonVHDHqAZQ/company-logo_100_100/0/1639415775313/kforce_logo?e=2147483647&v=beta&t=Y9PI5HIUZlNyOdpcqLYN0HHYEB1dr-aso4niUcJtuIY,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong>Kforce has a client in San Diego, CA that is seeking a Senior Cloud Data Engineer to be Hybrid - 3 days onsite in La Jolla, CA area. Responsibilities and Duties:<br/><br/><ul><li> Senior Data Cloud Engineer will create data systems used in the company's products</li><li> Working closely with a diverse group of hardware &amp; software engineers, systems engineers, and product managers from requirements definition through design, implementation, and testing</li><li> Creating product database schemas and managing lifecycle migrations</li><li> As a Senior Data Cloud Engineer, you will create an automated data archiving strategy including storage migration between the product's PC and customer SAN/NAS</li><li> Creating and managing software build systems</li><li> Creating data repository APIs used in company software products using JPA and/or JDBC</li><li> Creating and managing the cloud data infrastructure including building a data lake, data warehouses, apps, and data pipelines<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li> Bachelor's degree in Computer Science or a related field</li><li> 7+ years of experience as a member of Software Development &amp; IT Teams</li><li> Experience using Windows 11 Networking</li><li> Expertise using Gradle in a multi-module project</li><li> Expertise using Git, including use of submodules</li><li> Expertise with CI/CD using Bitbucket Pipelines</li><li> Expertise using Spring Data JPA and/or JDBC</li><li> Expertise with AWS and/or Heroku</li><li> Expertise with Bitbucket Pipelines</li><li> Java 17+ (for persistence API Development)<br/><br/></li></ul>The pay range is the lowest to highest compensation we reasonably in good faith believe we would pay at posting for this role. We may ultimately pay more or less than this range. Employee pay is based on factors like relevant education, qualifications, certifications, experience, skills, seniority, location, performance, union contract and business needs. This range may be modified in the future.<br/><br/>We offer comprehensive benefits including medical/dental/vision insurance, HSA, FSA, 401(k), and life, disability &amp; ADD insurance to eligible employees. Salaried personnel receive paid time off. Hourly employees are not eligible for paid time off unless required by law. Hourly employees on a Service Contract Act project are eligible for paid sick leave.<br/><br/>Note: Pay is not considered compensation until it is earned, vested and determinable. The amount and availability of any compensation remains in Kforce's sole discretion unless and until paid and may be modified in its discretion consistent with the law.<br/><br/>This job is not eligible for bonuses, incentives or commissions.<br/><br/>Kforce is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.<br/><br/>Salary: $160,000 - $170,000 per year
      </div>",$160000- $170000,Big Data Engineer
Staff/ Lead Software Engineer (FinTech) [Bangkok based – Relocation provided],Agoda,12/22/2023,https://www.linkedin.com/jobs/view/3742048645,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer,National Funding,12/20/2023,https://www.linkedin.com/jobs/view/3785066474,0,https://media.licdn.com/dms/image/C560BAQHV-zFAv771ig/company-logo_100_100/0/1631366268064?e=2147483647&v=beta&t=k69XYet-Fe78rYD8CnY8BCcRPZIRanWfZTxplomo3fc,San Diego Metropolitan Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Data Engineer </strong>- San Diego, CA or Orange County, CA</p><p><br/></p><p>Hybrid 3 days/week, Full time M-F 8am-5pm PST</p><p><br/></p><p>Being authorized to work in the U.S. is a precondition of employment.</p><p>National Funding does not consider candidates requiring 1099 or C2C.</p><p><br/></p><p>Exempt/Salary: $101,000-$151,000 + Bonus Incentive</p><p><br/></p><p>National Funding is continuing to grow its Data Analytics Department and has an exciting opportunity for a<strong> Data Engineer</strong>. Reporting to the Director of BI, the Data Engineer will help implement a new Snowflake Data Warehouse initiative.</p><p><br/></p><p><strong>Responsibilities: </strong></p><p>• The data engineer will participate in the data warehouse implementation and work closely with the DW team including analysts, BI developers, and SME experts. This includes the full DW lifecycle of requirements gathering, data modeling, data mapping, ETL, reporting and QA.</p><p>• The primary responsibility will be ETL work using dbt integrating data, applying business rules and transformations, creating both normalized and de-normalized data.</p><p>• They will be creating various ETL frameworks in dbt to semi-automate data transformation. This includes the full life cycle of ETL: applying business rules, data aggregation, data cleansing, and QA.</p><p>• Other responsibilities include supporting other data engineers working on administration, data sourcing, data orchestration, notifications, data lineage, and related aws work</p><p><br/></p><p><strong>Knowledge, Skills and Abilities Required: </strong></p><p>• 3+ years' experience working as a Data Engineer and 5+ years in Data warehouse, ETL, BI projects.</p><p>• Must have experience in dbt, or related ETL products.</p><p>• Expertise in data modeling, ELT using SQL, implementing complex stored Procedures and standard DWH and ETL concepts.</p><p>• Expertise in advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understanding how to use these features.</p><p>• Preferably having experience with aws data storage and management technologies such as S3.</p><p><br/></p><p><strong>Nice to have skills:</strong></p><p>• Hands-on experience with Snowflake utilities, SnowSQL, SnowPipe, techniques using UDFs.</p><p>• Deep understanding of relational data stores, methods, and approaches (star and snowflake, dimensional modeling).</p><p>• Snowflake certification a plus.</p><p>• Experience in creating frameworks in Snowflake:</p><p>- SCD framework</p><p>- Business Rules Engine</p><p>- Jobs Scheduling</p><p>- Capture Data Errors</p><p>- Data Transformations</p><p>- Snapshot data capture</p><p><br/></p><p><strong>Physical Demands:</strong></p><p>• Working in a temperature-controlled office environment</p><p>• Sitting at a desk for prolonged periods of time while viewing multiple computer screen monitors</p><p>• Potential lifting of boxes around 5-10lbs</p><p><strong>Why National Funding?</strong></p><ul><li>Positive, energetic, passionate, business casual environment with management who commits to your success</li><li>Fantastic benefits package: Our current benefit package includes medical, dental, vision, life, LTD and AD&amp;D insurance as well as a 401(k) Retirement Savings plan with an employer match. Eligibility for all benefits will start at the first of the month following 60 days of employment.</li><li>Numerous employee events throughout the year, including our annual traditions such as a Day at the Del Mar Racetrack, Del Mar Mud Run, Bring Your Kid to Work Day, Holiday Party, Employee and Family Picnic, sporting events and more.</li></ul><p><strong>National Funding</strong> is one of the leading providers of short-term loans and equipment leasing for small businesses across the United States. In both 2013 and 2014, we were ranked by the San Diego Business Journal as one of the 100 Fastest Growing Private Companies in San Diego and listed on the Inc. 5000 List of America’s Fastest Growing Private Companies. We serve the small business community nationwide by offering a range of financial services and products. Since 1999, we have been in the forefront of the equipment leasing business, working with businesses in hundreds of communities and industries to expand and upgrade their business equipment. As we have grown, so too has our product line, and now we are one of the country’s largest private lenders of small business loans. Our customers call on us to get working capital, merchant cash advances, credit card processing, and of course, equipment leasing.</p><p><br/></p><p>National Funding is an Equal Opportunity Employer.</p>
</div>",$101000- $151000,Big Data Engineer
"Healthcare Senior Data Engineer, Analytics Hub",ECG Management Consultants,12/20/2023,https://www.linkedin.com/jobs/view/3790406527,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789762711,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        A market leader in the analytics space, specifically focusing on analytics for the entertainment space is hiring a Senior Data Engineer to join their team of 5. This role will be a lot of new development and migrations as they are moving their SQL based pipelines over to Python, AWS, and Spark so strong SQL experience is a big plus. This company processes tens of billions of rows of data every year and has almost 20TB of processing data. The main tech stack for this role is SQL, Python, AWS, and Spark experience. This team also uses Glue, Power BI, Anthem, EMR, PySpark, and any experience working with marketing metrics/analysis is a plus. You will be building new capabilities for their analytics teams, integrating big data tools and moving to AWS within their pipelines.<br/><br/>This role is looking for someone to work PST hours. If you are local to Southern California that is a big plus but not required as this role is 100% fully remote. This is a small team so they ideally need someone open to wearing a few different hats who can interact with various teams within the organization so good communication is a must.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>5+ years professional Data Engineering Experience </li><li>Background in DBA/SQL Development </li><li>5 years of experience building ETL pipelines with Python, AWS, and Spark/PySpark </li><li>Experience working with large amounts of data <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Bachelors in STEM field </li><li>Excellent written and verbal communication skills </li><li>Any experience with Glue, Power BI, Anthem, or EMR </li><li>Experience working with marketing metrics data <br/><br/></li></ul>The Offer<br/><br/><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Sick Time </li><li>Paid Time Off </li><li>401(k) with match </li><li>Annual Bonus </li><li>Remote PST time <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Cassi Benson
      </div>",No Salary Info Found,Big Data Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765472151,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
CoStar Group - Senior Machine Learning Engineer,CoStar Group,12/19/2023,https://www.linkedin.com/jobs/view/3790343983,0,https://media.licdn.com/dms/image/C4E0BAQG3aaai8L_lEA/company-logo_100_100/0/1630644550246/costar_group_logo?e=2147483647&v=beta&t=zd1w8rSUJehBCWm2xn00s6DSnoJt8fApF0uDXcJfkAc,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>CoStar Group (NASDAQ: CSGP) is a leading global provider of commercial and residential real estate information, analytics, and online marketplaces. Included in the S&amp;P 500 Index and the NASDAQ 100, CoStar Group is on a mission to digitize the world’s real estate, empowering all people to discover properties, insights and connections that improve their businesses and lives.<br/><br/>We have been living and breathing the world of real estate information and online marketplaces for over 35 years, giving us the perspective to create truly unique and valuable offerings to our customers. We’ve continually refined, transformed and perfected our approach to our business, creating a language that has become standard in our industry, for our customers, and even our competitors. We continue that effort today and are always working to improve and drive innovation. This is how we deliver for our customers, our employees, and investors. By equipping the brightest minds with the best resources available, we provide an invaluable edge in real estate.<br/><br/>Homes.com is already one of the fastest growing real estate portals in the industry, we are driven to be #1. Just ask Brad Bellflower, Chief Change Officer at Apartments.com. After its acquisition in 2014, Apartments.com quickly turned into the most popular place to find a place. Proven success at the highest level – and we’re doing it again with the new Homes.com. Homes.com is a CoStar Group company with 20+ years' experience in leading and growing digital marketplaces. We pride ourselves on continually improving, innovating, and setting the standard for property search and marketing experiences. With Homes.com we’re building a brand on the cusp of defining the industry. We’re looking for big thinkers, brave leaders, and creative advertising wizards ready to influence a new age of homebuying within a tried-and-true, award-winning company.<br/><br/>Learn more about Homes.com<br/><br/>Machine Learning Engineers at CoStar play an important role in this process, by mining data from sources including billions of pageviews, millions of images, vast geographic data, deep property content, and much more. We enhance our extensive property database, personalize our customers’ experience on our product websites, and create innovative datasets and forecasts that are the industry standards in our market leading products.<br/><br/>We are searching for a Senior Machine Learning Engineer to join our collaborative group that includes a mix of big data, API, and full stack development teams. We are growing rapidly to help invent the future of Real Estate, with Data Science playing a critical role in that growth.<br/><br/>This position is located in San Diego, CA (UTC Area), and offers the following hybrid schedule option:<br/><br/><ul><li> 3 days onsite, 2 days remote<br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li>Collaborate on the continued improvement of CoStar’s cloud-based machine learning environment.</li><li>Design, build, test and deploy scalable, reusable, and maintainable models that handle large amounts of data.</li><li>Collaborate with other engineers, product owners, and leadership to create ML solutions that solve practical problems and improve our customer’s experience.</li><li>Gain an understanding of the CoStar business and how ML can improve things.<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><ul><li>Bachelor’s Degree required from an accredited, not for profit university or college. MSc or PhD is a plus. </li><li>A track record of commitment to prior employers</li><li>5+ years of professional development experience as Machine Learning Engineer, Data Scientist or related role</li><li>5+ years of programming experience with modern languages such as Python, C#, Java, or Scala.</li><li>Work experience with Image Classification, Object Detection, NER, or Recommendation Systems.</li><li>Experience building data pipelines to collect data, train and test models, measure model performance, run inference on large datasets, and output results.</li><li>Experience with ML libraries such as TensorFlow, Keras, and Scikit-learn.</li><li>Experience with data manipulation and visualization libraries such as pandas, matplotlib, seaborn, or Plotly.</li><li>Strong math and analytical skills.<br/><br/></li></ul><strong>Preferred Qualifications And Skills<br/><br/></strong><ul><li>Experience with databases, such as SQL Server, AWS RDS, DynamoDB.</li><li>Experience solving streaming and batch data processing problems at scale.</li><li>Experience with ML cloud tools such as Databricks, Amazon Personalize, Comprehend, SageMaker, and Rekognition.</li><li>Experience with integration of input data from a variety of sources.<br/><br/></li></ul><strong>What’s In It For You<br/><br/></strong>When you join CoStar Group, you’ll experience a collaborative and innovative culture working alongside the best and brightest to empower our people and customers to succeed.<br/><br/>We offer you generous compensation and performance-based incentives. CoStar Group also invests in your professional and academic growth with internal training, tuition reimbursement, and an inter-office exchange program.<br/><br/><strong>Our Benefits Package Includes (but Is Not Limited To)<br/><br/></strong><ul><li>Comprehensive healthcare coverage: Medical / Vision / Dental / Prescription Drug</li><li>Life, legal, and supplementary insurance</li><li>Virtual and in person mental health counseling services for individuals and family</li><li>Commuter and parking benefits</li><li>401(K) retirement plan with matching contributions</li><li>Employee stock purchase plan</li><li>Paid time off</li><li>Tuition reimbursement</li><li>On-site fitness center and/or reimbursed fitness center membership costs (location dependent), with yoga studio, Pelotons, personal training, group exercise classes</li><li>Access to CoStar Group’s Diversity, Equity, &amp; Inclusion Employee Resource Groups</li><li>Complimentary gourmet coffee, tea, hot chocolate, fresh fruit, and other healthy snacks<br/><br/></li></ul>We welcome all qualified candidates who are currently eligible to work full-time in the United States to apply. However, please note that CoStar Group is not able to provide visa sponsorship for this position.<br/><br/>This position offers a base salary range of <strong>$143,000 - </strong><strong>$231,000</strong>, based on relevant skills and experience and includes a generous benefits plan.<br/><br/>CoStar Group is an Equal Employment Opportunity Employer; we maintain a drug-free workplace and perform pre-employment substance abuse testing<br/><br/>
</div>",$143000- $231000,Big Data Engineer
"Data Conversion Developer, Senior Associate",PwC,12/19/2023,https://www.linkedin.com/jobs/view/3749933940,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
CoStar Group - Principal Software Engineer,CoStar Group,12/19/2023,https://www.linkedin.com/jobs/view/3708432830,0,https://media.licdn.com/dms/image/C4E0BAQG3aaai8L_lEA/company-logo_100_100/0/1630644550246/costar_group_logo?e=2147483647&v=beta&t=zd1w8rSUJehBCWm2xn00s6DSnoJt8fApF0uDXcJfkAc,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>Job Description<br/><br/>CoStar Group (NASDAQ: CSGP) is a leading global provider of commercial and residential real estate information, analytics, and online marketplaces. Included in the S&amp;P 500 Index and the NASDAQ 100, CoStar Group is on a mission to digitize the world’s real estate, empowering all people to discover properties, insights and connections that improve their businesses and lives.<br/><br/>We have been living and breathing the world of real estate information and online marketplaces for over 35 years, giving us the perspective to create truly unique and valuable offerings to our customers. We’ve continually refined, transformed and perfected our approach to our business, creating a language that has become standard in our industry, for our customers, and even our competitors. We continue that effort today and are always working to improve and drive innovation. This is how we deliver for our customers, our employees, and investors. By equipping the brightest minds with the best resources available, we provide an invaluable edge in real estate.<br/><br/>We develop CoStar's customer-facing Real Estate Analytics products. We think big, creating innovative data-intensive applications that take the vast amount of data collected by our CoStar Research teams to create a fast, reliable, and intuitive analytics platform for our customers.<br/><br/>Our CoStar for Lenders product development team is looking for an experienced Principal Software Engineer to own the architecture and design of our software systems, from full stack web products to high-volume, secure data pipelines. This role includes design of new greenfield systems, so being able to convert product requirements to system architecture is essential. It will also help guide the ongoing architectural evolution of our current solutions, meaning the ability to fully understand existing complex systems is required as well.<br/><br/>It is a highly collaborative role that comes with great influence on the technical solutions we are building and requires strong communication and cooperation across multiple teams and disciplines. This includes developers within the same team and Software Architects throughout the company. To be successful in this role you must be a problem-solving, collaborative person with deep technical skills, and the ability to work in a secure, performant, enterprise-scale environment.<br/><br/>This position is located in San Diego (UTC Area) and offers a hybrid schedule of 3 days onsite, 2 days remote.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Work in partnership with Product and Technology leadership to deeply understand a project’s complex functional requirements and drive implementation of appropriate technical solutions.</li><li>Collaborate with development teams to determine the right architectural direction based on project needs, level of effort, resourcing, timing, etc.</li><li>Understand existing systems and ensure they are well documented, so that you become a go-to source of architectural information across multiple systems.</li><li>Act as an architectural subject matter expert and source of good advice to technical leadership and developers.</li><li>Drive and evangelize architectural principles and guidelines to ensure high quality, consistent results across teams.</li><li>Partner with engineering managers to ensure that they are following established architectural best practices.</li><li>Create, organize, and maintain architectural diagrams and other system documentation.</li><li>Provide architectural guidance and mentoring to other technical staff on topics such as microservices, micro-frontends, high-volume data streaming / event processing, etc.</li><li>Stay up to date with emerging technologies, evaluate and development practices and identify how they might improve existing or new systems we are building.</li><li>Develop a deep understanding of the CoStar business, and how the technical work we are doing aligns with that strategy.</li><li>Advocate for and design solutions that are well-instrumented, so that we are confident we are building stable, high-performance products.</li><li>Be a go-to resource in the understanding and diagnosis of complex performance, scalability, and reliability issues.</li><li>Be an advocate for security and ensure that we are architecting and building secure software products and platforms.<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><ul><li>Bachelor’s degree, preferably in Computer Science/Engineering.</li><li>10+ years of hands-on experience in designing highly complex enterprise-level web applications, including deep knowledge of microservices, serverless, data, and web applications.</li><li>Experience designing and buildings secure systems and security minded development practices. Experience with financial data is a big plus.</li><li>Extensive experience in software engineering with expert-level proficiency in at least one of these programming languages: C#, Java, Python, JavaScript/TypeScript. Exposure to languages and platforms across the full web application stack is a big plus (e.g., GraphQL).</li><li>Significant, hands-on experience designing and implementing solutions using Amazon Web Services (AWS) services including Lambda, DynamoDB, CloudWatch, CloudFormation, SNS/SQS, S3, API Gateway, etc.</li><li>Experience with Test Driven Development methodologies.</li><li>Experience modeling and implementing large-scale relational and NoSQL database systems.</li><li>Experience designing/implementing event-oriented architectures and real-time data streaming solutions.</li><li>Strong ability to communicate through architectural diagrams.<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Architect-level certifications from AWS, Azure or GCP</li><li>Experience with agile development methodologies.</li><li>Experience with modern source control and CI/CD technologies including Git or Azure DevOps.</li><li>Experience establishing software development best practices, including standards, code reviews, source control, builds, testing and operations.</li><li>Experience with Infrastructure as Code in Terraform.</li><li>Experience in observability logging/tracing with CloudWatch and/or Kibana.</li><li>Experience building highly secure software, including tokenization, OpenID, etc.</li><li>Team or project leadership experience is a plus.<br/><br/></li></ul><strong>What’s In It For You<br/><br/></strong>When you join CoStar Group, you’ll experience a collaborative and innovative culture working alongside the best and brightest to empower our people and customers to succeed.<br/><br/>We offer you generous compensation and performance-based incentives. CoStar Group also invests in your professional and academic growth with internal training, tuition reimbursement, and an inter-office exchange program.<br/><br/><strong>Our Benefits Package Includes (but Is Not Limited To)<br/><br/></strong><ul><li>Comprehensive healthcare coverage: Medical / Vision / Dental / Prescription Drug</li><li>Life, legal, and supplementary insurance</li><li>Virtual and in person mental health counseling services for individuals and family</li><li>Commuter and parking benefits</li><li>401(K) retirement plan with matching contributions</li><li>Employee stock purchase plan</li><li>Paid time off</li><li>Tuition reimbursement</li><li>On-site fitness center and/or reimbursed fitness center membership costs (location dependent), with yoga studio, Pelotons, personal training, group exercise classes</li><li>Access to CoStar Group’s Diversity, Equity, &amp; Inclusion Employee Resource Groups</li><li>Complimentary gourmet coffee, tea, hot chocolate, fresh fruit, and other healthy snacks<br/><br/></li></ul>We welcome all qualified candidates who are currently eligible to work full-time in the United States to apply. However, please note that CoStar Group is not able to provide visa sponsorship for this position.<br/><br/>This position offers a base salary range of <strong>$140,000 - $253,000</strong>, based on relevant skills and experience and includes a generous benefits plan.<br/><br/>CoStar Group is an Equal Employment Opportunity Employer; we maintain a drug-free workplace and perform pre-employment substance abuse testing<br/><br/>
</div>",$140000- $253000,Big Data Engineer
"Senior Software Engineer, Full Stack",ClickJobs.io,12/25/2023,https://www.linkedin.com/jobs/view/3793412508,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
"Senior Software Engineer, DevOps",ClickJobs.io,12/25/2023,https://www.linkedin.com/jobs/view/3793412513,0,https://media.licdn.com/dms/image/C4E0BAQFyzTWG1MjMpA/company-logo_100_100/0/1633956451768/seven_acorns_logo?e=2147483647&v=beta&t=GQCrQQ0h9bh9O5ya-lO_ePwLuYdBK__rqhwSU2ZWhOs,"Camden, NJ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Center 1 (19052), United States of America, McLean, VirginiaSenior Software Engineer, DevOps<br/><br/><strong> Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive , and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who love to solve real problems and meet real customer needs. We are seeking <strong> DevOps Engineers</strong> who are passionate about marrying data with emerging technologies to join our team. As a DevOps Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. <br/><br/></strong><strong><strong>What You’ll Do:<br/><br/></strong></strong><ul><li> Utilize software including Microsoft Endpoint Configuration Manager (MECM) and Microsoft PowerBI in addition to configuration management tools including Terraform, Jenkins, and a variety of AWS tools and services to solve technically complex problems </li><li> Leverage scripting languages including Powershell and SQL to solve engineering challenges, aggregate data, and provide meaningful metrics and insights to operational and engineering teams </li><li> Automate delivery of software components working in collaboration with engineering, product, and design teams </li><li> Work within and across Agile teams to design, develop, test, implement, and support technical solutions across development tools and technologies </li><li> Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal &amp; external technology communities, and mentoring other members of the engineering community </li><li> Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment <br/><br/></li></ul><strong><strong>Basic Qualifications:<br/><br/></strong></strong><ul><li> Bachelor’s degree </li><li> At least 4 years of experience in DevOps Engineering (Internship experience does not apply) </li><li> At least 2 years of experience with Cloud Native technologies (Amazon Web Services, Microsoft Azure, Google Cloud Platform) </li><li> At least 2 years of Windows, Unix, or Linux system administration experience <br/><br/></li></ul><strong><strong>Preferred Qualifications:<br/><br/></strong></strong><ul><li> 4+ years of experience with Microsoft Endpoint Configuration Manager (MECM) </li><li> 2+ years of experience with coding and scripting in Powershell and SQL (or other languages including Python, Java, JavaScript, Golang, Bash, Perl or Ruby) </li><li> 2+ years of experience working with Microsoft PowerBI or similar reporting and visualization tools </li><li> 2+ years of experience working with Agile Development Practices </li><li> 2+ years of experience with Terraform or Ansible <br/><br/></li></ul><strong><em>At this time, Capital One will not sponsor a new applicant for employment authorization for this position.<br/><br/></em></strong>The minimum and maximum full-time annual salaries for this role are listed below, by location. Please note that this salary information is solely for candidates hired to perform work within one of these locations, and refers to the amount Capital One is willing to pay at the time of this posting. Salaries for part-time roles will be prorated based upon the agreed upon number of hours to be regularly worked.<br/><br/>New York City (Hybrid On-Site): $161,900 - $184,800 for Senior Software Engineer<br/><br/>Candidates hired to work in other locations will be subject to the pay range associated with that location, and the actual annualized salary amount offered to any candidate at the time of hire will be reflected solely in the candidate’s offer letter.<br/><br/>Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.<br/><br/>This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.<br/><br/>If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.<br/><br/>For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com<br/><br/>Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.<br/><br/>Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).
      </div>",$161900- $184800,Big Data Engineer
Senior Cloud Data Engineer,BDO USA,12/19/2023,https://www.linkedin.com/jobs/view/3765469452,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
"Lead Data Engineer (AWS, Azure, GCP)",CapTech,12/19/2023,https://www.linkedin.com/jobs/view/3751642559,0,https://media.licdn.com/dms/image/D4E0BAQEzvZZT9k7tQg/company-logo_100_100/0/1688216361303/captechconsulting_logo?e=2147483647&v=beta&t=wV_XeINYC7gUtPXYwqonUqAssSaid9KiHLw1Hxp4Z7Q,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>CapTech is an award-winning consulting firm that collaborates with clients to achieve what’s possible through the power of technology. At CapTech, we’re passionate about the work we do and the results we achieve for our clients. From the outset, our founders shared a collective passion to create a consultancy centered on strong relationships that would stand the test of time. Today we work alongside clients that include Fortune 100 companies, mid-sized enterprises, and government agencies, a list that spans across the country.<br/><br/><strong>Job Description<br/><br/></strong>CapTech Data Engineering consultants enable clients to build and maintain advanced data systems that bring together data from disparate sources in order to enable decision-makers. We build pipelines and prepare data for use by data scientists, data analysts, and other data systems. We love solving problems and providing creative solutions for our clients. Cloud Data Engineers leverage the client’s cloud infrastructure to deliver this value today and to scale for the future. We enjoy a collaborative environment and have many opportunities to learn from and share knowledge with other developers, architects, and our clients. <br/><br/>The Value You Deliver (or What You’ll Do)<br/><br/><ul><li>Be trusted advisor to customers with best practices, methodologies, and technologies to implement data engineering solutions. </li><li>Design, implement, and maintain modern data pipelines to deliver optimal solutions utilizing appropriate cloud technologies. </li><li>Partner with product owners and business SMEs to analyze customer requirements and provide a supportable and sustainable engineered solution. </li><li>Provide technical leadership and collaborate within and across teams to ensure that the overall technical solution is aligned with the customer needs. </li><li>Stay current with the latest cloud technologies, patterns, and methodologies; share knowledge by clearly articulating results and ideas to key stakeholders. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Experience building/operating highly available distributed systems of data extraction, ingestion, and processing large data sets </li><li>5+ years of experience delivering data engineering solutions on cloud platform </li><li>5+ years of experience implementing modern designs using at least one cloud-based solution/platform (AWS, Azure, GCP) </li><li>Advanced level proficiency with at least one ETL / Data Orchestration technology (Azure Data Factory, SSIS, Informatica, Alteryx, Ab Initio, Pentaho, Talend, Matillion) </li><li>Experience cloud-based data warehousing and data lake solutions like Snowflake, Redshift, Databricks </li><li>5+ years of experience with SQL or NoSQL database (PostgreSQL, MySQL, SQL server, Oracle, Aurora, Presto, BigQuery) </li><li>Expertise with SQL, database design/structure and data structure (star, snowflake schemas, de/normalized designs) </li><li>5+ years of experience with at least one programming language (Python, Java, R, C / C# / C++, Shell) </li><li>Familiarity with one or more DevOps tools (git, Jenkins, CI/CD, Jira) </li><li>Fundamental understanding of big data, open source, and data streaming concepts </li><li>Ability to think strategically and provide recommendations utilizing traditional and modern architectural components based on business needs    </li><li>Experience providing technical leadership and mentoring other engineers in data engineering space </li><li>Cloud certification on any platform a plus <br/><br/></li></ul><strong>Additional Information<br/><br/></strong>We want everyone at CapTech to be able to envision a lasting and rewarding career here, which is why we offer a variety of career paths based on your skills and passions. You decide where and how you want to develop, and we help get you there with customizable career progression and a comprehensive benefits package to support you along the way. Alongside our suite of traditional benefits encompassing generous PTO, health coverage, disability insurance, paid family leave and more, we’ve launched extended benefits to help meet our employees’ needs.<br/><br/><ul><li>CapFlex – Employee-first mentality that supports a remote and hybrid workforce and empowers daily flexibility while servicing our clients</li><li>Learning &amp; Development – Programs offering certification and tuition support, digital on-demand learning courses, mentorship, and skill development paths</li><li>Modern Health –A mental health and well-being platform that provides 1:1 care, group support sessions, and self-serve resources to support employees and their families through life’s ups and downs</li><li>Carrot Fertility –Inclusive fertility and family-forming coverage for all paths to parenthood – including adoption, surrogacy, fertility treatments, pregnancy, and more – and opportunities for employer-sponsored funds to help pay for care</li><li>Fringe –A company paid stipend program for personalized lifestyle benefits, allowing employees to choose benefits that matter most to them – ranging from vendors like Netflix, Spotify, and GrubHub to services like student loan repayment, travel, fitness, and more</li><li>Employee Resource Groups – Employee-led committees that embrace and incorporate diversity and inclusion into our day-to-day operations</li><li>Philanthropic Partnerships – Opportunities to engage in partnerships and pro-bono projects that support our communities. </li><li>401(k) Matching – Generous matching and no vesting period to help you continue to build financial wellness<br/><br/></li></ul>CapTech is an equal opportunity employer committed to fostering a culture of equality, inclusion and fairness — each foundational to our core values. We strive to create a diverse environment where each employee is encouraged to bring their unique ideas, backgrounds and experiences to the workplace. For more information about our Diversity, Inclusion and Belonging efforts, click HERE. As part of this commitment, CapTech will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please contact Laura Massa directly via email lmassa@captechconsulting.com.<br/><br/>At this time, CapTech cannot transfer nor sponsor a work visa for this position. Applicants must be authorized to work directly for any employer in the United States without visa sponsorship.<br/><br/>
</div>",No Salary Info Found,Big Data Engineer
Sr/Engineer-Data Science & Analytics - 90261266 - Philadelphia,Amtrak,12/19/2023,https://www.linkedin.com/jobs/view/3784453205,0,https://media.licdn.com/dms/image/C4D0BAQFFA5eXL3C_Bw/company-logo_100_100/0/1630519023586/amtrak_logo?e=2147483647&v=beta&t=KJai3kunau8ncxW5qOX4HXYZRHXSVzTb7YROjNsSGI8,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Your success is a train ride away!<br/><br/></strong>As we move America’s workforce toward the future, Amtrak connects businesses and communities across the country. We employ more than 20,000 diverse, energetic professionals in a variety of career fields throughout the United States. The safety of our passengers, our employees, the public and our operating environment is our priority, and the success of our railroad is due to our employees.<br/><br/><strong>Are you ready to join our team?<br/><br/></strong>Our values of ‘Do the Right Thing, Excel Together and Put Customers First’ are at the heart of what matters most to us, and our Core Capabilities, ‘Building Trust, Accountability, Effective Communication, Customer Focus, and Proactive Safety &amp; Security’ are what every employee needs to know and do to be most impactful at Amtrak. By living the Amtrak values, focusing on our capabilities, and actively embracing and fostering diverse ideas, backgrounds, and perspectives, together we will honor our past and make Amtrak a company of the future.<br/><br/><strong> This position is a tiered position. Incumbents will have a position level assigned based on their skills and experience, and in alignment with position development plans. Position placement is at Amtrak’s sole and absolute discretion. <br/><br/></strong><strong>Summary Of Duties<br/><br/></strong>The Engineer Data Science &amp; Analytics is responsible for data storage, processing, and analysis to provide information for the development of data-driven scopes of work for maintenance activities. This role will be responsible for collaborating with colleagues in the Research, Analytics &amp; Test Group and other key stakeholders to develop new tools for the visualization and analysis of infrastructure condition data.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li>Develop and implement graphical display and analytical software used by the Engineering Department for condition monitoring, work planning, and degradation analysis.</li><li>Collaborate with Senior Engineer Data Management &amp; Analytics to expand database and analysis capabilities of AssetWise software. </li><li>Collaborate with Manager Engineering Track Geometry Improvements to analyze curve data and develop recommendations for curve modifications.</li><li>Collaborate with Research &amp; Development Group to research and assess new software tools for data analysis. </li><li>Assist in providing technical, logistical, and administrative support to ensure the successful completion of assigned project tasks within scope, schedule and budget. </li><li>May be called upon to assist in inspections utilizing track geometry and catenary measurement cars.</li><li>May be called upon to assist in field inspections.<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>Bachelor of Science Degree in Civil/Transportation/Mechanical/Computer Engineering, or equivalent work experience and training in position of similar capacity.</li><li>Must be able to interface with all levels of employees and both external and internal customers.</li><li>Must be skilled and experienced with MS Office, creating spreadsheets, presentations, memorandums, and utilizing other applications to perform job functions.</li><li>Demonstrated effective communication skills both written and verbal.</li><li>Must become qualified in Roadway Worker Protection, AMT-2, NORAC/GCOR operating rules, and MW100 and maintain these qualifications.</li><li>Ability to learn and understand the use of software such as Matlab, Python, Bentley AssetWise, GeoDrive, PowerBI, Survey123, ArcGIS, ESRI, and Bentley Microstation.<br/><br/></li></ul><strong>MIMINUM KSA (Knowledge, Skills, And Abilities)<br/><br/></strong><ul><li>Must have excellent communication skills, both verbal and written</li><li>Understands how to collaborate with various work groups<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>3-6 years of relevant experience preferred </li><li>Familiarity with Matlab and/or Python coding languages </li><li>Experience with railroad construction, design, and maintenance</li><li>Experience with railroad operations<br/><br/></li></ul><strong>Work Environment<br/><br/></strong><ul><li>Up to 10% travel<br/><br/></li></ul><strong>Communications And Interpersonal Skills<br/><br/></strong>Must have excellent oral and written communication skills.<br/><br/>The salary/hourly range is $86,500 - $111,996 for the Engineer position and $103,700 - $134,460 for the Sr Engineer position. Pay is based on several factors including but not limited to education, work experience, certifications, internal equity, etc. Depending on an employee’s assigned worksite or location, Amtrak may consider a geo-pay differential to be applied to the employee’s base salary. Amtrak may offer additional incentive and pay programs to recognize and reward our employees, including a short-term incentive bonus based upon factors such as individual and company performance that is commensurate with the level of the position and/or long-term incentive plan compensation. In addition to your salary, Amtrak offers a comprehensive benefit package that includes health, dental, and vision plans; health savings accounts; wellness programs; flexible spending accounts; 401K retirement plan with employer match; life insurance; short and long term disability insurance; paid time off; back-up care; adoption assistance; surrogacy assistance; reimbursement of education expenses; Public Service Loan Forgiveness eligibility; Railroad Retirement sickness and retirement benefits; and rail pass privileges. Learn more about our benefits offerings here .<br/><br/><strong>Requisition ID:</strong>160551<br/><br/><strong>Posting Location(s):</strong>Pennsylvania<br/><br/><strong>Job Family/Function:</strong>Engineering<br/><br/><strong>Relocation Offered:</strong>Yes<br/><br/><strong>Travel Requirements:</strong>Up to 25%<br/><br/><strong>You power our progress through your performance.<br/><br/></strong>We want your work at Amtrak to be more than a job. We want your career at Amtrak to be a fulfilling experience where you find challenging work, rewarding opportunities, respect among colleagues, and attractive compensation. Amtrak maintains a culture that values high performance and recognizes individual employee contributions.<br/><br/>Amtrak is committed to a safe workplace free of drugs and alcohol. All Amtrak positions requires a pre-employment background check that includes prior employment verification, a criminal history check and a pre-employment drug screen.<br/><br/>Candidates who test positive for marijuana will be disqualified, regardless of any state or local statute, ordinance, regulation, or other law that legalizes or decriminalizes the use or possession of marijuana, whether for medical, recreational, or other use. Amtrak's pre-employment drug testing program is administered in accordance with DOT regulations and applicable law.<br/><br/>In accordance with DOT regulations (49 CFR<br/><br/><ul><li>40.25), Amtrak is required to obtain prior drug and alcohol testing records for applicants/employees intending to perform safety-sensitive duties for covered Department of Transportation positions. If an applicant/employee refuses to provide written consent for Amtrak to obtain these records, the individual will not be permitted to perform safety-sensitive functions.<br/><br/></li></ul>In accordance with federal law governing security checks of covered individuals for providers of public transportation (Title 6 U.S.C.<br/><br/><ul><li>1143), Amtrak is required to screen applicants for any permanent or interim disqualifying criminal offenses.<br/><br/></li></ul>Note that any education requirement listed above may be deemed satisfied if you have an equivalent combination of education, training and experience.<br/><br/>Amtrak is an EOE/Affirmative Action Minority/Female employer, and we welcome all to apply. We consider candidates regardless of race/color, religion, sex (including pregnancy, childbirth and related conditions), national origin/ethnicity, age, disability (intellectual, mental and physical), veteran status, marital status, ancestry, sexual orientation, gender identity and gender expression, genetic information, citizenship or any other personal characteristics protected by law.<br/><br/>
</div>",$86500- $111996,Big Data Engineer
"Lead Data Engineer, (Python, Java or Scala)",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788485237,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Big Data Engineer
"Lead Software Engineer, Full Stack",Capital One,12/20/2023,https://www.linkedin.com/jobs/view/3789036798,0,https://media.licdn.com/dms/image/C560BAQF0OgQyRZ9yAA/company-logo_100_100/0/1635782718446/capital_one_logo?e=2147483647&v=beta&t=diqoTjPVgshq6jmtU3GyOEMwVuHvU22Rse81s6NvOLc,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        1735 Market St (16035), United States of America, Philadelphia, PennsylvaniaLead Software Engineer, Full Stack<br/><br/><strong> Do you love building and pioneering in the technology space? Do you enjoy solving complex business problems in a fast-paced, collaborative, inclusive, and iterative delivery environment? At Capital One, you'll be part of a big group of makers, breakers, doers and disruptors, who solve real problems and meet real customer needs. We are seeking <strong>Full Stack Software Engineers</strong> who are passionate about marrying data with emerging technologies. As a Capital One Lead Software Engineer, you’ll have the opportunity to be on the forefront of driving a major transformation within Capital One. <br/><br/></strong><strong><strong>What You’ll Do: <br/><br/></strong></strong><ul><li> Lead a portfolio of diverse technology projects and a team of developers with deep experience in distributed microservices, and full stack systems to create solutions that help meet regulatory needs for the company </li><li> Share your passion for staying on top of tech trends, experimenting with and learning new technologies, participating in internal &amp; external technology communities, mentoring other members of the engineering community </li><li> Collaborate with digital product managers, and deliver robust cloud-based solutions that drive powerful experiences to help millions of Americans achieve financial empowerment </li><li> Utilize programming languages like JavaScript, Java, HTML/CSS, TypeScript, SQL, Python, and Go, Open Source RDBMS and NoSQL databases, Container Orchestration services including Docker and Kubernetes, and a variety of AWS tools and services <br/><br/></li></ul><strong><strong>Basic Qualifications: <br/><br/></strong></strong><ul><li> Bachelor’s Degree </li><li> At least 6 years of experience in software engineering (Internship experience does not apply) </li><li> At least 1 year experience with cloud computing (AWS, Microsoft Azure, Google Cloud) <br/><br/></li></ul><strong><strong>Preferred Qualifications:<br/><br/></strong></strong><ul><li> Master's Degree </li><li> 7+ years of experience in at least one of the following: JavaScript, Java, TypeScript, SQL, Python, or Go </li><li> 3+ years of experience with AWS, GCP, Microsoft Azure, or another cloud service </li><li> 4+ years of experience in open source frameworks </li><li> 1+ years of people management experience </li><li> 2+ years of experience in Agile practices <br/><br/></li></ul><strong><em>At this time, Capital One will not sponsor a new applicant for employment authorization for this position.<br/><br/></em></strong>Capital One offers a comprehensive, competitive, and inclusive set of health, financial and other benefits that support your total well-being. Learn more at the Capital One Careers website . Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level.<br/><br/>This role is expected to accept applications for a minimum of 5 business days.No agencies please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. All qualified applicants will receive consideration for employment without regard to sex (including pregnancy, childbirth or related medical conditions), race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state or local law. Capital One promotes a drug-free workplace. Capital One will consider for employment qualified applicants with a criminal history in a manner consistent with the requirements of applicable laws regarding criminal background inquiries, including, to the extent applicable, Article 23-A of the New York Correction Law; San Francisco, California Police Code Article 49, Sections 4901-4920; New York City’s Fair Chance Act; Philadelphia’s Fair Criminal Records Screening Act; and other applicable federal, state, and local laws and regulations regarding criminal background inquiries.<br/><br/>If you have visited our website in search of information on employment opportunities or to apply for a position, and you require an accommodation, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com . All information you provide will be kept confidential and will be used only to the extent required to provide needed reasonable accommodations.<br/><br/>For technical support or questions about Capital One's recruiting process, please send an email to Careers@capitalone.com<br/><br/>Capital One does not provide, endorse nor guarantee and is not liable for third-party products, services, educational tools or other information available through this site.<br/><br/>Capital One Financial is made up of several different entities. Please note that any position posted in Canada is for Capital One Canada, any position posted in the United Kingdom is for Capital One Europe and any position posted in the Philippines is for Capital One Philippines Service Corp. (COPSSC).
      </div>",No Salary Info Found,Big Data Engineer
Engineer,Tata Consultancy Services,12/20/2023,https://www.linkedin.com/jobs/view/3788451813,0,https://media.licdn.com/dms/image/C4D0BAQFPP1NRP4F5dQ/company-logo_100_100/0/1656657978597/tata_consultancy_services_logo?e=2147483647&v=beta&t=Ao4Ihtw2eg1ymYGPB7E4AEHoNQ83oX6bP1DrQIiqR1s,"Malvern, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Skill: Data Engineer<br/><br/><ul><li>Experience in AWS, Big Data, Scala, Python, SPARK, Hive, Tablea), SQL.</li><li>Min 6 yrs hands on experience in Spark, Python, Scala, Hadoop.</li><li>Must have hands on experience in AWS ETL Glue, Lambda, DynamoDB.</li><li>Must have hands on experience in Python / PySpark.</li><li>Must have experience in CI/CD, AWS S3, AWS EC2, AWS IAM, AWS Data Lake, SQL, Hive.</li><li>Building and managing public and private cloud infrastructure with AWS, EC2 and S3 resources.</li><li>Participating in requirement analysis and planning the development.</li><li>Support production environment.</li><li>Designing automation processes as per the operational needs of an organization.</li><li>Reviewing the code, design and providing expertise in the development and integration of systems.</li><li>Excellent SQL skills.<br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li>Work in a team of Data Engineer for Data ingestion process from Legacy System to AWS.</li><li>Work in a Support team to analyze, triage and debug the incidents and failures occurred.</li><li>Monitoring the cluster jobs in a daily basis.</li><li>Building and managing public and private cloud infrastructure with AWS, EC2 and S3 resources.</li><li>Participating in requirement analysis and planning the development.</li><li>Support production environment.</li><li>Designing automation processes as per the operational needs of an organization.<br/><br/></li></ul>
</div>",No Salary Info Found,Big Data Engineer
Sr. Data Engineer (Hybrid),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788642988,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Job Title: Senior Data Engineer (Hybrid) Location: Plano, Texas, United States We are looking for motivated individuals to join our team of passionate data engineers in creating Capital One's next generation of data products and capabilities. In this role, you will be responsible for building data pipeline frameworks, developing data APIs, and transforming complex analytical models into scalable solutions. You will collaborate with Product Owners and customers to deliver data products in a collaborative and agile environment. Responsibilities: - Develop sustainable data-driven solutions using the latest data technologies to meet the needs of our organization and business customers. - Adapt and master new technologies quickly to contribute to various initiatives. - Break down complex data issues and resolve them efficiently. - Build robust systems with long-term maintenance and support in mind. - Share knowledge with the broader team. - Understand complex multi-tier, multi-platform systems. Basic Qualifications: - Bachelor's Degree. - At least 4 years of experience in application development (Internship experience does not apply). Preferred Qualifications: - Master's Degree. - 6+ years of experience in application development (Python, SQL, Scala, or Java). - 4+ years of experience in big data technologies. - 4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud). - 4+ years of experience with distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL). - 4+ years of experience working on real-time data and streaming applications. - 4+ years of experience with NoSQL implementation (Mongo, Cassandra). - 4+ years of data warehousing experience (Redshift or Snowflake). - 4+ years of experience with UNIX/Linux including basic commands and shell scripting. - 4+ years of experience with Agile engineering practices. Salary Information: - New York City (Hybrid On-Site): $161,900 - $184,800 for Senior Data Engineer. - Candidates hired to work in other locations will be subject to the pay range associated with that location. Benefits: At Capital One, we offer a comprehensive and inclusive set of health, financial, and other benefits to support your overall well-being. To learn more about our benefits, please visit the Capital One Careers website. Eligibility may vary based on employment status. Equal Opportunity Employer: Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We welcome applicants from all backgrounds and prohibit any form of discrimination based on sex, race, age, disability, religion, sexual orientation, gender identity, veteran status, or any other protected characteristic, as outlined by applicable laws. We promote a drug-free workplace and consider qualified applicants with a criminal history in accordance with the requirements of the law. Accommodation: If you require accommodation during the application process, please contact Capital One Recruiting. We will ensure that your needs are met confidentially and reasonably. Technical Support: For technical support or questions about Capital One's recruiting process, please email Careers@capitalone.com. Note: Capital One Financial is made up of different entities. Positions posted in Canada are for Capital One Canada, positions in the United Kingdom are for Capital One Europe, and positions in the Philippines are for Capital One Philippines Service Corp. (COPSSC). Capital One does not endorse or guarantee third-party products or services available through this site. [Employee Inquiry Form] [Apply Now] We appreciate your interest in joining Capital One. Please fill out the form below so that we may contact you regarding your application: Full Name: Email: Phone Number: Location: Resume/CV: (Attach file) Additional Information: Thank you for your application. We will be in touch shortly. For General Inquiries: Phone: 1-800-304-9102 Email: RecruitingAccommodation@capitalone.com
      </div>",$161900- $184800,Big Data Engineer
Senior SAP MM Consultant,Syskoplan Reply US,12/20/2023,https://www.linkedin.com/jobs/view/3788686612,0,https://media.licdn.com/dms/image/C4E0BAQFxno5qth0_VA/company-logo_100_100/0/1670195657044/syskoplanreplyus_logo?e=2147483647&v=beta&t=To_aIvoYH7cqdI8VSdDXjRk5SgcVgCk4Vv5ErrSTBvU,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Senior SAP MM Consultant</p><p><br/></p><p><strong>PHILADELPHIA AREA, PENNSYLVANIA /SYSKOPLAN REPLY – DELIVERY CONSULTANT /FULL TIME/ HYBRID</strong></p><p><br/></p><p>Syskoplan Reply is a part of the Reply Network, focused on delivering transformative projects to our clients leveraging SAP solutions. Syskoplan Reply is an SAP Gold partner and has recognized expertise executing global projects in various industries and a wide range of competencies including business process consulting, customer experience, intelligent automation, ERP and more. </p><p><br/></p><p>At Syskoplan Reply, we are seeking a Senior SAP MM Consultant to join our team. You are an individual who has technical and functional expertise of the SAP Materials Management (MM) module which allows you to solve problems and deliver optimum solutions for the client. You have hands on S/4HANA and/or S/4HANA Cloud experience including use case of standard Fiori applications.</p><p><strong>Responsibilities</strong></p><ul><li>Act as a business consultant to help customers achieve their objectives understanding the importance of communication in a consultant's role</li><li>Problem solve with an extraordinary technical and functional understanding of business process and MM Principles and SAP products</li><li>Leads fit/gap and other types of working sessions to understand needs driven by business process requirements. Translate requirements into solutions, using SAP Best Practices</li><li>Prepare clear and concise documentation, as well as provide timely status updates</li><li>Proactively identify risks and develop strategies to mitigate potential issues. Assess corporate impacts of changes and recommend strategies to senior management</li><li>Provide knowledge transfer to clients and fellow consultants, in formal and ad hoc settings</li></ul><p><strong>Requirements</strong></p><ul><li>Bachelor’s Degree </li><li>Travel up to 50%</li><li>7 years of SAP experience with a minimum of 2 full-cycle SAP implementations</li><li>Excellent understanding of business processes associated Purchasing, Goods Receipt, Invoice Verification and Inventory Management</li><li>Expert in set-up and configuration of MM as well as cross functional design/build of modules such as SD and PP</li><li>Highly skilled in material master data set-up, cleansing, harmonization and migration, including LSMW and Migration Cockpit</li><li>Proficient in all aspects of a project from requirement gathering and gapping to realization to testing, go-live prep and go-live execution as well as hyper-care support. Ability to lead sessions and create requirements to develop the right client solution</li><li>Advanced ability to create impact analyses to make recommendations</li></ul><p><br/></p><p><strong>Preferred Qualifications</strong></p><ul><li>Other module configuration experience highly desired</li><li>Knowledge of IOT, Machine Learning and Big Data a plus</li><li>General understanding of automation and exchanging of data with external systems, as well as having the flexibility to engineer client’s preferred 3rd party or custom systems into the MM business processes</li><li>International project or SAP configuration experience in NAFTA, LATAM and/or EMEA is a plus</li><li>S/4 Certification a plus</li><li>Implementation experience in SAP Cloud environments</li></ul><p><br/></p><p>About Reply </p><p>Reply specializes in the design and implementation of solutions based on new communication channels and digital media. Reply is a network of highly specialized companies supporting global industrial groups operating in the telecom and media, industry and services, banking, insurance and public administration sectors in the definition and development of business models enabled for the new paradigms of AI, cloud computing, digital media and the Internet of Things. Reply services include Consulting, System Integration and Digital Services. www.reply.com </p><p><br/></p><p>Reply is an equal opportunity employer. We are committed to provide equal opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. If you need assistance and reasonable accommodation due to a disability during the application or the recruiting process, email us at jobusa@reply.com. Visit our website at www.reply.com to learn more about our open roles.</p>
</div>",No Salary Info Found,Big Data Engineer
Data Warehouse Engineer,Allied OneSource,12/25/2023,https://www.linkedin.com/jobs/view/3793148455,0,https://media.licdn.com/dms/image/C4D0BAQHaltqSnxzGjg/company-logo_100_100/0/1630580322442/allied_global_services_logo?e=2147483647&v=beta&t=1qUqth0lRjhgvdkQIcYmGyFXLXYAsqwqRjNrAYJFEwg,"St Louis, MO","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Are you ready to embark on an exciting journey where your expertise in data warehousing and visualization will play a pivotal role in shaping our data ecosystem? As a Data Warehouse Engineer, you will have the opportunity to work on complex, cutting-edge projects that drive the success of our organization. Under minimal supervision, you'll be at the forefront of creating and maintaining data warehousing applications, ensuring the continuous flow of data and enabling actionable insights. If interested in this remote opportunity, please apply! Don't miss out, interviews are happening next week!<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Craft and refine complex ETL routines, guaranteeing accurate data extraction, transformation, and loading, while implementing robust error handling and notification mechanisms. </li><li>Harness the power of APIs to seamlessly acquire data from diverse sources and integrate them into our data ecosystem. </li><li>Develop and maintain data marts and dimensional models, ensuring their accuracy and relevance through continuous updates. </li><li>Apply your deep understanding of the Kimball model and data warehousing best practices to optimize our data architecture. </li><li>Leverage Azure Data Factory to extract data from a variety of sources, including intricate big data structures. </li><li>Lead the design and implementation of efficient curation routines and data archival strategies, bolstering data quality and long-term usability. </li><li>Collaborate closely with cross-functional teams, providing technical leadership, insights into data flow best practices, and guidance for maintaining our data store ecosystem. <br/><br/></li></ul><strong>Qualifications:<br/><br/></strong><ul><li>Command over information technology concepts, encompassing service bus architecture, master data integration, and various data accessing methods. </li><li>Proficiency in Microsoft SQL Server, operating systems, and related tools to sustain seamless operations. </li><li>Demonstrated expertise in Azure Data Lake, SQL data warehouse, and Azure Data Factory, enriching and sustaining our data ecosystem. </li><li>Familiarity with CICD principles, embracing continuous integration and development practices, along with strong Git/DevOps knowledge. </li><li>Stellar communication and collaboration skills, enabling effective teamwork and independent contribution. </li><li>Bachelor's degree in a technical discipline like Computer Science, coupled with a minimum of 5 years of relevant technology experience or equivalent. </li><li>Extensive hands-on experience in data warehousing, with an emphasis on utilizing tools like Cognos and Microsoft Azure. <br/><br/></li></ul><strong>Salary: </strong>$114,000 - $124,000<br/><br/>AW<br/><br/>
</div>",$114000- $124000,Data Warehouse Engineer
Data Warehouse Engineer - 77043,Swoon,12/20/2023,https://www.linkedin.com/jobs/view/3766966252,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,Blackstone Talent Group,12/19/2023,https://www.linkedin.com/jobs/view/3790357905,0,https://media.licdn.com/dms/image/C560BAQHAFlnQg3firg/company-logo_100_100/0/1657148420727/blackstonetalentgroup_logo?e=2147483647&v=beta&t=RR2QR8qXLbGf4EMMe1qv0MfDEW6BsTugoFERHF1Nxgg,Washington DC-Baltimore Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>We are looking for a <strong>Data Engineer </strong>to join our team of experts to assist with building state-of-the-art data platforms for the client's premier data analytics platform.</p><p><br/></p><p><strong>Responsibilities:</strong></p><p>The Data Engineer will support data collection, ingestion, validation, and loading of optimized data in the appropriate data stores. They work on a team made up of analyst(s), developer(s), data scientist(s), and product leads, and everyone on the team collaborates in support of a specific mission. Working directly with the analyst(s) and the product lead, the data engineer identifies and implements solutions for the data requirements, including building pipelines to collect data from disparate, external sources and implementing rules to validate that expected data is received, cleansed, transformed, massaged and in an optimized output format for the data store. </p><p><br/></p><p>The Data Engineer performs validation and analytics corresponding with client requirements and evolves solutions through automation, optimizing performance with minimal human involvement. As pipelines are executed, the data engineer monitors their status, and performance, and troubleshoots issues while working on improvements to ensure the solution is the very best version to address the customer need. </p><p><br/></p><p><strong>Required Skills:</strong></p><ul><li><strong>Clearance: Secret or Top Secret Clearance</strong></li><li>6+ years of experience with SQL</li><li>6+ years of experience developing data pipelines using modern Big Data ETL technologies like NiFi or StreamSets</li><li>6+ years of experience with a modern programming language such as Python or Java</li><li>6 years of experience working in a big data and cloud environment</li><li>Documented experience with AWS, EC2, S3, and/or RDS</li></ul><p><br/></p><p><strong>Preferred Skills:</strong></p><ul><li>3 years of experience working in an agile development environment</li><li>Ability to quickly learn technical concepts and communicate with multiple functional groups</li><li>Ability to display a positive, can-do attitude to solve the challenges of tomorrow</li><li>Possession of excellent verbal and written communication skills</li><li>Preferred experience at the respective command with an understanding of analytical and data paint points and challenges across the J-Codes.</li></ul><p></p>
</div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer (L5),Netflix,12/19/2023,https://www.linkedin.com/jobs/view/3755880784,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Warehouse Engineer,Professional Diversity Network,12/19/2023,https://www.linkedin.com/jobs/view/3790079003,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
ETL Data Engineer,Zortech Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3788124368,0,https://media.licdn.com/dms/image/C4E0BAQFLYN9bJoNeQg/company-logo_100_100/0/1630602268967?e=2147483647&v=beta&t=VbFirFeWDqzftzmA-xuL4-Rh3UkhihCRtFcB66Ze6Cg,"Georgia, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Note for full time candidates: (Visa Independent Only for FTE)<br/><br/></strong><strong>Role: ETL Data Engineer<br/><br/></strong><strong>Location: Augusta GA (100% Onsite)<br/><br/></strong><strong>Duration: C2C/Fulltime<br/><br/></strong><strong>Job Description<br/><br/></strong><ul><li>Strong hands-on coding experience with 6 to 8 years of experience in ETL </li><li>Hands on exp. on SQL/PL SQL </li><li>Strong hands-on Experience using Azure cloud </li><li>Hands on exp. on Data cloud platforms like Snowflake </li><li>Ability to plan and own the work packets and with minimal supervision or direction is highly desired</li></ul>
</div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer III,CENTSTONE SERVICES LLC,12/19/2023,https://www.linkedin.com/jobs/view/3787600817,0,https://media.licdn.com/dms/image/D560BAQEHGwI18S3Z1A/company-logo_100_100/0/1701985832044/centstone_logo?e=2147483647&v=beta&t=A8amdDy9CZbv7SI-o6TnQn1-_oC6qdmINumKiuuYahc,"Houston, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Title: Data Engineer III<br/><br/></strong><strong>Location: Houston TX (100% On-Site)<br/><br/></strong><strong>Job Type: Long Term Contract<br/><br/></strong><strong>Contract: ONLY W2<br/><br/></strong><strong>﻿Responsibilities Include<br/><br/></strong><ul><li>Work directly with Business domain experts and Data Scientists to develop high quality, reliable, scalable, machine learning systems</li><li>Design and implement frameworks and tools to streamline the machine learning process</li><li>Automate manual data collection and processing tasks to improve efficiency</li><li>Leverage software architecture and design patterns to develop fault tolerant microservices</li><li>Convert research-based machine learning models into production-ready software</li><li>Implement processes to ensure coding standards, code quality, documentation, and test coverage<br/><br/></li></ul>﻿<br/><br/><strong>Qualifications<br/><br/></strong>The successful candidate will meet the following qualifications:<br/><br/><ul><li>7+ years of programming experience in Python</li><li>Expertise in developing and maintaining data pipelines</li><li>Experience in testing, packaging, and deploying machine learning models</li><li>Experience in software engineering practices such as Design Principles and Patterns, Unit Testing, Refactoring, CI/CD, and version control</li><li>Expertise in Object-Oriented Design Principals and Functional Programming Principals</li><li>Experience with common Python Data Engineering packages including Pandas, Numpy, Pyarrow, Pytest, Scikit-Learn, and Boto3</li><li>Experience in implementing distributed computing systems</li><li>Experience in designing modular, reusable software components</li><li>Experience in developing API endpoints and microservices</li><li>Knowledgeable of MLOps Principles</li><li>Knowledgeable of ML platform technologies including Apache Airflow, Kubernetes, Dask, Ray, and MLFlow<br/><br/></li></ul><strong>Thanks &amp; Regards,<br/><br/></strong><strong>NadeemUddin – IT Recruiter<br/><br/></strong><strong>CENTSTONE SERVICES <br/><br/></strong><strong>Direct Contact: +1 332-456-5874<br/><br/></strong><strong>Email</strong>: nadeem.uddin@centstone.com
      </div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer,Accroid Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788129009,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
ETL Test Engineer,Motion Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3790879896,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Senior Data Warehouse Engineer (Hybrid),Enova International,12/20/2023,https://www.linkedin.com/jobs/view/3759692241,0,https://media.licdn.com/dms/image/C4D0BAQGulVsv9HtBbA/company-logo_100_100/0/1631344411570?e=2147483647&v=beta&t=9nVicROxVM1-lW1ILBL0Zwb5mZ5O6wMf8NfeeGAm124,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>We are interested in every qualified candidate who is eligible to work in the United States. However, we are not able to sponsor visas or take over sponsorship at this time.<br/><br/></em><strong>About the role:<br/><br/></strong>The Data Engineering, Warehouse, and Operations Team effectively and sustainably builds data strategy and provides data solutions and tools across the organization. We integrate, transform, and improve volumes of data at the project or enterprise level for streamlined processes, greater efficiencies, and smarter, more informed decision-making. This team is high-energy, dynamic and in a business-critical domain space. This role is an opportunity to make a real difference in the data space, and we need confident, experienced people eager to bring in solutions, with a demonstrated ability to learn fast and make that happen. #BI-Hybrid<br/><br/><strong>Requirements:<br/><br/></strong><em>Experience designing, developing, and working with dimensional models is a must.<br/><br/></em><ul><li>8+ years of strong databases and SQL experience </li><li>Strong experience in data warehousing methodologies</li><li>Experience leading projects/teams from conception to completion, in fast paced dynamic environments</li><li>6+ years of experience in the design and implementation of ETL/ELT frameworks for complex data mart projects</li><li>Hands-on experience in architecting, designing, implementing, and maintaining multi-layered SQL and Python processes</li><li>Experience working with Relational Database Management Systems, including PostgreSQL, MS SQL Server, MySQL, RDS, and Cloud Data Warehouses such as Snowflake and AWS Redshift</li><li>A Bachelor’s or Master’s degree in Engineering, Computer Science, IT or related study is preferred</li><li>Nice to have: AWS and/or Snowflake Certifications<br/><br/><br/></li></ul><strong>Responsibilities:<br/><br/></strong><ul><li>Opportunity to lead technical initiatives by architecting the solution and collaborating with team members and peers to execute the solution</li><li>Act diligently to respond to urgent projects and tasks</li><li>Troubleshooting discrepancies in existing databases, data pipelines, warehouses, and reporting</li><li>Collaborating with principals, peers, leadership, and the business</li><li>Work as a “full stack” Data Engineer contributing to each phase of the SDLC, building a new pipeline between two data sources or working with the business to design and develop a new dashboard</li><li>Advise on best practices and innovative designs/solutions </li><li>Perform other functions as assigned by management to support the operation of the business<br/><br/><br/></li></ul>#BI-Hybrid<br/><br/><strong>Benefits &amp; Perks:<br/><br/></strong><ul><li>Flexible work schedule (In-office T/W/Th and remote M/F for hybrid-eligible roles)</li><li>Health, dental, and vision insurance including mental health benefits</li><li>401(k) matching plus a roth option (U.S. Based employees only)</li><li>PTO &amp; paid holidays off</li><li>Sabbatical program (for eligible roles)</li><li>Summer hours (for eligible roles)</li><li>Paid parental leave</li><li>DEI groups (B.L.A.C.K. @ Enova, HOLA @ Enova, Women @ Enova, Pride @ Enova, South Asians @ Enova, APEX @ Enova, and Parents @ Enova)</li><li>Employee recognition and rewards program</li><li>Charitable matching and a paid volunteer day…Plus so much more!<br/><br/><br/></li></ul><em>Full-Time Employees working 30+ hours per week are eligible for benefits; interns are not eligible.<br/><br/></em><strong>About Enova<br/><br/></strong>Enova International is a leading financial technology company that provides online financial services through our AI and machine learning-powered Colossus™platform. We serve non-prime consumers and businesses alike, while offering world-class technology and services to traditional banks—in order to create accessible credit for millions.<br/><br/>Being a values-driven organization is at the core of Enova’s success. We live our values by listening to our customers, challenging assumptions, thinking big, setting high expectations, and hiring and developing the best. Through our values and our commitment to making Enova an awesome place to work, we maintain an environment of inclusion and culture where our employees can thrive. You can learn more about Enova’s values and culture here.<br/><br/>It is our policy to provide equal employment opportunity for all persons and not discriminate in employment decisions by placing the most qualified person in each job, without regard to any other classification protected by federal, state, or local law. California Applicants: Click here to review our California Privacy Policy for Job Applicants.<br/><br/>
</div>",No Salary Info Found,Data Warehouse Engineer
Security Officer - Data Warehouse,GardaWorld,12/24/2023,https://www.linkedin.com/jobs/view/3791302787,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789086619,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $130,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$130000- $173000,Data Warehouse Engineer
Senior Product Application Engineer: System Solutions Architect Data Center GPU,AMD,12/19/2023,https://www.linkedin.com/jobs/view/3727249173,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Tableau Developer with Adobe,Calypso Way,12/19/2023,https://www.linkedin.com/jobs/view/3788424978,0,https://media.licdn.com/dms/image/C560BAQH8nwwTRz4TtA/company-logo_100_100/0/1630646526452?e=2147483647&v=beta&t=y0q1yN2XM3dWbkwwp3Bry3dNWqvo3qtZbiNP-SE_Fmo,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Title: Tableau Developer with Adobe<br/><br/>Location: Austin, TX<br/><br/></strong><strong>Duration: 12+ months<br/><br/></strong><strong>Type: W2<br/><br/></strong><strong>Required<br/><br/></strong><ul><li>2+ years of Tableau and SQL experience.</li><li>Worked with Clickstream data in the web analytics environment. <br/><br/></li></ul>Calypso Way is a California technology staffing service, that delivers a competitive advantage for its customers through software, solutions, and services. Established in 2019. Calypso Way is headquartered in San Ramon, California. We work with technology giants in Silicon Valley California.
      </div>",No Salary Info Found,Data Warehouse Engineer
Staff Data Engineer - Emerging AI Tech Team,Visa,12/19/2023,https://www.linkedin.com/jobs/view/3771228074,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
"Data Solution Engineer (Madison, WI or Austin, TX – Onsite)",Carex Consulting Group,12/19/2023,https://www.linkedin.com/jobs/view/3746213147,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Entry Level Data Scientist/Analyst(REMOTE),SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784098160,0,https://media.licdn.com/dms/image/C560BAQHPrA2XO9lh7g/company-logo_100_100/0/1663564885547/synergisticit_logo?e=2147483647&v=beta&t=biDnkXeeFcJXgnh87P53V9KGn6j1mqUOEQpisfcfR74,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Job Market is Challenging due to more than 150,000 Tech Layoffs in 2022 and in 2023 more than 240,000 layoffs so almost 3,90,00 tech employees have been laid off since 2022 and its still going on . The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers.<strong> Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. </strong>In such a scenario the Job seekers need <strong> to differentiate themselves by ensuring to obtain exceptional skills and technologies to be hired by clients as its an employer's market presently and they have a lot of hiring choices.<br/><br/></strong>For more than 12+ years Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.<br/><br/>All Positions are open for all visas and US citizens<br/><br/>We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers.<br/><br/>We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like <strong> apple, google, Paypal, western union, Client, visa, walmart lab</strong>s etc to name a few.<br/><br/>We have an excellent reputation with the clients. Currently, We are looking for <strong> entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers</strong> for full time positions with clients.<br/><br/>Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry<br/><br/><strong> We assist in filing for STEM extension and also for H1b and Green card filing to Candidates <br/><br/></strong>We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.<br/><br/><strong> please check the below links to see success outcomes of our candidates</strong> and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers<br/><br/><strong> https://www.synergisticit.com/candidate-outcomes/ <br/><br/></strong><strong> We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023 <br/><br/></strong>Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTube<br/><br/><strong> https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn <br/><br/></strong><strong> https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=EmO7NrWHkLM <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=OAFOhcGy9Z8 <br/><br/></strong><strong> https://www.youtube.com/watch?v=Yy74yvjatVg <br/><br/></strong>For preparing for interviews please visit <strong> https://www.synergisticit.com/interview-questions/ <br/><br/></strong><strong> We are looking for the right matching candidates for our clients <br/><br/></strong><strong> Please apply via the job posting <br/><br/></strong><strong>Required Skills<br/><br/></strong><strong> REQUIRED SKILLS For Java /Full stack/Software Programmer <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning Positions <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow <br/><br/></strong><strong> If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements. <br/><br/></strong><strong> No phone calls please. </strong> Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates
      </div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer,Braintrust,12/19/2023,https://www.linkedin.com/jobs/view/3789766635,0,https://media.licdn.com/dms/image/C560BAQHbQYFSQsK__A/company-logo_100_100/0/1630511738029/usebraintrust_logo?e=2147483647&v=beta&t=KwbYjG0MdxQVYAijRBYsSuBn-w2onHZNpCmM31LViso,"Austin, Texas Metropolitan Area","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality.<br/><br/><strong>About The Hiring Process<br/><br/></strong>The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match.<br/><br/>Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies.<br/><br/><strong>JOB TYPE:</strong> Direct Hire/ FTE Position (no agencies/C2C - see notes below)<br/><br/><strong>LOCATION:</strong> Work from anywhere - Anytime | No timezone overlap required<br/><br/><strong>SALARY RANGE</strong> $110,000 – $130,000 /yr<br/><br/><strong>ESTIMATED DURATION:</strong> 40/week - long term<br/><br/><strong>EXPERIENCE:</strong> 3-4 years<br/><br/><strong>BRAINTRUST JOB ID:</strong> 11526<br/><br/>The Opportunity<br/><br/><strong>Required Skills<br/><br/></strong><ul><li> T-SQL (DDL, Stored Proces, Views, CTEs, etc) </li><li> VCS (Git, SVN, etc) <br/><br/></li></ul><strong>Bonus Skills<br/><br/></strong><ul><li> Candidates with a CPA/CFA or other financial services background are preferred. </li><li> Candidates who understand web technologies and can program in other languages in addition to SQL will be preferred. JavaScript/ES6/NodeJS preferred. </li><li> VS Code, SSMS, and other IDEs. </li><li> CI/CD experience with integrating database changes into deployment models. <br/><br/></li></ul>What You'll Be Working On<br/><br/><ul><li>This is a FTE position and is only open to US-based candidates**<br/><br/></li></ul>InvestEdge is seeking a database specialist with expert knowledge in relational data modeling, querying, and data analysis.<br/><br/>This role requires expert knowledge of working with MSSQL and Postgres databases, and can write complex queries, stored procedures, and views.<br/><br/><strong>The Candidate<br/><br/></strong><ul><li> has likely worked as a senior data developer or data architect role, and also understands database administration concepts such as indexing strategies, backup and fault-tolerance strategies, and how to organize and secure data at rest. </li><li> have a background in financial services and understand how financial markets work. </li><li> Has a CPA/CFA with the ability to write advanced SQL should be a shoe-in. <br/><br/></li></ul>This role will work with InvestEdge's senior data architect to implement new solutions as well as improve existing ones. Also, the role will be working with large data sets and large database footprints and should understand concepts such as performance tuning, SQL Injection, and data security best practices.<br/><br/>In addition to an emphasis on data manipulation and storage, the candidate will also work on other aspects of the application including UX and middle-tier concerns relating to the presentation, use, and manipulation of data. The ideal candidate is a well-rounded developer that is comfortable in any layer of the application, even as their focus is data and the persistence of that data.<br/><br/><strong>Roles And Responsibilities<br/><br/></strong><ul><li> Work with the senior data architect to implement data routines in a financial services environment. </li><li> Create new queries, views, and stored procedures for a large existing relational data set. </li><li> Debug and troubleshoot logical issues in database code. </li><li> Debug and troubleshoot performance issues in database code. </li><li> Serve as a subject matter expert on a large in-house enterprise database model. </li><li> Understand the business domain of the application. </li><li> Work in an Agile environment on a cross-functional team. <br/><br/></li></ul><strong>Apply Now!<br/><br/></strong><strong>Notes<br/><br/></strong>Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.<br/><br/>Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
      </div>",$110000- $130000,Data Warehouse Engineer
Data Engineer,AtkinsRéalis,12/20/2023,https://www.linkedin.com/jobs/view/3785085485,0,https://media.licdn.com/dms/image/D4E0BAQENGaGvdO3TOw/company-logo_100_100/0/1695059107065/atkinsrealis_logo?e=2147483647&v=beta&t=97_WWS0g7kyFfGgXfDApNXY-v0y8Brbx7XxsaTAebUE,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Why join us? <br/><br/></strong>We are hiring! The <strong>Data Engineer</strong> is an integral part of our Community &amp; Intermodal Infrastructure Mountain Team. This is an entry-level position and is based out of <strong>Austin, TX</strong>.<br/><br/><strong>About Us<br/><br/></strong>AtkinsRéalis is one of the world’s most respected design, engineering and project management consultancies. AtkinsRéalis has been providing infrastructure planning, engineering, construction, environmental consulting, urban planning, architecture, and program management services to public and private clients across the United States for more than 50 years. AtkinsRéalis has the depth and breadth of expertise to respond to the most technically challenging and time-critical infrastructure projects and the urgent transition to a low-carbon economy.<br/><br/><strong>How will you contribute to the team?<br/><br/></strong><ul><li>Adept analytic skills including knowledge of MS Excel, PowerBI and other business analysis and intelligence software</li><li>Strong written communication skills including prior experience in MS Word and MS PowerPoint</li><li>Strong verbal communication skills</li><li>Focus on customer service<br/><br/></li></ul><strong>What will you contribute? <br/><br/></strong><ul><li>EXPERIENCE: Business analytics from one or more prior internships; basic understanding of engineering practices such as CAD</li><li>EDUCATION: Bachelor of Science in Engineering</li><li>SPECIAL SKILLS: MS Excel, PowerBI, PowerPoint</li><li>PROFESSIONAL REGISTRATIONS: None required<br/><br/></li></ul><strong>What We Offer At AtkinsRéalis<br/><br/></strong>As an Intern, you will enjoy a host of developmental benefits which includes:<br/><br/><ul><li>Competitive salary</li><li>Hands-on experience with industry leaders</li><li>Support and mentorship from various professionals throughout the business</li><li>Career and educational exploration opportunities such as Client Site Visits, Weekly Lunch &amp; Learns, &amp; various virtual and/or in-person activities<br/><br/></li></ul>As a Full-Time employee, you may enjoy a robust rewards package which includes:<br/><br/><ul><li>Opportunity to work on various projects of various sizes</li><li>Competitive salary</li><li>Flexible work schedules</li><li>Group Insurance</li><li>Retirement Savings Plan with employer match</li><li>Employee Assistance Program (EAP)</li><li>Learning and development programs, training, career opportunities and a highly regarded tuition reimbursement program<br/><br/></li></ul><strong>Expected compensation range is between $70,000 - $78,000 annually/hourly depending on skills, experience, and geographical location. <br/><br/></strong><strong>If this sounds like you and you would like to expand your career with us, apply today! <br/><br/></strong>AtkinsRéalis Is An Equal Opportunity, Drug-free Employer Committed To Diversity In The Workplace. EOE/Minorities/Females/Vet/Disability. Please Review AtkinsRéalis Equal Opportunity Statement Here<br/><br/>https://careers.atkinsrealis.com/equal-opportunities-statement<br/><br/>Upon acceptance of an offer, all candidates must go through a drug screen test and background check. AtkinsRéalis is a federal contractor which mandates a satisfactory background screening report and drug test that supersedes state laws.<br/><br/><strong>AtkinsRéalis cares about your privacy</strong> and are committed to protecting your privacy. Please consult our Privacy Notice on our Careers site to know more about how we collect, use and transfer your Personal Data. By submitting your personal information to AtkinsRéalis, you confirm that you have read and accept our Privacy Notice.<br/><br/><strong>Note To Staffing And Direct Hire Agencies<br/><br/></strong>In the event a recruiter or agency who is not on our preferred supplier list submits a resume/candidate to anyone in the company, AtkinsRéalis family of companies, we explicitly reserve the right to recruit and hire the candidate(s) at our discretion and without any financial obligation to the recruiter or agency. https://careers.atkinsrealis.com/recruitment-agencies<br/><br/>#URR222
      </div>",$70000- $78000,Data Warehouse Engineer
Data Engineer- REMOTE (W2 & Benefits provided) - 4239,Braintrust,12/20/2023,https://www.linkedin.com/jobs/view/3790464872,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
"Analytics Engineer, Data Insights",MERU,12/25/2023,https://www.linkedin.com/jobs/view/3599305298,0,https://media.licdn.com/dms/image/C4E0BAQEVuf3UK2EhgQ/company-logo_100_100/0/1631333559352?e=2147483647&v=beta&t=KDydjKATbpF7A3q6-c3kxeDG9KTxggW0DkHeCIqNdcw,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><u>Meet the Company:</u></p><p>We are MERU. A values-driven, impact-oriented team dedicated to fixing companies. We provide advisory services and data analytics support to middle-market companies ($50M - $2B in annual sales), and our clients include private equity firms, credit funds, investment banks, and law firms. We bring deep turnaround experience, a group of veteran operators, and an incentive-aligned approach to any situation. MERU was founded by professionals from Alvarez &amp; Marsal and McKinsey and has seen rapid growth in the five-plus years since its founding.</p><p><br/></p><p><u>The MERU Way &amp; Valuing Our Team:</u></p><p><strong>We're Partners, not consultants.</strong> When you join MERU, you will help our clients solve their most pressing problems, supported by a team of people who will challenge you, support you, and inspire you.</p><p><br/></p><p>In order to be Partners, <strong>we don't silo people into just one functional area of the business, instead advancing our team's capabilities by providing training for every service that MERU offers. </strong>Additionally, we don't just focus on technical skills but also leadership style and soft skills, so MERU team members not only know what it means to manage a client engagement but to lead a team to success. <strong>In training team members to be well-rounded individuals, we can deliver an overall higher impact to clients</strong>, allowing each individual the ability to gain experience in diligence, turnarounds, interim management, data science, and more.</p><p><br/></p><p>To aid this career advancement and development, MERU provides an internal Coach to each team member in order to guide and maintain their professional development plan goals. <strong>Unlike most Firms, we actually focus on the achievement of those goals for each individual team member, providing opportunities that would not usually be offered. </strong></p><p><br/></p><p>Finally, <strong>MERU values personal time, only traveling when necessary, in order to celebrate and respect your personal life</strong>. We believe that by encouraging and mandating balance, it will lead to happier and longer-tenured team members.</p><p><br/></p><p><strong>When you come to MERU, you come to further your career and maintain your entrepreneurial spirit, never losing sight of the desire to provide meaningful impact, solutions, and value to clients. </strong>Learn more about our colleagues’ core characteristics and culture here: https://wearemeru.com/meru-way/</p><p><br/></p><p><strong><u>Responsibilities: </u></strong></p><ul><li>Demonstrates ownership of individual workstreams with minimal supervision from senior team members, with the ability to coach junior team members on the engagement</li><li>Complete ownership for end-to-end process of engaging stakeholders for design sessions and requirements gathering and solution build​</li><li>Produces high quality, production level code, balances on-time delivery with long-term sustainability</li><li>Proactively communicates progress and roadblocks to senior team members on an ongoing basis; proactively develops solutions to the roadblocks</li><li>Contributes to proposal development (i.e., assistance with analysis/presentation, etc.) and proactively identifies ways to improve the proposal quality (i.e., research, package case studies, etc.)</li><li>Assists Partners in preparation for pitches and attends as required</li><li>Proactively identifies ways to improve proposal quality</li><li>Supports in the development of Firm Contribution areas, such as Recruiting, Professional Development, Marketing, etc.</li></ul><p><br/></p><p><strong><u>Qualifications:</u></strong></p><ul><li><strong>3+ years of business intelligence or data analytics experience</strong></li><li><strong>Previous experience in data and analytics consulting or a client-facing role, required</strong></li><li>Bachelor’s degree from a top university, required</li><li>Strong knowledge and delivery experience with Tableau, Power BI, Qlik, or any other data visualization tools</li><li>Working knowledge of ETL tools like Power Query, Azure Data Factory, FiveTran, Stitch, Alteryx, and languages like SQL, Python, or R</li><li>Relevant certifications associated with business intelligence tools, and enthusiasm to learn new tools and technologies and attain certifications</li><li>Experience in mentoring junior analysts and leading cross-functional teams to deliver data products</li><li>Demonstrated ability to interact and work collaboratively with junior and senior team members, senior management, and other stakeholders or professionals</li><li>Experience in independently managing deliverables with little oversight</li><li>Effective communication skills to explain technical concepts to a non-technical audience or senior executives</li><li>“Roll up your sleeves” mentality and willingness to complete any task if needed, no matter the role</li><li>Ability to assist with internal firm initiatives (e.g., marketing, client pitches)</li><li>Willingness to travel up to 20%</li><li>Ability to work full time in an office and remote environment; physically able to sit/stand at a computer and work in front of a computer screen for significant portions of the workday</li><li>Authorization to work in the United States</li><li>Commitment to living MERU’s values and core characteristics</li></ul><p><br/></p><p><strong><u>Overview of MERU Service Offerings: </u></strong></p><p><br/></p><p>Data Insights:</p><p>Work with companies at all stages of their digital transformation journey to automate reporting processes, build scalable data platforms, and leverage predictive analytics to transform data from a liability into an asset. Services include Data Discovery and Analysis, Data Prep and Integration, Self-Service Analytics, Data Visualization and Reporting, Data Science and Advanced Analytics, and Strategy Enablement.</p><p><br/></p><p>Performance Improvement:</p><p>Help companies identify and achieve their full potential by leveraging a value-focused approach to driving sustainable margin expansion impact. Services include MERU 360° Assessment, Transformation Plan Development, Chief Transformation Officer placement, Cash Cycle and Working Capital Optimization, and Implementation Performance Management.</p><p><br/></p><p>Turnaround &amp; Restructuring:</p><p>Partner with clients during uncertain times to help stabilize operations and rapidly triage the causes of financial distress, charting a path back to long-term sustainability. Services include Interim Management, Turnaround Plan Development and Execution, Liquidity Management, Stakeholder Negotiations, Strategic Alternatives Assessment, Bankruptcy, Insolvency, and Case Management.</p><p><br/></p><p>Transaction Services:</p><p>Partner with private equity firms across the investment lifecycle, from due diligence to portfolio value creation and exit planning. Services include Due Diligence, Pre-Close Planning, Post-Close Implementation, and Exit Planning.</p><p><br/></p><p><strong><u>Salary Range:</u></strong><u> </u></p><p>$105,000 – $155,000. In addition to benefits, MERU also offers an extremely competitive bonus program that is based on firm contribution efforts and performance.</p><p><br/></p><p><strong><u>Voluntary Inclusion:</u></strong></p><p>It is MERU’s policy to provide and promote equal opportunity in employment, compensation, and other terms and conditions of employment without discrimination because of race, color, sex, sexual orientation, family medical history or genetic information, political affiliation, military service, pregnancy, marital status, family status, religion, national origin, age or disability or any other non-merit based factor in accordance with all applicable laws and regulations.</p><p><br/></p><p><strong><u>Unsolicited Resumes from Third-Party Recruiters:</u></strong></p><p>Please note that we do not accept unsolicited resumes from third-party recruiters unless such recruiters are engaged to provide candidates for a specified opening. Any employment agency, person, or entity that submits an unsolicited resume does so with the understanding that MERU will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person, or entity.</p>
</div>",$50- $2,Data Warehouse Engineer
Data Warehouse Developer (W2 Only),Dice,12/21/2023,https://www.linkedin.com/jobs/view/3791469898,0,https://media.licdn.com/dms/image/C560BAQEYK67Tel_mng/company-logo_100_100/0/1630655500596/dice_logo?e=2147483647&v=beta&t=rllH_-w7fwNGRPjMmwRghSwN8osS0JKW18T_-sIwDn4,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, MRoads, is seeking the following. Apply via Dice today!<br/><br/>Hello ,<br/><br/>I hope this message finds you in good health and high spirits.<br/><br/>I am Chandra and we specialize in connecting skilled professionals with exceptional opportunities in the industry. Today, I'm thrilled to share an exciting position with our esteemed client.<br/><br/>Working with our client offers a multitude of benefits for prospective candidates. Here are just a few reasons why this opportunity is worth considering:<br/><br/><ul><li>Innovative Work Environment</li><li>Collaborative Culture:</li><li>Professional Growth</li><li>Comprehensive Benefits Package</li><li>Positive Work-Life Balance<br/><br/></li></ul>I'm excited to share more details about this opportunity and how it aligns with your skills and career goals. Please find the job description for your review.<br/><br/>Job Description:<br/><br/>The Developer must have extensive experience in software analysis, design, development, implementation and maintenance of Data Warehouse/Data Marts. The Developer will work closely with project managers, IT staff, program staff and other stakeholders to define and develop requirements for the enterprise data warehouse. The Developer will apply a range of specialized skills and tools to complete the following specific duties and responsibilities:<br/><br/>The Developer will use their extensive knowledge of business analysis best practices to facilitate requirements sessions and communicate clearly and effectively with end-users, applications developers, senior business managers and other team members. The Developer will be accountable for providing coordination to ensure the appropriate collection of data; documentation of information; and presentation of findings. The Developer will provide documentation and flow-charts of the organization's workflow, as well as ad-hoc query support and report creation.<br/><br/>The Developer must have strong technical knowledge and understanding of IT systems and applications as well as the ability to plan and track business analyses activities as part of a project. The Developer also must have good listening skills and interviewing skills to talk with individuals and groups about their needs and ask the right questions to surface essential requirements information. The ideal candidate will also possess good writing skills to ensure effective communication of information to customers, marketing, managers, and technical staff.<br/><br/><strong>Responsibilities Include (but not limited to):<br/><br/></strong><ul><li>Extensive experience in architecting and designing solutions at Enterprise scale in Enterprise Data warehouse applications.</li><li>Experience in developing Data Warehouse/Data Marts using, as examples, OBIEE, OBI APPS, Cognos, Business Objects, SPSS, SSIS, SSRS, Informatica Power Center, OWB and ODI.</li><li>Experience on design and development of Data Warehouse Architecture for Enterprise Data Warehouse (EDW), Operational data Store (ODS), Operational Data Marts and Data Marts.</li><li>Experience in defining metadata standards for the enterprise data warehouse.</li><li>Experience in design and development of:</li><li>ETL processes using Dimensional Modeling for ROLAP and MOLAP.</li><li>ETL technical architecture.</li><li>BI load dependency plan, job scheduling and cycle management.</li><li>Experience in developing end-to-end Data warehouse ETL routines.</li><li>Experience in using SQL in advanced analytical functions.</li><li>Experience in writing complex PL/SQL packages stored Procedures, functions, cursors, triggers, views, and materialized views.</li><li>Experience in creation of enterprise data Warehouse Test plan, Test script creation and Test Script Execution for different test environments such as System, Integration and User Acceptance.</li><li>Experience developing optimal approach for obtaining data from diverse source system platforms and moving it to the Enterprise Data Warehouse.</li><li>Experience in Logical and Physical data Models for enterprise data warehouse and applications.</li><li>Experience developing and configuring Interactive Dashboards with drill-down capabilities, links/images, HTML objects and folders.</li><li>Proficient in using the time-series functions to support historical time comparison analysis.</li><li>Experience with Calculated Measures and assigned Aggregation levels based on Dimension Hierarchies.<br/><br/></li></ul><strong>Qualifications:<br/><br/></strong><ul><li>Bachelor's degree; MBA or relevant technical degree preferred.</li><li>A strong background in technology, analysis and critically evaluating information gathered from multiple sources.</li><li>Experience decomposing high-level information into details, distinguishing user requests from the underlying true needs, and developing solution ideas from requirements.</li><li>Strong experience writing business requirements documentation (BRDs) and functional requirements documentation (FRDs).</li><li>Proven experience successfully working in a team setting and ability to reconcile conflicts.</li><li>Minimum seven 7-10 years of experience in related professional business/project analyst capacity.</li><li>Excellent oral and written communication skills.</li><li>Experience in the housing and financial sector is preferred and a major plus, especially around accounting, bonds, mortgages, underwriting, loans origination and servicing; in addition to, experience around grants, tax credits, property/buildings asset management and compliance reporting.</li><li>Excellent experience with MS Office 2013/2016 and above as well as design tools and flowcharting tools, e.g. Visio.<br/><br/></li></ul>If you have any questions or would like further information, feel free to reach out. I look forward to discussing this exciting opportunity with you.<br/><br/>Data Warehouse Developer (W2 Only)
      </div>",No Salary Info Found,Data Warehouse Engineer
Lead Data Engineer,Perennial Resources International,12/19/2023,https://www.linkedin.com/jobs/view/3770403212,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer - New York – Hedge Fund,Jobs via eFinancialCareers,12/19/2023,https://www.linkedin.com/jobs/view/3790367167,0,https://media.licdn.com/dms/image/C4E0BAQHhjDirlg_ONg/company-logo_100_100/0/1668664938817/jobs_on_efinancialcareers_logo?e=2147483647&v=beta&t=refvTgFdHLVIMsTAE3P24huUvKBbu0AOPPx69Z2BohQ,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        My client is looking for a Data Engineer to play a key role in designing, developing, and maintaining their data infrastructure. You will work closely with the Quantitative Research team and help develop ETL processes, as well as implementing high quality data.<br/><br/>Requirements:<br/><br/><ul><li>Bachelor's or Master's degree in Computer Science, Data Engineering, or a related field.</li><li>Proven experience as a Data Engineer in the finance industry, preferably within a hedge fund or asset management firm.</li><li>Strong proficiency in programming languages such as Python, Java, or Scala.</li><li>Experience with cloud-based technologies, such as AWS or Azure.<br/><br/><br/></li></ul>To apply please send your CV to quantresearch@octaviusfinance.com<br/><br/>
</div>",No Salary Info Found,Data Warehouse Engineer
Lead Data Engineer,GoodRx,12/19/2023,https://www.linkedin.com/jobs/view/3771706055,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Quality Engineer,Knights of Columbus,12/19/2023,https://www.linkedin.com/jobs/view/3784446203,0,https://media.licdn.com/dms/image/C4D0BAQGXNytfraStuw/company-logo_100_100/0/1630503801075/knights_of_columbus_logo?e=2147483647&v=beta&t=zzv_Aey9H7lfcPj7FWiBEZQJ3nCzvhmtvfShB0zdqk4,"New Haven, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Job description:<br/><br/><p><strong>Feel Good About Doing Good</strong></p><p>The Knights of Columbus is a tax-exempt Catholic fraternal benefit society that provides financial security to members and their families through our life insurance, long-term care insurance, disability income insurance, investment and annuity products. Charity is at the core of our missions: our profits are donated to help those in need and to support our faith - $1.73B over the past ten years.</p><p> </p><p>While we have many employees who are not Catholic, we follow the Church’s teachings in our investment strategies and our employee benefits. As part of our religious mission, we support the pro-life cause by contributing to the March for Life and pregnancy resource centers, we oppose assisted suicide and euthanasia, we are evangelists for the Catholic faith, and we help Christians who are facing religious persecution in the Middle East.  We all work together to support our two million members as they volunteer to help others in their parishes and communities around the world.</p><p> </p><p><strong>Share Your Talent. Live Your Purpose.</strong></p><p>We are a growing and purpose-driven community of professionals. Join us to discover how you can meet your goals and ours!</p><p> </p> <strong>Overview</strong> <p>The Data Quality Engineer is responsible for designing, developing, documenting, and performing data quality checks across all data assets. That includes ETL jobs, reports, dashboards, and data pipelines. The primary goal for this role is to ensure high quality of data delivered to internal stakeholders and customers. Validation of data in data repositories against data from source systems and validation of metrics and data in reports/dashboards against data in the repositories is a key responsibility to ensure data assets are consistently accurate for users. The Sr. Data Quality engineer will engage in all data related activities such as data profiling, cleansing, deduplication, standardization, and conversion.</p> <strong>Core Responsibilities</strong> <ul><li>Work in conjunction with Developers and Data Engineers to ensure high quality Data Deliverable</li><li>Working with the development teams from different groups in the organization, help identify inconsistent data patterns, and how they are manifested from the source processes.</li><li>Design, implement and use data quality assurance frameworks to support the process of identifying inconsistent data patterns.</li> </ul> <ul><li>Analyze complex data systems to develop automated and reusable solutions for extracting requested information while assuring data validity and integrity.</li><li>Perform tasks spanning the full lifecycle of data management activities including but not limited to defining completeness, accuracy, and consistency specifications by data element, writing scripts, and developing tools to monitor quality, developing impact analysis, building data lineage to downstream reporting and analytics, building defining and implementing controls for key data quality measures, and producing interactive data quality dashboards.</li><li>Derives data management structures and metadata to support consistency of information retrieval, combination, analysis, pattern recognition and interpretation, throughout the organization.</li> </ul> <ul><li>Perform ongoing monitoring and refinement of the Data Lakehouse.</li><li>Maintain data standards, enforce standard development protocols, and analyze requirements to ensure technical and standard operating procedure impacts are considered.</li><li>Limit non-standard solutions and escalate when used with documentation supporting exception requirements.</li><li>Assist report writers and data visualization and team members with data sourcing.</li> </ul> <strong>Skills Qualifications</strong>     <p><strong>Required: </strong></p> <ul><li>Strong  understanding and experience in development activities for all aspects of Software Development Cycle (SDLC). Data Vault Methodologies (nice to have)</li><li>Excellent problem solving and critical thinking skills</li><li>Effective communication skills with an ability to explain technical concepts to developers, product managers, and business partners. </li><li>Knowledge and experience with database design principles including referential integrity normalization, and indexing to support application development </li> </ul> <p><strong>Preferred</strong><strong>:</strong></p> <ul><li>Understanding of ETL methodologies and Data Quality principles, approaches, technologies, and architectures including the concepts, designs, andusage of data warehouses and data marts.</li> </ul> <strong>Education</strong> <p><strong>Required:</strong></p> <ul><li>Bachelor’s degree or master’s degree in a quantitative field such as Computer Science and Information Systems, Database Management, Big Data, Data Engineering, Data Science, Applied Math, etc.</li><li>5+ years of professional data analytics working experience. Experience with automotive data is a plus</li> </ul> <p> </p> <p> </p> <p><strong>Preferred:</strong></p> <ul><li>3+ years of experience working with large data and variety of data sources.</li><li>Experience working in virtualized cloud environment including cloud-based IaaS/SaaS/PaaS solutions</li><li>Experience in Power BI, and SQL</li> </ul>     Compensation   <p>The wage range for this role takes into account a broad array of factors that are considered in making compensation decisions, including but not limited to: skill sets; experience and training; licensure and certifications; and other business and organizational needs.  The range below applies as long as the work is performed in Connecticut; the Knights of Columbus reserves the right to adjust the wage range if the position is performed in another location.  At the Knights of Columbus, it is not typical for an individual to be hired at or near the top of the range for their role, and compensation decisions are dependent on the facts and circumstances of each case. A reasonable estimate of the current range is $140,900-$172,400.</p>     Authorization to work in the United States is required   <p>This position is not eligible for visa sponsorship</p> <strong>Physical Demands</strong> <p> </p><p><strong>KofC Cares</strong></p><p>Our mission is focused on family and faith, and we support our employees in seeking a balanced life.</p><p> </p><p>Employee benefits include:</p><p> </p><p>Time Away: 13 paid holidays per year in addition to vacation and paid sick leave, and flexible workweek schedules.</p><p> </p><p>Professional Development: Certifications, designation, and tuition reimbursement.</p><p> </p><p>Retirement Benefits: 401(k) retirement savings plan with matching company contributions, and cash balance retirement plans fully funded by the company.</p><p> </p><p>Health and Wellness:</p><p> </p><ul><li>Short-term disability and term life insurance fully paid for by the company;</li><li>Up to 12 weeks of childbirth leave under STD policy.</li><li>One week of fully paid parental leave for all new parents, including adoptive and foster parents.</li><li>A variety of health insurance options, including premium-level family coverage and a pre-tax Health Savings Account with employer contributions. The Order's health plans do not cover abortion, sterilization, or contraception, and the Order has helped advocate for other employers who do not want to provide coverage.</li><li>Long-term disability insurance;</li><li>Dental insurance;</li><li>Vision insurance;</li><li>Health club membership reimbursement;</li><li>Employee Assistance Program</li> </ul><p> </p>
</div>",$1.73- $140900,Data Warehouse Engineer
Cloud Data Engineer,Talener,12/19/2023,https://www.linkedin.com/jobs/view/3748836564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Staff Data Engineer,Altice USA,12/20/2023,https://www.linkedin.com/jobs/view/3788623769,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Business Intelligence Developer,Fordham University,12/20/2023,https://www.linkedin.com/jobs/view/3785078742,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
"Lead Data Engineer, Data Productivity",SiriusXM,12/20/2023,https://www.linkedin.com/jobs/view/3768755997,0,https://media.licdn.com/dms/image/D560BAQGZYZJBUsuzbg/company-logo_100_100/0/1700146850253/siriusxm_logo?e=2147483647&v=beta&t=mV830XuN8ytZ4D5kSWTIg2jiQLNLiCpQLTTSfAE8xhY,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Who We Are<br/><br/></strong>SiriusXM and its brands (Pandora, SXM Media, AdsWizz, Simplecast, and SiriusXM Connected Vehicle Services) are leading a new era of audio entertainment and services by delivering the most compelling subscription and ad-supported audio entertainment experience for listeners -- in the car, at home, and anywhere on the go with connected devices. Our vision is to shape the future of audio, where everyone can be effortlessly connected to the voices, stories and music they love wherever they are. This is the place where a diverse group of emerging talent and legends alike come to share authentic and purposeful songs, stories, sounds and insights through some of the best programming and technology in the world. Our critically-acclaimed, industry-leading audio entertainment encompasses music, sports, comedy, news, talk, live events, and podcasting. No matter their individual role, each of our employees plays a vital part in bringing SiriusXM’s vision to life every day.<br/><br/>SiriusXM is the leading audio entertainment company in North America, and the premier programmer and platform for subscription and digital advertising-supported audio products. SiriusXM’s platforms collectively reach approximately 150million listeners, the largest digital audio audience across paid and free tiers in North America, and deliver music, sports, talk, news, comedy, entertainment and podcasts. Pandora, a subsidiary of SiriusXM, is the largest ad-supported audio entertainment streaming service in the U.S. SiriusXM's subsidiaries Simplecast and AdsWizz make it a leader in podcast hosting, production, distribution, analytics and monetization. The Company’s advertising sales organization, which operates as SXM Media, leverages its scale, cross-platform sales organization and ad tech capabilities to deliver results for audio creators and advertisers. SiriusXM, through Sirius XM Canada Holdings, Inc., also offers satellite radio and audio entertainment in Canada. In addition to its audio entertainment businesses, SiriusXM offers connected vehicle services to automakers.<br/><br/><strong>How You'll Make An Impact<br/><br/></strong>We are seeking a highly skilled and motivated Lead Data Productivity Engineer to join our dynamic team at SiriusXM. As a Lead Data Productivity Engineer, you will play a key role in designing, building, and maintaining the tools and services used by our data professionals in order to effectively drive the business in a data-driven manner. The ideal candidate will have a strong background in cloud technologies, data engineering, infrastructure as code, API design, and experience applying software engineering and DevOps best practices.<br/><br/><strong>What You'll Do<br/><br/></strong><ul><li>Design, develop, and maintain tools and services that empower data professionals to streamline their workflows and enhance productivity.</li><li>Collaborate with cross-functional teams to understand data analysis, engineering, and modeling needs and translate them into effective and user-friendly solutions.</li><li>Implement best practices for optimizing data processing workflows, ensuring efficient utilization of resources, and minimizing latency in data-related tasks.</li><li>Identify and address bottlenecks in existing tools and services to improve overall system performance.</li><li>Integrate data productivity tools with existing data infrastructure and platforms, fostering seamless collaboration among teams.</li><li>Develop and implement automation solutions to streamline repetitive tasks and enhance the efficiency of data processes.</li><li>Create comprehensive documentation for tools and services, ensuring that users have access to clear and concise instructions.</li><li>Provide training and support to data professionals, enabling them to effectively leverage the tools and services developed.</li><li>Work closely with data scientists, engineers, and analysts to understand their requirements and challenges, fostering a collaborative and innovative environment.</li><li>Communicate project status, issues, and solutions effectively to stakeholders and team members.<br/><br/></li></ul><strong>What You’ll Need<br/><br/></strong><ul><li>Bachelor's degree in a relevant technical field (Computer Science, Information Technology, etc.), and 5+ years' career experience</li><li>Proven experience in software development, with a focus on tools and services for data professionals.</li><li>Proficiency in programming languages such as Python, Scala, or Java.</li><li>Experience with infrastructure as code tools such as CDK or Terraform.</li><li>Experience with big data technologies (e.g., Apache Spark, Hadoop) and data processing frameworks.</li><li>Knowledge of data storage solutions, database systems, and data warehousing.</li><li>Familiarity with machine learning frameworks and model development is a plus.</li><li>Excellent problem-solving skills and a proactive approach to addressing challenges.</li><li>Strong communication and collaboration skills.<br/><br/></li></ul>At SiriusXM, we carefully consider a wide range of factors when determining compensation, including your background and experience. These considerations can cause your compensation to vary. We expect the base salary for this position to be in the range of $126,000 to $145,800 and will depend on your skills, qualifications, and experience. Additionally, this role might be eligible for discretionary short-term and long-term incentives. We encourage all interested candidates to apply.<br/><br/>Our goal at SiriusXM is to provide and maintain a work environment that fosters mutual respect, professionalism and cooperation. SiriusXM is an equal opportunity employer that does not discriminate on the basis of actual or perceived race, creed, color, religion, national origin, ancestry, alienage or citizenship status, age, disability or handicap, sex, gender identity, marital status, familial status, veteran status, sexual orientation or any other characteristic protected by applicable federal, state or local laws.<br/><br/>The requirements and duties described above may be modified or waived by the Company in its sole discretion without notice.<br/><br/>R-2023-11-87
      </div>",$126000- $145800,Data Warehouse Engineer
"Data Enginner, CorpFPA",Amazon,12/23/2023,https://www.linkedin.com/jobs/view/3787203007,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083989,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $140,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$140000- $173000,Data Warehouse Engineer
"Data Engineer, TikTok Multimedia",TikTok,12/19/2023,https://www.linkedin.com/jobs/view/3603931307,0,https://media.licdn.com/dms/image/C510BAQGCdThXIss7UQ/company-logo_100_100/0/1630606162248/tiktok_logo?e=2147483647&v=beta&t=139uJTX7-HNeX1_kJsHK-Ztmj2K9yb9XfIIGQoNOW3c,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong> TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices, including Los Angeles, New York, London, Paris, Berlin, Dubai, Mumbai, Singapore, Jakarta, Seoul, and Tokyo.<br/><br/>Why Join Us<br/>At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.  <br/><br/>About the Team<br/>The Multimedia Data Platform team is responsible for optimizing app experience related to performance for TikTok users by providing data support. Working in collaboration with various teams throughout TikTok, the data platform team focuses on the creation and consumption of video content to provide comprehensive optimization solutions. This includes end-to-end optimization solutions such as client, video shooting, uploading, video playback, video delivery and player, etc.<br/><br/>Responsibilities:<br/><br/>Our Multimedia data platform team work closely with our product managers and data analysts by building state of the art streaming and batch data processing solution. The entire data pipeline is not only supporting the core business at TikTok -- short video, but also horizontal business across TikTok. In this role, you will see a direct link between your work, and the company's business success. You will have opportunities to deal with Petabyte-level data warehouse. Some of the world's most challenging technical and business problems are waiting for you to solve.<br/><br/>- Apply broad knowledge of technology options, technology platforms, design techniques and approaches across the Data Engineering ecosystem to build systems that meet quality needs.<br/>- Build systems and datasets using software engineering best practices, data management fundamentals, data storage principles, recent advances in distributed systems, and operational and engineering excellence best practices.<br/>- Analyze systems, define transformation requirements, design suitable data models and document the design/specifications.<br/>- Demonstrate passion for quality and productivity by using efficient development techniques, standards and guidelines.<br/>- Drive the design, to build, execute, and maintain automated tests and/or manage deep data profiling runs to ensure data products and pipelines meet expectations<br/>- Partner with analysts, engineers, subject matter experts, and product managers to apply TikTok Multimedia analytical and quality methods to satisfy client needs.<br/>- Participate in the growth of the Data Quality Excellence practice by sharing knowledge and lessons learned, continually improving best practices, and contributing to methods that will systematically advance workforce capabilities<br/>- Effectively communicate through technical documentation, commented code, and interactions with stakeholders and adjacent teams<br/>- Contribute to building a vibrant workplace, where teams can thrive, and model the organization’s positive, supportive culture of respect and excellence <br/><br/><strong>Qualifications<br/><br/></strong> - BS/BA in Technical Field, Computer Science or Mathematics.<br/>- 3+ years experience in the data warehouse space.<br/>- 3+ years experience in custom ETL design, implementation and maintenance.<br/>- 2+ years experience working with big data technologies (Hadoop, Hive, Spark, Clickhouse, etc.) .<br/>-  2+ years experience with schema design and dimensional data modeling.<br/>-  3+ years experience in writing SQL statements. <br/>-  Proficient in one of Programming languages (e.g., Python, Go, C++)<br/>-  Communication skills, including the ability to identify and communicate data driven insights.<br/>- Ability in managing and communicating data warehouse plans to internal clients.<br/><br/>TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too. <br/><br/>TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at gprd.accommodations@tiktok.com. <br/><br/><strong>Job Information:<br/><br/></strong>【For Pay Transparency】Compensation Description (annually) <p>The base salary range for this position in the selected city is $145000 - $250000 annually.<span>​</span></p><p>Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.<span>​</span></p><p>Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: <span>​</span></p><p>We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&amp;D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. <span>​</span></p><p>Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. <span>​</span></p><p>We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.<span>​</span></p>
</div>",$145000- $250000,Data Warehouse Engineer
"Staff Data Engineer, Data Products (Contract)",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3759869668,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Platform Engineer,GSK,12/19/2023,https://www.linkedin.com/jobs/view/3787663116,0,https://media.licdn.com/dms/image/C4E0BAQE52m4AbEhxCw/company-logo_100_100/0/1663675238924/glaxosmithkline_logo?e=2147483647&v=beta&t=6Td8hCQOgB4Yx1roeAvIKbaMn-ru_w3eZThfb-FZ_Jc,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Site Name:</strong> USA - California - San Francisco, Cambridge 300 Technology Square, London The Stanley Building, Seattle Sixth Ave<br/><br/><strong>Posted Date:</strong> Dec 18 2023<br/><br/>At GSK, we want to supercharge our data capability to better understand our patients and accelerate our ability to discover vaccines and medicines. The Onyx Research Data Platform organization represents a major investment by GSK R&amp;D and Digital &amp; Tech, designed to deliver a step-change in our ability to leverage data, knowledge, and prediction to find new medicines. We are a full-stack shop consisting of product and portfolio leadership, data engineering, infrastructure and DevOps, data / metadata / knowledge platforms, and AI/ML and analysis platforms, all geared toward:<br/><br/><li>Building a next-generation, metadata- and automation-driven data experience for GSK’s scientists, engineers, and decision-makers, increasing productivity and reducing time spent on “data mechanics” </li><li>Providing best-in-class AI/ML and data analysis environments to accelerate our predictive capabilities and attract top-tier talent. </li><li>Aggressively engineering our data at scale, as one unified asset, to unlock the value of our unique collection of data and predictions in real-time.</li>Automation of end-to-end data flows: Faster and reliable ingestion of high throughput data in genetics, genomics, and multi-omics, to extract value of investments in new technology (instrument to analysis-ready data in <li>Enabling governance by design of external and internal data:  with engineered practical solutions for controlled use and monitoring </li><li>Innovative disease-specific and domain-expert specific data products: to enable computational scientists and their research unit collaborators to get faster to key insights leading to faster biopharmaceutical development cycles. </li><li>Supporting e2e code traceability and data provenance: Increasing assurance of data integrity through automation, integration </li><li>Improving engineering efficiency: Extensible, reusable, scalable, updateable, maintainable, virtualized traceable data and code would be driven by data engineering innovation and better resource utilization. <br/><br/></li>We are looking for a skilled and experienced <strong>Data Platform Engineer I </strong>to join our growing team. Data Platform Engineers take full ownership of delivering high-performing, high-impact data platform as products, and services, from a description of a problem customer Data Engineers are trying to solve all the way through to final delivery (and ongoing monitoring and operations). They are standard bearers for software engineering and quality coding practices within the team and are expected to mentor more junior engineers; they may even coordinate the work of more junior engineers on a large project. They devise useful metrics ensuring their services are meeting customer demand, having an impact, and iterate to deliver and improve on those metrics in an agile fashion.<br/><br/>A <strong>Data Platform Engineer I </strong>should have awareness of the most common tools (languages, libraries, etc) within their specialization. They should be constantly seeking feedback and guidance to further develop their technical skills and expertise and should take feedback well from all sources in the name of development.<br/><br/><strong><strong>Why You</strong>?<br/><br/></strong><strong>Basic Qualifications<br/><br/></strong>We are looking for professionals with these required skills to achieve our goals:<br/><br/><br/><ul><li>Bachelor's degree in computer science, Software Engineering, or related discipline.</li><li>Experience with standard components for cloud-based data pipelines including ingestion, transformation, and orchestration. </li><li>Experience with Standard components for publishing data to file-based, relational, and other sorts of data storage.  </li><li>Experience with Standardized physical storage and search / indexing systems.  </li><li>Experience with Standard API architectures and tooling for QA / evaluation.  </li><li>Provide L3 support to existing tools / services / pipelines.<br/><br/><br/></li></ul><strong>Preferred Qualifications:<br/><br/></strong>If you have some of the following characteristics, it would be a plus:<br/><br/><br/><ul><li>Master's degree in computer science, Software Engineering with 0-2 Years of experience.</li><li>Schema and governance management (data + metadata + versioning + provenance + access control)    </li><li>Experience using at least one common programming language (e.g., Python, Scala, Java), including toolchains for documentation and testing</li><li>Experience with common data engineering tooling like Spark, data warehousing, ETL tools, workflow tools.</li><li>Exposure to Infrastructure/Configuration as Code tools and techniques</li><li>Exposure to modern software development tools / ways of working (e.g. git/GitHub, devops tools, …)</li><li>Exposure to tools, techniques, etc relevant to their specialization area (e.g. AI/ML, DevOps, Data Platforms)<br/><br/><br/></li></ul>#GSKOnyx<br/><br/>The annual base salary for new hires in this position ranges from $92,251 to $124,810 taking into account a number of factors including work location, the candidate’s skills, experience, education level and the market rate for the role. In addition, this position offers an annual bonus and eligibility to participate in our share based long term incentive program which is dependent on the level of the role. Available benefits include health care and other insurance benefits (for employee and family), retirement benefits, paid holidays, vacation, and paid caregiver/parental and medical leave.<br/><br/>Please visit GSK US Benefits Summary to learn more about the comprehensive benefits program GSK offers US employees.<br/><br/><strong>Why Us?<br/><br/></strong>GSK is a global biopharma company with a special purpose – to unite science, technology and talent to get ahead of disease together – so we can positively impact the health of billions of people and deliver stronger, more sustainable shareholder returns – as an organization where people can thrive. Getting ahead means preventing disease as well as treating it, and we aim to positively impact the health of 2.5 billion people by the end of 2030.<br/><br/>Our success absolutely depends on our people. While getting ahead of disease together is about our ambition for patients and shareholders, it’s also about making GSK a place where people can thrive. We want GSK to be a workplace where everyone can feel a sense of belonging and thrive as set out in our Equal and Inclusive Treatment of Employees policy. We’re committed to being more proactive at all levels so that our workforce reflects the communities we work and hire in, and our GSK leadership reflects our GSK workforce.<br/><br/>If you require an accommodation or other assistance to apply for a job at GSK, please contact the GSK Service Centre at 1-877-694-7547 (US Toll Free) or +1 801 567 5155 (outside US).<br/><br/>GSK is an Equal Opportunity Employer and, in the US, we adhere to Affirmative Action principles. This ensures that all qualified applicants will receive equal consideration for employment without regard to race, color, national origin, religion, sex, pregnancy, marital status, sexual orientation, gender identity/expression, age, disability, genetic information, military service, covered/protected veteran status or any other federal, state or local protected class.<br/><br/><strong>Important notice to Employment businesses/ Agencies<br/><br/></strong>GSK does not accept referrals from employment businesses and/or employment agencies in respect of the vacancies posted on this site. All employment businesses/agencies are required to contact GSK's commercial and general procurement/human resources department to obtain prior written authorization before referring any candidates to GSK. The obtaining of prior written authorization is a condition precedent to any agreement (verbal or written) between the employment business/ agency and GSK. In the absence of such written authorization being obtained any actions undertaken by the employment business/agency shall be deemed to have been performed without the consent or contractual agreement of GSK. GSK shall therefore not be liable for any fees arising from such actions or any fees arising from any referrals by employment businesses/agencies in respect of the vacancies posted on this site.<br/><br/>Please note that if you are a US Licensed Healthcare Professional or Healthcare Professional as defined by the laws of the state issuing your license, GSK may be required to capture and report expenses GSK incurs, on your behalf, in the event you are afforded an interview for employment. This capture of applicable transfers of value is necessary to ensure GSK’s compliance to all federal and state US Transparency requirements. For more information, please visit GSK’s Transparency Reporting For the Record site.<br/><br/>
</div>",$92251- $124810,Data Warehouse Engineer
Data Engineer,PitchBook,12/19/2023,https://www.linkedin.com/jobs/view/3721103987,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
"Data Engineer, Product Analytics",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3725767513,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Redmond, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.<br/><br/>Data Engineer, Product Analytics Responsibilities:<br/><br/><ul><li>Conceptualize and own the data architecture for multiple large-scale projects, while evaluating design and operational cost-benefit tradeoffs within systems</li><li>Create and contribute to frameworks that improve the efficacy of logging data, while working with data infrastructure to triage issues and resolve</li><li>Collaborate with engineers, product managers, and data scientists to understand data needs, representing key data insights in a meaningful way</li><li>Define and manage SLA for all data sets in allocated areas of ownership</li><li>Determine and implement the security model based on privacy requirements, confirm safeguards are followed, address data quality issues, and evolve governance processes within allocated areas of ownership</li><li>Design, build, and launch collections of sophisticated data models and visualizations that support multiple use cases across different products or domains</li><li>Solve our most challenging data integration problems, utilizing optimal ETL patterns, frameworks, query techniques, sourcing from structured and unstructured data sources</li><li>Assist in owning existing processes running in production, optimizing complex code through advanced algorithmic concepts</li><li>Optimize pipelines, dashboards, frameworks, and systems to facilitate easier development of data artifacts</li><li>Influence product and cross-functional teams to identify data opportunities to drive impact</li><li>Mentor team members by giving/receiving actionable feedback<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.</li><li>4+ years of work experience in data engineering (a minimum of 2+ years with a Ph.D)</li><li>Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Master's or Ph.D degree in a STEM field</li><li>Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy</li><li>Experience working with terabyte to petabyte scale data<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data Warehouse Engineer
"Data Engineer , Amazon Pharmacy",Amazon,12/20/2023,https://www.linkedin.com/jobs/view/3768741058,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,Meta,12/20/2023,https://www.linkedin.com/jobs/view/3703435524,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,Cognitiv,12/22/2023,https://www.linkedin.com/jobs/view/3786755333,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
"Data Engineer, Google Customer Solutions",Google,12/23/2023,https://www.linkedin.com/jobs/view/3790696258,0,https://media.licdn.com/dms/image/C4D0BAQHiNSL4Or29cg/company-logo_100_100/0/1631311446380?e=2147483647&v=beta&t=5bmvSDVt4i-ECxTU43yiS4iXUM4inJiG-e9PHOUlxx0,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This role may also be located in our Playa Vista, CA campus.<br/><br/>Note: By applying to this position you will have an opportunity to share your preferred working location from the following: <strong>Redwood City, CA, USA; Ann Arbor, MI, USA; Chicago, IL, USA; New York, NY, USA; Los Angeles, CA, USA; San Francisco, CA, USA</strong>.<strong>Minimum qualifications:<br/><br/></strong><ul><li>Bachelor’s degree or equivalent practical experience.</li><li>2 years of experience in software development in one or more general purpose programming languages (e.g., Java, C/C++, C#, Python, etc.), including experience with SQL.</li><li>Experience in data pipeline development and business communication.</li><li>Experience in relational/non-relational databases, API development (e.g. REST), or backend system design.<br/><br/></li></ul><strong>Preferred qualifications:<br/><br/></strong><ul><li>Master’s degree in Business, Statistics, Mathematics, Economics, Engineering, or Applied Science, or a related field.</li><li>Ability to work with stakeholders to provide technical solutions to business challenges.</li><li>Excellent project management skills and ability to prioritize tasks.</li><li>Basic proficiency in and passion for data analysis.<br/><br/></li></ul><strong>About The Job<br/><br/></strong>The Revenue Strategy and Operations (RSO) team is the strategic and operational arm of Google Customer Solutions (GCS) and is responsible for setting priorities and then driving implementation.<br/><br/>Within RSO, the Engineering team is responsible for creating technical solutions to support and maximize traction with Google's advertisers. We lead the design, planning, and operations, using a scalable and analytical programmatic approach to drive business initiatives through our products, in collaboration with cross-functional teams across Sales, Marketing, Product, and Engineering.<br/><br/>When our millions of advertisers and publishers are happy, so are we! Our Google Customer Solutions (GCS) team of entrepreneurial, enthusiastic and client-focused members are the ""human face"" of Google, helping entrepreneurs both individually and broadly build their online presence and grow their businesses. We are dedicated to growing the unique needs of advertising companies. Our teams of strategists, analysts, advisers and support specialists collaborate closely to spot and analyze customer needs and trends. In collaboration, we create and implement business plans broadly for all types of businesses.<br/><br/>The US base salary range for this full-time position is $93,500-$135,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.<br/><br/>Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Design, build, deploy, and improve data pipelines and applications using standard and Google-specific software development tools. This may include ensuring reliable backends, building pipelines to aggregate data from multiple sources, or enhancing performance of existing tools and services.</li><li>Analyze problems and develop solutions, while identifying dependencies and resolving issues to drive implementation. Make technical contributions, including writing and reviewing design documents, tests, and code.</li><li>Provide subject-matter expertise and utilize comprehensive knowledge of Google's relevant technologies, principles, practices, and coding standards.</li><li>Collaborate with cross-functional users and stakeholders to identify pain points and devise innovative technical solutions.<br/><br/><br/></li></ul>Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .
      </div>",$93500- $135000,Data Warehouse Engineer
Data Analyst,VEGAMOUR,12/22/2023,https://www.linkedin.com/jobs/view/3789934613,0,https://media.licdn.com/dms/image/C560BAQGN9AZYNXQjNA/company-logo_100_100/0/1630664015519/vegamour_hair_logo?e=2147483647&v=beta&t=oLGaYC6o9DNSk98W9czItDldk5WJbh_Qml2yjE6Xf4Y,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>VEGAMOUR is a rapidly growing hair wellness company that combines sustainably harvested, plant-based actives with the latest advances in molecular science to produce clean formulas that effectively promote hair &amp; scalp health. We believe in biodiversity, community, Fair Trade and corporate responsibility. Our mission is to advocate the use of thoughtfully sourced, organic plant actives in creating superior wellness &amp; beauty products that neither harm the people who use them or the planet we all share.<br/><br/><strong>What You’ll Do<br/><br/></strong>We are seeking an experienced Data Analyst to join our Data &amp; Analytics team. Reporting to the Sr. Director, Data &amp; Analytics the ideal candidate has strong technical ability (SQL, Python, R) and is passionate about influencing outcomes with analytics and insights.<br/><br/>The Data Analyst will leverage data to develop actionable recommendations and insights, dashboards, and ad hoc analysis that support strategic initiatives at VEGAMOUR. They will be a thought partner in the business and work closely with Performance Marketing, CRM, Digital Product, and Finance teams to establish KPIs and improve LTV, AOV, and retention.<br/><br/>A successful candidate is proficient in SQL and other coding languages (Python, R), has experience building dashboards in Tableau, and possesses the ability to clearly communicate complex analytical concepts to both technical and non-technical audiences.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>Partner with the eCommerce teams to understand key opportunities and evaluate the impact of A/B tests, media spend, and CRM flows</li><li>Perform ad hoc and exploratory analysis to fuel growth at VEGAMOUR</li><li>Build Tableau dashboards that improve data visibility and enable a culture of data driven decision making</li><li>Design and develop data tables to enable scalable analytics and improve speed to insight <br/><br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Bachelors Degree in a quantitative field (Economics, Math, Statistics) </li><li>2-4 years of experience working in an Analytics role</li><li>Proficiency in data wrangling and manipulation (SQL, Python, R)</li><li>Experience building data visualization and dashboards with Tableau (preferred) or other data visualization tool</li><li>Highly analytical, creative problem solver, who can identify trends and insights from disparate data sources</li><li>Nice to have:</li><ul><li>DTC subscription experience at a consumer goods company</li><li>Experience with MMM models and media optimization</li><li>Knowledge of eCommerce KPIs and metrics<br/></li></ul></ul><strong>Compensation &amp; Benefits<br/><br/></strong>Base Salary Range: $100K - $120K. Individual pay decisions are based on a number of factors including qualifications for the role and experience.<br/><br/><strong>We Also Currently Offer<br/><br/></strong><ul><li>Competitive total package including annual bonus and equity</li><li>Health Insurance: Medical, Dental and Vision - we cover 90% for employees and 60% for dependents</li><li>401K + 3% match plan</li><li>Unlimited PTO</li><li>Generous Paid Parental Leave <br/><br/><br/></li></ul><em>All qualified applicants will receive consideration for employment regardless of race, creed, color, or national origin. It is important to Vegamour to create a diverse and inclusive team so even if you don't meet all of the requirements listed in the job description please consider applying anyway!<br/><br/></em>
</div>",$100- $120,Data Warehouse Engineer
Junior Data Engineer,goop,12/19/2023,https://www.linkedin.com/jobs/view/3775680912,0,https://media.licdn.com/dms/image/D560BAQEuXX5sW7EgDA/company-logo_100_100/0/1667506305560/goop__logo?e=2147483647&v=beta&t=fZmW-5CU9ewymLvff3ItOmGVh__JJls4wRtJ8BFWilI,"Santa Monica, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>About The Company</strong></p><p><br/></p><p>Gwyneth Paltrow launched goop from her kitchen as a homespun weekly newsletter. It’s grown a lot since then; goop is a lifestyle platform encompassing curated products and content about beauty, wellness, fashion, food, and home. Pioneering the contextual commerce platform, goop allows readers to shop with meaning. goop is one of the rare places on the web where food, shopping, and mindfulness collide—where the ever-evolving intent is to make every choice count. We’re all resource-strapped, so goop hopes to surface the very best experiences, recipes, products, and advice.</p><p><br/></p><p><strong>About You</strong></p><p><br/></p><p>You possess technical knowledge in SQL, Python, and wrangling large amounts of data, but you are also a strong collaborator and a passionate advocate for data. </p><p><br/></p><p><strong>About The Role</strong></p><p><br/></p><p>goop is looking for a talented and innovative Jr. Data Engineer to join our team. In this role you will help unify and bring to life our ever-growing data from all areas of business – e-commerce, retail, web analytics, logistics, marketing, and more. You will develop, deploy, and maintain data systems that will allow the company to use data in impactful and exciting ways. </p><p><br/></p><p>Responsibilities Include:</p><p><br/></p><ul><li>Architect new data solutions that will allow us to process batched and real-time data.</li><li>Build and maintain ETLs from 3rd party data sources.</li><li>Ensure data quality through automated testing and alerting.</li><li>Identify, design, and implement internal process improvements such as automating manual processes and optimizing infrastructure.</li></ul><p><br/></p><p><strong>Qualifications &amp; Experience</strong></p><p><br/></p><ul><li>2+ years of experience working on backend software using modern scripting languages and frameworks (Python)</li><li>2+ years of engineering experience relating to data engineering and large-scale data transformations; strong experience with relational databases (PostgreSQL, Redshift, MySQL)</li><li>Hands-on experience in cloud computing (AWS, EC2, S3, Athena, Lambda)</li><li>Experience with batch and real-time data processing (Airflow, Kinesis, Kafka)</li><li>Proficiency in Agile development process preferred.</li><li>Skillful problem solver, detail oriented with experience and ability to QA multiple data sources.</li><li>Strategic, cross-functional thinking with ability to gather business partners’ buy-in for projects.</li></ul><p><br/></p><p><strong>FAQ</strong> </p><p><br/></p><ul><li>Compensation:<strong> </strong>$100,000-$115,000 + Equity. This is a full time, exempt role. Please note that this range represents the low and high end of the anticipated base salary range for the Los Angeles, CA based position. Goop, in good faith, reasonably expects to pay the position within this salary range. Goop provides the salary range in compliance with all applicable federal, state and local laws. The actual base salary will depend on numerous factors such as: experience, training, knowledge and skills, and if the location of the job changes.</li><li>Benefits: Generous health benefits package, fertility benefits and paid parental leave. </li><li>Perks: “goopcation” paid company summer break, generous goop discounts, special offers with brand partners, access to custom lifestyle resources and events, and a beautiful work space in Santa Monica </li><li>Work Philosophy: At goop we believe that creativity, innovation and camaraderie are essential to our business, our culture and our employee’s growth and development. With our Hybrid Work Policy, we are committed to promoting collaboration, productivity and employee well-being by maximizing the benefits of both in-person and remote work. We are in office Tuesdays and Thursdays, as well as Mondays for those within a 15-mile radius of our Santa Monica office.</li></ul><p><br/></p><p><em>goop is an Equal Opportunity Employer. goop does not discriminate on the basis of race, religion, color, sex, gender identity, sexual orientation, age, non-disqualifying physical or mental disability, national origin, veteran status or any other basis covered by appropriate law. All employment is decided on the basis of qualifications, merit, and business need. All information provided by the applicant is collected, stored and processed in accordance with the terms of our CCPA Notice for Job Candidates. </em></p><p><br/></p><ul><li>Job Disclosures: No applicant disclosures related to physical requirements or ADA-related considerations are relevant for this role </li><li>Application Requirements: All applicants will be reviewed through Greenhouse submission. Direct submissions to the People Operations Team members will not be reviewed separately. </li><li>Candidate Requirements: Applicant must have US work authorization.</li></ul>
</div>",$100000- $115000,Data Warehouse Engineer
Data Engineer,University of Southern California,12/19/2023,https://www.linkedin.com/jobs/view/3500265434,0,https://media.licdn.com/dms/image/C4E0BAQHatTfEv4Af6w/company-logo_100_100/0/1631312619853?e=2147483647&v=beta&t=SMp5VNiFDNwEqti49w8FPl5yYzg-RYxhNB3IEE0jqZI,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The University of Southern California, founded in 1880, is located in the heart of downtown and is the largest private employer in the City of Los Angeles. As an employee of USC, you will be a part of a world-class research university and a member of the “Trojan Family.”<br/><br/>USC University Advancement is seeking a collaborative <strong>Data Engineer</strong> to design, build, and launch new data models to provide intuitive analytics to customers. Reporting to the Executive Director of Business Intelligence, the Data Engineer will move data from our Data Warehouse Systems into downstream databases and data marts for analysis. This is a hybrid position based in our downtown Los Angeles office (USC Tower).<br/><br/>USC values diversity and is committed to equal opportunity in employment. USC University Advancement is committed to fostering a diverse, equitable, and inclusive culture in which all advancement staff and our stakeholders have the opportunity to connect, belong, and grow while supporting the USC’s mission, values, and goals.<br/><br/><strong>Job Accountabilities<br/><br/></strong><ul><li>Architect, build, and launch new data models that provide intuitive analytics to your customers</li><li>Design, build and launch extremely efficient &amp; reliable data pipelines to move data (both large and small amounts) from our Data Warehouse Systems into downstream databases and data marts for analysis</li><li>Develop strategies to extract, resolve, and unify information of various types from numerous disparate data sources and integrate cohesively with external business applications</li><li>Collaborate with a cross-functional team of client leads, application developers, operations engineers, and architects to translate complex product requirements into technical specs and design requirements</li><li>Optimize performance and cost efficiency of cloud-based processes across multiple cloud environments (AWS, Azure, GCP)</li><li>Design, build and deploy ETL and data management processes with reliable error/exception handling and rollback framework</li><li>Provide production support for data load jobs and develop customized query to generate automatic periodic reports</li><li>Build applications writing SQL/Python scripts to manipulate data and/or writing specific instructions for off-shore programmers to write the scripts</li><li>Provide daily monitoring, management, troubleshooting, and issue resolution to existing and new data solutions and systems’ interfaces affected by them.</li><li>Develop high quality, reliable, and fault-tolerant data solutions based on internal and external customers/users’ requirements, applying best practices and new trends/technologies all along the solution lifecycle.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>2+ years of overall experience developing cloud-native data solutions on Azure/AWS (Must have a solid understanding of cloud concepts: Storage, Compute, Network and Managed Services)</li><li>Broad knowledge of different database technologies beyond RDBMS, vendor/solution capabilities in data management and reporting/analytics – data federation, big data, data quality, Business Intelligence, etc., and writing complex SQL queries in a data warehouse environment</li><li>3+ years of experience programming in PowerShell and C#</li><li>3+ years of experience in SQL, data transformations, statistical analysis, and troubleshooting across more than one Database Platform (Cassandra, MySQL, Snowflake, PostgreSQL, Redshift, Azure SQL Warehouse, etc.).</li><li>3+ years of experience designing and building solutions utilizing various Cloud services such as EC2, S3, EMR, Kinesis, RDS, Redshift/Spectrum, Lambda, Glue, Athena, API gateway, etc.</li><li>Experience with one or more relevant tools (Sqoop, Flume, Kafka, Oozie, Hue, Zookeeper, HCatalog, Solr, Avro, SSIS)</li><li>Experience with one or more SQL-on-Hadoop technology (Hive, Impala, Spark SQL, Presto)</li><li>Experience with AWS ecosystem (Data Lake Formation, Glue, Data Pipelines, EC2, Redshift, S3, Glacier, DynamoDB, Lambda, etc.)<br/><br/></li></ul><strong>Documentation And Additional Information<br/><br/></strong>To apply, please include a resume and cover letter.<br/><br/>The annual base salary range for this position is $96,739.35 - $110,000. When extending an offer of employment, the University of Southern California considers factors such as (but not limited to) the scope and responsibilities of the position, the candidate’s work experience, education/training, key skills, internal peer equity, federal, state, and local laws, contractual stipulations, grant funding, as well as external market and organizational considerations.<br/><br/>USC has excellent benefits, including health benefits for staff &amp; their family with access to the renowned university medical network; retirement plans with employer contributions once you meet Program’s eligibility; tuition benefits for staff &amp; their family; central Los Angeles location with easy access to commuter trains, buses &amp; free tram pick up services.<br/><br/>The University of Southern California values diversity and is committed to equal opportunity in employment.<br/><br/>Minimum Education: Bachelor's degree Minimum Experience: 3 years Minimum Field of Expertise: Direct knowledge and experience in data modeling, data warehousing and reporting. Project management experience for complex projects. Demonstrated organizational, critical thinking, interpersonal, planning, problem solving, and business analytical skills. Able to work at a high functional and technical level.
      </div>",$96739.35- $110000,Data Warehouse Engineer
Data Engineer,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3790370222,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Burbank, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Looking for someone with a strong background working as a data engineer pulling and extracting data, as well as building pipelines &amp; distributed systems. The ideal candidate will have strong experience with Python, PySpark, SQL, and AWS.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>Experience with Python programming </li><li>Experience with PySpark </li><li>Strong AWS experience </li><li>Comfortable working within several SQL databases </li><li>Experience with one or more data warehousing technology <br/><br/></li></ul>What You Will Be Doing<br/><br/>Tech Breakdown<br/><br/><ul><li>50% Building Pipelines with PySpark </li><li>50% Data cleaning and integration <br/><br/></li></ul>Daily Responsibilities<br/><br/><ul><li>100% Hands On <br/><br/></li></ul>The Offer<br/><br/><ul><li>Competitive base salary and equity offered <br/><br/></li></ul><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical &amp; Dental Insurance </li><li>Health Savings Account (HSA) </li><li>401(k) with 3% match </li><li>Unlimited Paid Time Off </li><li>Pre-tax Commuter Benefit </li><li>Unlimited remote access </li><li>Flexible work from home schedule (onsite 2-3 days/month) </li><li>On-site Gym <br/><br/></li></ul>Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Julie Bennett
      </div>",No Salary Info Found,Data Warehouse Engineer
Data and Platform Engineer,"Honda of America Mfg., Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3790802092,0,https://media.licdn.com/dms/image/C4E0BAQHJzoYpgeuWkw/company-logo_100_100/0/1631310920236?e=2147483647&v=beta&t=sPSFxpdwUEU0KcluhRMcpvXucMepm76QmsROz96EVLo,"Torrance, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Workstyle: </strong>Hybrid (20% onsite)<br/><br/><strong>Preferred onsite location: </strong>Torrance, OH or Marysville, OH<br/><br/>The <strong>Data and Platform Engineer</strong> plays a crucial role in designing, developing, and maintaining scalable and reliable data platforms to support the organization's data needs. With a propensity of action over analysis , they are responsible for ensuring efficient data ingestion, storage, processing, and retrieval, as well as providing data integration solutions to enable effective data analysis and reporting. This role requires a strong understanding of data engineering concepts, data management, and programming languages to deliver innovative data solutions while respecting governance principles like responsible AI and data privacy.<br/><br/><strong>Data Integration And Transformation<br/><br/></strong><ul><li>Develop and implement data integration solutions to enable seamless data movement across various systems and platforms.</li><li>Implement efficient data workflows, data pipelines, and ETL processes to accommodate structured and unstructured data from various sources to ensure the timely delivery of high-quality data.</li><li>Define data models and build data hierarchy structures to support AI/ML model integrations that are reliable and scalable.</li><li>Transform and cleanse data to ensure accuracy, consistency, and integrity.</li><li>Collaborate with data analysts and data scientists to understand data requirements and deliver tailored solutions.</li><li>Troubleshoot and resolve data integration issues in a timely manner.<br/><br/></li></ul><strong>Data Platform Development And Maintenance<br/><br/></strong><ul><li>Design, develop, and maintain scalable data platforms that support data ingestion, storage, processing, and retrieval.</li><li>Collaborate with cross-functional teams to ensure data platforms meet the organization's evolving data requirements.</li><li>Regularly monitor the data platform's performance, identifying and resolving any issues or bottlenecks<br/><br/></li></ul><strong>Data Quality, Governance And Security<br/><br/></strong><ul><li>Implement and enforce data quality and governance assurance policies, ensuring compliance with relevant data protection regulations and industry best practices.</li><li>Develop and maintain data security measures, including access controls, encryption, and data anonymization techniques.</li><li>Monitor data usage and access patterns, proactively identifying and mitigating potential security risks.</li><li>Collaborate with the IT and cybersecurity teams to address data-related vulnerabilities and incidents.</li><li>Perform data profiling, data validation, and data cleansing activities to ensure data.accuracy and completeness.</li><li>Collaborate with stakeholders to identify and resolve data quality issues.</li><li>Define and monitor data quality metrics to measure and improve data quality over time.</li><li>Conduct regular audits and reviews to ensure adherence to data quality standards.</li><li>Ensure data governance and compliance standards, including responsible AI principles and data privacy, are adhered to during data integration and transformation processes.<br/><br/></li></ul><strong>Performance Optimization<br/><br/></strong><ul><li> Identify and implement performance optimization strategies for data platforms and processes. </li><li> Optimize database design, data structures, and query performance to enhance data retrieval speed. </li><li> Monitor and analyze data processing and query performance metrics, taking proactive actions to optimize their performance. </li><li> Collaborate with infrastructure and network teams to ensure optimal data platform performance. </li><li> Conduct regular performance testing and tuning activities and optimize data platforms for performance, reliability, and security. <br/><br/></li></ul><strong>Documentation And Knowledge Sharing<br/><br/></strong><ul><li> Document data platform architecture, data models, data flows, and technical specifications. </li><li> Create and maintain comprehensive documentation of data engineering processes and workflows. </li><li> Share knowledge and best practices with team members and stakeholders. </li><li> Provide training and support to users on data engineering tools and technologies. </li><li> Contribute to the development and enhancement of data engineering standards and guidelines. </li><li> Continuously research, evaluate and implement emerging technologies and best practices in data engineering to drive innovation. </li><li> BS in Technical discipline such as Computer Science, Information Systems, Computer Engineering or a related field. Proven experience as a Data Engineer, Database Developer, or relevant experience and certifications are welcome in lieu of a degree. <br/><br/></li></ul><strong>Minimum Experience<br/><br/></strong><ul><li> Strong understanding of data engineering principles, data management, and data modeling concepts. </li><li> Proficient in programming languages such as Python, Java, or Scala, with experience in database query languages (e.g., SQL). </li><li> Experience with cloud-based data platforms (e.g., AWS, Azure, GCP) and associated services (e.g., S3, Redshift, BigQuery). </li><li> Familiarity with data integration techniques, ETL frameworks (e.g., Apache Spark), and workflow management tools (e.g., Airflow). </li><li> Experience with data streaming and real-time data processing frameworks (e.g., Kafka, Apache Flink, AWS Kinesis, etc). </li><li> Familiarity with machine learning and AI techniques for data analysis and prediction. </li><li> Understanding of data security, encryption, privacy, and compliance requirements. </li><li> Excellent problem-solving and analytical skills, with the ability to optimize data processing pipelines for performance and efficiency. </li><li> Strong communication skills, with the ability to effectively collaborate with cross-functional teams and explain complex technical concepts to non-technical stakeholders. <br/><br/></li></ul><strong>Other Job-specific Skills<br/><br/></strong><ul><li> Experience with data engineering tools and frameworks such as Apache Airflow, Apache NiFi, Talend, etc. </li><li> Experience with Data science tools such as Open Data Hub (Seldon, Prometheus, Dataiku, IBM Watson Studio, etc) </li><li> Deep learning - machine learning that is a neural network with three or more layers, which helps to “learn” from large amounts of data. </li><li> Cloud/big data tools (ex. blob storage, Redshift, Kafka, Hadoop, Spark, Hive etc.). </li><li> Experience with containerization technologies such as Docker or Kubernetes.</li></ul>
</div>",No Salary Info Found,Data Warehouse Engineer
"Data Engineer, Product Analytics",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3725959368,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for our 3 billion plus users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match.<br/><br/>Data Engineer, Product Analytics Responsibilities:<br/><br/><ul><li>Manage and execute data warehouse plans for a product or a group of products to solve well-scoped problems</li><li>Identify the data needed for a business problem and implement logging required to ensure availability of data, while working with data infrastructure to triage issues and resolve</li><li>Collaborate with engineers, product managers and data scientists to understand data needs, representing key data insights in a meaningful way</li><li>Build data expertise and leverage data controls to ensure privacy, security, compliance, data quality, and operations for allocated areas of ownership</li><li>Design, build and launch new data models and visualizations in production, leveraging common development toolkits</li><li>Independently design, build and launch new data extraction, transformation and loading processes in production, mentoring others around efficient queries</li><li>Support existing processes running in production and implement optimized solutions with limited guidance</li><li>Define and manage SLA for data sets in allocated areas of ownership<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.</li><li>2+ years of work experience in data engineering</li><li>Experience with SQL, ETL, data modeling, and at least one programming language (e.g., Python, C++, C#, Scala, etc.)<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Experience with one or more of the following: data processing automation, data quality, data warehousing, data governance, business intelligence, data visualization, data privacy</li><li>Experience working with terabyte to petabyte scale data<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer,STAND 8 Technology Services,12/20/2023,https://www.linkedin.com/jobs/view/3773569628,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Cloud Data Engineer,BDO USA,12/20/2023,https://www.linkedin.com/jobs/view/3784492450,0,https://media.licdn.com/dms/image/D560BAQFsPZUT0bTpJg/company-logo_100_100/0/1689000656484/bdo_usa_logo?e=2147483647&v=beta&t=-M1FfX9Kow8d2drx-DmltN3u3liHKtB3vVhqpNf3A8Q,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>Job Summary:<br/><br/></strong>This position will work with cutting edge technology, deliver high quality solutions across various industries, and collaborate with teams on engagements that range in size and scope. This position will receive continuous career development opportunities, given the size and potential of client engagements. This role will perform hands-on delivery of data analytics projects, contributing to the development and unit testing of solutions.<br/><br/><strong>Job Duties<br/><br/></strong><ul><li> Designs and implements best in class data ingestion strategies, data warehouse and data mart structures, semantic layers and models, visualizations, streaming processes, API integrations, and automation (RPA) solutions for end-to-end data analytics solutions on primarily, but not limited to, cloud analytics platforms such as Azure and AWS </li><li> Listens to client needs to align solution with business requirements and delivery schedule </li><li> Creates written functional and technical designs </li><li> Participates in project status and stand meetings, and assists with providing project status for project and program managers </li><li> Assists with SLA compliance of solutions, and performs performance tuning and optimization efforts of end-to-end solutions </li><li> Writes code using multiple languages and correctly applies frameworks, architectural patterns, and software development principles </li><li> Delivers high-performance, scalable, repeatable, and secure deliverables with broad impact (high throughput and low latency) </li><li> Assists with implementation of data governance programs and best practices </li><li> Performs the cleaning and transforming of data from source systems into analytics models </li><li> Implements models to support data visualizations and integrations </li><li> Assists with implementing DevOps, DataOps and MLOps methodologies on projects </li><li> Writes custom integration logic in applicable programming languages </li><li> Works directly with clients and team members to establish secure data analytics platforms and infrastructure </li><li> Contributes to successful deployments of developed solutions and integration of DevOps tools </li><li> Maintains a broad and current understanding of data analytics and business intelligence strategies, cloud platforms, methodologies, and tools </li><li> Builds client relationships during project execution </li><li> Participates in support activities for existing software solutions </li><li> Other duties as assigned <br/><br/><br/></li></ul><strong>Supervisory Responsibilities<br/><br/></strong><ul><li> N/A <br/><br/><br/></li></ul><strong>Education<br/><br/></strong><strong>Qualifications, Knowledge, Skills and Abilities:<br/><br/></strong><ul><li> High School diploma or GED equivalent, required </li><li> Bachelor’s degree, preferred; focus in Information Systems, Data Science or Computer Science, preferred <br/><br/><br/></li></ul><strong>Experience<br/><br/></strong><ul><li> Three (3) or more years of experience within Data Analytics, Business Intelligence, Artificial Intelligence, or Application Development, required <br/><br/><br/></li></ul><strong>Software<br/><br/></strong><ul><li> Strong SQL skills including Data Definition Language (DDL), Data Manipulation Language (DML), views, functions, stored procedures, or performance tuning, required </li><li> Experience with Data Warehousing, Data Modeling, Semantic Model Definition or Star Schema Construction, preferred </li><li> Hands on delivery experience of end-to-end cloud data analytics solutions within Azure or AWS, preferred </li><li> Experience with one (1) or more of the following computer languages, preferred:</li><ul><li> C# </li><li> Python </li><li> Java </li><li> Scala </li></ul><li> Experience with tabular modeling within Microsoft Fabric, Power BI, or Azure Analysis Services, preferred </li><li> Experience with Git and DevOps deployment technologies, preferred </li><li> Experience with Linux, preferred </li><li> Experience with one (1) or more of the following, preferred:</li><ul><li> Data Lake Medallion Architecture </li><li> Batch and/or streaming data ingestion into a data lake </li><li> AI Algorithms/Machine Learning </li><li> Automation tools such as UiPath, Alteryx, etc. </li><li> Computer Vision based AI technologies <br/></li></ul></ul><strong>Other Knowledge, Skills &amp; Abilities<br/><br/></strong><ul><li> Ability to work with a high degree of professionalism and autonomy </li><li> Excellent verbal and written communication skills </li><li> Solid organizational skills, especially the ability to meet project deadlines with a focus on details </li><li> Ability to successfully multi-task while working independently or within a group environment </li><li> Ability to work in a deadline-driven environment, and handle multiple projects simultaneously </li><li> Ability to interact effectively with people at all organizational levels of the Firm </li><li> Ability to build and maintain strong relationships with internal and client personnel </li><li> Ability to encourage a team environment on engagements <br/><br/><br/></li></ul><strong>Keywords: </strong> Data Analytics, Business Intelligence, BI, Synapse, IoT, Machine Learning, Data Lake, Stream, Cube, Microsoft, SQL Server, Tableau, .Net, C#, Qlik, Power BI, Machine Learning, Azure Data Factory, RedShift, UiPath, Cloud, RPA, AWS, Redshift, Kinesis, QuickSight, SageMaker, S3, Databricks, AWS Lake Formation, Snowflake, Python, Qlik, Athena, Data Pipeline, Glue, Star Schema, Data Modeling, SQL, SSIS, SSAS, SSRS, PySpark, Microsoft Fabric, dbt, Linux, Terraform, Bicep, Data Ops, Purview, Git, Delta, Pandas, Spark SQL<br/><br/>Individual salaries that are offered to a candidate are determined after consideration of numerous factors including but not limited to the candidate’s qualifications, experience, skills, and geography.<br/><br/>California Range: $94,000 - $121,000<br/><br/>Colorado Range: $94,000 - $121,000<br/><br/>New York City/ Valhalla Range: $94,000 - $121,000<br/><br/>Washington Range: $94,000 - $121,000<br/><br/><strong>About Us<br/><br/></strong>BDO delivers assurance, tax, digital technology solutions and financial advisory services to clients throughout the country and around the globe. We offer numerous industry-specific practices, world-class resources, and an unparalleled commitment to meeting our clients’ needs. We currently serve more than 400 publicly traded domestic and international clients.<br/><br/><ul><li>Unparalleled partner-involvement </li><li>Deep industry knowledge and participation</li><li>Geographic coverage across the U.S.</li><li>Cohesive global network </li><li>Focused capabilities across disciplines<br/><br/><br/></li></ul>BDO brings world-class resources and exceptional service to each and every one of our clients. BDO USA is a member of BDO International, the world’s fifth largest accounting network.<br/><br/>BDO offers a competitive Total Rewards package that encompass so much more than – “traditional benefits”. Our wide range of rewards and our employees’ ability to customize rewards to their individual needs are two of the reasons why BDO has been honored with so many workplace awards, including 100 Best Companies for Working Parents, Working Mother 100 Best Companies, Top Entry Level Employer, 2022 National Best &amp; Brightest Companies to Work For and more.<br/><br/><strong>Some Examples Of Our Total Rewards Offerings Include<br/><br/></strong><ul><li>Competitive pay and eligibility for an annual performance bonus. </li><li>A 401k plan plus an employer match</li><li>Comprehensive, medical, dental, vision, FSA, and prescription insurance from day one</li><li> Competitive Paid Time Off with daily accrual from day one of employment, plus paid holidays </li><li>Paid Parental Leave</li><li>Adoption Assistance</li><li>Firm paid life insurance</li><li>Wellness programs</li><li>Additional offerings include BDO Flex, Group Legal insurance, Pet insurance and Long-Term Care Insurance <br/><br/><br/></li></ul>Above offerings may be subject to eligibility requirements.<br/><br/>Click here to find out more!<br/><br/>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability or protected veteran status.<br/><br/>""BDO USA, P.A. is an EO employer M/F/Veteran/Disability""<br/><br/>
</div>",$94000- $121000,Data Warehouse Engineer
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789086620,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $160,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$160000- $173000,Data Warehouse Engineer
"Data Engineer, Data Platform",Grammarly,12/25/2023,https://www.linkedin.com/jobs/view/3656898066,0,https://media.licdn.com/dms/image/C560BAQFroT18wpIblQ/company-logo_100_100/0/1669669290715/grammarly_logo?e=2147483647&v=beta&t=ztA7DBsCxjynNbw6oGlEHqtgqJneLWUJ1rfYbYVi91A,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>Grammarly is excited to offer a </em><em>remote-first hybrid working model</em><em>. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.<br/><br/></em><em>All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków. </em><em>This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.<br/><br/></em><em>Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.<br/><br/></em><strong>The opportunity <br/><br/></strong>Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.<br/><br/>To achieve our ambitious goals, we’re looking for a Data Engineer to join our Data Engineering Platform team. This person will build highly automated, low latency core datasets that will help data engineers and end users across Grammarly to work with analytical data at scale.<br/><br/>Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.<br/><br/><strong>Your impact<br/><br/></strong>As a Data Engineer on our Data Engineering Platform team, you will:<br/><br/><ul><li>Drive improvements to make our analytics effortless by creating and adjusting core data models and storage structures, all while understanding the needs of our users. </li><li>Make analytical data and metrics usable within a few minutes of real world events occuring, and build streaming processes for the output derived events and aggregate data.</li><li>Model structure, storage, and access of data at very high volumes for our data lakehouse.</li><li>Improve developer productivity and self-serve solutions by contributing components to our stream data processing framework(s).</li><li>Own data engineering's infrastructure-as-code for provisioning services that allow our engineers to deploy mature software installations within a few hours.</li><li>Build a world-class process that will allow our systems to scale.</li><li>Mentor other back-end engineers on the team and help them grow.</li><li>Build and contribute to AWS high-scale distributed systems on the back-end.<br/><br/></li></ul><strong>We’re Looking For Someone Who<br/><br/></strong><ul><li>Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.</li><li>Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.</li><li>Is able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub where the team is based.</li><li>Has experience with Python, Scala, or Java.</li><li>Has experience with designing database objects and writing relational queries</li><li>Has experience designing and standing up APIs and services.</li><li>Has experience with system design and building internal tools.</li><li>Has experience handling applications that work with data from data lakes.</li><li>Has at least some experience building internal Admin sites.</li><li>Has good knowledge of and at least some experience with AWS (or, alternatively, has deep expertise in Azure or GCE and is willing to learn AWS in a short time frame).</li><li>Can knowledgeably choose an open source or third-party service to accomplish what they need or, alternatively, can devise a quick and simple solution on their own.<br/><br/></li></ul><strong>Support for you, professionally and personally<br/><br/></strong><ul><li>Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.</li><li>A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs. <br/><br/></li></ul><strong>Compensation And Benefits<br/><br/></strong>Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:<br/><br/><ul><li>Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)</li><li>Disability and life insurance options</li><li>401(k) and RRSP matching </li><li>Paid parental leave</li><li>Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days </li><li>Home office stipends</li><li>Caregiver and pet care stipends</li><li>Wellness stipends</li><li>Admission discounts</li><li>Learning and development opportunities<br/><br/></li></ul>Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.<br/><br/>Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.<br/><br/><strong>United States<br/><br/></strong>Zone 1: $167,000 - $242,000/year (USD)<br/><br/>Zone 2: $150,000 – $218,000/year (USD)<br/><br/>Zone 3: $142,000 – $206,000/year (USD)<br/><br/>Zone 4: $134,000 – $194,000/year (USD)<br/><br/><strong>We encourage you to apply<br/><br/></strong>At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).<br/><br/><em>Please note that EEOC is optional and specific to US-based candidates.<br/><br/></em>#NA<br/><br/><em>All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.<br/><br/></em>
</div>",$167000- $242000,Data Warehouse Engineer
Data Solutions Engineer,Analytica,12/20/2023,https://www.linkedin.com/jobs/view/3785044139,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,Blackstone Talent Group,12/19/2023,https://www.linkedin.com/jobs/view/3790357905,0,https://media.licdn.com/dms/image/C560BAQHAFlnQg3firg/company-logo_100_100/0/1657148420727/blackstonetalentgroup_logo?e=2147483647&v=beta&t=RR2QR8qXLbGf4EMMe1qv0MfDEW6BsTugoFERHF1Nxgg,Washington DC-Baltimore Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>We are looking for a <strong>Data Engineer </strong>to join our team of experts to assist with building state-of-the-art data platforms for the client's premier data analytics platform.</p><p><br/></p><p><strong>Responsibilities:</strong></p><p>The Data Engineer will support data collection, ingestion, validation, and loading of optimized data in the appropriate data stores. They work on a team made up of analyst(s), developer(s), data scientist(s), and product leads, and everyone on the team collaborates in support of a specific mission. Working directly with the analyst(s) and the product lead, the data engineer identifies and implements solutions for the data requirements, including building pipelines to collect data from disparate, external sources and implementing rules to validate that expected data is received, cleansed, transformed, massaged and in an optimized output format for the data store. </p><p><br/></p><p>The Data Engineer performs validation and analytics corresponding with client requirements and evolves solutions through automation, optimizing performance with minimal human involvement. As pipelines are executed, the data engineer monitors their status, and performance, and troubleshoots issues while working on improvements to ensure the solution is the very best version to address the customer need. </p><p><br/></p><p><strong>Required Skills:</strong></p><ul><li><strong>Clearance: Secret or Top Secret Clearance</strong></li><li>6+ years of experience with SQL</li><li>6+ years of experience developing data pipelines using modern Big Data ETL technologies like NiFi or StreamSets</li><li>6+ years of experience with a modern programming language such as Python or Java</li><li>6 years of experience working in a big data and cloud environment</li><li>Documented experience with AWS, EC2, S3, and/or RDS</li></ul><p><br/></p><p><strong>Preferred Skills:</strong></p><ul><li>3 years of experience working in an agile development environment</li><li>Ability to quickly learn technical concepts and communicate with multiple functional groups</li><li>Ability to display a positive, can-do attitude to solve the challenges of tomorrow</li><li>Possession of excellent verbal and written communication skills</li><li>Preferred experience at the respective command with an understanding of analytical and data paint points and challenges across the J-Codes.</li></ul><p></p>
</div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer,Tential Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3771471112,0,https://media.licdn.com/dms/image/C560BAQHnOqVlYhs_Qw/company-logo_100_100/0/1644376641769/tential_logo?e=2147483647&v=beta&t=KGNXyf8sS9RdkjXtqLM2TG9fNnJmesGJvYC4j3btUis,"Vienna, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>Modernize an On-Prem architecture migrating to Azure creating new data pipelines and contributing to architectural decisions. Develop strategies for data acquisition, and database implementation. Responsible for designing, building, integrating data from various resources, and managing big data. Solves highly complex problems; takes a broad perspective to identify solutions. Works independently.<br/><br/><strong>Requirements<br/><br/></strong><ul><li>Must have strong hands-on experience with Azure Data Factory and Databricks.</li><li>3+ years of experience in data engineering.</li><li>Experienced in sourcing, maintaining, and updating data in On-Prem and Cloud environments.</li><li>Strong SQL skills and knowledge of data warehousing and ETL best practices.</li><li>Experience designing, building and monitoring of data pipelines using Azure Data Factory.</li><li>Understands data warehousing, data cleaning, data pipelines and other analytical techniques required for data usage.</li><li>Experience using GIT &amp; Source Control. </li><li>Some experience in developing NO SQL solutions using Azure Cosmos DB.</li><li>Bachelor’s degree in Information Systems, Computer Science, Engineering, or related field, or the equivalent combination of education, training and experience.<br/><br/><br/></li></ul><strong>Responsibilities:<br/><br/></strong><ul><li>Develop high-performance data pipelines.</li><li>Contribute to architectural decisions and system evaluations.</li><li>Build conceptual and logical data models for stakeholders and management.</li><li>Ensure data quality and continuous improvement.</li><li>Familiarity with data warehousing concepts and best practices.</li><li>Perform other duties as assigned.<br/><br/><br/></li></ul><strong>Additional Information:<br/><br/></strong><ul><li>Our client is looking for candidates local to either the VA or Pensacola (but preference is Pensacola) area but are open to Full-time remote within the United States.<br/><br/><br/></li></ul>#Dice<br/><br/>#Remote<br/><br/>
</div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer,ASCENDING Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3790307654,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,Kearney & Company,12/19/2023,https://www.linkedin.com/jobs/view/3790345109,0,https://media.licdn.com/dms/image/C4D0BAQF6_7WsdCwmqg/company-logo_100_100/0/1631311582093?e=2147483647&v=beta&t=G5FR9nbxsXrXyuSMW9lZYvvigcpM_rJQ-k6pqY3_sW0,"Arlington, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Kearney and Company is currently seeking a Data Engineer to join our Arlington, VA team. The Data Engineer will develop pipelines for data acquisition and ingestion, enabling detailed data analytics using industry leading tools and capabilities. You will be part of a customer focused team developing productive working relationships with client personnel, delivering capabilities for the Department of Defense through agile methodology.<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Create and update data pipelines and conduct data ingesting operations</li><li>Query, discover, export, and connect dashboards/analytic models to data provided by DoD stakeholders</li><li>Develop and translate functional data requirements to assemble datasets and program related business logic</li><li>Ensure the data catalog is updated with metadata related to new data being ingested.</li><li>Maintain relationships and communicate with key client personnel to understand business operations, processes, and functions</li><li>Develop and run reconciliation scripts to support customer data and use cases</li><li>Adhere to management’s Agile Development process, including using JIRA and Slack daily</li><li>Present progress to senior stakeholders</li><li>Balance multiple projects concurrently<br/><br/></li></ul><strong>Qualifications<br/><br/></strong>Required Qualifications<br/><br/><ul><li>BA, BS or BBA degree in mathematics, engineering, computer science, or related area and at least 2 years of relevant experience</li><li>Must have at least an active Secret clearance</li><li>Prior experience as a data engineer, data architect, or data scientist</li><li>Experience with using Databricks to perform data transformations or modeling (including Databricks SQL and Delta Lake)</li><li>Intermediate knowledge of SQL and Python</li><li>Experience working with Accounting and Financial Management Data</li><li>Experience independently evaluating controls over security processes, infrastructure, network, applications and databases</li><li>Ability to provide on-site support 3-5 days a week at the Pentagon or Mark Cente<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Data engineer or data architect certification: Amazon Web Services (AWS) Certified Data Analytics - Specialty, or other related designation preferred</li><li>Experience with StreamSets</li><li>Understanding of DoD Financial Management Systems</li><li>Experience with PySpark</li><li>Experience with bash scripting</li><li>Experience with ini/cfg configuration files<br/><br/></li></ul><strong>Overview<br/><br/></strong>Exclusively focused on the Government, Kearney &amp; Company provides financial services, including auditing, consulting, and technology services. Our commitment to our employees and clients as well as to dedication and trust, critical values to our Firm, have led to Kearney’s recognition as one of the leading accounting firms in the country. Based on our employees’ feedback, we are also consistently rated a Best Place to Work. Employment at Kearney means a flexible, collaborative, and open-minded work environment. We hope it is your “first easy decision.” Learn more at www.kearneyco.com/careers.<br/><br/><strong>EEO Notice<br/><br/></strong><strong> Applicants have rights under Federal Employment Laws <br/><br/></strong>EEO Notice<br/><br/>Work location is subject to change based on client requirements.<br/><br/>Kearney &amp; Company is an Equal Opportunity Employer and will consider all qualified applicants without regard to race, color, creed, genetic information, religion, national origin, ethnicity, gender; gender identity, sexual orientation, pregnancy, childbirth or related medical condition, age, disability or handicap, servicemember status, relationship or association with a protected veteran, and any other category protected by Federal, state, or local law. Click here to learn more.<br/><br/>If you would like to request a reasonable accommodation, regarding accessibility of our website, a modification or adjustment of the job application or interview process due to a disability, please call 703-236-2391 or email accommodations@kearneyco.com. Please be advised that this contact information is for accommodation requests only and cannot be used to inquire about the status of an application.<br/><br/><strong> Family and Medical Leave Act (FMLA) <br/><br/></strong>FMLA is designed to help employees balance their work and family responsibilities by allowing them to take reasonable unpaid leave for certain family and medical reasons. Kearney &amp; Company provides eligible employees with up to 12 weeks of unpaid, job-protected leave per year. Military family leave is available for up to 26 weeks under FMLA. Click here to learn more.<br/><br/><strong> Employee Polygraph Protection Act (EPPA) <br/><br/></strong>The EPPA prohibits most private employers from using lie detector tests either for pre-employment screening or during the course of employment. Kearney &amp; Company adheres all provisions of the EPPA. Click here to learn more.
      </div>",No Salary Info Found,Data Warehouse Engineer
Data Warehouse Engineer,Professional Diversity Network,12/19/2023,https://www.linkedin.com/jobs/view/3790079003,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,AIS (Applied Information Sciences),12/19/2023,https://www.linkedin.com/jobs/view/3790397815,0,https://media.licdn.com/dms/image/C560BAQHp1kpjCizStA/company-logo_100_100/0/1650474047060/appliedis_logo?e=2147483647&v=beta&t=0zaStHXJmyvvuARlyARf-YfhCfDN5Stw6-i6UVPjAgM,"Reston, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        As a <strong>Data Engineer</strong>, you will use cutting-edge cloud and data technologies to help global brands and federal agencies solve challenging problems through innovative technology solutions. Work on exciting projects, future-proof your skills and grow into your dream job alongside some of the industry's most talented, knowledgeable, and dedicated technologists.<br/><br/><strong>What You'll Be Doing<br/><br/></strong><ul><li>Work in a team using cutting edge technologies to solve challenging business problems and build solutions.</li><li>Apply your skills in Azure Cognitive Services, Azure PaaS, data science, data analytics, and data warehousing to pioneer Azure cloud and data services.</li><li>Interact directly with our client(s) to understand their needs and meet or exceed their expectations by meeting delivery deadlines.<br/><br/></li></ul><strong>Location and Travel Details<br/><br/></strong>This is a remote position with occasional travel (if needed).<br/><br/><strong>Profile of Success<br/><br/></strong><ul><li>Minimum of six years of comparable data engineering experience.</li><li>Deep knowledge of data ingestion strategies and understanding of the V-dimensions of data (velocity, volume, variety, veracity).</li><li>Extensive experience with Azure storage technologies (Azure Data Lake, Azure SQL Data Warehouse, Azure SQL Database).</li><li>Extensive experience with Azure data movement and transformation capabilities (Azure Data Factory, Data Lake Analytics, Data Bricks, Stream Analytics).</li><li>Comfortable with Microsoft SQL data technologies (SSAS/SSIS/SSRS). <br/><br/></li></ul><strong>Desirable Skills<br/><br/></strong><ul><li>Microsoft related certifications.</li><li>Experience with visualization tools such as Power BI or Tableau.<br/><br/></li></ul><strong>About AIS<br/><br/></strong><strong>AIS, Dedicated to Our People<br/><br/></strong>AIS employees can spend their entire career at AIS doing challenging, rewarding work and reach their desired level of achievement and responsibility. We offer the opportunity to move up, without the obligation to move out of a position where one excels. We are committed to our employee's success; however, they define it.<br/><br/>It's our dedication to our employees that inspired our leadership to invest in our future and become partially employee-owned through an Employee Stock Ownership Program (ESOP).<br/><br/>Our employees are our greatest strength, and we do all that we can to serve them. We invest in technology as early adopters, allowing us to create transformative and innovative solutions for our customers while exposing our team to cutting edge technology.<br/><br/>We hire outstanding individuals who are committed to curiosity, passionate about emerging technology, and who are excited to find innovative solutions for the biggest tech challenges facing international brands and government agencies today.<br/><br/>We Invest in Individuals Committed to Innovation<br/><br/>AIS is seeking professionals of a certain character and level of excellence. People that we can learn from and that we can help grow to achieve their personal career goals.<br/><br/><strong>We are looking for:<br/><br/></strong><ul><li>Smart people with a passion for technology</li><li>Strong technical capabilities with a consultancy mindset</li><li>Close involvement with local technical communities</li><li>A willingness to think outside of the box to provide innovative solutions to clients</li><li>Ability to solve challenging technical business problems</li><li>Self-directed professionals<br/><br/></li></ul><strong>Our Core Values<br/><br/></strong><ul><li>Client Success </li><li>Continued Learning and Technical Excellence</li><li>Strong Client Relationships</li><li>Citizenship and Community<br/><br/></li></ul><strong>EEO Statement<br/><br/></strong>Applied Information Sciences is an Equal Opportunity Employer and does not discriminate on the basis of race, national origin, religion, color, gender, sexual orientation, age, disability, protected veteran status, or any other basis covered by law. Employment decisions are based solely on qualifications, merit, and business need.
      </div>",No Salary Info Found,Data Warehouse Engineer
Data Warehouse System Engineer,"Freedom Technology Solutions Group, LLC",12/19/2023,https://www.linkedin.com/jobs/view/3788138050,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Lead Data Engineer,b.well Connected Health,12/19/2023,https://www.linkedin.com/jobs/view/3788400303,0,https://media.licdn.com/dms/image/D560BAQEHw4NSx1G2tQ/company-logo_100_100/0/1665072270644/icanbwell_logo?e=2147483647&v=beta&t=Ejy8ERHl6Rc2Sw7gg0JqMg1V0UHmCP7CchIFkbYYBZM,Washington DC-Baltimore Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Lead Data Engineer - Data Interoperability Team</strong></p><p><br/></p><p>As a Lead Data Engineer, you will be a critical member of the Data Interoperability team responsible for building and maintaining data pipelines and data infrastructure that connects to thousands of data sources around the country to bring together a person’s health record in one place. </p><p><br/></p><p>b.well Connected Health has the largest set of connected health data for any person in the United States. By bringing a person’s health data into one place, we are able to help everyone get convenient and affordable health care.</p><p><br/></p><p>This position is available for fully remote work.</p><p><br/></p><p><strong>What You'll Do:</strong></p><p><br/></p><ul><li>Design, build, and maintain b.well’s data pipeline infrastructure using Python, Spark, Prefect, Kubernetes and other modern technologies</li><li>Lead a team of data engineers to build data pipelines and infrastructure that connects to thousands of data sources around the country including health providers, insurance companies, pharmacies and labs.</li><li>Launch new projects from ideation to completion</li><li>Help lead other developers to improve their career development and coding abilities</li><li>You will safeguard sensitive data by following policies and training concerning your security and privacy responsibilities</li></ul><p><br/></p><p><strong>Job Requirements:</strong></p><p><br/></p><ul><li>7+ years of professional programming experience (must include Python)</li><li>2+ years building microservices in Python</li><li>Exceptional and demonstrable data engineering experience</li><li>Experience in loading, validating, cleaning, and manipulating data files</li><li>Strong experience with unit testing and test-driven development</li><li>Strong experience with relational and/or NoSQL databases</li><li>Strong experience with cloud-based infrastructure</li><li>Comfort with Linux/Unix command line</li></ul><p><br/></p><p><strong>Great to Have:</strong></p><p><br/></p><ul><li>7+ years of Advance Python experience</li><li>5+ years of data pipeline engineering experience</li><li>1+ years of experience with Spark</li><li>Experience with Airflow or Prefect</li><li>Experience with Docker</li><li>Experience with streaming data</li><li>Experience scaling technology solutions to hundreds of thousands active users</li><li>Experience mentoring other developers</li><li>Deep understanding of common API methodologies</li><li>Startup experience</li></ul><p><br/></p><p><strong>Blow Us Away:</strong></p><p><br/></p><ul><li>Experience working with third-party healthcare APIs, HL7, data streams, and/or flat files</li><li>Experience in cybersecurity</li><li>Experience with HIPAA, HITECH, and HITRUST</li><li>An active GitHub profile or other public code portfolio</li><li>Active Stack Overflow profile</li><li>Documented work on open source projects</li></ul><p><br/></p><p>We are committed to an inclusive and diverse b.well. We are an equal opportunity employer. We do not discriminate based on race, ethnicity, color, ancestry, national origin, religion, sex, sexual orientation, gender identity, age, disability, veteran, genetic information, marital status or any other legally protected status.</p>
</div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer (1010914),The Judge Group,12/23/2023,https://www.linkedin.com/jobs/view/3786157763,0,https://media.licdn.com/dms/image/C4D0BAQGH4WOP34jGTA/company-logo_100_100/0/1630528651657/the_judge_group_logo?e=2147483647&v=beta&t=njix2ikW6D1eqCrPNZaRBPW5vxQoSDtFEHuWL4s8WY0,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Location: </strong> Dallas, TX<br/><br/><strong>Description: </strong> Perm salary 110-130k plus bonus<br/><br/>Must be a w2 employee of The Judge Group<br/><br/>Designs, develops, optimizes, and maintains data architecture and pipelines that adhere to ELT principles and business goals.<br/><br/>Solves complex data problems to delivers insights that helps business achieve its goals.<br/><br/>Creates data products for engineer, analyst, and data scientist team members to accelerate their productivity.<br/><br/>Engineer effective features for modelling in close collaboration with data scientists and businesses Leads the evaluation, implementation and deployment of emerging tools and process for analytics data engineering to improve productivity and quality.<br/><br/>Partners with machine learning engineers, BI, and solutions architects to develop technical architectures for strategic enterprise projects and initiatives. Fosters a culture of sharing, re-use, design for scale stability, and operational efficiency of data and analytical solutions.<br/><br/>Advises, consults, mentors, and coach other data and analytic professionals on data standards and practices.<br/><br/>Develops and delivers communication and education plans on analytic data engineering capabilities, standards, and processes.<br/><br/>Learns about machine learning, data science, computer vision, artificial intelligence, statistics, and/or applied mathematics as necessary to carry out role effectively.<br/><br/><strong>Minimum Skills And Qualification Requirements<br/><br/></strong>Bachelor’s degree in computer science, statistics, engineering, or a related field 5-10 years of experience required.<br/><br/>Experience with designing and maintaining data warehouses and/or data lakes with big data technologies such as Spark/Databricks, or distributed databases, like Redshift and Snowflake, and experience with housing, accessing, and transforming data in a variety of relational databases. Experience in building data pipelines and deploying/maintaining them following modern DE best practices (e.g., DBT, Airflow, Spark, Python OSS Data Ecosystem)<br/><br/>Knowledge of Software Engineering fundamentals and software development tooling (e.g., Git, CI/CD, JIRA) and familiarity with the Linux operating system and the Bash/Z shell Experience with cloud database technologies (e.g., Azure) and developing solutions on cloud computing services and infrastructure in the data and analytics space.<br/><br/>Basic familiarity with BI tools (e.g., Alteryx, Tableau, Power BI, Looker)<br/><br/>Expertise in ELT and data analysis, SQL primarily Conceptual knowledge of data and analytics, such as dimensional modelling, reporting tools, data governance, and structured and unstructured data<br/><br/><strong>Contact:</strong> teb@judge.com<br/><br/><em>This job and many more are available through The Judge Group. Find us on the web at www.judge.com</em>
</div>",No Salary Info Found,Data Warehouse Engineer
"Distinguished Engineer, Enterprise Data Platforms - Data Creation",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788648180,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Plano, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Job Title: Distinguished Engineer, Enterprise Data Platforms - Data Creation Location: McLean, Virginia, United States About the Role: Join our Enterprise Data &amp; Machine Learning group to contribute to the development of a highly scalable and well-governed data ecosystem. You will have the opportunity to shape the future of a platform that handles large amounts of data between Capital One and partners. We value diversity of thought and are looking for individuals who can provide innovative solutions. What You'll Do: - Help accelerate the adoption of modern technologies and share the benefits of these technologies with others - Balance lending your expertise with creating an inclusive environment where others' ideas are heard and championed - Promote a culture of engineering excellence and encourage the reuse of solutions whenever possible - Communicate effectively with stakeholders at all levels of the organization - Act as a trusted advisor in a specific technology domain - Mentor and recruit talent to strengthen Capital One's technical expertise Basic Qualifications: - Bachelor’s Degree - At least 7 years of Software Architecture or Enterprise Architecture experience - At least 5 years of experience in software architecture and design patterns - At least 5 years of AWS cloud experience Preferred Qualifications: - Masters' Degree - Experience with developing strategies and implementing target architectures - AWS Solution Architect - Professional or AWS Certified Data Analytics - Specialty certification - 8+ years of experience in data governance, data access, data lineage, data monitoring, and security controls - 7+ years of experience in programming languages such as Python, Java, Scala, or Node - 3+ years of experience in modern database technology evaluation and data modeling - 3+ years of experience building data products and implementing enterprise-level data governance - 3+ years of experience in building highly resilient distributed data systems - 3+ years of experience in data engineering, including distributed data pipelines and test data engineering - 3+ years of experience dealing with communication across multiple AWS accounts - 3+ years of experience in Agile practices Salary: - McLean, Virginia: $285,400 - $325,700 annually for Distinguished Engineer Benefits: At Capital One, we offer a comprehensive set of health, financial, and other benefits to support your well-being. Visit the Capital One Careers website for more information on eligibility. Equal Opportunity Employer: Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We do not discriminate based on sex, race, age, disability, genetic information, marital status, sexual orientation, gender identity, veteran status, or any other basis prohibited by law. Accommodation: If you require accommodation during the application process, please contact Capital One Recruiting at 1-800-304-9102 or email RecruitingAccommodation@capitalone.com. All information provided will be kept confidential and used only to provide the necessary accommodations. Contact: For technical support or questions about the recruiting process, please email Careers@capitalone.com. Note: Capital One Financial consists of several different entities. Position postings are specific to certain entities (e.g., Capital One Canada, Capital One Europe, Capital One Philippines).
      </div>",$285400- $325700,Data Warehouse Engineer
ETL / SQL Developer,Ripple Logics,12/19/2023,https://www.linkedin.com/jobs/view/3784435302,0,https://media.licdn.com/dms/image/C560BAQEs9_OmangmhA/company-logo_100_100/0/1630668734522/ripple_logics_logo?e=2147483647&v=beta&t=vnTIHgr-l5etLCF5AOgKV6urazhOXrDZ4qZ4F6bAbyg,Dallas-Fort Worth Metroplex,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Position:</strong></p><p><strong>L</strong>ooking to hire a skilled SQL ETL developer</p><p>Duties will include consulting with the data management team, interacting with different business partners, Analyzing/extracting data from various applications and load into SQL Server Database.</p><p>To ensure success as an SQL ETL developer in this position, you should have extensive knowledge of TSQL coding language and be able to communicate your ideas and meet deadlines clearly.</p><p> </p><p><strong>ETL Developer Responsibilities:</strong></p><ul><li>Experience with heavy TSQL coding and ETL</li><li>Who can work and think independently and quickly to find solutions during the ETL process.</li><li>Data Mapping, Data sourcing, and data Analytical skills.</li><li>Working experience with the SSIS ETL tool.</li><li>Experience with at least one data migration project from a different source to SQL server/Azure.</li><li>Knowledge of Snowflake environment.</li><li>Good Communication skills</li><li>Proactively interact with various team members and Business partners</li><li>7+ years of working experience in Microsoft SQL Server Databases</li><li>5+ years of TSQL Experience and at least 3 years of ETL Experience.</li><li>1+ Years of working experience in Azure Environment</li><li>2 years of SSIS Experience.</li></ul>
</div>",No Salary Info Found,Data Warehouse Engineer
Data Solutions Engineer,Brown & Brown Insurance,12/19/2023,https://www.linkedin.com/jobs/view/3732174351,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer Manager,PepsiCo,12/19/2023,https://www.linkedin.com/jobs/view/3755657823,0,https://media.licdn.com/dms/image/C4E0BAQES6SfNFl84wA/company-logo_100_100/0/1679328336145/pepsico_logo?e=2147483647&v=beta&t=1NNobGNmPsdocoZorT8TPZU3vaTZngxteeIiyDXTMyk,"Plano, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>PepsiCo operates in an environment undergoing immense and rapid change. Big-data and digital technologies are driving business transformation that is unlocking new capabilities and business innovations in areas like eCommerce, mobile experiences and IoT. The key to winning in these areas is being able to leverage enterprise data foundations built on PepsiCo’s global business scale to enable business insights, advanced analytics and new product development. PepsiCo’s <strong>Enterprise Data Operations (EDO) </strong>team is tasked with the responsibility of developing quality data collection processes, maintaining the integrity of our data foundations, and enabling business leaders and data scientists across the company to have rapid access to the data they need for decision-making and innovation.<br/><br/>What PepsiCo Enterprise Data Operations (EDO) does:<br/><br/><ul><li>Maintain a predictable, transparent, global operating rhythm that ensures always-on access to high-quality data for stakeholders across the company</li><li>Responsible for day-to-day data collection, transportation, maintenance/curation and access to the PepsiCo corporate data asset </li><li>Work cross-functionally across the enterprise to centralize data and standardize it for use by business, data science or other stakeholders</li><li>Increase awareness about available data and democratize access to it across the company<br/><br/></li></ul><strong>Responsibilities<br/><br/></strong>As a data engineering manager, you will be the key technical expert overseeing PepsiCo's data product build &amp; operations and drive a strong vision for how data engineering can proactively create a positive impact on the business. You'll be empowered to create &amp; lead a strong team of data engineers who build data pipelines into various source systems, rest data on the PepsiCo Data Lake, and enable exploration and access for analytics, visualization, machine learning, and product development efforts across the company. As a member of the data engineering team, you will help lead the development of very large and complex data applications into public cloud environments directly impacting the design, architecture, and implementation of PepsiCo's flagship data products around topics like revenue management, supply chain, manufacturing, and logistics. You will work closely with process owners, product owners and business users. You'll be working in a hybrid environment with in-house, on-premise data sources as well as cloud and remote systems.<br/><br/>Accountabilities<br/><br/><ul><li>Provide leadership and management to a team of data engineers, managing processes and their flow of work, vetting their designs, and mentoring them to realize their full potential.</li><li>Act as a subject matter expert across different digital projects.</li><li>Oversee work with internal clients and external partners to structure and store data into unified taxonomies and link them together with standard identifiers.</li><li>Manage and scale data pipelines from internal and external data sources to support new product launches and drive data quality across data products.</li><li>Build and own the automation and monitoring frameworks that captures metrics and operational KPIs for data pipeline quality and performance.</li><li>Responsible for implementing best practices around systems integration, security, performance and data management.</li><li>Empower the business by creating value through the increased adoption of data, data science and business intelligence landscape.</li><li>Collaborate with internal clients (data science and product teams) to drive solutioning and POC discussions.</li><li>Evolve the architectural capabilities and maturity of the data platform by engaging with enterprise architects and strategic internal and external partners.</li><li>Develop and optimize procedures to “productionalize” data science models.</li><li>Define and manage SLA’s for data products and processes running in production.</li><li>Support large-scale experimentation done by data scientists.</li><li>Prototype new approaches and build solutions at scale.</li><li>Research in state-of-the-art methodologies.</li><li>Create documentation for learnings and knowledge transfer.</li><li>Create and audit reusable packages or libraries.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>8+ years of overall technology experience that includes at least 6+ years of hands-on software development, data engineering, and systems architecture. </li><li>6+ years of experience with Data Lake Infrastructure, Data Warehousing, and Data Analytics tools. </li><li>6+ years of experience in SQL optimization and performance tuning, and development experience in programming languages like Python, PySpark, Scala etc.). </li><li>4+ years in cloud data engineering experience in Azure. </li><li>Fluent with Azure cloud services. Azure Certification is a plus. </li><li>Experience scaling and managing a team of engineers. </li><li>Experience with integration of multi cloud services with on-premises technologies. </li><li>Experience with data modeling, data warehousing, and building high-volume ETL/ELT pipelines. </li><li>Experience with data profiling and data quality tools like Apache Griffin, Deequ, and Great Expectations. </li><li>Experience building/operating highly available, distributed systems of data extraction, ingestion, and processing of large data sets. </li><li>Experience with at least one MPP database technology such as Redshift, Synapse or SnowFlake. </li><li>Experience with running and scaling applications on the cloud infrastructure and containerized services like Kubernetes. </li><li>Experience with version control systems like Github and deployment &amp; CI tools. </li><li>Experience with Azure Data Factory, Azure Databricks and Azure Machine learning tools. </li><li>Experience with Statistical/ML techniques is a plus. </li><li>Experience with building solutions in the retail or in the supply chain space is a plus </li><li>Understanding of metadata management, data lineage, and data glossaries is a plus. </li><li>Working knowledge of agile development, including DevOps and DataOps concepts. </li><li>Familiarity with business intelligence tools (such as PowerBI). </li><li>BA/BS in Computer Science, Math, Physics, or other technical fields. <br/><br/></li></ul><strong>Skills, Abilities, Knowledge<br/><br/></strong><ul><li>Excellent communication skills, both verbal and written, along with the ability to influence and demonstrate confidence in communications with senior level management.</li><li>Proven track record of leading, mentoring, hiring and scaling data teams.</li><li>Strong change manager. Comfortable with change, especially that which arises through company growth. Able to lead a team effectively through times of change.</li><li>Ability to understand and translate business requirements into data and technical requirements.</li><li>High degree of organization and ability to manage multiple, competing projects and priorities simultaneously.</li><li>Positive and flexible attitude to enable adjusting to different needs in an ever-changing environment. </li><li>Strong leadership, organizational and interpersonal skills; comfortable managing trade-offs.</li><li>Foster a team culture of accountability, communication, and self-management.</li><li>Proactively drives impact and engagement while bringing others along.</li><li>Consistently attain/exceed individual and team goals</li><li>Ability to lead others without direct authority in a matrixed environment.</li><li>Highly influential and having the ability to educate challenging stakeholders on the role of data and its purpose in the business. </li><li>Understands both the engineering and business side of the Data Products released. </li><li>Places the user in the center of decision making. </li><li>Teams up and collaborates for speed, agility, and innovation. </li><li>Experience with and embraces agile methodologies. </li><li>Strong negotiation and decision-making skill. </li><li>Experience managing and working with globally distributed teams.<br/><br/></li></ul><strong>EEO Statement<br/><br/></strong>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, protected veteran status, or disability status.<br/><br/>PepsiCo is an Equal Opportunity Employer: Female / Minority / Disability / Protected Veteran / Sexual Orientation / Gender Identity<br/><br/>If you'd like more information about your EEO rights as an applicant under the law, please download the available EEO is the Law &amp; EEO is the Law Supplement documents. View PepsiCo EEO Policy.<br/><br/>Please view our Pay Transparency Statement.
      </div>",No Salary Info Found,Data Warehouse Engineer
Course Data Analyst,WebCE,12/20/2023,https://www.linkedin.com/jobs/view/3788477617,0,https://media.licdn.com/dms/image/C4D0BAQF736dymJcX-A/company-logo_100_100/0/1631332257913?e=2147483647&v=beta&t=7EfjK1mzGVQeQyWgvvx8E0DMwW3-PIYPHHhVOl-vtBw,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        WebCE is expanding and adding a Course Data Analyst to our team. In this role you will proactively gather and analyze data on our various educational courses to enhance processes, answer key questions, and collaborate with management to pinpoint areas for improvement. You will work independently to collect and present findings.<br/><br/>You will use intermediate Excel skills to produce charts, graphs and pivot tables as well as work with existing dashboards or create new ones to identify data trends and patterns. This position serves a single department only and will not require a significant amount of data analysis as compared to cross departmental or larger companies. No use of SQL or other Engineering related languages.<br/><br/><strong>Requirements<br/><br/></strong><ul><li>Must be authorized to work in the U.S. for any employer without sponsorship</li><li>Must be located in the state of Texas and willing to commute to the corporate office in North Dallas for hybrid work</li><li>Associate degree or equivalent experience</li><li>Extensive knowledge of Microsoft Excel 365</li><li>Proficiency in Smartsheet and familiarity with Power BI are helpful<br/><br/></li></ul><strong>About WebCE<br/><br/></strong>Based in Dallas, TX, what started as a continuing education company has grown into a suite of professional education products for every stage of our customer's careers. For over 25 years, we have served over 1.5 million online courses each year to professionals nationwide and know what it takes to engage adult learners with different learning styles. The industries we currently serve are Financial Services, Insurance, Securities, Real Estate, Tax &amp; Accounting and Funeral. At WebCE, our employees are enthusiastic, experienced, and dedicated to delivering great service.<br/><br/><strong>A day in the life at WebCE<br/><br/></strong>Working from your own cubicle and your own home, we will give you the opportunity to do lots of different things. Primarily, you will be responsible for collecting, analyzing, and interpreting data from various internal sources relating to our various courses. With that data, you will maintain existing dashboards and reports or create new ones as needed to identify data trends and patterns. You will recommend process improvements and offer insight based on collected data.<br/><br/>If you have a question or need some help, you'll be surrounded by helpful, friendly people who are ready to jump in and collaborate with you in finding the best solution. Our open-door policy ensures that you can get access to the person who has the information or knowledge that you need to get the job done.<br/><br/><strong>Benefits Offered To Full-time Employees At WebCE<br/><br/></strong><ul><li>Voted in the ""Top 100"" places to work with a friendly, diverse, and inclusive culture</li><li>Robust and full-featured benefits package</li><li>Hybrid work environment</li><li>Annual profit-sharing bonus</li><li>9 paid holidays (including 1 floating) + up to 16 paid days off per year</li><li>Tuition reimbursement program</li><li>Casual dress code</li><li>An employer with over a 25-year track record of financial stability<br/><br/></li></ul><strong>Are you ready to join our team?<br/><br/></strong>If you feel like you are the right candidate for this job, click on the apply button. Our quick application should take you less than 5 minutes to fill out, and your information will then be instantly sent to our hiring team for review. We do our best to provide details on the next steps within 2-3 business days.<br/><br/>Want to learn more about the life of a WebCE employee? Simply click here or visit https://webce.wistia.com/medias/9oxvcoqfby.<br/><br/><strong><em>Job Posted by ApplicantPro</em></strong>
</div>",No Salary Info Found,Data Warehouse Engineer
"Principal Associate, Data Loss Prevention (DLP) Engineer",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3789003049,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Lead Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788698711,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Plano, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Job Title: Lead Data Engineer Location: Plano, Texas, United States of America Are you passionate about technology and solving complex problems? Do you thrive in a collaborative and inclusive work environment? At Capital One, we are a diverse team of problem solvers who use emerging technologies to meet the needs of our customers. We are seeking Data Engineers who are excited about merging data with new technologies and driving transformation at Capital One. In this role, you will work on a team dedicated to building data infrastructure for our suite of products that connect car dealers with potential buyers. This includes designing, developing, testing, and implementing technical solutions using full-stack development tools and technologies. You will collaborate with experienced developers in machine learning, distributed microservices, and full stack systems. Additionally, you will have the opportunity to stay up-to-date with tech trends, learn new technologies, and mentor others in the engineering community. Basic Qualifications: - Bachelor's Degree - At least 6 years of application development experience (no internship experience will be considered) - At least 2 years of experience in big data technologies - At least 1 year of experience with cloud computing (AWS, Microsoft Azure, Google Cloud) Preferred Qualifications: - 7+ years of application development experience including Python, SQL, Scala, or Java - 4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) - 4+ years of experience with distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL) - 4+ years of experience working on real-time data and streaming applications - 4+ years of experience with NoSQL implementation (Mongo, Cassandra) - 4+ years of data warehousing experience (Redshift or Snowflake) - 4+ years of experience with UNIX/Linux - 2+ years of experience with Agile engineering practices Capital One is committed to diversity and inclusion in the workplace. We are an equal opportunity employer, providing consideration for employment without regard to sex, race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited by law. We promote a drug-free workplace and comply with applicable laws regarding criminal background inquiries. We offer a comprehensive set of health, financial, and other benefits to support your well-being. To learn more about our benefits, visit the Capital One Careers website. To apply for this position or if you require any accommodations, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information you provide will be kept confidential and used only to provide necessary accommodations. For technical support or questions about the recruiting process, please email Careers@capitalone.com. Please note that Capital One Financial is made up of different entities, and the positions posted in Canada, United Kingdom, and Philippines are specific to those regions.
      </div>",No Salary Info Found,Data Warehouse Engineer
Analytics Engineer–Aftermarket & Sustainment (Onsite),Pratt & Whitney,12/20/2023,https://www.linkedin.com/jobs/view/3755002414,0,https://media.licdn.com/dms/image/D4E0BAQEtg2PpCDdBoA/company-logo_100_100/0/1687872730252/pratt__whitney_logo?e=2147483647&v=beta&t=lRFjtqN3CIcX4QW6WP0fIatuX9gbv_C42AabCkK1Dos,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Date Posted:<br/><br/></strong>2023-11-01<br/><br/><strong>Country:<br/><br/></strong>United States of America<br/><br/><strong>Location:<br/><br/></strong>PW132: Dallas 2701 Regent Blvd, Suite 300, Dallas, TX, 75261 USA<br/><br/><strong>Position Role Type:<br/><br/></strong>Onsite<br/><br/>Pratt &amp; Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious.<br/><br/>Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future.<br/><br/>Innovation through diversity of thought. At Pratt &amp; Whitney, we believe diversity of thought enables creativity, innovation, and a foundation for inclusion. By fostering an inclusive culture, we accept a shared accountability and responsibility to recognize, sponsor, coach, hire and promote talent equally. We welcome our employees to be their whole - best - selves at work because trust, respect and integrity, are a part of our DNA.<br/><br/>At Pratt &amp; Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond?<br/><br/>In this position candidate will serve as Inspection &amp; technical data analytics engineer for the ASE at the Dallas Inspection Center of Excellence facility in Dallas, TX. Support various data streams, data analytics &amp; aggregations, transitions/flow into the DMRO Hub for digital infrastructure development &amp; sustainment. Incubate automated inspection technologies/equipment aimed at improving inspection efficiency, speed, and volume.<br/><br/>The analytics engineer will report to ASE cell Manager.<br/><br/>In this challenging position, you will apply your engineering, analytics, computer, software, background, and knowledge to manage and grow the ASE cell engineering analytics footprint.<br/><br/><strong>Key Responsibilities:<br/><br/></strong><ul><li>Responsible for the development, integration, and deployment of analytics models/packages that includes fusion of both technical and business processes. </li><li>Grow the analytics team with appropriate talent capable to be self-sustaining. </li><li>Create strategies for scalable and sustainable analytics models. </li><li>Develop, Implement, and improve analytics tools and processes to instill such capabilities as integral part of cell operations. </li><li>Create synergies and coordination with other P&amp;W entities: ASE technology/RRDC, shops, Engineering, programs, RTRC, etc. </li><li>Be the primary interface with our stakeholders/customers to understand requirements and communicate progress. <br/><br/></li></ul><strong>Basic Qualifications:<br/><br/></strong><ul><li>BS degree in Engineering, Data Science or equivalent with a minimum of 3-5 years' experience. </li><li>Analytics development, Programming experience </li><li>GDT, blueprint reading, CAD, NX UG, MiniTab, MATLAB, Simulink, Finite Element Analysis, CFD </li><li>Must be a U.S. Person/Permanent Resident ""Green Card"" holder. <br/><br/></li></ul><strong>Preferred Qualifications:<br/><br/></strong><ul><li>Excellent written and verbal communication skills. </li><li>Team centric individual that cab be innovative self-starter capable of working independently to resolve onsite issues. <br/><br/></li></ul>What is my role type?<br/><br/>In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is:<br/><br/>Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines.<br/><br/>Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility.<br/><br/>Requires advanced knowledge of work area typically obtained through advanced education combined with experience. May have practical knowledge of project<br/><br/>management. Practical to substantial knowledge of RTX projects, programs or systems with the ability to make enhancements and leverage in daily work.<br/><br/>Typically requires:<br/><br/>A University Degree or equivalent experience and minimum 5 years prior relevant experience, or An Advanced Degree in a related field and minimum 3 years experience<br/><br/>Engineering/Other Technical Positions:<br/><br/>Typically requires a degree in Science,Technology, Engineering or Mathematics (STEM) and a minimum of 5 years of prior relevant experience unless prohibited by local laws/regulations.<br/><br/><strong><em>RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.<br/><br/></em></strong><strong>Privacy Policy and Terms:<br/><br/></strong>Click on this link to read the Policy and Terms<br/><br/><strong>01660386</strong>
</div>",No Salary Info Found,Data Warehouse Engineer
"INTERN- BI, Power BI Developer",At Home Group Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3774987741,0,https://media.licdn.com/dms/image/C560BAQHvC_Xavs_C-g/company-logo_100_100/0/1656016532088/athomestores_logo?e=2147483647&v=beta&t=mK_M3lde2IJVWUr0e2Olo2B0CI7ImwZthLvt5g03w5I,"Coppell, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>Internship Program<br/><br/>The internship program with At Home offers talented college students an opportunity to develop leadership skills and gain hands on experience in working with a number of leaders to learn the retail business from one of the leading home decor retailers. During a 10-week period, selected candidates will be aligned to functional teams that align with their professional career path to learn day-to-day operations, increase their professional skills and overall comprehension of the retail business.<br/><br/>The internship program involves opportunities to contribute and grow on the following teams, Accounting, IT (Apps &amp; Development), Merchandising, Planning/Allocation, Direct Sourcing, Real Estate, Finance, Supply Chain, and Marketing.<br/><br/><strong>Key Roles &amp; Responsibilities<br/><br/></strong><ul><li> Use strategic thinking to approach problems and create solutions </li><li> Prepare and deliver insights and recommendations based on analysis </li><li> Synthesize findings and draw conclusions from analyses, through oral/written recommendations to upper management </li><li> Execute tasks directly related to functional projects and/or process improvements </li><li> Participate in team meetings and engage with high-level executives, gaining exposure to cross-functional business units, building networking relationships, learning from top-level management at a recently rebranded retail company, and engaging in real world business situations that have a direct impact on team members </li><li> Responsible for the accuracy and quality of work performed </li><li> Develop and implement project plans; determine requirements, deliverables, resources, timing/milestones, and communicate findings and project status clearly and professionally through presentations </li><li> Provide comprehensive reports out to senior leaders on assignments and other related projects </li><li> Typically reports to Manager or Team Lead with no direct responsibility for supervising others <br/><br/></li></ul><strong>Qualifications &amp; Competencies<br/><br/></strong><ul><li> Ability to thrive in an individual contributor role and work in a team-oriented environment </li><li> Strong analytical skills </li><li> Use strategic thinking to see the big picture, determine the problem and understand fundamental parts of the problem </li><li> Demonstrate results-oriented leadership </li><li> Ability to manage multiple tasks, assign priorities, and meet deadlines <br/><br/></li></ul><strong>About Us<br/><br/></strong>When you’re a part of our team, you have the full support of a diverse, close-knit team in our stores. We consider all applicants for employment without regard to race, color, religion, gender, sexual orientation, national origin, age, disability, gender identity and expression, marital or military status. We also provide reasonable accommodations to qualified individuals with disabilities in accordance with the Americans with Disabilities Act and applicable state and local law. At Home is committed to knitting diversity and inclusion into the fabric of our culture; we respect, appreciate and celebrate the experiences and qualities that differentiate everyone on the At Home team.
      </div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer (DE),Zortech Solutions,12/24/2023,https://www.linkedin.com/jobs/view/3787251275,0,https://media.licdn.com/dms/image/C4E0BAQFLYN9bJoNeQg/company-logo_100_100/0/1630602268967?e=2147483647&v=beta&t=VbFirFeWDqzftzmA-xuL4-Rh3UkhihCRtFcB66Ze6Cg,"Paradise Valley, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Role: Data Engineer (DE)<br/><br/></strong><strong>Location: Scottsdale AZ (day 1 onsite)<br/><br/></strong><strong>Duration: Fulltime <br/><br/></strong><strong>Must have skill set: Java , Scala , S3, Glue, Redshift<br/><br/></strong><ul><li>You have 6-8 years of relevant software development experience. </li><li>You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is critical. </li><li>Highly analytical and data oriented. </li><li>Experience in SQL, NoSql Database </li><li>Data masking of on prem PII data. </li><li>Develop API calls with using secure data transfer. </li><li>Take standard output data to lower environments for pre prod testing! </li><li>Enable secured channels for data models and data science activities. </li><li>Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 mins </li><li>You have experience with development tools and agile methodologies.</li></ul>
</div>",No Salary Info Found,Data Warehouse Engineer
"ONSITE : Hiring AWS Data Engineer, Phoenix, AZ","Conch Technologies, Inc",12/20/2023,https://www.linkedin.com/jobs/view/3788676101,0,https://media.licdn.com/dms/image/C4E0BAQHKm43b1OSSsw/company-logo_100_100/0/1630593845537/conch_technologies_logo?e=2147483647&v=beta&t=fddpsK_rqbhSRB1GStFAtD-sfi1Bxsv8oh8oupv0EEY,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Hi<br/><br/>Greetings from Conch Technologies Inc<br/><br/><strong>Title: AWS application Engineer ( 6+ Years exp or more )<br/><br/></strong><strong>Duration: 12+ months with heavy possible extension<br/><br/></strong><strong>Location: 100% Onsite, Phoenix, AZ<br/><br/></strong><strong>Job Description<br/><br/></strong>Position Overview:<br/><br/>We are seeking a highly skilled and motivated AWS Application Engineer to join our dynamic team. As an AWS Application Engineer, you will play a key role in designing, developing, and maintaining applications that leverage the power of Amazon Web Services (AWS). The ideal candidate should have a strong background in software development, hands-on experience with AWS services, and a passion for building scalable, secure, and reliable applications in the cloud.<br/><br/><strong>Responsibilities<br/><br/></strong>Application Development:<br/><br/>Write, test, and deploy code for applications running on AWS.<br/><br/>Collaborate with software development teams to understand application requirements and implement new features.<br/><br/><strong>Cloud Architecture<br/><br/></strong>Design and implement scalable, reliable, and secure architectures for applications on AWS.<br/><br/>Select and configure appropriate AWS services based on application needs.<br/><br/><strong>Infrastructure As Code (IaC)<br/><br/></strong>Utilize Infrastructure as Code (IaC) tools (e.g., AWS CloudFormation, Terraform) to automate infrastructure provisioning and management.<br/><br/><strong>Integration<br/><br/></strong>Integrate applications with various AWS services, such as databases, storage, and messaging.<br/><br/>Handle third-party integrations as required.<br/><br/><strong>Security<br/><br/></strong>Implement and enforce security best practices.<br/><br/>Configure access controls, encryption, and other security features to safeguard applications and data.<br/><br/><strong>Monitoring And Optimization<br/><br/></strong>Set up monitoring solutions to track application performance on AWS.<br/><br/>Identify and address performance bottlenecks and optimize resource utilization for cost efficiency.<br/><br/><strong>Collaboration<br/><br/></strong>Collaborate effectively with cross-functional teams, including DevOps, QA, and business stakeholders.<br/><br/>Communicate technical concepts and solutions clearly to team members and stakeholders.<br/><br/><strong>Documentation<br/><br/></strong>Create and maintain documentation for architecture, configurations, deployment procedures, and troubleshooting guides.<br/><br/>Document best practices and lessons learned for knowledge sharing.<br/><br/><strong>Continuous Improvement<br/><br/></strong>Stay informed about AWS services, updates, and best practices.<br/><br/>Continuously seek opportunities to improve application performance, reliability, and efficiency.<br/><br/><strong>Troubleshooting And Support<br/><br/></strong>Quickly identify and resolve issues during development, testing, and production phases.<br/><br/>Collaborate with support teams and leverage AWS tools for effective diagnostics.<br/><br/><strong>Qualifications<br/><br/></strong>Bachelor’s degree in Computer Science, Engineering, or a related field.<br/><br/>Proven experience in software development, with proficiency in relevant programming languages.<br/><br/>Hands-on experience with AWS services, including but not limited to EC2, S3, Lambda, RDS, and others.<br/><br/>Strong understanding of cloud architecture and best practices.<br/><br/>Experience with Infrastructure as Code (IaC) tools such as AWS CloudFormation or Terraform.<br/><br/>Knowledge of security best practices for cloud-based applications.<br/><br/>Excellent problem-solving and troubleshooting skills.<br/><br/>Effective communication and collaboration skills.<br/><br/>AWS certifications (e.g., AWS Certified Developer, AWS Certified Solutions Architect) are a plus.<br/><br/>--<br/><br/><strong>With Regards,<br/><br/></strong><strong>Nagesh G<br/><br/></strong><strong>Mobile: </strong><strong>408-381-5645<br/><br/></strong><strong>Desk: </strong><strong>901-313-3066<br/><br/></strong><strong>Email: nagesh@conchtech.com <br/><br/></strong><strong>Web: </strong><strong>www.conchtech.com</strong>
</div>",No Salary Info Found,Data Warehouse Engineer
Engineer I-Marketing (Data ),Microchip Technology Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3787622459,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Scientist/Engineer - Junior,SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784400083,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
"ONSITE JOB: Hiring Data Engineer GCP , Phoenix, AZ","Conch Technologies, Inc",12/19/2023,https://www.linkedin.com/jobs/view/3788118349,0,https://media.licdn.com/dms/image/C4E0BAQHKm43b1OSSsw/company-logo_100_100/0/1630593845537/conch_technologies_logo?e=2147483647&v=beta&t=fddpsK_rqbhSRB1GStFAtD-sfi1Bxsv8oh8oupv0EEY,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Hi,<br/><br/>Greetings from Conch Technologies Inc<br/><br/><strong>Position: Data Engineer (GCP AI/ML)<br/><br/></strong><strong>Experience: 9+ years<br/><br/></strong><strong>Location: Phoenix, AZ<br/><br/></strong><strong>Duration: 12+ Months Contract <br/><br/></strong><strong>100% onsite<br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li>9+ Years experience as a GCP</li><li>AI/ML some experience needed</li><li>Good to have experience in Machine Learning</li><li>Good experience in Artificial Intelligence.</li><li>Good Communication Skills.<br/><br/></li></ul><strong>_<br/><br/></strong><strong>Thanks and Regards,<br/><br/></strong><strong>Chanakya </strong><strong>[IT Recruiter]<br/><br/></strong><strong>Direct : 214-247-7117<br/><br/></strong><strong>chanakya@conchtech.com<br/><br/></strong><strong>linkedin.com/in/nameischanikya</strong>
</div>",No Salary Info Found,Data Warehouse Engineer
Business Intelligence Engineer,Valley Metro RPTA,12/19/2023,https://www.linkedin.com/jobs/view/3790307099,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,FinTech LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785602219,0,https://media.licdn.com/dms/image/C510BAQFobT67_rqX5Q/company-logo_100_100/0/1631354807936?e=2147483647&v=beta&t=CXbQEnqxvT96ZgdqitGhoNB0NNM99yTZMM41grqF724,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><span><span>About Client:<br/></span></span></strong><span><span> The client is a global technology, consulting, and digital solutions company with problem-solving abilities and an emphasis on developing ingenious solutions that allow its clients to remain competitive, profitable, and secure in an evolving business environment.<br/>Client anticipates and leads change to remain in the leader’s quadrant for profitable growth, driven by partnerships with globally leading hyperscales like AWS, Google Cloud, and Microsoft. It has built strong capabilities in new as well as existing technologies such as cloud, data, and digital, pioneering new frontiers.<br/><br/><br/><br/><strong>Rate Range: $65-$70/Hr on C2C all-inclusive<br/><br/><br/><br/>Job Description:</strong></span></span></p><ul><li><span><span>We are seeking a talented and experienced Data Engineer to join our dynamic team. </span></span></li><li><span><span>As a Data Engineer, you will be responsible for designing, developing, testing, and maintaining data processing pipelines that handle both batch and real-time data from various sources. </span></span></li><li><span><span>The ideal candidate will have a strong foundation in building frameworks for data ingestion, making critical technical decisions, and ensuring the scalability, reliability, and security of our data infrastructure.</span></span></li></ul><strong><span><span>Responsibilities:</span></span></strong><ul><li><span><span>Build frameworks for data ingestion pipeline for a variety of data sources: batch and real-time</span></span></li><li><span><span>Participate in technical decisions</span></span></li><li><span><span>Design, develop, test, and maintain data processing pipelines</span></span></li><li><span><span>Design and build scalable, reliable data infrastructure with paramount focus on data quality, security, and privacy techniques</span></span></li></ul><strong><span><span>Required skills:</span></span></strong><ul><li><span><span>Proficient in Java, Python or Scala</span></span></li><li><span><span>Cloud experience</span></span></li><li><span><span>Experience with relational SQL and NoSQL databases</span></span></li><li><span><span>Experience with Spark, Kafka</span></span></li><li><span><span>Strong analytical and communication skills: verbal and written.</span></span></li></ul><p> <br/><br/><br/><span><span><strong>About ApTask:<br/></strong>Join ApTask, a global leader in workforce solutions and talent acquisition services, as we shape the future of work. We offer a comprehensive suite of offerings, including staffing and recruitment services, managed services, IT consulting, and project management, providing unparalleled opportunities for professional growth and development. As a member of our dynamic team, you'll have the chance to connect businesses with top-tier professionals, optimize workforce performance, and drive success for our clients across diverse industries. If you are passionate about excellence, collaboration, and innovation, and aspire to make a meaningful impact in the world of work, come join us at ApTask and be a part of our mission to empower organizations to thrive.<br/><br/>Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.<br/><br/></span></span><strong><span><span>Candidate Data Collection Disclaimer:<br/></span></span></strong><span><span>At ApTask, we prioritize safeguarding your privacy. As part of our recruitment process, certain Personally Identifiable Information (PII) may be requested by our clients for verification and application purposes. Rest assured, we strictly adhere to confidentiality standards and comply with all relevant data protection laws. Please note that we only collect the necessary information as specified by each client and do not request sensitive details during the initial stages of recruitment.<br/><br/></span></span><span><span>If you have any concerns or queries about your personal information, please feel free to contact our compliance team at </span></span><span><span>businessexcellence@aptask.com </span><span>.</span></span></p>
</div>",$65- $70,Data Warehouse Engineer
Data Warehouse Developer,Kforce Inc,12/20/2023,https://www.linkedin.com/jobs/view/3785040948,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,E-Solutions,12/20/2023,https://www.linkedin.com/jobs/view/3790807805,0,https://media.licdn.com/dms/image/D4D0BAQHxBWPl28ZenQ/company-logo_100_100/0/1696854753424/e_solutions_inc_logo?e=2147483647&v=beta&t=MtCyEjXxS0OJFfRfwzD6OrCf1E2S_4jONsoDefE70kU,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Position: Data Engineer (More than 10+ Years of exp)</strong></p><p><strong>Location: Scottsdale AZ (day 1 onsite)</strong></p><p><strong>Duration: Contract/Fulltime</strong></p><p> </p><p><strong>Job description:</strong></p><p><strong> </strong></p><p><strong>Must have skill set: <em>Java, Scala, S3, Glue, Redshift , AWS</em></strong></p><p><strong> </strong></p><p>10-15 years of IT experience focusing on enterprise data architecture and management.</p><p>• Experience in Conceptual/Logical/Physical Data Modeling &amp; expertise in Relational and Dimensional Data Modeling</p><p>• Experience with Databricks &amp; on Prem , Structured Streaming, Delta Lake concepts, and Delta Live Tables required</p><p>• Experience with Spark scala and java programming</p><p>• Data Lake concepts such as time travel and schema evolution and optimization</p><p>• Structured Streaming and Delta Live Tables with Databricks a bonus</p><p>• Experience leading and architecting enterprise-wide initiatives specifically system integration, data migration, transformation, data warehouse build, data mart build, and data lakes implementation / support</p><p>• Advanced level understanding of streaming data pipelines and how they differ from batch systems</p><p>• Formalize concepts of how to handle late data, defining windows, and data freshness</p><p>• Advanced understanding of ETL and ELT and ETL/ELT tools such as Data Migration Service etc</p><p>• Understanding of concepts and implementation strategies for different incremental data loads such as tumbling window, sliding window, high watermark, etc.</p><p>• Familiarity and/or expertise with Great Expectations or other data quality/data validation frameworks a bonus</p><p>• Familiarity with concepts such as late data, defining windows, and how window definitions impact data freshness</p><p>• Advanced level SQL experience (Joins, Aggregation, Windowing functions, Common Table Expressions, RDBMS schema design performance optimization)</p><p>• Indexing and partitioning strategy experience</p><p>• Debug, troubleshoot, design and implement solutions to complex technical issues</p><p>• Experience with large-scale, high-performance enterprise big data application deployment and solution</p><p>• Architecture experience in AWS environment a bonus</p><p>• Familiarity working with Lambda specifically with how to push and pull data, how to use AWS tools to view data for processing massive data at scale a bonus</p><p>• Experience with Gitlabs and CloudWatch and ability to write and maintain gitlabs for supporting CI/CD pipelines</p><p>• Experience working with AWS Lambdas for configuration and optimization and experience with S3</p><p>• Familiarity with Schema Registry, message formats such as Avro, ORC, etc.</p><p>• Ability to thrive in a team-based environment</p><p>• Experience briefing the benefits and constraints of technology solutions to technology partners, stakeholders, team members, and senior level of management</p>
</div>",No Salary Info Found,Data Warehouse Engineer
Data Engineer,"Phoenix Staff, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789019676,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Quality Analyst,Aston Carter,12/25/2023,https://www.linkedin.com/jobs/view/3793428297,0,https://media.licdn.com/dms/image/D4E0BAQGfPcCYR-BJKA/company-logo_100_100/0/1688582713106/aston_carter_logo?e=2147483647&v=beta&t=0x_nsq8b9vOidbm9PvA6fXqLf4YGUl_ZU7UlVZyuCoQ,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Data Quality Analyst II is responsible for identifying data quality issues, analyzing impact, recommending solutions, and monitoring results. The Data Quality Analyst II will regularly create and communicate actionable analyses to internal stakeholders. This role will develop and implement a data quality framework by creating standard data quality metrics, setting baselines, and targets. The Data Quality Analyst II will also be responsible for duplicate record management. Must possess both strong technical skills as well as a passion for using data to positively impact change in our community. Job Description:<br/><br/><ul><li>Develop methodology for data quality (completeness and accuracy) metrics, set baselines and targets, and build accessible reports and Tableau dashboards for internal teams.</li><li>Regularly analyze data to identify data quality issues, research issues to assess the frequency, depth, and potential causes.</li><li>Recommend concise and actionable solutions for identified data quality issues.</li><li>Remediate data quality issues.</li><li>Build reports to monitor corrective actions and provide timely feedback to internal staff and CIE partners to continuously address data quality concerns.</li><li>Provide monthly snapshots with executive summary for communication to senior leadership.</li><li>Perform descriptive and predictive analyses to evaluate key strategic questions, interpret, and contextualize findings; create presentations to synthesize complex analyses into actionable summaries and tangible recommendations.</li><li>Create compelling and reader-friendly infographics, tables, graphs, maps and other presentation visuals to communicate complex ideas, issues and trends gleaned from statistical reports.</li><li>Manipulate data using Excel to create tables and graphs and is comfortable using Pivot Tables to further analyze datasets.</li><li>Utilize appropriate technical writing skills when preparing narrative statistical summaries.</li><li>Proofread and double-check department work to avoid errors or mistakes.</li><li>Adhere to all department policies, practices and procedures related to data use, maintenance, and privacy.</li><li>Develop or contribute training material to support internal teams in understanding data quality standards, risks, and best practices Qualifications:</li><li>4+ years of experience with data analysis, writing comprehensive reports, research projects, and/or quality assurance.</li><li>1+ years of experience building and monitoring business intelligence dashboards in Tableau or similar data visualization tool.</li><li>1+ years of experience writing complex SQL queries, working with stored procedures, and/or database administration activities.</li><li>1+ years of experience with supervising a team is preferred.</li><li>A focus on the growth and well-being of people and the communities to which they belong.</li><li>A positive attitude, desire to learn and grow and aspirations to lead.</li><li>Candidate must demonstrate solid mathematical ability, analytic thinking, and effective oral and written communication of quantitative findings. Experience writing programs or scripts in at least one statistical or mathematical package or computer programming language is required.</li><li>Expert proficiency with Microsoft Office Suite required, including advanced Excel functions.</li><li>Experience with reporting tools, such as SQL Management Studio, Tableau, SPSS, and ArcGIS.</li><li>Experience with Salesforce CRM or another CRM tool preferred.</li><li>Familiarity with a variety of the field’s concepts, practices and procedures, including database technologies, and researching and recommending methods to proactively manage data and data quality.</li><li>Must have excellent attention to detail, ability to multi-task, and strong organizational, and project management skills.</li><li>Excellent oral and written communication skills that support effective working relationships with a diverse group of individuals both internal and external to the organization.<br/><br/></li></ul>About Aston Carter:<br/><br/>Please Note: Scammers are posing as Aston Carter. We'll never contact you via Gmail, Telegram, or WhatsApp and we'll never solicit money from you.<br/><br/>At Aston Carter, we’re dedicated to expanding career opportunities for the skilled professionals who power our business. Our success is driven by the talented, motivated people who join our team across a range of positions – from recruiting, sales and delivery to corporate roles. As part of our team, employees have the opportunity for long-term career success, where hard work is rewarded and the potential for growth is limitless. Established in 1997, Aston Carter is a leading staffing and consulting firm, providing high-caliber talent and premium services to more than 7,000 companies across North America. Spanning four continents and more than 200 offices, we extend our clients’ capabilities by seeking solvers and delivering solutions to address today’s workforce challenges. For organizations looking for innovative solutions shaped by critical-thinking professionals, visit [AstonCarter.com.](AstonCarter.com) Aston Carter is a company within Allegis Group, a global leader in talent solutions. The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law. If you would like to request a reasonable accommodation, such as the modification or adjustment of the job application process or interviewing process due to a disability, please call 888-237-6835 or email [astoncarteraccommodation@astoncarter.com](mailto:%20astoncarteraccommodation@astoncarter.com) for other accommodation options. However, if you have questions about this position, please contact the Recruiter located at the bottom of the job posting. The Recruiter is the sole point of contact for questions about this position.
      </div>",No Salary Info Found,Data Warehouse Engineer
Insurance - Data Analyst - REMOTE,Wahve LLC,12/20/2023,https://www.linkedin.com/jobs/view/3790963546,0,https://media.licdn.com/dms/image/D560BAQHLpAj4KcNwxw/company-logo_100_100/0/1689949451872/wahve_logo?e=2147483647&v=beta&t=ijNXVviKcnM87hQBvAX-WppSZZwnFb7A4YL9Fiqr6Zk,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><em>Put your Insurance Experience to work - FROM HOME!<br/><br/></em></strong>At <strong>Wahve</strong>, we value significant insurance experience and want to revolutionize the way people think about <strong><em>phasing into</em> <em>retirement</em></strong> by offering qualified candidates the opportunity to continue their career working from home. As we say - <strong><em>retire from the office but not from work</em></strong>. Our unique platform provides you with <em>real</em> work/life balance and allows you to customize your own work schedule while continuing to utilize your insurance expertise in <strong><em>a remote, long-term position</em></strong>.<br/><br/><strong>What You’ll Love About Wahve<br/><br/></strong>We created a welcoming place to work with friendly and professional leadership. We are known for the great care we take with our staff and our clients. We are passionate and determined about delivering the best customer service, preserving insurance industry knowledge, and making a difference by the work that we do.<br/><br/><strong>What We Are Seeking<br/><br/></strong>We have assignments available to help our <em>insurance industry</em> clients in <strong>Data Analyst positions. Responsibilities include:<br/><br/></strong><ul><li>Build and maintain data warehouse, new reports, and ad hoc reports. </li><li>Work with user groups to identify reporting issues/enhancements and document business requirements. </li><li>Will serve as a member of a project team and/or work independently on projects. </li><li>Support and train internal users as needed. </li><li>Compile and prepare data for customer analysis. </li><li>Experience in C#, Visual Studio, JavaScript, CSS, and current web technologies such as .NET, ASP, JSON, and XML. </li><li>Experience with ANY of the following technologies: SQL Server Reporting Services (SSRS), SSIS Reporting, Power BI, Dynamics CRM, Dynamics GP, Share point, Excel, Power Query, Power Pivot. </li><li>Ability to compile data results and author commentary on industry studies is a plus. </li><li>Insurance or financial services industry experience required. <br/><br/></li></ul><strong>TO BECOME A WORK-AT-HOME VINTAGE EXPERT, WE REQUIRE<br/><br/></strong><ul><li>25 years of full-time work experience</li><li>Experience working in a data analysis role in the insurance or financial services industry - required<br/><br/></li></ul><strong>Benefits Of Becoming a Wahve Vintage Expert<br/><br/></strong><ul><li>Retire from the office but not from work. </li><li>Eliminate the office stress and the commute. </li><li>Choose the work you would like to do now. </li><li>Customize your schedule - full or part time. </li><li>Continue to earn an income. </li><li>Utilize your years of insurance industry knowledge. </li><li>Be part of our dynamic yet virtual team environment and connect with other experienced insurance professionals like yourself!<br/><br/></li></ul><strong>How To Get Started<br/><br/></strong>Click <strong><em>APPLY NOW</em></strong> to complete our simple preliminary profile. Be sure to include your preferred contact information as one of our Qualification Specialists will connect with you promptly.<br/><br/><strong>WE LOOK FORWARD TO MEETING YOU!</strong>
</div>",No Salary Info Found,Data Warehouse Engineer
"Electrical Engineer, Command and Data Handling Architect",General Atomics,12/19/2023,https://www.linkedin.com/jobs/view/3639927083,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789762711,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        A market leader in the analytics space, specifically focusing on analytics for the entertainment space is hiring a Senior Data Engineer to join their team of 5. This role will be a lot of new development and migrations as they are moving their SQL based pipelines over to Python, AWS, and Spark so strong SQL experience is a big plus. This company processes tens of billions of rows of data every year and has almost 20TB of processing data. The main tech stack for this role is SQL, Python, AWS, and Spark experience. This team also uses Glue, Power BI, Anthem, EMR, PySpark, and any experience working with marketing metrics/analysis is a plus. You will be building new capabilities for their analytics teams, integrating big data tools and moving to AWS within their pipelines.<br/><br/>This role is looking for someone to work PST hours. If you are local to Southern California that is a big plus but not required as this role is 100% fully remote. This is a small team so they ideally need someone open to wearing a few different hats who can interact with various teams within the organization so good communication is a must.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>5+ years professional Data Engineering Experience </li><li>Background in DBA/SQL Development </li><li>5 years of experience building ETL pipelines with Python, AWS, and Spark/PySpark </li><li>Experience working with large amounts of data <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Bachelors in STEM field </li><li>Excellent written and verbal communication skills </li><li>Any experience with Glue, Power BI, Anthem, or EMR </li><li>Experience working with marketing metrics data <br/><br/></li></ul>The Offer<br/><br/><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Sick Time </li><li>Paid Time Off </li><li>401(k) with match </li><li>Annual Bonus </li><li>Remote PST time <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Cassi Benson
      </div>",No Salary Info Found,Data Warehouse Engineer
CI Data Analyst,Eaton,12/19/2023,https://www.linkedin.com/jobs/view/3766732316,0,https://media.licdn.com/dms/image/C4E0BAQFlHTyFXVYarg/company-logo_100_100/0/1630597759539/eaton_logo?e=2147483647&v=beta&t=EvGycDnRc0YENXF-evyXoQa1WDgkajbQnckCEdqoiV0,"Tijuana, Baja California, Mexico","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Eaton’s division is currently seeking a CI Data Analyst.<br/><br/><strong>What You’ll Do<br/><br/></strong><strong>Primary Function:<br/><br/></strong>Will work closely with the operations service department, to improve current data analysis, reporting, presentation, and standardization of data for the Operations team.<br/><br/>Build and maintain decision support tools, identify opportunities to increase productivity at all levels of the organization. Should be able to connect sources of data as MFGPRO, ORACLE and MS Office and not limited to others (UBISENSE, Thinkworkx, AI)<br/><br/>This position will work directly with CI in a support role to drive improvement in our manufacturing operations, including the operations services team (program management, automation, i4.0, manufacturing engineering and maintenance).<br/><br/>These functions may include, but are not limited to cost improvement activities, process development, new business development, creation and deployment of division wide manufacturing strategies and new initiatives.<br/><br/>This position will also monitor project portfolio performance within the business units or functional areas. The position drives continuous improvement while utilizing the framework of the Eaton Business System (EBS) and the Continuous Improvement Framework (CIF).<br/><br/><strong>Essential Functions<br/><br/></strong>Migrate current reporting process of Excel, Power Point and Word to Power BI<br/><br/>Development of data collection process and data management system.<br/><br/>Standardize and narrow current dashboards and power apps.<br/><br/>Maintain and support current systems, apps, or dashboards with high utilization culture in the organization. Evolve those systems so they can be embracing as standard in all regions.<br/><br/>Upgrade CI SharePoint with latest information from the plant, monthly.<br/><br/>Be the champion of Best Practices exchange activities for digital solutions. Monitor and distribute improvements generated by teams of manufacturing experts to all regional manufacturing sites.<br/><br/><strong>Qualifications<br/><br/></strong><ul><li> Bachelor’s degree in engineering from an accredited institution is required</li><li> English, able to communicate verbally</li><li> Minimum 3 years of manufacturing operations experience is required.</li><li> Minimum 2 years of proven experience working with Power BI &amp; Apps.</li><li> Good knowledge in Share Point and Power Automate</li><li> SQL Server (only for connection with PowerApps)</li><li> Knowledge on developments using Power Platform o Dynamics 365</li><li> Knowledge of cloud data base: SQL Azure, SQL Data Warehouse</li><li> Proven experience of data analysis and data base</li><li> Manufacturing knowledge of equipment and process skills</li><li> ERP Knowledge (preferable MFGPRO, Oracle).</li><li> Financial skills and business acumen.<br/><br/><br/></li></ul>Solid interpersonal skills effective in building strategic relationships, team building, and ability to interact and influence through all levels of the organization<br/><br/><strong>Skills<br/><br/></strong><strong>Preferred Specialized Knowledge (not required to be qualified for position):<br/><br/></strong><ul><li> Advanced degree in engineering or business management from an accredited institution.</li><li> Trainings or Certifications in Microsoft Azure</li><li> Trainings or Certifications in MS teams, Office 365, Share Point etc.</li><li> Training or certifications on Data bases</li><li> Autocad</li><li> Previous lean manufacturing experience, CI basic tools knowledge</li><li> Experience and exposure to numerous manufacturing operations.</li><li> Strong business understanding of financials statements and impacts on P&amp;L.</li><li> Strong presentation and communication skills and experiences with global cultures.</li><li> Ability to think both tactically as well as strategically<br/><br/><br/></li></ul>We are committed to ensuring equal employment opportunities for job applicants and employees. Our recruitment processes use balanced selection criteria and avoid unlawful discrimination against applicants on the basis of their age, colour, disability, marital status, national origin, gender, gender identity, genetic information, race or racial origin, religion, sexual orientation or any other status protected or required by law.<br/><br/>]]&gt;<br/><br/>
</div>",No Salary Info Found,Data Warehouse Engineer
Data Visualization Developer,Vaco,12/20/2023,https://www.linkedin.com/jobs/view/3785095175,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Warehouse Engineer
Data Engineer,National Funding,12/20/2023,https://www.linkedin.com/jobs/view/3785066474,0,https://media.licdn.com/dms/image/C560BAQHV-zFAv771ig/company-logo_100_100/0/1631366268064?e=2147483647&v=beta&t=k69XYet-Fe78rYD8CnY8BCcRPZIRanWfZTxplomo3fc,San Diego Metropolitan Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Data Engineer </strong>- San Diego, CA or Orange County, CA</p><p><br/></p><p>Hybrid 3 days/week, Full time M-F 8am-5pm PST</p><p><br/></p><p>Being authorized to work in the U.S. is a precondition of employment.</p><p>National Funding does not consider candidates requiring 1099 or C2C.</p><p><br/></p><p>Exempt/Salary: $101,000-$151,000 + Bonus Incentive</p><p><br/></p><p>National Funding is continuing to grow its Data Analytics Department and has an exciting opportunity for a<strong> Data Engineer</strong>. Reporting to the Director of BI, the Data Engineer will help implement a new Snowflake Data Warehouse initiative.</p><p><br/></p><p><strong>Responsibilities: </strong></p><p>• The data engineer will participate in the data warehouse implementation and work closely with the DW team including analysts, BI developers, and SME experts. This includes the full DW lifecycle of requirements gathering, data modeling, data mapping, ETL, reporting and QA.</p><p>• The primary responsibility will be ETL work using dbt integrating data, applying business rules and transformations, creating both normalized and de-normalized data.</p><p>• They will be creating various ETL frameworks in dbt to semi-automate data transformation. This includes the full life cycle of ETL: applying business rules, data aggregation, data cleansing, and QA.</p><p>• Other responsibilities include supporting other data engineers working on administration, data sourcing, data orchestration, notifications, data lineage, and related aws work</p><p><br/></p><p><strong>Knowledge, Skills and Abilities Required: </strong></p><p>• 3+ years' experience working as a Data Engineer and 5+ years in Data warehouse, ETL, BI projects.</p><p>• Must have experience in dbt, or related ETL products.</p><p>• Expertise in data modeling, ELT using SQL, implementing complex stored Procedures and standard DWH and ETL concepts.</p><p>• Expertise in advanced concepts like setting up resource monitors, RBAC controls, virtual warehouse sizing, query performance tuning, Zero copy clone, time travel and understanding how to use these features.</p><p>• Preferably having experience with aws data storage and management technologies such as S3.</p><p><br/></p><p><strong>Nice to have skills:</strong></p><p>• Hands-on experience with Snowflake utilities, SnowSQL, SnowPipe, techniques using UDFs.</p><p>• Deep understanding of relational data stores, methods, and approaches (star and snowflake, dimensional modeling).</p><p>• Snowflake certification a plus.</p><p>• Experience in creating frameworks in Snowflake:</p><p>- SCD framework</p><p>- Business Rules Engine</p><p>- Jobs Scheduling</p><p>- Capture Data Errors</p><p>- Data Transformations</p><p>- Snapshot data capture</p><p><br/></p><p><strong>Physical Demands:</strong></p><p>• Working in a temperature-controlled office environment</p><p>• Sitting at a desk for prolonged periods of time while viewing multiple computer screen monitors</p><p>• Potential lifting of boxes around 5-10lbs</p><p><strong>Why National Funding?</strong></p><ul><li>Positive, energetic, passionate, business casual environment with management who commits to your success</li><li>Fantastic benefits package: Our current benefit package includes medical, dental, vision, life, LTD and AD&amp;D insurance as well as a 401(k) Retirement Savings plan with an employer match. Eligibility for all benefits will start at the first of the month following 60 days of employment.</li><li>Numerous employee events throughout the year, including our annual traditions such as a Day at the Del Mar Racetrack, Del Mar Mud Run, Bring Your Kid to Work Day, Holiday Party, Employee and Family Picnic, sporting events and more.</li></ul><p><strong>National Funding</strong> is one of the leading providers of short-term loans and equipment leasing for small businesses across the United States. In both 2013 and 2014, we were ranked by the San Diego Business Journal as one of the 100 Fastest Growing Private Companies in San Diego and listed on the Inc. 5000 List of America’s Fastest Growing Private Companies. We serve the small business community nationwide by offering a range of financial services and products. Since 1999, we have been in the forefront of the equipment leasing business, working with businesses in hundreds of communities and industries to expand and upgrade their business equipment. As we have grown, so too has our product line, and now we are one of the country’s largest private lenders of small business loans. Our customers call on us to get working capital, merchant cash advances, credit card processing, and of course, equipment leasing.</p><p><br/></p><p>National Funding is an Equal Opportunity Employer.</p>
</div>",$101000- $151000,Data Warehouse Engineer
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment Partners LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785064004,0,https://media.licdn.com/dms/image/C4E0BAQGbIGAVD9Ugtg/company-logo_100_100/0/1630587145865/motion_recruitment_partners_llc_logo?e=2147483647&v=beta&t=alBjyOtSVLguJoyqNF0DXJ9Pwg7PtTJhNsISoDSt9QU,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Motion Recruitment Partners, LLC, is seeking the following. Apply via Dice today!<br/><br/>A market leader in the analytics space, specifically focusing on analytics for the entertainment space is hiring a Senior Data Engineer to join their team of 5. This role will be a lot of new development and migrations as they are moving their SQL based pipelines over to Python, AWS, and Spark so strong SQL experience is a big plus. This company processes tens of billions of rows of data every year and has almost 20TB of processing data. The main tech stack for this role is SQL, Python, AWS, and Spark experience. This team also uses Glue, Power BI, Anthem, EMR, PySpark, and any experience working with marketing metrics/analysis is a plus. You will be building new capabilities for their analytics teams, integrating big data tools and moving to AWS within their pipelines.<br/><br/>This role is looking for someone to work PST hours. If you are local to Southern California that is a big plus but not required as this role is 100% fully remote. This is a small team so they ideally need someone open to wearing a few different hats who can interact with various teams within the organization so good communication is a must.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>5+ years professional Data Engineering Experience </li><li>Background in DBA/SQL Development </li><li>5 years of experience building ETL pipelines with Python, AWS, and Spark/PySpark </li><li>Experience working with large amounts of data <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Bachelors in STEM field </li><li>Excellent written and verbal communication skills </li><li>Any experience with Glue, Power BI, Anthem, or EMR </li><li>Experience working with marketing metrics data <br/><br/></li></ul>The Offer<br/><br/><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Sick Time </li><li>Paid Time Off </li><li>401(k) with match </li><li>Annual Bonus </li><li>Remote PST time <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future. Data Engineer / Background in SQL / Migrate to AWS
      </div>",No Salary Info Found,Data Warehouse Engineer
Data Analyst,TEKsystems,12/20/2023,https://www.linkedin.com/jobs/view/3788626864,0,https://media.licdn.com/dms/image/D4E0BAQFLrODAdU8Mdw/company-logo_100_100/0/1688568814937/teksystems_logo?e=2147483647&v=beta&t=oUxSISiI6GoLA1ohGI74ZDRCRqtO7-AJ3HQb3Iu_Rnk,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Description <br/><br/>Data Analyst (for EHR data migration)<br/><br/><ul><li>ideal candidate has 4 – 10 years experience (but open to up to 15 years)</li><li> This position will support with EHR migration from Cerner to SmartCare (by Streamline)<br/><br/><br/></li></ul> Job Duties <br/><br/><ul><li> Data Analyst job duties for a large data migration– analysis, requirements gathering, compliance, etc. Data entry, data processing, data integrity,</li><li> Responsible for the analysis, compliance, integration, aggregation and management of data – i.e. patient information, clinical measures, registries, and determinants</li><li> Data Systems and Process Management - Assure all data processes supported or defined by the EHR comply with guidance from regulatory agencies and acts</li><li> Support the development and maintenance of Clinical Data Security, Handling, and Compliance Procedures</li><li> Provide support, analysis, guidance, feedback and recommendations to colleagues, organizational leadership, clinical staff and clinical systems vendors on data, business intelligence,</li><li> Act as initial point of contact for issues regarding population health systems</li><li> Collect all required issue data for problem analysis and resolution<br/><br/><br/></li></ul> Additional Skills &amp; Qualifications <br/><br/>NICE TO HAVE:<br/><br/><ul><li> Reporting Tools – Tableau, BusinessObjects, DA2/CCL</li><li> Database Tools – Snowflake</li><li> Programming languages – Python</li><li> Bachelor's degree in computer science or related field</li><li> Knowledge of the regulatory (standards, compliance, etc.) environment related to EHR implementations (Joint Commission, OSHPD, HIPAA, etc.)<br/><br/><br/></li></ul> About TEKsystems <br/><br/>We're partners in transformation. We help clients activate ideas and solutions to take advantage of a new world of opportunity. We are a team of 80,000 strong, working with over 6,000 clients, including 80% of the Fortune 500, across North America, Europe and Asia. As an industry leader in Full-Stack Technology Services, Talent Services, and real-world application, we work with progressive leaders to drive change. That's the power of true partnership. TEKsystems is an Allegis Group company.<br/><br/>The company is an equal opportunity employer and will consider all applications without regards to race, sex, age, color, religion, national origin, veteran status, disability, sexual orientation, gender identity, genetic information or any characteristic protected by law.
      </div>",No Salary Info Found,Data Warehouse Engineer
Experience Data Analyst - 127286,UC San Diego Health,12/20/2023,https://www.linkedin.com/jobs/view/3790960212,0,https://media.licdn.com/dms/image/C560BAQHOuav9D9b55A/company-logo_100_100/0/1630614149196/ucsdhealth_logo?e=2147483647&v=beta&t=x4wR-a5-XkyVi1kUT2g_5TDJCrllNPch60JPc-1tCGE,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        #127286 Experience Data Analyst<br/><br/><strong>Filing Deadline: Wed 1/3/2024<br/><br/></strong><strong>UC San Diego values equity, diversity, and inclusion. If you are interested in being part of our team, possess the needed licensure and certifications, and feel that you have most of the qualifications and/or transferable skills for a job opening, we strongly encourage you to apply.<br/><br/></strong><strong>This position will remain open until filled.<br/><br/></strong><em>UCSD Layoff from Career Appointment</em>: Apply by 12/22/23 for consideration with preference for rehire. All layoff applicants should contact their Employment Advisor.<br/><br/><em>Special Selection Applicants</em>: Apply by 1/3/24. Eligible Special Selection clients should contact their Disability Counselor for assistance.<br/><br/><strong>This position will work a hybrid schedule which includes a combination of working both onsite in Mission Valley and remote..<br/><br/></strong><strong>Description<br/><br/></strong>The Experience Data Analyst is Involved in analyzing complex business problems using data to provide insight to decision-makers. Identifies and interprets trends and patterns in datasets to locate influences, develops forecasts, recommendations, and strategic/tactical plans based on business data and market knowledge, and works with business and/or clinical units to understand and prioritize data and information requirements. The Experience Data Analyst creates specifications for reports and analysis based on business needs and required / available data elements. Optimizes the performance of enterprise business intelligence tools by defining data to filter and index that add value to the user. Develops business cases to support enterprise-wide business intelligence solutions. Applies skills and experience as a seasoned business analytics professional to projects of medium size at all levels of complexity, or to portions of large, multidimensional projects.<br/><br/>The Experience Data Analyst plays a lead role in Patient Satisfaction Survey project management and other related patient satisfaction activities for the UCSD Health System including the standardized patient experience surveys, HCAHPS and other publically reported survey requirements, development of Customer Service Standards, and other projects as identified internally or required via external regulations.<br/><br/>The Experience Data Analyst actively advances UCSD Health System’s patient satisfaction/customer service program through team leadership and membership, data analysis, and proactive problem-solving. Designs strategies for 1) extracting and managing patient satisfaction/patient complaint data from disparate sources, 2) aggregating and analyzing it to meet organization-wide patient satisfaction goal requirements and to identify areas for improvements, and 3) disseminating patient satisfaction information Health System-wide including over 80 ambulatory practices, the Emergency Department, Inpatient Specialties, and 35 Inpatient units at both the UCSD Medical Center - Hillcrest and La Jolla campus.<br/><br/>The Experience Data Analyst is the primary Health System contact for using patient satisfaction scores to analyze data. The Analyst determines if organization-wide and individual departmental patient satisfaction goals have been met and identifies performance improvement opportunities. Reports to the Supervisor of Data Analytics and supports the work of selected Health System patient satisfaction improvement committees and activities. Responds to complex patient inquiries, and exercises appropriate judgment in complex situations. Supports Patient Rights and Responsibilities. Role models excellent interpersonal communication skills and problem-solving with a focus on teamwork and collaboration. Performs data extraction and analysis to support the department. Responsible for ensuring HIPAA compliance for the database and department activities. Performs other related duties as required.<br/><br/><strong>Minimum Qualifications<br/><br/></strong><ul><li>Seven (7) years of related experience, education/training, OR a Bachelor’s degree in related area plus three (3) years of related experience/training.</li><li>Thorough knowledge of business intelligence functions, analytics, industry standards and best practices.</li><li>High degree of computer literacy and competence in using Microsoft Word, PowerPoint, and Outlook. Expert in Excel - charts, pivot tables, linking workbooks, etc. </li><li>Demonstrated experience with designing and writing survey questions.</li><li>Experience with Data visualization (i.e., Tableau, infographics, etc.).</li><li>Proven experience with qualitative analytics.</li><li>Experience analyzing voice of the customer data</li><li>Strong communication skills (verbal and written) needed to interact professionally and effectively in the work environment and effectively and accurately share patient feedback.</li><li>Excellent organizational and time management skills, with the ability to adapt to changing priorities, manage numerous diverse projects simultaneously, meet deadlines, and apply creativity (originality) in problem-solving<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Master’s Degree.</li><li>Tableau Experience.</li><li>Experience with NRC or another Experience Survey Vendor.</li><li>Experience with Qualtrics.</li><li>Project Management experience.</li><li>Experience in Healthcare.<br/><br/></li></ul>SPECIAL CONDITIONS<br/><br/><ul><li>Must be able to work various hours and locations based on business needs.</li><li>Employment is subject to a criminal background check and pre-employment physical.<br/><br/></li></ul><em>Pay Transparency Act<br/><br/></em>Annual Full Pay Range: $63,400 - $142,800 (will be prorated if the appointment percentage is less than 100%)<br/><br/>Hourly Equivalent: $30.36 - $68.39<br/><br/>Factors in determining the appropriate compensation for a role include experience, skills, knowledge, abilities, education, licensure and certifications, and other business and organizational needs. The Hiring Pay Scale referenced in the job posting is the budgeted salary or hourly range that the University reasonably expects to pay for this position. The Annual Full Pay Range may be broader than what the University anticipates to pay for this position, based on internal equity, budget, and collective bargaining agreements (when applicable).<br/><br/><strong>If employed by the University of California, you will be required to comply with our Policy on Vaccination Programs, which may be amended or revised from time to time. Federal, state, or local public health directives may impose additional requirements.<br/><br/></strong><strong>If applicable, life-support certifications (BLS, NRP, ACLS, etc.) must include hands-on practice and in-person skills assessment; online-only certification is not acceptable.<br/><br/></strong>UC San Diego Health is the only academic health system in the San Diego region, providing leading-edge care in patient care, biomedical research, education, and community service. Our facilities include two university hospitals, a National Cancer Institute-designated Comprehensive Cancer Center, Shiley Eye Institute, Sulpizio Cardiovascular Center, the only Burn Center in the county, and and dozens of outpatient clinics. We invite you to join our team!<br/><br/>Applications/Resumes are accepted for current job openings only. For full consideration on any job, applications must be received prior to the initial closing date. If a job has an extended deadline, applications/resumes will be considered during the extension period; however, a job may be filled before the extended date is reached.<br/><br/>To foster the best possible working and learning environment, UC San Diego strives to cultivate a rich and diverse environment, inclusive and supportive of all students, faculty, staff and visitors. For more information, please visit<br/><br/>UC San Diego Health Is An Equal Opportunity/Affirmative Action Employer. All Qualified Applicants Will Receive Consideration For Employment Without Regard To Race, Color, Religion, Sex, National Origin, Disability, Age, Protected Veteran Status, Gender Identity Or Sexual Orientation. For The Complete University Of California Nondiscrimination And Affirmative Action Policy See<br/><br/>UC San Diego is a smoke and tobacco free environment. Please visit<br/><br/>UC San Diego Health maintains a marijuana and drug free environment. Employees may be subject to drug screening.
      </div>",$63400- $142800,Data Warehouse Engineer
Data Analyst Junior Assistant ( Remote),AllStaff Staffing & Recruiting,12/25/2023,https://www.linkedin.com/jobs/view/3787808545,0,https://media.licdn.com/dms/image/C4D0BAQEuscJFY3dABw/company-logo_100_100/0/1631327180414?e=2147483647&v=beta&t=-ioqjmXkb5C0U1cc22Zh-Ajlwue7RzdGOya5vHhvLzw,United States,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Very Important: Check Your Email Inbox or Spam After Applying For Next Steps.<br/><br/></strong><strong>Check Your Email Inbox After Applying For Next Steps. After applying , You </strong><strong>will get an email in 5 minutes for next steps to follow your application.<br/><br/></strong>Join us as we expand our team with the addition of a Remote Data Entry Clerk. In this position, you will oversee data entry tasks, ensuring their punctual completion and the preservation of high-quality standards. Proficiency in data entry roles, razor-sharp analytical abilities, and the ability to collaborate seamlessly with diverse teams constitute the bedrock of this role. If you are a proactive individual armed with exceptional data entry skills, we wholeheartedly encourage your participation in our organization's journey to achievement, all within the convenience of your remote workspace.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Precisely input information into computer systems and databases.</li><li> Thoroughly validate and examine data for errors or inconsistencies.</li><li> Safeguard the integrity and confidentiality of data.</li><li> Organize and categorize documents in preparation for data input.<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li> Skilled in Microsoft Office Suite, especially Excel and Word</li><li> Outstanding typing speed with precision</li><li> Possession of a high school diploma or its equivalent, along with exceptional typing skills</li><li> Aptitude for managing sensitive information with integrity</li></ul>
</div>",No Salary Info Found,Data Modeler
BI Data Modeler - Erwin,CareerAddict,12/25/2023,https://www.linkedin.com/jobs/view/3791669783,0,https://media.licdn.com/dms/image/C4E0BAQHQUo3YFS080Q/company-logo_100_100/0/1630594573373/career_addict_logo?e=2147483647&v=beta&t=hlZnAyyIVBvbBfiOiJmKLhmpwyazTzU_0eCdWkhqD1E,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        NO SPONSORSHIP<br/><br/>BI Data Modeler - Erwin/Transact<br/><br/>SALARY: $140k - $150k plus 10% bonus<br/><br/>LOCATION: Chicago, IL<br/><br/>Looking for a BI Data Modeler with Erwin, Transact, SQL SSMS ETL Talend and SSMS Preferred Microsoft SQL Server Azure Synapse GIT Microsoft power BI Quik sense and tableau. Scripting in python<br/><br/>This role involves working closely with business analysts, data engineers, and other stakeholders to design/optimize data structures and flows that facilitate efficient data analysis and reporting. The BI Data Modeler has both technical and business-facing skills that allows driving solutions from a functional and technical perspective. The Data Modeler is well versed with industry best practices for creating, deploying, and managing data models for the Enterprise Data Warehouse, Data Marts, Data Cubes etc.<br/><br/><strong>Qualifications&amp; Requirements<br/><br/></strong>Education, Work Experience,<br/><br/><strong>Skills<br/><br/></strong>The candidate must have a BA/BS<br/><br/>Datamodelling skills (eg, using Erwin to create and manage Logical/physical data models) and expertise in modelling OLAP marts, cubes etc., and understanding on data grain, slowly changing dimensions (SCDs), snowflake/star schemas, row/object level security designs etc. (required).<br/><br/>Experience working with Transact SQL and other data query/reporting tools (required).<br/><br/>Knowledge of database design techniques and advanced SQL skills preferably on the SQL Server platform and/or Azure Synapse Data Marts (required).<br/><br/>Experience building, managing and optimizing data flows using ETL or ELT techniques in support of the data model buildout (required).<br/><br/>Python Scripting
      </div>",$140- $150,Data Modeler
BI Data Modeler,CareerAddict,12/19/2023,https://www.linkedin.com/jobs/view/3788414592,0,https://media.licdn.com/dms/image/C4E0BAQHQUo3YFS080Q/company-logo_100_100/0/1630594573373/career_addict_logo?e=2147483647&v=beta&t=hlZnAyyIVBvbBfiOiJmKLhmpwyazTzU_0eCdWkhqD1E,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Salary: Open + Bonus<br/><br/>Location: Chicago, IL/Houston, TX/Dallas, TX/Austin, TX/Miami, FL/NY, NY/San Fransisco, CA<br/><br/>Hybrid: 3 days on-site, 2 days remote<br/><br/>*We are unable to provide sponsorship for this role*<br/><br/><strong>Qualifications<br/><br/></strong><ul><li>Bachelors degree</li><li>5+ years' experience in data modelling concepts and techniques, ETL and data warehousing</li><li>Experience working with relational and dimensional data models, and in developing complex queries using Transact SQL and other data query/reporting tools.</li><li>Strong knowledge of relational database management systems (RDBMS) such as Microsoft SQL Server and Azure Synapse.</li><li>Experience building, managing, and optimizing data flows using ETL or ELT techniques in support of the data model buildout.</li><ul><li>Erwin for data modelling</li><li>Transact-SQL query using tools like SSMS</li><li>ETL Tools - Talend and/or ADF preferred.</li><li>Experience with version control systems like Git.</li><li>Familiarity with BI and reporting tools like Microsoft Power BI, Qlik Sense and Tableau.</li><li>Proficiency in Scripting languages like Python or programming languages like Java or C# is a plus.<br/></li></ul></ul><strong>Responsibilities<br/><br/></strong><ul><li>Work with business resources to identify business needs then design and develop conceptual, logical, and physical data models for the needs and support data analysis and reporting.</li><li>Define and create ETL processes for data extraction, transformation, and loading into the data warehouse or BI platform.</li><li>Implement data quality checks and validation rules to ensure data accuracy and consistency.</li><li>Continuously monitor and optimize data models and database performance for efficient data retrieval and reporting.</li><li>Maintain comprehensive documentation of data models, schemas, and related processes.</li></ul>
</div>",No Salary Info Found,Data Modeler
Data Modeler,ALIS Software LLC,12/19/2023,https://www.linkedin.com/jobs/view/3790330613,0,https://media.licdn.com/dms/image/C510BAQHRkjWiliYRRw/company-logo_100_100/0/1630632987362/alissoftwarellc_logo?e=2147483647&v=beta&t=1xK2SlNttnkMuD_u2A4K9xT3nm1gpammDywayYxB9KU,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Role : Data Modeler </strong></p><p><strong>Location : Local to Austin, TX or Fort Mills, SC or Charlotte, NC</strong></p><p><strong>Model : Hybrid - 2 days onsite</strong></p><p><strong>Type : Contract</strong></p><p><strong><span class=""ql-cursor""> </span></strong></p><ul><li><strong>Must have : . Min 10+ years experience</strong></li></ul><p>-</p><p><strong>Req Skills:</strong> Strong experience in AWS, Glue, Data Modeling|</p>
</div>",No Salary Info Found,Data Modeler
Data Modeler This Position is Exempt from State of DE,State of Delaware,12/19/2023,https://www.linkedin.com/jobs/view/3784091278,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Principal Data Modeler - (14+ Years),Enexus Global Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3788432062,0,https://media.licdn.com/dms/image/C4D0BAQHQMdJHWhkMzQ/company-logo_100_100/0/1630565513437/enexusglobal_logo?e=2147483647&v=beta&t=ZKdlK4kumv_WNN33tc6JgiXBrFGaqg2cu1HgLY422Tk,United States,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Role : Principal Data Modeler (Insurance Background)<br/><br/></strong><strong>Location : Remote<br/><br/></strong><strong>Contract type : W2/C2C/1099<br/><br/></strong><strong>Experience : 14+ years<br/><br/></strong><strong>Skills : Python, Erwin, ETL, Spark, hadoop<br/><br/></strong><strong>Role Description<br/><br/></strong>You’ll be responsible for (Responsibilities):<br/><br/><ul><li>Background in Data Warehouse and Business Intelligence</li><li>Strong understanding of programming languages like Java, Scala, or Python.</li><li>6+ years of strong ETL experience on either Information, Ab-Initio, Talend, DataStage, Syncsort.</li><li>Designing and implementing Data security and privacy controls.</li><li>Experience with version control tools like Git, SVN</li><li>10+ years of experience building large scale data models using ERWIN or equivalent tool for larger and medium enterprise.</li><li>Experience in Spark, Hive, Hadoop, Kafka, Columnar Databases.</li><li>Experience in designing solutions for multiple large data warehouses with a good understanding of cluster and parallel architecture as well as high-scale or distributed RDBMS and/or knowledge on NoSQL platforms.<br/><br/></li></ul><strong>You’ll Have (Qualification &amp; Experience)<br/><br/></strong><ul><li>Bachelor's Degree in related field is required.</li></ul>
</div>",No Salary Info Found,Data Modeler
Data Modeler,Customers Bank,12/19/2023,https://www.linkedin.com/jobs/view/3756321662,0,https://media.licdn.com/dms/image/C4D0BAQGK_oAD3hCgYg/company-logo_100_100/0/1639609245732/customers_bank_logo?e=2147483647&v=beta&t=yzW_PvmmALMgqs2WN3pa0uj0mayWFFS-IifqNVcvR84,"Malvern, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Customers Bank, we believe in working hard, working smart, working together to deliver memorable customer experiences and having fun. Our vision, mission, and values guide us along our path to achieve excellence. Passion, attitude, creativity, integrity, alignment, and execution are cornerstones of our behaviors. They define who we are as an organization and as individuals. Everyone is encouraged to have personal development plans. By doing so, our team members are on their way to achieve their highest potential and be successful in their personal and professional lives.<br/><br/><strong>Work Location:</strong> Hybrid in the Malvern, PA location, coming into the office at least 3 days per week with Monday, Tuesday, and Thursday being set days, or the position is open to being Remote – East Coast<br/><br/><strong>The expected salary range for this position is </strong>$100,000-$115,000. (this is a good faith estimate of what we expect to pay for this position. The final salary will consider experience, accomplishments, and location.<br/><br/><strong>Who is Customers Bank?<br/><br/></strong>Founded in 2009, Customers Bank is a super-community bank with over $22 billion in assets. We believe in dedicated personal service for the businesses, professionals, individuals, and families we work with.<br/><br/><strong>We get you further, faster. <br/><br/></strong><strong>Focused on you: </strong>We provide every customer with a single point of contact. A dedicated team member who’s committed to meeting your needs today and tomorrow.<br/><br/><strong>On the leading edge:</strong> We’re innovating with the latest tools and technology so we can react to market conditions quicker and help you get ahead.<br/><br/><strong>Proven reliability:</strong> We always ground our innovation in out deep experience and strong financial foundation, we we’re a partner you can trust.<br/><br/><strong>What You’ll Do<br/><br/></strong>We are seeking a talented and experienced Data Modeler to join our Data Management and Analytics team at Customers Bank. As a Data Modeler, you will play a crucial role in designing and building our data warehouse solutions that ingest data from across the bank and are used for executive leadership reporting.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Creating conceptual and physical data models of tables and views from complex datasets that adhere to best practices and guiding principles</li><li>Design flexable and scalable solutions that can grow with the bank’s ever expanding product sets and customer base</li><li>Collaborate with data team to understand new data model requirements and develop supporting solutions</li><li>Enforce best practices for database, table structures and naming conventions across data team</li><li>Maintain Documentation for data model, schemas and data definitions for fields including information regarding joins, default values, etc</li><li>Work in an Agile environment and adhering to the focus on prioritized initiatives.</li><li>Stay up to date with industry trends, best practices, and emerging technologies in the field of data analysis and reporting<br/><br/></li></ul><strong>What do you need?<br/><br/></strong><ul><li>4 to 6 years of proven experience as a lead data modeler, preferably in the banking or financial industry</li><li>Deep knowledge and hands on experience with Snowflake and Oracle environments</li><li>Experience using SQLdbm and dbt to model and create physical data models</li><li>Experience documenting data model definitions to support lineage and data governance efforts</li><li>Detail-oriented mindset with the ability to prioritize and manage multiple tasks in a dynamic environment.</li><li>Strong problem-solving skills and the ability to think critically to identify and resolve business challenges.</li><li>Bachelor's degree in Business Administration, Computer Science, or a related field.</li><li>Excellent communication skills with the ability to effectively collaborate with stakeholders at various levels.<br/><br/></li></ul><strong>Technology Skills<br/><br/></strong><ul><li>Microsoft Office applications<br/><br/></li></ul>Customers Bank is an Equal Opportunity Employer
      </div>",$100000- $115000,Data Modeler
Data Modeler,Optomi,12/20/2023,https://www.linkedin.com/jobs/view/3775440609,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Modeler,Incedo Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3790921120,0,https://media.licdn.com/dms/image/C4D0BAQEzqnAdsML8AQ/company-logo_100_100/0/1656661706797/incedo_inc_logo?e=2147483647&v=beta&t=lTHWgZfnEyk0Gwvr1BTpOPP3jxHm4Xl-INBATyFxapM,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Description</strong></p><p>· The data modeler designs, implements, and documents data architecture and data modeling solutions, which include the use of relational, dimensional, and NoSQL databases. These solutions support enterprise information management, business intelligence, machine learning, data science, and other business interests.</p><p>· The successful candidate will:</p><p>· Be responsible for the development of the conceptual, logical, and physical data models, the implementation of RDBMS, operational data store (ODS), data marts, and data lakes on target platforms (SQL/NoSQL).</p><p>· Oversee and govern the expansion of existing data architecture and the optimization of data query performance via best practices. The candidate must be able to work independently and collaboratively.</p><p><br/></p><p><br/></p><p><strong>Responsibilities</strong></p><p>· Implement business and IT data requirements through new data strategies and designs across all data platforms (relational, dimensional, and NoSQL) and data tools (reporting, visualization, analytics, and machine learning).</p><p>· Work with business and application/solution teams to implement data strategies, build data flows, and develop conceptual/logical/physical data models</p><p>· Define and govern data modeling and design standards, tools, best practices, and related development for enterprise data models.</p><p>· Identify the architecture, infrastructure, and interfaces to data sources, tools supporting automated data loads, <strong>security concerns, analytic models, and data visualization</strong>.</p><p>· Hands-on <strong>modeling, design, configuration, installation, performance tuning, and sandbox POC.</strong></p><p>· Work proactively and independently to address project requirements and articulate issues/challenges to reduce project delivery risks.</p><p>· Strong with <strong>AWS cloud background</strong></p><p><br/></p><p><strong>Skills</strong></p><p>· Bachelor’s or master’s degree in computer/data science technical or related experience.</p><p>· 5+ years of hands-on relational, dimensional, and/or analytic experience (using RDBMS, dimensional, NoSQL data platform technologies, and ETL and data ingestion protocols).</p><p>· Experience with data warehouse, data lake, and enterprise big data platforms in multi-data-center contexts required.</p><p>· Good knowledge of metadata management, data modeling, and related tools (Erwin or ER Studio or others) required.</p>
</div>",No Salary Info Found,Data Modeler
Data Modeler,Concord IT Systems,12/21/2023,https://www.linkedin.com/jobs/view/3785666596,0,https://media.licdn.com/dms/image/C510BAQFvHlB6wvgCBg/company-logo_100_100/0/1630614000626?e=2147483647&v=beta&t=lh_y80ZGw5EPjWtIjyza45_Al2Yeql5yNuQvJe8I4IE,"Englewood, CO","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title: Data Modeler </strong></p><p><span>Location: Englewood, CO</span></p><p><br/></p><p><strong>Job Description: </strong></p><p><strong>Position Overview: </strong></p><p>A Data Modeler plays a critical role in an organization's data management and analytics efforts </p><p>by consolidating various databases and data stores, eliminating redundancy, and optimizing </p><p>data structures for improved efficiency. This role requires a deep understanding of data </p><p>modeling, database design, and data integration principles. The Data Modeler collaborates </p><p>closely with data engineers, data scientists, and other stakeholders to ensure that the </p><p>organization's data assets are structured and organized for optimal performance and usability. </p><p><strong> </strong></p><p><strong>Key Responsibilities: </strong></p><p><strong> </strong></p><p>1. Data Consolidation: - Identify and analyze existing databases, data sources, and data stores within the </p><p>organization. - Develop strategies and plans for consolidating disparate data assets into a unified and </p><p>coherent structure. - Assess the quality and relevance of data from different sources and recommend data </p><p>consolidation techniques. </p><p>2. Data Modeling: - Design and create data models that represent the structure and relationships within the </p><p>organization's data. - Utilize industry-standard modeling techniques such as Entity-Relationship Diagrams (ERD) </p><p>and/or multidimensional modeling as necessary. - Ensure data models are consistent, maintainable, and scalable. </p><p>3. Redundancy Removal: - Identify and eliminate redundant data across different systems, databases, or data stores. - Implement data normalization and denormalization strategies where appropriate to </p><p>optimize data storage and retrieval. </p><p>4. Database Optimization: - Work with database administrators and developers to optimize the performance of database </p><p>systems. - Fine-tune data storage configurations, indexing, and query performance. - Identify and implement strategies for data archiving, partitioning, and purging to improve </p><p>efficiency. </p><p>5. Data Efficiency: </p><p>- Collaborate with data analysts and data scientists to understand their data requirements and </p><p>optimize data structures accordingly. - Implement data compression, caching, and indexing techniques to improve data access </p><p>times. - Continuously monitor data performance and make adjustments as needed. </p><p>6. Documentation: - Create and maintain detailed documentation of data models, schema designs, and data </p><p>integration processes. - Ensure that data-related documentation is kept up-to-date and accessible to relevant </p><p>stakeholders. </p><p>7. Data Governance: - Ensure that data modeling and consolidation efforts comply with data governance policies, </p><p>security standards, and regulatory requirements. - Collaborate with data governance teams to establish and enforce data standards. </p><p> </p><p><strong>Qualifications:</strong> - Bachelor's or Master's degree in Computer Science, Information Systems, or a related field. - Proven experience in data modeling, database design, and data consolidation. - Proficiency in data modeling tools such as ERwin, ER/Studio, or similar software. - Strong knowledge of database management systems (SQL and NoSQL). - Familiarity with data warehousing concepts and ETL processes. - Excellent problem-solving skills and attention to detail. - Strong communication and collaboration skills to work with cross-functional teams. - Knowledge of data governance and data security best practices is a plus.</p>
</div>",No Salary Info Found,Data Modeler
Data Engineer - 100% remote,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791621839,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Join our growing Engineering team!<br/><br/></strong>This Jobot Job is hosted by Mike Duffy<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $100,000 - $140,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>We are rapidly growing equipment finance company with over 25 years in business!<br/><br/>The Data Engineer will be responsible for building data-driven analytics tools that are used across the entire organization to improve decision making.<br/><br/>The Data Engineer should have 3+ years of experience with Python, ETL, and SQL<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Excellent pay &amp; benefits!</li><li> 100% remote flexibility!</li><li> Room for growth!</li><li> Outstanding company culture!<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency, and other key business performance metrics.</li><li> Has demonstrated proficiency in designing and developing data marts in Snowflake schema.</li><li> Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL Server, NoSQL, Kafka using AWS or AZURE Big Data technologies.</li><li> Use troubleshooting skills to identify and correct root cause of workflow failures based on error log outputs and environmental conditions.</li><li> Use SQL to examine, filter, and aggregate data in Microsoft SQL Server.</li><li> Experience working with data transformation processing.</li><li> Anticipate, identify, and solve issues concerning data management to improve data quality.</li><li> Experience working with Microsoft BI and Microsoft SQL server.</li><li> Perform POCs on new technology, architecture patterns.</li><li> Must have Experience with at least one Columnar MPP Cloud data warehouse (Snowflake /Azure Synapse / Redshift)</li><li> Design of complex physical data models, projects and cloud-based data lake constructs including SQL/NoSQL database systems. Leads the creation of integrated data views based on business or analytics requirements.</li><li> Design, implement, and automate data pipelines sourcing data from internal and external systems, transforming the data for the optimal needs of various systems and business requirements.</li><li> Experience in ETL tools like DBT is nice to have.</li><li> Experience with version control and DevOps platforms such as AZURE DevOps, GitHub, GitLab</li><li> Experience with CI/CD Pipelines and SDLC best practices.</li><li> Experience using Agile methods and project management tools like Jira preferred.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Software Engineering, Information Technology, or a related field.</li><li> Minimum of 3 years of experience in a data engineer or similar role.</li><li> Strong knowledge of Python, ETL, SQL, data integration, and data pipelines.</li><li> Experience with data architecture, data modeling, schema design, and software development.</li><li> Proficiency in data migration, transformation, and scripting.</li><li> Familiarity with machine learning models and their data needs.</li><li> Understanding of distributed systems as it pertains to data storage and computing.</li><li> Strong project management and organizational skills.</li><li> Ability to analyze problems and strategize for better solutions.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$100000- $140000,Data Modeler
GCP Data Engineer,CloudMR,12/24/2023,https://www.linkedin.com/jobs/view/3792797836,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
BI Data Modeler,CareerAddict,12/19/2023,https://www.linkedin.com/jobs/view/3788414592,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Associate Analytics Engineer,NexusLeap,12/19/2023,https://www.linkedin.com/jobs/view/3784428116,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Engineer,Visa,12/19/2023,https://www.linkedin.com/jobs/view/3790090038,0,https://media.licdn.com/dms/image/C560BAQEP8_eM4zW8bw/company-logo_100_100/0/1630663392691/visa_logo?e=2147483647&v=beta&t=TzxC8Eby4Etg1Y4aK9Ul8pUVAccJ4Do5GJP4uVtlOBY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.<br/><br/>When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.<br/><br/><strong>Join Visa: A Network Working for Everyone.<br/><br/></strong><strong>Job Description<br/><br/></strong>Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area.<br/><br/>Visa AI as a Service (VAIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, VAIaS automates the updates to data, models, and applications. Combined with strong AI governance, VAIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!<br/><br/>This position is for a Data Engineer with solid development experience who will focus on creating new capabilities for Visa AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.<br/><br/>You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.<br/><br/>This position will be based in Austin, TX. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li> Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions</li><li> Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards</li><li> Responsibilities span all phases of solution development including:</li><li> Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved</li><li> Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner<br/><br/></li></ul>This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.<br/><br/><strong>Qualifications<br/><br/></strong>Basic Qualifications:<br/><br/><ul><li> Bachelors degree, OR 3+ years of relevant work experience<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li> 2 or more years of work experience</li><li> Exposure to leading-edge areas such as Machine Learning, Big Data, Distributed Systems or SRE. </li><li> Experience in at least one of the following: Golang, Java, or C/C++, Spark</li><li> Familiarity with web service standards and related patterns (REST, gRPC)</li><li> Experience implementing solutions for low-latency, distributed services using open standard technologies. <br/><br/></li></ul><strong>Additional Information<br/><br/></strong><strong>Work Hours:</strong> Varies upon the needs of the department.<br/><br/><strong>Travel Requirements:</strong> This position requires travel 5-10% of the time.<br/><br/><strong>Mental/Physical Requirements:</strong> This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.<br/><br/>Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.<br/><br/>Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.<br/><br/><strong>U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 89,600.00 to 114,300.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.</strong>
</div>",No Salary Info Found,Data Modeler
Data Modeler,ALIS Software LLC,12/19/2023,https://www.linkedin.com/jobs/view/3790330613,0,https://media.licdn.com/dms/image/C510BAQHRkjWiliYRRw/company-logo_100_100/0/1630632987362/alissoftwarellc_logo?e=2147483647&v=beta&t=1xK2SlNttnkMuD_u2A4K9xT3nm1gpammDywayYxB9KU,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Role : Data Modeler </strong></p><p><strong>Location : Local to Austin, TX or Fort Mills, SC or Charlotte, NC</strong></p><p><strong>Model : Hybrid - 2 days onsite</strong></p><p><strong>Type : Contract</strong></p><p><strong><span class=""ql-cursor""> </span></strong></p><ul><li><strong>Must have : . Min 10+ years experience</strong></li></ul><p>-</p><p><strong>Req Skills:</strong> Strong experience in AWS, Glue, Data Modeling|</p>
</div>",No Salary Info Found,Data Modeler
"Data Analyst, Residential Energy Operations",Tesla,12/19/2023,https://www.linkedin.com/jobs/view/3737833368,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Modeler,Incedo Inc.,12/20/2023,https://www.linkedin.com/jobs/view/3790921120,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Analyst II,Texas Health and Human Services,12/20/2023,https://www.linkedin.com/jobs/view/3792572148,0,https://media.licdn.com/dms/image/C4E0BAQH1GwRpPT_nlg/company-logo_100_100-alternative/0/1630609595744/hhsc_logo?e=2147483647&v=beta&t=ydOr4Zqm5J6mwTJGg8-qMTSs9cX0oYiMZDsSSe87Ums,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>Data Analyst II<br/><br/>The data abstractor in the Injury Prevention Unit performs compiling of data related to violent deaths (i.e., homicides, suicides) in Texas. They will be primarily responsible for analyzing and identifying pertinent information from death certificates, justice of the peace/medical examiner records, and law enforcement records. Data entries will be made into the Centers for Disease Control and Prevention (CDC) federal database (National Violent Death Reporting System). Requests, tracks and receives documents from new and existing data providers. Cleans, scans, stores, and organizes documents pertaining to Texas violent deaths from data providers, which include federal, state and county agencies, health care providers, law enforcement agencies, private organizations and associations, employers, and the general public. Engage in data quality improvement projects such as re-abstracting cases and maintaining record management systems. Works under the Manager for the Texas Violent Death Reporting System.<br/><br/><strong>Essential Job Functions<br/><br/></strong>Attends work on a regular and predictable schedule in accordance with agency leave policy and performs other duties as assigned.<br/><br/>(30%) Compiles violent death data from multiple data sources (i.e. death certificates, medical examiner and justice of the peace reports, and law enforcement reports). Analyzes and identifies pertinent information from source documents as defined by the National Violent Death Reporting System. Translates pertinent information into NVDRS registry codes based on established CDC guidelines. Adhere to CDC guidelines for timeliness (16 months for full data abstraction), grant deadlines (annually), and administrative and programmatic requirements.<br/><br/>(30%) Contact justices of the peace, medical examiners, and law enforcement agencies to obtain data/verification information on cases in a timely fashion (within 16 months). Receives and organizes documents from new and existing data providers pertaining to violent deaths (i.e. homicides, suicides) in Texas, which include federal, state and county agencies, health care providers, law enforcement agencies, private organizations, and the general public. Follow up with reporting sources as needed. Assist in improving data collection processes by identifying issues and assisting in mitigating them.<br/><br/>(20%) Engage in data quality improvement and security projects. Will provide re-abstraction and cross validation of cases as needed to ensure high quality abstraction. Crosstrain and support other abstractors on maintaining and implementing secure systems for digital and physical files throughout the abstraction process.<br/><br/>(15%) Assist epidemiologist in responding to requests for data. Write responses to correspondence and/or reply to telephone inquiries by providing required data, information or assistance as required.<br/><br/>(5%) Other duties as assigned include but are not limited to actively participating and/or serving in a supporting role to meet the agency’s obligations for disaster response and/or<br/><br/>recovery or Continuity of Operations (COOP) activation. Such participation may require an alternate shift pattern assignment and/or location.<br/><br/><strong>Knowledge Skills Abilities<br/><br/></strong>List the knowledge, skills, and abilities critical to performance in this position:<br/><br/>Knowledge of office practices and administrative procedures.<br/><br/>Knowledge of English grammar, spelling, punctuation, and writing style.<br/><br/>Skill in organizing, supporting, coordinating, facilitating, and monitoring various activities of diverse individuals and/or groups and teams.<br/><br/>Skill in email, e.g. Outlook, and calendar software functions.<br/><br/>Skill in searching the Internet for information.<br/><br/>Skill in constructing and maintaining databases and spreadsheets.<br/><br/>Skill in constructing, proofing, editing, formatting and maintaining documents, databases and spreadsheets.<br/><br/>Skill in organizing information and developing reports, training materials and presentations using word processing and other software (MS Word, PowerPoint, Excel).<br/><br/>Skill in communicating information clearly, concisely, and effectively, both verbally and in writing.<br/><br/>Skill in using logic and reasoning to identify the strengths and weaknesses of alternative solutions, conclusions, or approaches to problems.<br/><br/>Skill in coordinating, facilitating, organizing, and processing travel arrangements and reimbursements.<br/><br/>Ability to interpret and apply agency rules, regulations, policies, and procedures.<br/><br/>Ability to organize and manage multiple and diverse tasks/projects in an effective and efficient manner.<br/><br/>Ability to work under deadline pressures and cope well in stressful environments.<br/><br/>Ability to write clearly and concisely with minimal grammar, spelling, punctuation and formatting errors.<br/><br/>Ability to review information of a violent nature and be able to clearly identify and write narratives.<br/><br/>Ability to communicate effectively within the agency and with the public.<br/><br/>Ability to implement administrative procedures and to evaluate their effectiveness.<br/><br/>Ability to exercise judgment and critical thinking in evaluating situations, making decisions, and effectively working through areas of conflict.<br/><br/>Ability to establish and maintain effective working relationships with supervisors and co-workers.<br/><br/>Must be able to move at least 25lbs, e.g., copy paper boxes, chairs and conference room tables with or without accommodations.<br/><br/><strong>Registration Or Licensure Requirements<br/><br/></strong>N/A<br/><br/><strong>Initial Selection Criteria<br/><br/></strong>Graduation from an accredited 4-year college or university and<br/><br/>a minimum of one (1) year of experience with review of either: death certificates, coroner/medical examiner reports, law enforcement reports or equivalent medical/legal record review.<br/><br/>OR<br/><br/>A minimum of three (3) years of experience with review of either: death certificates, coroner/medical examiner reports, law enforcement reports or equivalent medical/legal records.<br/><br/>Note: Graduation from an accredited four-year college or university preferred. As described above, three or more years of experience may substitute for an accredited four-year college or university degree.<br/><br/><strong>Additional Information<br/><br/></strong>IMPORTANT, PLEASE READ THE FOLLOWING INFORMATION PRIOR TO SUBMITTING AN APPLICATION FOR THIS POSITION:<br/><br/>Information on the application must clearly state how the applicant meets initial selection criteria in the Summary of Experience section in order to be interviewed. Resumes will not be accepted in lieu of an application.<br/><br/>Applicants must provide information relevant to the required experience for this position. Answer all questions and completely summarize your experience including technical and managerial responsibilities and any special training, skills and qualifications for each position you have held in the employment history section of application.<br/><br/>All fields on the application must be filled-in completely. This includes, but is not limited to, previous salary, previous supervisor, and reason for leaving previous position.<br/><br/>Applicants selected for an interview will be required to complete an in-basket exercise.<br/><br/>Position may be eligible for part-time telework upon successful completion of the required probationary period of 90 days.<br/><br/>Agency salary policy, budget and candidate’s qualifications will dictate final salary offer.<br/><br/>Note: There may be no military occupation(s) that relate to the initial selection criteria and registration or licensure requirements for this position. All active duty military, reservists, guardsmen, and veterans are encouraged to apply if qualified to fill this position. For more information see the Texas State Auditor’s Military Crosswalk at http://www.hr.sao.state.tx.us/Compensation/JobDescriptions.aspx<br/><br/>This position is eligible for full-time telework within the state of Texas.<br/><br/><strong>MOS Code<br/><br/></strong>N/A<br/><br/>Top 10 Tips for Success when Applying to Jobs at HHSC and DSHS<br/><br/>HHS agencies use E-Verify. You must bring your I-9 documentation with you on your first day of work.<br/><br/>I-9 Form - Click here to download the I-9 form.<br/><br/>In compliance with the Americans with Disabilities Act (ADA), HHS agencies will provide reasonable accommodation during the hiring and selection process for qualified individuals with a disability. If you need assistance completing the on-line application, contact the HHS Employee Service Center at 1-888-894-4747. If you are contacted for an interview and need accommodation to participate in the interview process, please notify the person scheduling the interview.
      </div>",No Salary Info Found,Data Modeler
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789086619,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $130,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$130000- $173000,Data Modeler
"Data Engineering Intern, Analytics",Meta,12/25/2023,https://www.linkedin.com/jobs/view/3763484916,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Burlingame, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Every month, billions of people leverage Meta products to connect with friends and loved ones from across the world. On the Data Engineering Team, our mission is to support these products both internally and externally by delivering the best data foundation that drives impact through informed decision making. As a highly collaborative organization, our data engineers work cross-functionally with software engineering, data science, and product management to optimize growth, strategy, and experience for over three billion users, as well as our internal employee community. In this role, you will see a direct correlation between your work, company growth, and user satisfaction. Beyond this, you will work with some of the brightest minds in the industry, and you'll have a unique opportunity to solve some of the most interesting data challenges with efficiency and integrity, at a scale few companies can match. As we continue to expand and create, we have a lot of exciting work ahead of us!<br/><br/>Data Engineering Intern, Analytics Responsibilities:<br/><br/><ul><li>Architect, implement and deploy new data models and data processes in production</li><li>Perform data analysis to generate business insights</li><li>Interface with Engineers, Product Managers and Data Scientists to understand product goals and data needs</li><li>Build data expertise and own data quality for allocated areas of ownership</li><li>Manage data warehouse plans for a product or a group of products</li><li>Support critical data processes running in production<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>Currently has, or is in the process of obtaining, a Bachelors, or Masters degree in Computer Science, Information Science, Mathematics, or related technical field</li><li>Knowledge of SQL, data modeling and at least one programming language(e.g., Python, C++, C#, Scala)</li><li>Must obtain work authorization in country of employment at the time of hire, and maintain ongoing work authorization during employment<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Intent to return to degree-program after the completion of the internship</li><li>Curious, self-driven, analytical and excited to play with data</li><li>Ability to thrive in a fast paced work environment</li><li>Experience in collaborating with individuals and organizations<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data Modeler
"Staff Data Engineer, Data Products (Contract)",SoFi,12/20/2023,https://www.linkedin.com/jobs/view/3759869691,0,https://media.licdn.com/dms/image/C560BAQH0xjWQVXJr6w/company-logo_100_100/0/1630660955481/sofi_logo?e=2147483647&v=beta&t=FVZG0dNVAhdZ-W3Op_NDxjxwWCaIzunudLIIydaqJQI,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Employee Applicant Privacy Notice<br/><br/></strong><strong>Who we are:<br/><br/></strong>Shape a brighter financial future with us.<br/><br/>Together with our members, we’re changing the way people think about and interact with personal finance.<br/><br/>We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. <strong>Join us to invest in yourself, your career, and the financial world.<br/><br/></strong><strong>Team: <br/><br/></strong>SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.<br/><br/><strong>Role:<br/><br/></strong>A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.<br/><br/><strong>What you’ll do:<br/><br/><br/></strong><ul><li>Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.</li><li>Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,</li><li>Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.<br/><br/><br/></li></ul><strong>What you’ll need:<br/><br/><br/></strong><ul><li>A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;</li><li>Over 8 years of experience in data engineering and analytics technical strategy. </li><li>Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..</li><li>Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP</li><li>Strong in Python and/or another data centric language. </li><li>Thorough knowledge of data modeling, database design, data architecture principles, and data operations.</li><li>Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.</li><li>Experience in the Fintech industry is advantageous.<br/><br/><br/></li></ul><em><strong>Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.<br/><br/></strong></em><strong>Compensation And Benefits<br/><br/></strong>The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.<br/><br/>To view all of our comprehensive and competitive benefits, visit our <strong>Benefits at SoFi </strong>page!<br/><br/>SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.<br/><br/>The Company hires the best qualified candidate for the job, without regard to protected characteristics.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.<br/><br/>New York applicants: Notice of Employee Rights<br/><br/>SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.<br/><br/>Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.<br/><br/><strong>Internal Employees<br/><br/></strong>If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.
      </div>",No Salary Info Found,Data Modeler
Principal Data Cloud Data Modeler,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3725138199,0,https://media.licdn.com/dms/image/C560BAQHZ9xYomLW7zg/company-logo_100_100/0/1630658255326/salesforce_logo?e=2147483647&v=beta&t=GvAdJRB6d3hWoiMBjIAOP9tjZzbWxLNF84FnSTgWblE,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.<br/><br/></em>Job Category<br/><br/>Software Engineering<br/><br/>Job Details<br/><br/><strong>About Salesforce<br/><br/></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/>The <strong>Principal Data Cloud Data Modeler</strong> will be joining a world-class data modeling team with a real passion for well-architected analytical software that delivers unparalleled customer success. You will work on canonical Data Cloud data models for “horizontal“ (e.g. sales, service, marketing) and industry-specific analytic applications, helping to shape the structure of data across a much broader range of subject areas than most data modelers see in their careers. Salesforce is leading the way to bring AI, data, automation and deep industry-specific functionality to our customers. Join our high performance culture of trust, collaboration, transparency, continuous improvement and making work fun!<br/><br/><strong>Responsibilities<br/><br/></strong>Success will be measured by the individual’s ability to lead Salesforce T&amp;P to deliver well-architected Data Cloud data models at a steady pace of innovation, and to influence the architecture of Data Cloud itself to enable well-architected analytical data models.<br/><br/><ul><li>Provide expert data modeling design advice to Salesforce product teams for OLAP and AI applications built with Data Cloud, as well as OLTP applications.</li><li>Identify overlapping data model requirements across multiple product teams and drive the combined canonical data model design to consensus and consistency.</li><li>Lead and contribute to hands-on detailed design, development, testing and publishing of canonical data models.</li><li>Take ownership of the data model designs developed and deployed and represent them to internal and external stakeholders.</li><li>Identify and articulate gaps in current Data Cloud features necessary to properly support the many use cases for Data Cloud. Collaborate with Data Cloud architects, product owners and developers to design features that close those gaps.</li><li>Coach, mentor and enhance the data modeling design skills of our own team and all the teams we work with.</li><li>Lead and contribute to Data Cloud data model documentation and collateral to enable the Salesforce ecosystem to understand and properly adopt the Salesforce data model.</li><li>Seek continuous improvement in Salesforce’s processes, methods and tooling to improve our efficiency and effectiveness.<br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><ul><li>20+ years of demonstrated, hands-on analytical data modeling and design experience across multiple industries for analytical systems</li><li>Strong knowledge of data modeling principles and best practices including a good understanding of canonical and semantic data modeling concepts</li><li>Significant experience in data warehousing, data lakes, ML pipelines, batch and real-time data transformation (ETL/ELT) and processing</li><li>Significant experience with several of relational, columnar, graph, vector, NoSQL, streaming databases</li><li>Ability to quickly grasp technological and business concepts</li><li>Strong verbal and written communication skills; experience communicating with engineers, software professionals, product management and executives to succinctly explain technical and functional concepts</li><li>Experience with the full software lifecycle delivering enterprise software products or large-company analytical information technology projects</li><li>Experience and desire to work within a fast-paced environment with short release cycles and an iterative development methodology</li><li>Able to work on multiple projects/products simultaneously and comfortable working with minimal specifications</li><li>A related technical degree required<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Experience with modern data stack and analytical technologies such as Apache Iceberg, Snowflake, MongoDB, Neo4j, Neptune, and similar</li><li>Experience across a variety of business processes and industries; especially communications, media, energy, utilities, financial services, health, manufacturing, consumer packaged goods, retail, non-profit, education, public sector and sustainability</li><li>Strong, hands-on knowledge of SQL (or Salesforce SOQL) including performance tuning</li><li>Strong knowledge of Salesforce product and platform features, capabilities, and the best use of them such as Data Cloud and Tableau.</li><li>Good understanding of enterprise architecture principles</li><li>Experience with Agile development methodologies</li><li>Ability to serve as a trusted advisor to customers, with a deep curiosity to understand them, their motivations and needs, and how to approach ensuring their success</li><li>Experience with data modeling tools, processes, BI tools, reporting software and data analysis and data analytics<br/><br/></li></ul>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.<br/><br/>﻿Salesforce welcomes all.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.<br/><br/>For Washington-based roles, the base salary hiring range for this position is $172,500 to $280,200.<br/><br/>For California-based roles, the base salary hiring range for this position is $188,200 to $305,600.<br/><br/>Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.
      </div>",$172500- $280200,Data Modeler
Data Engineer,Generate,12/19/2023,https://www.linkedin.com/jobs/view/3784462577,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Engineer,CBS Philadelphia,12/19/2023,https://www.linkedin.com/jobs/view/3789847083,0,https://media.licdn.com/dms/image/D4E0BAQEMPwKIf8jpwA/company-logo_100_100/0/1681502322691/cbsphiladelphia_logo?e=2147483647&v=beta&t=78mlu3uJv8sahkqXT8p_1GQEnYuEQozChyXtt3i2RVE,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Search by Keyword or Req ID<br/><br/>Search by Location<br/><br/>Click Here to Search by Job Function<br/><br/>Loading...<br/><br/>Job Function<br/><br/>All<br/><br/>Brand<br/><br/>All<br/><br/>Job Type<br/><br/>All<br/><br/><strong>Select How Often (in Days) To Receive An Alert<br/><br/></strong>Select how often (in days) to receive an alert:<br/><br/>Apply now »<br/><br/><strong> Data Engineer <br/><br/></strong>38443<br/><br/>San Francisco, CA, US, 94107 New York, NY, US, 10036 New York, NY, US, 10016 Fort Lauderdale, FL, US, 33309<br/><br/>Research<br/><br/>San Francisco<br/><br/>Full-Time<br/><br/>Hybrid<br/><br/>We are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data &amp; Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business.<br/><br/><ul><li>Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. </li><li>Able to break down and communicate highly complex data problems into simple, feasible solutions. </li><li>Extract patterns from large datasets and transform data into an informational advantage.</li><li>Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations.</li><li>Partner with the internal product and business intelligence teams to determine the best approaches around data ingestion, structure, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. </li><li>Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. </li><li>Ongoing development of technical solutions while developing and maintaining documentation, at times training impacted teams. </li><li>Early on, collaborate with the team on internal initiatives to create strategies that improve company processes.<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><ul><li>STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations.</li><li>Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB)</li><li>Proficient in Python and SQL.</li><li>Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis</li><li>Experience with exploratory data analysis using tools like iPython Notebook, Pandas &amp; matplotlib, etc.</li><li>Strong problem-solving and creative-thinking skills.</li><li>Ability to break down and communicate highly complex data problems as simple, feasible solutions</li><li>Demonstrated development of ongoing technical solutions while developing and maintaining documentation, at times training impacted teams. </li><li>Experience developing solutions to business requirements via hands-on discovery and exploration of data.</li><li>Robust written and verbal communication skills, including the ability to communicate technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions</li><li>Experience building and deploying applications on a cloud platform (Google Cloud Platform preferred)<br/><br/></li></ul><strong>Additional Qualifications<br/><br/></strong><ul><li>Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus.</li><li>Experience with Apache Airflow is a plus.</li><li>Familiarity with Data Modeling.</li><li>Familiar with GIT. </li><li>Can perform statistical analyses using tools such as R, Numpy/SciPy with Python</li><li>Experience with Adobe Analytics (Omniture) or Google Analytics. </li><li>Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising.</li><li>Familiarity with ELT/ETL concepts. <br/><br/></li></ul>38443<br/><br/>Join the Paramount Streaming Talent Community ! Get the inside scoop on life at Paramount Streaming and about career opportunities.<br/><br/>Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage.<br/><br/><strong>Additional Information<br/><br/></strong>Hiring Salary Range: $85,600-$120,000.<br/><br/>The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible.<br/><br/>https://www.paramount.com/careers/benefits<br/><br/>Paramount is an equal opportunity employer (EOE) including disability/vet.<br/><br/>At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status.<br/><br/>If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.<br/><br/><strong>Nearest Major Market: </strong>San Francisco<br/><br/><strong>Nearest Secondary Market: </strong>Oakland<br/><br/>Apply now »<br/><br/><strong>Find Similar Jobs<br/><br/></strong>Paramount Streaming, Noggin, All Current Job Opportunities<br/><br/>
</div>",$85600- $120000,Data Modeler
Senior Data Cloud Data Modeler,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3725136731,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
"Data Analyst, Strategy & Diagnostics",Lyft,12/20/2023,https://www.linkedin.com/jobs/view/3788642888,0,https://media.licdn.com/dms/image/C560BAQFoMDej0VdZVA/company-logo_100_100/0/1630565402130/lyft_logo?e=2147483647&v=beta&t=ZP-NFPxZPUKGL-odxJYvJwUPGQa3FfeKeCwD-pTgP6k,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Lyft, our mission is to improve people’s lives with the world’s best transportation. To do this, we start with our own community by creating an open, inclusive, and diverse organization.<br/><br/>The Marketplace team at Lyft is responsible for accelerating the growth of the business and for delivering our top business/company goals related to marketplace and business performance.<br/><br/>Within Marketplace, the Decisions &amp; Insights team identifies and develops an understanding of our marketplace’s most critical problems &amp; opportunities and creates business &amp; product strategies to address them. We’re looking for a Data Analyst to drive deep dive business &amp; product analyses and communicate key trends in our data to senior leadership.<br/><br/>The ideal candidate has strong analytical problem solving skills, effective communication skills, and proactively takes ownership of their workstreams.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Develop hypotheses and analytical frameworks for understanding market dynamics and provide recommendations to senior leadership.</li><li>Influence business strategy and product roadmaps through insightful analytics and business modeling. Be an analytical thought leader.</li><li>Analyze marketplace product &amp; marketplace trends and provide cross-functional teams with actionable insights on improvements and problem areas.</li><li>Evaluating areas of improvement and business growth opportunities within our business.</li><li>Work in a fast-paced environment and effectively manage time to deliver business impact in a time-efficient manner</li><li>Become an expert in marketplace trends and support weekly reporting for the senior leadership.<br/><br/></li></ul><strong>Experience<br/><br/></strong><ul><li>3+ years experience in management consulting, strategic data science/analytics roles in a technology company, or an equivalent analytical role in a high growth startup</li><li>Experience in leading high visibility projects and influencing others in a cross-functional team environment</li><li>Experience in communicating with and presenting to senior leaders and data storytelling</li><li>Strong ability in building decision making frameworks and data analysis, able to understand business issues, analyze large amounts of data, and draw actionable conclusions</li><li>Entrepreneurial self-starter - you naturally take ownership, look for opportunities, and do whatever it takes to drive results<br/><br/></li></ul><strong>Skills<br/><br/></strong><ul><li>Ability to independently break down large datasets and synthesize inputs from multiple sources</li><li>Ability to think strategically about complex and unstructured business problems, leading to recommendations and action plans</li><li>Ability to craft a compelling story and concisely present recommendations across teams and levels including both technical and non-technical audiences</li><li>Ability to manage, influence, negotiate, and inspire others in a fast-moving environment</li><li>Ability to use data visualization tools to provide actionable insights and reusable frameworks</li><li>Strong written and verbal communication skills for internal stakeholders, including senior leadership</li><li>Strong product and user experience sense</li><li>Excellent organization, planning skills, and attention to detail</li><li>Advanced analytical and problem solving skills</li><li>Proficiency in SQL<br/><br/></li></ul><strong>Benefits:<br/><br/></strong><ul><li>Great medical, dental, and vision insurance options</li><li>Mental health benefits</li><li>Family building benefits</li><li>In addition to 12 observed holidays, salaried team members have unlimited paid time off, hourly team members have 15 days paid time off</li><li>401(k) plan to help save for your future</li><li>18 weeks of paid parental leave. Biological, adoptive, and foster parents are all eligible</li><li>Pre-tax commuter benefits</li><li>Lyft Pink - Lyft team members get an exclusive opportunity to test new benefits of our Ridership Program<br/><br/></li></ul><em>Lyft is an equal opportunity/affirmative action employer committed to an inclusive and diverse workplace. All qualified applicants will receive consideration for employment without regards to race, color, religion, sex, sexual orientation, gender identity, national origin, disability status, protected veteran status or any other basis prohibited by law. We also consider qualified applicants with criminal histories consistent with applicable federal, state and local law. <br/><br/></em><em>This role will be in-office on a hybrid schedule — Team Members will be expected to work in the office 3 days per week on Mondays, Thursdays and a team-specific third day. Additionally, hybrid roles have the flexibility to work from anywhere for up to 4 weeks per year.<br/><br/></em><em>The expected base pay range for this position in the US is $106,875 - $118,750. Salary ranges are dependent on a variety of factors, including qualifications, experience and geographic location. Range is not inclusive of potential equity offering, bonus or benefits. Your recruiter can share more information about the salary range specific to your working location and other factors during the hiring process.</em>
</div>",$106875- $118750,Data Modeler
"Data Engineer, Product Analytics",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3725767514,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Clinical Data Analyst,SciPro,12/20/2023,https://www.linkedin.com/jobs/view/3785034345,0,https://media.licdn.com/dms/image/C4E0BAQHTyumhHUvpEw/company-logo_100_100/0/1671113810355/scipro_logo?e=2147483647&v=beta&t=iQdthCnZPhpuJ-B_V2cyvaVeoT8rstM9HqVsar8RssA,"Redwood City, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><u>Clinical Data Analyst, Clinical Data Science</u></strong></p><p><strong>12mth contract <em>(likely extension / conversion opportunity after 12mths)</em></strong></p><p><strong>Hybrid - </strong>Redwood City, CA (1day a week onsite)</p><p><strong> </strong></p><p>Supporting clinical-stage oncology focused company.</p><p><strong> </strong></p><p><strong>This position:</strong></p><ul><li>Collaborate with data managers, statistical programmers, biostatistics, clinical operations, and external vendors to review, sign off on the data transfer specifications, and transfer data from external sources, ensuring data is received and validated for data integrity.</li><li>Collaborate in the development of programming specifications and the creation of program-specific validation plans using established validation practices and processes.</li><li>Provide robust technical SAS programming expertise to support data management, including the development, validation, implementation, and maintenance of data review listings, metrics, dashboards, and reconciliation reports for all studies.</li><li>Work experience in using CRF-Annotation, FDA regulations such as CDISC, 21 CFR Part 11, ICH, GCP guidelines, and other regulatory submissions to the NDA.</li><li>Participate in the development and implementation of SAS programming standards, SOPs, and work instructions, including program validation and documentation.</li><li>Work with data managers and generate outputs to support data cleaning, enhance data integrity, and ensure timely, targeted, and accurate deliverables.</li><li>Ensure quality and timely delivery of clinical trial data in preparation for data review and statistical review.</li><li>Address data issues identified by cross-functional team members.</li><li>Ensure accuracy of clinical trial results for internal and external audiences (e.g., regulatory authorities).</li><li>Contribute to the development of SAS macro programs and participate in modifying existing SAS macro programs to improve efficiency throughout the project life cycle.</li></ul><p><br/></p><p><strong>Experience, skills, and education:</strong></p><ul><li>MS, BS/BA degree or other suitable qualification with relevance to the field.</li><li>Real-time 6+ years of work experience in Phases I, II, and III oncology clinical trial studies.</li><li>Custom reporting using Business Objects, SAS, Python, Crystal Reports, and understanding of Medidata Rave Study Build is required.</li><li>Possessing SAS certification, work experience in Spotfire or Tableau or Power BI and windows batch script is preferred.</li></ul>
</div>",No Salary Info Found,Data Modeler
Data Engineer,Patreon,12/20/2023,https://www.linkedin.com/jobs/view/3777355795,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Digital Data Analyst (Entry Level),Kompi Agency Freedom,12/25/2023,https://www.linkedin.com/jobs/view/3787826106,0,https://media.licdn.com/dms/image/D4D0BAQFaYFpSH0qtVA/company-logo_100_100/0/1703409741963?e=2147483647&v=beta&t=Dy8P8UX4mFNscid_kKpvjmUAAbkmsIHGD9hGZqkdA9Q,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are seeking a motivated and analytic individual to join our team as a Remote Digital Data Analyst. As a Data Analyst, you will be responsible for interpreting and analysing large data sets, making data-driven decisions, and presenting findings to management.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Collect and analyse large data sets from various sources</li><li> Interpret data and identify trends and patterns</li><li> Create reports and visualisations to communicate findings</li><li> Collaborate with cross-functional teams to provide data-driven insights</li><li> Continuously monitor data for accuracy and completeness</li><li> Identify areas for improvement and make recommendations<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li> Proficient in SQL, Excel, and data visualisation tools such as Tableau or Power BI</li><li> Strong analytic skills with the ability to interpret complex data</li><li> Excellent communication and presentation skills</li><li> Ability to work independently and as part of a team</li><li> Attention to detail and accuracy<br/><br/></li></ul>If you are a self-starter who is passionate about data and enjoys problem-solving, we encourage you to apply. This is an entry-level position with room for growth within the company.<br/><br/>To apply, please submit your resume and cover letter highlighting your qualifications and why you would be a great fit for this position. We look forward to hearing from you!
      </div>",No Salary Info Found,Data Modeler
Quantitative Developer - MBS,WhiteCap Search,12/21/2023,https://www.linkedin.com/jobs/view/3741108790,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Analyst,Curinos,12/19/2023,https://www.linkedin.com/jobs/view/3784412206,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Senior Database Developer/ Data Modeler,AgileEngine,12/19/2023,https://www.linkedin.com/jobs/view/3789818199,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
BI Data Modeler,CareerAddict,12/19/2023,https://www.linkedin.com/jobs/view/3788415487,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Quantitative Researcher,Goliath Partners,12/19/2023,https://www.linkedin.com/jobs/view/3787104068,0,https://media.licdn.com/dms/image/C4E0BAQEGxoU_V_HCSw/company-logo_100_100/0/1675096738538/goliath_partners_inc_logo?e=2147483647&v=beta&t=ZvH84troMh_Ji_IEhTAey2-_8K0suGZfx3yYqrxTfls,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Goliath Partners has two requirements at an Algo Trading firm for Quantitative Researchers, with experience working on Systematic Trading with C++/Python. The firm is looking for people that have the ability to accelerate their growth across a number of asset classes and be a part of a high performing team.</p><p> </p><p><strong>Role:</strong></p><p>Rigorous &amp; innovative research to discover systematic anomalies in equity market </p><p>Complete automated electronic trading strategy reconciliation and performance monitoring</p><p>Develop pricing models and assess risk</p><p> </p><p><strong>Essential skills:</strong></p><p>BS in Comp Sci/ Mathematics/ Physics or similarly related field.</p><p>Experience with working closely to trading teams on assisting in the implementation of trading strategies.</p><p>Developing short term alpha signals (intraday or a few days)</p><p>3+ YOE in trading environment </p><p>Proficiency in C++/Python/R</p><p> </p><p>Beneficial skills:</p><p>MSCS/ PhD in CS or a similarly related field.</p><p>Mathematical achievements / competitions.</p><p>Constant hunger to stay at the forefront of technology.</p><p> </p><p>Compensation for this is significant depending on experience and they are globally recognized as a leader in their scale as well as pay. It can be considered an incredibly fair market rate amongst the leading players in industry.</p><p> </p><p>If interested and you believe you would be a good fit, please apply &amp; we'll be in touch.</p>
</div>",No Salary Info Found,Data Modeler
"Staff Data Engineer, Data Products (Contract)",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3759870591,0,https://media.licdn.com/dms/image/C560BAQH0xjWQVXJr6w/company-logo_100_100/0/1630660955481/sofi_logo?e=2147483647&v=beta&t=FVZG0dNVAhdZ-W3Op_NDxjxwWCaIzunudLIIydaqJQI,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Employee Applicant Privacy Notice<br/><br/></strong><strong>Who we are:<br/><br/></strong>Shape a brighter financial future with us.<br/><br/>Together with our members, we’re changing the way people think about and interact with personal finance.<br/><br/>We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. <strong>Join us to invest in yourself, your career, and the financial world.<br/><br/></strong><strong>Team: <br/><br/></strong>SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.<br/><br/><strong>Role:<br/><br/></strong>A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.<br/><br/><strong>What you’ll do:<br/><br/><br/></strong><ul><li>Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.</li><li>Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,</li><li>Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.<br/><br/><br/></li></ul><strong>What you’ll need:<br/><br/><br/></strong><ul><li>A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;</li><li>Over 8 years of experience in data engineering and analytics technical strategy. </li><li>Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..</li><li>Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP</li><li>Strong in Python and/or another data centric language. </li><li>Thorough knowledge of data modeling, database design, data architecture principles, and data operations.</li><li>Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.</li><li>Experience in the Fintech industry is advantageous.<br/><br/><br/></li></ul><em><strong>Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.<br/><br/></strong></em><strong>Compensation And Benefits<br/><br/></strong>The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.<br/><br/>To view all of our comprehensive and competitive benefits, visit our <strong>Benefits at SoFi </strong>page!<br/><br/>SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.<br/><br/>The Company hires the best qualified candidate for the job, without regard to protected characteristics.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.<br/><br/>New York applicants: Notice of Employee Rights<br/><br/>SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.<br/><br/>Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.<br/><br/><strong>Internal Employees<br/><br/></strong>If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.
      </div>",No Salary Info Found,Data Modeler
Snowflake Data Engineer,Capgemini,12/20/2023,https://www.linkedin.com/jobs/view/3785037830,0,https://media.licdn.com/dms/image/D4D0BAQH7wERIbu2fvQ/company-logo_100_100/0/1702673452642/capgemini_logo?e=2147483647&v=beta&t=NBnhHRGoBlo-42X39edX25CaIyU2ED_clduyxHli004,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Title: Snowflake Data Engineer</strong></p><p><strong>Location: New York, NY</strong></p><p><br/></p><p><strong>Required Skills</strong></p><ul><li>2 years of experience in Snowflake.</li><li>5 years of experience in software development process or maintenance projects.</li><li>At least 4 years of experience in Design and architecture review.</li><li>Hands on in complex SQL python and data modeling.</li><li>Hands on experience creating Snowflake procedures UDFs.</li><li>Relevant experience with Splunk, Azure, Event Grid, Sailpoint and IDM integration.</li><li>Hands on experience in data loading into Snowflake from diverse sources.</li><li>Experience with semi structured data type.</li><li>Experience in building Enterprise DW Data Lake Provision and administer Snowflake corporate cloud infrastructure hosted on public cloud preferably on Azure Provision and manage cloud infrastructure using Terraform Cloud Formation tools.</li><li>Strong communication and Analytical skills.</li><li>Experience working in, and desire to work in, a Global delivery environment.</li><li>Good to have experience in ETL tool.</li></ul><p><br/></p><p><strong>Life at Capgemini</strong></p><p>Capgemini supports all aspects of your well-being throughout the changing stages of your life and career. For eligible employees, we offer:</p><ul><li>Flexible work</li><li>Healthcare including dental, vision, mental health, and well-being programs</li><li>Financial well-being programs such as 401(k) and Employee Share Ownership Plan</li><li>Paid time off and paid holidays</li><li>Paid parental leave</li><li>Family building benefits like adoption assistance, surrogacy, and cryopreservation</li><li>Social well-being benefits like subsidized back-up child/elder care and tutoring</li><li>Mentoring, coaching and learning programs</li><li>Employee Resource Groups</li><li>Disaster Relief</li></ul><p><br/></p><p><strong>About Capgemini</strong></p><p>Capgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. The Group is guided everyday by its purpose of unleashing human energy through technology for an inclusive and sustainable future. It is a responsible and diverse organization of over 360,000 team members in more than 50 countries. With its strong 55-year heritage and deep industry expertise, Capgemini is trusted by its clients to address the entire breadth of their business needs, from strategy and design to operations, fueled by the fast evolving and innovative world of cloud, data, AI, connectivity, software, digital engineering and platforms. The Group reported in 2022 global revenues of €22 billion.</p><p>Get The Future You Want | www.capgemini.com</p><p><br/></p><p><strong>Disclaimer</strong></p><p>Capgemini is an Equal Opportunity Employer encouraging diversity in the workplace. All qualified applicants will receive consideration for employment without regard to race, national origin, gender identity/expression, age, religion, disability, sexual orientation, genetics, veteran status, marital status or any other characteristic protected by law.</p><p>This is a general description of the Duties, Responsibilities and Qualifications required for this position. Physical, mental, sensory or environmental demands may be referenced in an attempt to communicate the manner in which this position traditionally is performed. Whenever necessary to provide individuals with disabilities an equal employment opportunity, Capgemini will consider reasonable accommodations that might involve varying job requirements and/or changing the way this job is performed, provided that such accommodations do not pose an undue hardship.</p><p>Capgemini is committed to providing reasonable accommodations during our recruitment process. If you need assistance or accommodation, please reach out to your recruiting contact.</p><p>Click the following link for more information on your rights as an Applicant http://www.capgemini.com/resources/equal-employment-opportunity-is-the-law</p><p><br/></p><p><strong><span class=""ql-cursor""> </span>Salary Transparency</strong></p><p>Capgemini discloses salary range information in compliance with state and local pay transparency obligations. The disclosed range represents the lowest to highest salary we, in good faith, believe we would pay for this role at the time of this posting, although we may ultimately pay more or less than the disclosed range, and the range may be modified in the future. The disclosed range takes into account the wide range of factors that are considered in making compensation decisions including, but not limited to, geographic location, relevant education, qualifications, certifications, experience, skills, seniority, performance, sales or revenue-based metrics, and business or organizational needs. At Capgemini, it is not typical for an individual to be hired at or near the top of the range for their role. The base salary range for the tagged location is $80420 - $106050 /yearly.</p><p>This role may be eligible for other compensation including variable compensation, bonus, or commission. Full time regular employees are eligible for paid time off, medical/dental/vision insurance, 401(k), and any other benefits to eligible employees. </p><p>Note: No amount of pay is considered to be wages or compensation until such amount is earned, vested, and determinable. The amount and availability of any bonus, commission, or any other form of compensation that are allocable to a particular employee remains in the Company's sole discretion unless and until paid and may be modified at the Company’s sole discretion, consistent with the law.</p>
</div>",$80420- $106050,Data Modeler
Data Modeler,Tempus AI,12/20/2023,https://www.linkedin.com/jobs/view/3790925788,0,https://media.licdn.com/dms/image/C4E0BAQH7yUoflbYhgg/company-logo_100_100/0/1630636194531/tempuslabs_logo?e=2147483647&v=beta&t=Vh85Eh0FY9uysBOrIrK11VGcSwZE4JIR2LA7D_STHko,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Passionate about precision medicine and advancing the healthcare industry?<br/><br/></strong>Recent advancements in underlying technology have finally made it possible for AI to impact clinical care in a meaningful way. Tempus' proprietary platform connects an entire ecosystem of real-world evidence to deliver real-time, actionable insights to physicians, providing critical information about the right treatments for the right patients, at the right time.<br/><br/>We now have more healthcare data than ever before, but providers often do not have the systems or expertise to make sense of all of this valuable data. At Tempus, we are building the infrastructure to modernize and enhance cancer treatment. We are on a mission to connect an entire ecosystem to redefine how data is used to improve patient outcomes. The Clinical Informatics team is seeking a highly-motivated clinical informatics analyst who enjoys working with complex datasets and developing models to improve how data from our pipelines is structured and normalized.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Collaborate with cross-functional teams including medical oncologists, research scientists, and engineers to develop and maintain clinical data models.</li><li>Create and execute validation plans in conjunction with SMEs for new models and disease types.</li><li>Translate customer needs and product requests into key concept definitions and business logic for complex models.</li><li>Facilitate integration of data model into workflows, applications, and data deliveries.</li><li>Structure and normalize data from a variety of sources, including Tempus curated data, EHR integrations, and lab systems.</li><li>Develop and maintain knowledge bases for clinical concepts.</li><li>Proactively monitor and support quality assurance and process improvement initiatives.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Advanced degree in medical informatics or related discipline or equivalent professional experience.</li><li>5+ years of oncology informatics experience.</li><li>Experience working with standard medical terminologies (e.g., SNOMED CT, RxNorm, LOINC, ICD-9/10).</li><li>Experience working with real world data from various sources (e.g., curation workflows, EHRs, lab systems, claims, research datasets).<br/><br/></li></ul><strong>Nice-to-haves<br/><br/></strong><ul><li>Clinical background (MD/DO, PharmD, PA, NP, RN, etc.) preferred.</li><li>Familiarity with next-generation sequencing data. </li><li>Experience manipulating or analyzing data in Python or R.</li><li>Familiarity with semantic web technologies (RDF, OWL, SPARQL) and vocabulary management software (e.g., TopQuadrant, Protege).</li><li>Participation in informatics organizations (e.g., OHDSI, AMIA).<br/><br/></li></ul>The expected salary range below is applicable if the role is performed from [<em>New York</em>] and may vary for other locations. Actual salary may vary based on qualifications and experience. Tempus offers a full range of benefits, which may include incentive compensation, restricted stock units, medical and other benefits, depending on the position.<br/><br/>New York Pay Range<br/><br/>$100,000—$140,000 USD<br/><br/>We are an equal opportunity employer. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.<br/><br/>
</div>",$100000- $140000,Data Modeler
Python Data Engineer,Synechron,12/20/2023,https://www.linkedin.com/jobs/view/3788676786,0,https://media.licdn.com/dms/image/C4D0BAQF-kdmTYpOKFg/company-logo_100_100/0/1663673608492/synechron_logo?e=2147483647&v=beta&t=srG-HyAPgRmdiRELy-32e05tZFPYByEm48tZ92tcIg4,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><u>Role:</u></strong> Python Data Engineer</p><p><strong><u>Work Location</u>: </strong>New York, New York, United States</p><p><strong><u>Contact</u>:</strong> Sachin.s@synechron.com</p><p><br/></p><p><strong><u>Our Challenge:</u></strong></p><p>We are looking for strong Python Developer with strong background in data engineering and integration experience.</p><p><br/></p><p><strong><u>The Role</u></strong></p><p><strong><u>Responsibilities:</u></strong></p><ul><li>Integration Engineer responsible for daily support and project-based development of credit risk management systems.</li><li>ETL developers are responsible for designing and creating the data warehouse and all related extraction, transformation and load of data functions.</li><li>This is an opportunity to gain experience in risk management processing using new technologies.</li></ul><p><br/></p><p><strong><u>Requirements:</u></strong></p><p><strong><u>You are:</u></strong></p><ul><li>5+ years of full-time development experience using Python.</li><li>Experience building data pipelines using Azure Data Factory and Databricks.</li><li>Experience with Python application frameworks (Django, Flask, Pyramid, Tornado).</li><li>Experience with Python testing and code analysis tools (Pytest, Pylint).</li><li>Strong SQL skills.</li><li>Familiarity with SSIS.</li><li>Strong troubleshooting skills.</li><li>On-point communication skills.</li></ul><p><br/></p><p><strong><u>Education:</u></strong></p><ul><li>Bachelor’s degree in computer science or finance.</li></ul><p><br/></p><p><strong><u>We can offer you:</u></strong></p><ul><li>A highly competitive compensation and benefits package</li><li>A multinational organization with 45 offices in 19 countries and the possibility to work abroad.</li><li>Laptop and a mobile phone</li><li>10 days of paid annual leave (plus sick leave and national holidays)</li><li>Maternity &amp; Paternity leave plans</li><li>A comprehensive insurance plan including medical, dental, vision, life insurance, and long-/short-term disability (plans vary by region)</li><li>Retirement savings plans</li><li>A higher education certification policy</li><li>Commuter benefits (varies by region)</li><li>Extensive training opportunities, focused on skills, substantive knowledge, and personal development.</li><li>On-demand Udemy for Business for all Synechron employees with free access to more than 5000 curated courses</li><li>Coaching opportunities with experienced colleagues from our Financial Innovation Labs (FinLabs) and Center of Excellences (CoE) groups</li><li>Cutting edge projects at the world’s leading tier-one banks, financial institutions and insurance firms.</li><li>A flat and approachable organization</li><li>A truly diverse, fun-loving and global work culture</li></ul><p><br/></p><p><strong><u>SYNECHRON’S DIVERSITY &amp; INCLUSION STATEMENT</u></strong></p><p>Diversity &amp; Inclusion are fundamental to our culture, and Synechron is proud to be an equal opportunity workplace and is an affirmative action employer. Our Diversity, Equity, and Inclusion (DEI) initiative ‘Same Difference’ is committed to fostering an inclusive culture – promoting equality, diversity and an environment that is respectful to all. We strongly believe that a diverse workforce helps build stronger, successful businesses as a global company. We encourage applicants from across diverse backgrounds, race, ethnicities, religion, age, marital status, gender, sexual orientations, or disabilities to apply. We empower our global workforce by offering flexible workplace arrangements, mentoring, internal mobility, learning and development programs, and more. All employment decisions at Synechron are based on business needs, job requirements and individual qualifications, without regard to the applicant’s gender, gender identity, sexual orientation, race, ethnicity, disabled or veteran status, or any other characteristic protected by law.</p>
</div>",No Salary Info Found,Data Modeler
Junior Data Analyst - US Residents Only,Team Remotely Incorporation,12/25/2023,https://www.linkedin.com/jobs/view/3793150443,0,https://media.licdn.com/dms/image/D4D0BAQFKPwUb2y1chw/company-logo_100_100/0/1702987730303?e=2147483647&v=beta&t=-X5LVvheBqm_7DpHnmichw7-gf09NLhB7Tq6GJJcKm8,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong> Junior Data Analyst - US Residents Only, 1 year experience, remote)<br/><br/></strong>Team Remotely Inc. is a staffing and recruitment agency that offers a comprehensive solution for talent acquisition, including sourcing, vetting, pay rolling, and managing talent. Whether you need contract staffing, direct hire, direct sourcing, talent pools, or diversity initiatives, our model can support your hiring strategy.<br/><br/><strong> Hiring Type:</strong> Full-Time<br/><br/><strong> Base Salary:</strong> $60K-$70K Per Annum.<br/><br/><strong> How to Apply:</strong> Please visit teamremotely.com to learn more &amp; apply.<br/><br/><strong>Role Responsibilities:<br/><br/></strong>Work in close collaboration with the Business Intelligence Lead, Federal Data Lead, and other Program teams<br/><br/>Develop, maintain, and improve BI tools, build and enhance standard operating procedures (SOPs)<br/><br/>Manage various data sets and active Google workbooks with adjacent contract teams, monitor and analyze financial health information at the project and program levels<br/><br/>Communicate with client leadership to assess data needs and emerging requirements<br/><br/>Work with large data sets, workbooks, and spreadsheets to manipulate and manage program-level information using macros, queries, scripts, etc.<br/><br/>Gather requirements and lead the development of long-term data management tools, processes, and solutions based on organizational needs.<br/><br/>Be comfortable working with collaboration tools such as; Google Suite, Microsoft Office<br/><br/>Providing general support to the client including, but not limited to, analysis, data calls, financial management, risk management, audits, and project management-related tasks.<br/><br/><strong>Qualifications:<br/><br/></strong>Bachelor's Degree in business, business intelligence, data or information management, or similar.<br/><br/>Proficient in Google Scripts<br/><br/>Minimum 1 year of data or information management and/or data analysis experience.<br/><br/>Experience using Microsoft Excel and Google Sheets (macros, imports, query functions).<br/><br/>Experience with developing in Google App Script is a plus.<br/><br/>Experience using SQL Developer is a plus.<br/><br/>Excellent written and verbal communication skills.<br/><br/>Willing to work in an administratively manual environment while working towards automation of processes in the future.<br/><br/><strong> Why work with Team Remotely?<br/><br/></strong>Team Remotely Inc. is a staffing platform offering a seamless experience for employers and candidates. Employers can post job openings and specify their requirements, while candidates can create profiles and upload resumes.<br/><br/>The team of Team Remotely continuously learns and adapts based on previous successful placements, constantly improving its matching capabilities. This ensures that the recommendations provided by Team Remotely are tailored and accurate, increasing the likelihood of a successful match between employers and candidates. By providing intelligent and data-driven solutions, they strive to enhance the efficiency and effectiveness of the hiring process, ultimately helping companies find the best talent and individuals find their dream jobs.<br/><br/>
</div>",$60- $70,Data Modeler
Insurance - Data Analyst - REMOTE,Wahve LLC,12/20/2023,https://www.linkedin.com/jobs/view/3790962880,0,https://media.licdn.com/dms/image/D560BAQHLpAj4KcNwxw/company-logo_100_100/0/1689949451872/wahve_logo?e=2147483647&v=beta&t=ijNXVviKcnM87hQBvAX-WppSZZwnFb7A4YL9Fiqr6Zk,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><em>Put your Insurance Experience to work - FROM HOME!<br/><br/></em></strong>At <strong>Wahve</strong>, we value significant insurance experience and want to revolutionize the way people think about <strong><em>phasing into</em> <em>retirement</em></strong> by offering qualified candidates the opportunity to continue their career working from home. As we say - <strong><em>retire from the office but not from work</em></strong>. Our unique platform provides you with <em>real</em> work/life balance and allows you to customize your own work schedule while continuing to utilize your insurance expertise in <strong><em>a remote, long-term position</em></strong>.<br/><br/><strong>What You’ll Love About Wahve<br/><br/></strong>We created a welcoming place to work with friendly and professional leadership. We are known for the great care we take with our staff and our clients. We are passionate and determined about delivering the best customer service, preserving insurance industry knowledge, and making a difference by the work that we do.<br/><br/><strong>What We Are Seeking<br/><br/></strong>We have assignments available to help our <em>insurance industry</em> clients in <strong>Data Analyst positions. Responsibilities include:<br/><br/></strong><ul><li>Build and maintain data warehouse, new reports, and ad hoc reports. </li><li>Work with user groups to identify reporting issues/enhancements and document business requirements. </li><li>Will serve as a member of a project team and/or work independently on projects. </li><li>Support and train internal users as needed. </li><li>Compile and prepare data for customer analysis. </li><li>Experience in C#, Visual Studio, JavaScript, CSS, and current web technologies such as .NET, ASP, JSON, and XML. </li><li>Experience with ANY of the following technologies: SQL Server Reporting Services (SSRS), SSIS Reporting, Power BI, Dynamics CRM, Dynamics GP, Share point, Excel, Power Query, Power Pivot. </li><li>Ability to compile data results and author commentary on industry studies is a plus. </li><li>Insurance or financial services industry experience required. <br/><br/></li></ul><strong>TO BECOME A WORK-AT-HOME VINTAGE EXPERT, WE REQUIRE<br/><br/></strong><ul><li>25 years of full-time work experience</li><li>Experience working in a data analysis role in the insurance or financial services industry - required<br/><br/></li></ul><strong>Benefits Of Becoming a Wahve Vintage Expert<br/><br/></strong><ul><li>Retire from the office but not from work. </li><li>Eliminate the office stress and the commute. </li><li>Choose the work you would like to do now. </li><li>Customize your schedule - full or part time. </li><li>Continue to earn an income. </li><li>Utilize your years of insurance industry knowledge. </li><li>Be part of our dynamic yet virtual team environment and connect with other experienced insurance professionals like yourself!<br/><br/></li></ul><strong>How To Get Started<br/><br/></strong>Click <strong><em>APPLY NOW</em></strong> to complete our simple preliminary profile. Be sure to include your preferred contact information as one of our Qualification Specialists will connect with you promptly.<br/><br/><strong>WE LOOK FORWARD TO MEETING YOU!</strong>
</div>",No Salary Info Found,Data Modeler
Systems Engineer I/II,Fred Hutch,12/19/2023,https://www.linkedin.com/jobs/view/3764616774,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Senior Data Cloud Data Modeler,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3725133925,0,https://media.licdn.com/dms/image/C560BAQHZ9xYomLW7zg/company-logo_100_100/0/1630658255326/salesforce_logo?e=2147483647&v=beta&t=GvAdJRB6d3hWoiMBjIAOP9tjZzbWxLNF84FnSTgWblE,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.<br/><br/></em>Job Category<br/><br/>Software Engineering<br/><br/>Job Details<br/><br/><strong>About Salesforce<br/><br/></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/>The<strong> Data Cloud Data Modeler</strong> will be joining a world-class data modeling team with a real passion for well-architected analytical software that delivers unparalleled customer success. You will work on canonical Data Cloud data models for “horizontal“ (e.g. sales, service, marketing) and industry-specific analytic applications, helping to shape the structure of data across a much broader range of subject areas than most data modelers see in their careers. Salesforce is leading the way to bring AI, data, automation and deep industry-specific functionality to our customers. Join our high performance culture of trust, collaboration, transparency, continuous improvement and making work fun!<br/><br/><strong>Responsibilities<br/><br/></strong>Success will be measured by the individual’s ability to deliver well-architected Data Cloud data models at a steady pace of innovation.<br/><br/><ul><li>Hands-on detailed design, development, testing and publishing of canonical data models for OLAP and AI applications built with Data Cloud, as well as OLTP applications.</li><li>Evaluate and advise product teams to determine data model requirements. Identify overlapping data model requirements across multiple product teams and influence the combined canonical data model design to consensus and consistency.</li><li>Assist in identifying and articulating gaps in current Data Cloud features necessary to properly support the many use cases for Data Cloud. Collaborate with Data Cloud architects, product owners and developers to design features that close those gaps.</li><li>Work to improve the data modeling design skills of the product teams we work with.</li><li>Assist in creating Data Cloud data model documentation and collateral to enable the Salesforce ecosystem to understand and properly adopt the Salesforce data model.</li><li>Seek continuous improvement in Salesforce’s processes, methods and tooling to improve our efficiency and effectiveness.<br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><ul><li>10+ years of demonstrated, hands-on analytical data modeling and design experience across multiple industries for analytical systems</li><li>Good knowledge of data modeling principles and best practices including a good understanding of canonical and semantic data modeling concepts</li><li>Significant experience in data warehousing, data lakes, ML pipelines, batch and real-time data transformation (ETL/ELT) and processing</li><li>Significant experience with several of relational, columnar, graph, vector, NoSQL, streaming databases</li><li>Ability to quickly grasp technological and business concepts</li><li>Strong verbal and written communication skills; experience communicating with engineers, software professionals and product management to succinctly explain technical and functional concepts</li><li>Experience with the full software lifecycle delivering enterprise software products or large-company analytical information technology projects</li><li>Experience and desire to work within a fast-paced environment with short release cycles and an iterative development methodology</li><li>Able to work on multiple projects/products simultaneously and comfortable working with minimal specifications</li><li>A related technical degree required<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Experience with modern data stack and analytical technologies such as Apache Iceberg, Snowflake, MongoDB, Neo4j, Neptune, and similar</li><li>Experience across a variety of business processes and industries; especially communications, media, energy, utilities, financial services, health, manufacturing, consumer packaged goods, retail, non-profit, education, public sector and sustainability</li><li>Strong, hands-on knowledge of SQL (or Salesforce SOQL) including performance tuning</li><li>Strong knowledge of Salesforce product and platform features, capabilities, and the best use of them such as Data Cloud and Tableau.</li><li>Good understanding of enterprise architecture principles</li><li>Experience with Agile development methodologies</li><li>Experience with data modeling tools, processes, BI tools, reporting software and data analysis and data analytics<br/><br/></li></ul>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.<br/><br/>﻿Salesforce welcomes all.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance and the Los Angeles Fair Chance Initiative for Hiring, Salesforce will consider for employment qualified applicants with arrest and conviction records.<br/><br/>For Washington-based roles, the base salary hiring range for this position is $146,600 to $201,700.<br/><br/>For California-based roles, the base salary hiring range for this position is $160,000 to $220,000.<br/><br/>Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.
      </div>",$146600- $201700,Data Modeler
Database Reliability Engineer II - Remote,Get It Recruit - Information Technology,12/19/2023,https://www.linkedin.com/jobs/view/3784094879,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
IBM infosphere Datastage developer,Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3766605990,0,https://media.licdn.com/dms/image/C4D0BAQFPP1NRP4F5dQ/company-logo_100_100/0/1656657978597/tata_consultancy_services_logo?e=2147483647&v=beta&t=Ao4Ihtw2eg1ymYGPB7E4AEHoNQ83oX6bP1DrQIiqR1s,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<ul><li>Strong knowledge and expertise in large data platform solution architecture and transformation.</li><li>Hands-on experience with to design, develop and deploy ETL solutions across Tera data, Oracle databases.</li><li>Design the data replication strategy and deployment across the environment.</li><li>Solid understanding of native Cloud architecture (On-Prem to Cloud) networking, migrating On-premises database to Cloud database like Google Cloud.</li><li>Strong in Oracle, Teradata and SQL Server databases and solutions.</li><li>Expert level skill in tools like ER/WIN, DataStage Suite, SQL Navigator, Toad/All Fusion, fabFORCE DB Designer, ER/Studio.</li><li>Data Validation Experience: aggregations, data types, casting errors, rounding errors, etc.</li><li>Solving data types problems with different databases and mange master data through master data management tools.</li><li>Expert in with Linux/Unix commands (file manipulation, file inspection, and ssh) and ability to understand and modify shell scripts sh(bash, zsh, etc.) for loading data</li><li>Comfortable with git commands (Gitlab)</li><li>Excellent oral and written communication skills</li></ul>
</div>",No Salary Info Found,Data Modeler
Principal Data Cloud Data Modeler,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3725135547,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083989,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $140,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$140000- $173000,Data Modeler
Data Engineer- REMOTE (W2 & Benefits provided) - 4239,Braintrust,12/20/2023,https://www.linkedin.com/jobs/view/3790533491,0,https://media.licdn.com/dms/image/C560BAQHbQYFSQsK__A/company-logo_100_100/0/1630511738029/usebraintrust_logo?e=2147483647&v=beta&t=KwbYjG0MdxQVYAijRBYsSuBn-w2onHZNpCmM31LViso,Greater Seattle Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality.<br/><br/><strong>About The Hiring Process<br/><br/></strong>The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match.<br/><br/>Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies.<br/><br/><strong>JOB TYPE:</strong> Freelance, Contract Position (no agencies/C2C - see notes below)<br/><br/><strong>LOCATION:</strong> Work from anywhere - Anytime | No timezone overlap required<br/><br/><strong>HOURLY RANGE</strong> Our client is looking to pay $60.00 – $72.00/hr<br/><br/><strong>ESTIMATED DURATION:</strong> 40/week - long term<br/><br/><strong>EXPERIENCE:</strong> 5-9 years<br/><br/><strong>BRAINTRUST JOB ID:</strong> 11534<br/><br/>The Opportunity<br/><br/><strong>Job Duties<br/><br/></strong><ul><li>Develop ETL processes to move third-party data into Airbnb’s data warehouse, including housing and rental supply, census and demographics, legislation that may/does impact Airbnb, and social listening. Implement a refresh cadence for each source based on value and how often it’s updated. </li><li>Design, implement, and maintain data pipelines to connect Airbnb internal and external data. This foundational data set drives ML models that predict where legislative challenges/opportunities are likely to arise and the Airbnb users most likely to engage politically. </li><li>Partner with E&amp;I and DS to build data visualizations that enable service reporting on Airbnb’s legislative and regulatory landscape, incorporating available internal data and new external data sources as ETL processes are implemented. </li><li>Support the launch and optimization of Iterable (Email marketing automation platform) that Public Policy is using to engage legislators, journalists, partners, and Hosts by moving audience data into Iterable for automated communications and extracting engagement events and marketing campaign metadata to support data visualization. </li><li>Implement the integration of regulatory product and compliance data from Airbnb’s data warehouse -&gt; the Policy Cloud (Salesforce CRM) where the Public Policy team manages legislative and regulatory efforts. </li><li>Maintain and expand upon data pipelines that move structured internal Airbnb data into the Policy Cloud including host, listing, regulatory, compliance, and business value. <br/><br/></li></ul>What You'll Be Working On<br/><br/><strong>Requirements/Desired Experience &amp; Skills<br/><br/></strong><ul><li>Expertise in data and analytics engineering/data architecture. </li><li>Expertise in Python and SQL. Expertise in R is a plus. </li><li>Experience leveraging disparate data sets, in particular legislative/regulatory/economic/geospatial. </li><li>Expertise in transforming data to be leveraged for self-service data visualization resources. </li><li>Experience building and implementing ML models is a plus</li><li>Talent for breaking down complex technical concepts into common language and acting as a bridge between technical and departmental stakeholders. </li><li>Experience working with complex and big data systems across a multitude of relationships and metrics. Ability to apply a creative and nuanced perspective to look beyond common data indicators in order to meet business goals. </li><li>Ability to self-serve and take the initiative to find answers to technical questions. <br/><br/></li></ul>Education<br/><br/>Bachelor degree in Computer Science or Computer Engineering<br/><br/><strong>Apply Now!<br/><br/></strong><strong>Notes<br/><br/></strong>Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.<br/><br/>Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
      </div>",$60.00- $72.00,Data Modeler
Geospatial Systems Engineer,Langan Engineering & Environmental Services,12/20/2023,https://www.linkedin.com/jobs/view/3731539312,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
SQL Developer - US Residents Only,Team Remotely Incorporation,12/25/2023,https://www.linkedin.com/jobs/view/3793403189,0,https://media.licdn.com/dms/image/D4D0BAQFKPwUb2y1chw/company-logo_100_100/0/1702987730303?e=2147483647&v=beta&t=-X5LVvheBqm_7DpHnmichw7-gf09NLhB7Tq6GJJcKm8,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong> SQL Developer - US Residents Only, 1 year experience, remote)<br/><br/></strong>Team Remotely Inc. is a staffing and recruitment agency that offers a comprehensive solution for talent acquisition, including sourcing, vetting, pay rolling, and managing talent. Whether you need contract staffing, direct hire, direct sourcing, talent pools, or diversity initiatives, our model can support your hiring strategy.<br/><br/><strong> Hiring Type:</strong> Full-Time<br/><br/><strong> Base Salary:</strong> $60K-$70K Per Annum.<br/><br/><strong> How to Apply:</strong> Please visit teamremotely.com to learn more &amp; apply.<br/><br/><strong>Description:<br/><br/></strong>As an SQL Developer, you will play a crucial role in designing, implementing, and optimizing database solutions, enabling efficient data storage, retrieval, and manipulation. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet our clients' needs. This is a unique opportunity to work on diverse projects, tackle complex data challenges, and make a significant impact in the world of data.<br/><br/><strong>Responsibilities:<br/><br/></strong>Collaborate with stakeholders to gather data requirements and translate them into efficient SQL queries, stored procedures, and functions.<br/><br/>Design, develop, and maintain database schemas, ensuring data integrity, security, and performance.<br/><br/>Write complex SQL queries for data extraction, transformation, and loading (ETL) processes.<br/><br/>Optimize SQL queries and database performance, identifying and resolving bottlenecks and inefficiencies.<br/><br/>Develop data validation and quality assurance processes to ensure accuracy and reliability.<br/><br/>Collaborate with cross-functional teams to integrate SQL code into applications and reporting systems.<br/><br/>Conduct data analysis to identify trends, patterns, and insights that drive business decisions.<br/><br/>Stay up-to-date with the latest trends and advancements in SQL and database technologies.<br/><br/><strong>Requirements:<br/><br/></strong>Bachelor's degree in Computer Science, Information Technology, or a related field.<br/><br/>Proven experience as an SQL Developer or Database Developer, working with complex databases.<br/><br/>Strong proficiency in SQL and experience with relational databases (e.g., MySQL, Oracle, SQL Server).<br/><br/>Solid understanding of database design principles, data modeling, and normalization.<br/><br/>Proficiency in writing complex SQL queries, stored procedures, and functions.<br/><br/>Experience with performance optimization and tuning of SQL queries and database indexing.<br/><br/>Familiarity with ETL processes and tools (e.g., SSIS, Informatics) is a plus.<br/><br/>Knowledge of data warehousing concepts and dimensional modeling is desirable.<br/><br/>Strong problem-solving skills and the ability to analyze complex data requirements.<br/><br/>Excellent attention to detail and a commitment to delivering high-quality solutions.<br/><br/>Effective communication and collaboration skills to work with cross-functional teams<br/><br/><strong> Why work with Team Remotely?<br/><br/></strong>Team Remotely Inc. is a staffing platform offering a seamless experience for employers and candidates. Employers can post job openings and specify their requirements, while candidates can create profiles and upload resumes.<br/><br/>The team of Team Remotely continuously learns and adapts based on previous successful placements, constantly improving its matching capabilities. This ensures that the recommendations provided by Team Remotely are tailored and accurate, increasing the likelihood of a successful match between employers and candidates. By providing intelligent and data-driven solutions, they strive to enhance the efficiency and effectiveness of the hiring process, ultimately helping companies find the best talent and individuals find their dream jobs.<br/><br/>
</div>",$60- $70,Data Modeler
Data Engineer- REMOTE (W2 & Benefits provided) - 4239,Braintrust,12/20/2023,https://www.linkedin.com/jobs/view/3790532702,0,https://media.licdn.com/dms/image/C560BAQHbQYFSQsK__A/company-logo_100_100/0/1630511738029/usebraintrust_logo?e=2147483647&v=beta&t=KwbYjG0MdxQVYAijRBYsSuBn-w2onHZNpCmM31LViso,Greater Boston,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>Braintrust is a user-owned talent network that connects top-tier professionals with the world's leading enterprises. We prioritize transparency, eliminating middlemen and high markups, ensuring job-seekers are matched swiftly to innovative roles while clients benefit from unparalleled efficiency and quality.<br/><br/><strong>About The Hiring Process<br/><br/></strong>The hiring process for this role involves completing your Braintrust profile, applying directly to the role on Braintrust, and undergoing a one-time screening to ensure you meet our vetted talent specifications. After this, the hiring team will contact you directly if they believe you are a suitable match.<br/><br/>Our process isn't for everyone, that's intentional. If you believe that you are a top candidate for this job, please join our network to give yourself the opportunity to work with top companies.<br/><br/><strong>JOB TYPE:</strong> Freelance, Contract Position (no agencies/C2C - see notes below)<br/><br/><strong>LOCATION:</strong> Work from anywhere - Anytime | No timezone overlap required<br/><br/><strong>HOURLY RANGE</strong> Our client is looking to pay $60.00 – $72.00/hr<br/><br/><strong>ESTIMATED DURATION:</strong> 40/week - long term<br/><br/><strong>EXPERIENCE:</strong> 5-9 years<br/><br/><strong>BRAINTRUST JOB ID:</strong> 11534<br/><br/>The Opportunity<br/><br/><strong>Job Duties<br/><br/></strong><ul><li>Develop ETL processes to move third-party data into Airbnb’s data warehouse, including housing and rental supply, census and demographics, legislation that may/does impact Airbnb, and social listening. Implement a refresh cadence for each source based on value and how often it’s updated. </li><li>Design, implement, and maintain data pipelines to connect Airbnb internal and external data. This foundational data set drives ML models that predict where legislative challenges/opportunities are likely to arise and the Airbnb users most likely to engage politically. </li><li>Partner with E&amp;I and DS to build data visualizations that enable service reporting on Airbnb’s legislative and regulatory landscape, incorporating available internal data and new external data sources as ETL processes are implemented. </li><li>Support the launch and optimization of Iterable (Email marketing automation platform) that Public Policy is using to engage legislators, journalists, partners, and Hosts by moving audience data into Iterable for automated communications and extracting engagement events and marketing campaign metadata to support data visualization. </li><li>Implement the integration of regulatory product and compliance data from Airbnb’s data warehouse -&gt; the Policy Cloud (Salesforce CRM) where the Public Policy team manages legislative and regulatory efforts. </li><li>Maintain and expand upon data pipelines that move structured internal Airbnb data into the Policy Cloud including host, listing, regulatory, compliance, and business value. <br/><br/></li></ul>What You'll Be Working On<br/><br/><strong>Requirements/Desired Experience &amp; Skills<br/><br/></strong><ul><li>Expertise in data and analytics engineering/data architecture. </li><li>Expertise in Python and SQL. Expertise in R is a plus. </li><li>Experience leveraging disparate data sets, in particular legislative/regulatory/economic/geospatial. </li><li>Expertise in transforming data to be leveraged for self-service data visualization resources. </li><li>Experience building and implementing ML models is a plus</li><li>Talent for breaking down complex technical concepts into common language and acting as a bridge between technical and departmental stakeholders. </li><li>Experience working with complex and big data systems across a multitude of relationships and metrics. Ability to apply a creative and nuanced perspective to look beyond common data indicators in order to meet business goals. </li><li>Ability to self-serve and take the initiative to find answers to technical questions. <br/><br/></li></ul>Education<br/><br/>Bachelor degree in Computer Science or Computer Engineering<br/><br/><strong>Apply Now!<br/><br/></strong><strong>Notes<br/><br/></strong>Our employers all have varying legal and geographic requirements for their roles, they trust Braintrust to find them the talent that meet their unique specifications. For that reason, this role is not available to C2C candidates working with an agency. If you are a professional contractor who has created an LLC/corp around their consulting practice, this is well aligned with Braintrust and we’d welcome your application.<br/><br/>Braintrust values the multitude of talents and perspectives that a diverse workforce brings. All qualified applicants will receive consideration for employment without regard to race, national origin, religion, age, color, sex, sexual orientation, gender identity, disability, or protected veteran status.
      </div>",$60.00- $72.00,Data Modeler
Data Analyst/Financial Crimes,ASK Consulting,12/19/2023,https://www.linkedin.com/jobs/view/3788118001,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Engineer,PA Consulting,12/19/2023,https://www.linkedin.com/jobs/view/3752017186,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Intern - 1P Data,"Hydrow, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3790405259,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Center Engineer,Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3732385209,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
SQL / Reports / Informatica engineer - W2 only,Incendia Partners,12/19/2023,https://www.linkedin.com/jobs/view/3784463463,0,https://media.licdn.com/dms/image/C560BAQH9RSncE7GcSw/company-logo_100_100/0/1631377003997?e=2147483647&v=beta&t=J9v5VVLAQDYb7S9PP3zNWsHrZ2DbaAz-P1-3psidELg,"Billerica, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        GC or US citizens only<br/><br/>Decription:<br/><br/>Looking for a SQL Engineer with informatica experience to join our Modernization team.<br/><br/>This SQL / Report engineer will work closely with other team members to design, implement, test, and maintain current and future products.<br/><br/>This software engineer will be responsible for developing and maintaining current products that support numerous initiatives. This role is ideal for versatile engineer to write queries pull data and execute deliverables.<br/><br/>Personality and drive is THE most important factor, We want someone with intensity and curiosity.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li> 5+ years' experience in a professional environment focused on SQL programming and data analysis work</li><li> 3+ years' Informatica (ETL tool) working experience</li><li> Familiarity within a Full stack environment (javascript, c# flexible)</li><li> Ability to reconcile multiple data sets</li><li> Design and maintain a wide array of reports, both scheduled and ad hoc, from multiple SQL data sources and using multiple systems like Microsoft SSRS, Microsoft Power BI, and Microsoft CRM</li><li> Proven ability to create, publish, and deploy reports, report optimization, and report maintenance, manage content packs, with security and integrity in Power BI or similar reporting tools.</li><li> Designing databases and ensuring stability</li><li> Create complex functions, scripts, stored procedures, and triggers to support application development.<br/><br/><br/></li></ul>#ZR<br/><br/>
</div>",No Salary Info Found,Data Modeler
Data Modeler,Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3768260858,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Analyst,LinxAI,12/19/2023,https://www.linkedin.com/jobs/view/3790031884,0,https://media.licdn.com/dms/image/D4E0BAQEvqV75wGB5Pw/company-logo_100_100/0/1667090470337/linxai_logo?e=2147483647&v=beta&t=bJPfUjLQIikus3VHSg-s4w20qaWWE-VmRHJp-7QoOW4,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title : Data Analyst</strong></p><p><strong>Visa : Any</strong></p><p><strong>Rate : Open Based on Experience</strong></p><p><strong>Location :</strong> <strong>Boston MA</strong></p><p><strong>Looking on W2 only</strong></p><p><br/></p><p><strong><u>Required Qualifications :</u></strong></p><p><br/></p><ul><li>A Bachelor's degree in a quantitative discipline (e.g., Statistics, Computer Science, Math, Engineering) or equivalent consulting experience.</li><li>3+ years of experience with data exploration and visualization like Tableau, Looker, PowerBI, etc. It is a plus if you can share a portfolio of clear, intuitive, and insightful visualizations.</li><li>3+ years of experience in data analytics, including building and deploying enterprise-wide data models with applications to real- world problems.</li><li>Effective written and verbal communication skills to translate technical solutions and methodologies to executive leadership. Demonstrated success working in a collaborative, service- oriented team environment.</li><li>Experience working in a cross-functional setting, managing the full lifecycle of projects.</li><li>Experience working well with ambiguity, prioritizing needs, and delivering results in a dynamic environment.</li><li>Attention to detail with self-discipline and a drive for results. Advanced problem-solving, organizational, analytical, and critical thinking skills.</li><li>Proven experience with tolerance for ambiguity working through incubation to actual product definition.</li><li>Pragmatic attitude and ability to rapidly iterate and evolve ideas into practical implementations.</li><li>Proficient in SQL and/or other data query languages. Experience of handling large scale data with efficiency. Familiar with Python or R is a plus.</li><li>Experience in medical device or healthcare industry is a plus.</li><li>Facilitate the ideation and creation of analytical solutions for various functions.</li><li>Capture requirements and suggest improvements for analytical processes.</li><li>Collaborate extensively across cross-functional teams and the organization.</li><li>Drive the development and deployment of analytical solutions, fostering analytics and insights that yield positive business outcomes.</li><li>Ensure the development of Analytics &amp; Insights aligns with the End-to-End (E2E) business processes and business objectives. Act as a key resource to support and drive analytics initiatives. Ensure a high level of customer value and satisfaction through extreme ownership.</li><li>Promote the adoption and usage of analytics tools and insights. Support training of analytic tools.</li><li>Ensure timely and efficient delivery of solutions.</li><li>Serve as a steward of your analytics by generating insights for business use cases.</li></ul>
</div>",No Salary Info Found,Data Modeler
Data Engineer on W2,ACL Digital,12/20/2023,https://www.linkedin.com/jobs/view/3785070917,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Analyst,Infinite Computer Solutions,12/23/2023,https://www.linkedin.com/jobs/view/3786767872,0,https://media.licdn.com/dms/image/D4E0BAQENJsIHQHM8pQ/company-logo_100_100/0/1687442778909/infinite_computer_solutions_logo?e=2147483647&v=beta&t=cG3oCS8ypjvJdIID3mV0vQEPYa1kzJ1pw3BCJyVLgrI,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        17597BR<br/><br/>Washington<br/><br/><strong>Job Description<br/><br/></strong><strong> Data Analyst (SAS and Tableau) <br/><br/></strong><ul><li> 7 years of extensive experience as Data analyst using SAS and Tableau </li><li> Collaborate with internal and external stakeholders to understand business requirements and provide data-driven solutions. </li><li> Develop and maintain effective dashboards, visualizations, and reports using SAS and Tableau for data analysis, insights, and interpretation. </li><li> Proven track record and portfolio of successful work in SAS Visual Analytics and Healthcare Analytics. </li><li> Work with large and complex data sets, applying statistical techniques to generate insights, make recommendations and support strategic decision-making. </li><li> Conduct data quality analysis and ensure data accuracy, completeness, and consistency. </li><li> Perform ad-hoc analysis to support business initiatives, answer key business questions and drive insights. </li><li> Stay current on industry trends and best practices, and proactively recommend process improvements and data-driven solutions. </li><li> Experience in creating workbooks and dashboards using Tableau that includes tools like Tableau Desktop and Tableau Server </li><li> Experience in ad-hoc data analysis, solution design, reporting &amp; dashboard development. </li><li> Experience with one or more BI tools like Cognos BI, SAS BI. </li><li> Good to have experience in Geospatial Analytics using tools like esri ArcGIS. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong>Graduate<br/><br/>Range of Year Experience-Min Year<br/><br/>7<br/><br/>Range of Year Experience-Max Year<br/><br/>8
      </div>",No Salary Info Found,Data Modeler
Data Analyst,Jobs for Humanity,12/23/2023,https://www.linkedin.com/jobs/view/3791027091,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Guidehouse to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Guidehouse<br/><br/><strong>Job Description<br/><br/></strong><strong>Job Family:<br/><br/></strong>Data Science &amp; Analysis<br/><br/><strong>Travel Required:<br/><br/></strong>None<br/><br/><strong>Clearance Required:<br/><br/></strong>Active Top Secret (TS)<br/><br/><strong>What You Will Do</strong><strong>:<br/><br/></strong>We are seeking a data analyst to join our team. In this role, you will help migrate data from various sources into a structured case management solution. You will also contribute to business process improvement and automation projects to make our operations more efficient. Your responsibilities will include:<br/><br/><ul><li>Handling file manipulation, loading, conversion services, database indexing, and quality checks of data loads</li><li>Developing and modifying methodologies and procedures for manipulating files for use with commercial off-the-shelf (COTS) products and litigation support applications</li><li>Ensuring that incoming case information, records, and productions meet the required specifications, and notifying the Program Lead of any deficiencies</li><li>Performing advanced tasks related to importing and exporting data from different databases and sources<br/><br/></li></ul><strong>What You Will Need:<br/><br/></strong><ul><li>An active and current Top Secret federal security clearance</li><li>A bachelor's degree or relevant years of experience</li><li>Three or more years of relevant experience<br/><br/></li></ul><strong>What Would Be Nice To Have:<br/><br/></strong><ul><li>An active and current Top Secret/SCI federal security clearance</li><li>Two or more years of experience in eDiscovery or other legal document management roles</li><li>Knowledge of government IT environment and experience with various software tools</li><li>PMP or similar certification<br/><br/></li></ul><strong>What We Offer:<br/><br/></strong>Guidehouse values diversity and provides a supportive workplace. We offer a comprehensive total rewards package, including:<br/><br/><ul><li>Medical, dental, vision insurance</li><li>Personal and family sick time, company-paid holidays</li><li>Discretionary variable incentive bonus</li><li>Parental leave and adoption assistance</li><li>401(k) retirement plan</li><li>Life insurance and other supplemental benefits</li><li>Health savings accounts, flexible spending accounts</li><li>Short-term and long-term disability</li><li>Student loan paydown assistance</li><li>Tuition reimbursement and personal development opportunities</li><li>Skills development and certifications</li><li>Employee referral program</li><li>Community outreach and corporate-sponsored events</li><li>Emergency backup childcare program</li><li>Mobility stipend<br/><br/></li></ul><strong>About Guidehouse<br/><br/></strong>Guidehouse is committed to providing equal employment opportunities to all individuals. We welcome applicants from diverse backgrounds and do not discriminate based on race, color, national origin, ancestry, citizenship status, military status, protected veteran status, religion, creed, physical or mental disability, medical condition, marital status, sex, sexual orientation, gender identity or expression, age, genetic information, or any other protected characteristic as established by law.<br/><br/>Guidehouse will consider qualified applicants with criminal histories in accordance with applicable law or ordinance, including the Fair Chance Ordinance of Los Angeles and San Francisco.<br/><br/>If you require an accommodation during the application process, please contact Guidehouse Recruiting at 1-571-633-1711 or via email at RecruitingAccommodation@guidehouse.com. Your information will be kept confidential and used solely for the purpose of providing necessary accommodations.<br/><br/><em>Note: Guidehouse does not accept unsolicited resumes from search firms or staffing agencies. Unsolicited resumes will be considered the property of Guidehouse, and no placement fee will be paid in case of hiring.</em>
</div>",No Salary Info Found,Data Modeler
Hybrid Data Modeler - Mid Level,Peraton,12/19/2023,https://www.linkedin.com/jobs/view/3738647101,0,https://media.licdn.com/dms/image/C4D0BAQFGuMwJFeN1eQ/company-logo_100_100/0/1641481571799/peraton_logo?e=2147483647&v=beta&t=TCzFcSt-h13zRuRWMuVZycca6Z9kjznUiIQTiJpQqx8,"Herndon, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Peraton Overview<br/><br/></strong>Peraton drives missions of consequence spanning the globe and extending to the farthest reaches of the galaxy. As the world's leading mission capability integrator and transformative enterprise IT provider, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our employees do the can't be done, solving the most daunting challenges facing our customers.<br/><br/><strong>Responsibilities<br/><br/></strong>As one of the world's leading mission capability integrator and transformative enterprise IT providers, we deliver trusted and highly differentiated national security solutions and technologies that keep people safe and secure. Peraton serves as a valued partner to essential government agencies across the intelligence, space, cyber, defense, civilian, health, and state and local markets. Every day, our 22,000 employees ""Do The Can't Be Done"", solving the most daunting challenges facing our customers.<br/><br/>Peraton's National Programs Business Intelligence Systems &amp; Applications Operating Unit has a need for an experienced Data Modeler to support its SITE III JIOC contract charged with the orchestration, sustainment, and evolution of a portfolio of applications that focus on Collection Management, Intelligence Surveillance and Reconnaissance (ISR) and intelligence operations that directly support intelligence analysts, operations, and collection managers across the Combatant Commands. The SITE III JIOC contract is designed to establish and ensure a multi-discipline approach to requirements engineering, solutions engineering, scheduling, reliability, resiliency, services development, integration, test and evaluation, maintainability and analysis across the National apparatus of Defense Intelligence, Combatant Commands, supporting Partner Nations and other Federal Agencies to ensure timely and accurate Joint Intelligence Operations (JIOC) collection, correlation and dissemination. Our support team applies best practices in architecture design, data science, cloud services, DevSecOps and platform integration to develop, sustain and continually evolve the enterprise business systems environment, systems integration, and back-end business process workflows.<br/><br/><strong>The successful candidate will perform the following:<br/><br/></strong><ul><li>Ensures the successful implementation and day-to-day operation of database systems supporting critical Agency systems. </li><li>Designs, models, documents, and guides the logical and conceptual relationship of data and database changes for complex applications. </li><li>Analyzes needs and requirements of existing and proposed systems, and develops technical, structural, and organizational specifications. </li><li>May create standards and/or do modeling to monitor and enhance capacity and performance. Communicates with technical, applications, and operational staff, in order to design an optimal database architecture (performance, accessibility, backup, and recovery plan). </li><li>Analyzes and makes recommendations for improvements to existing software regarding database performance, stability, usability and scalability. </li><li>Performs logical and physical data modeling, designs relational database models and creates physical data models from logical data models. </li><li>Designs database servers and interfaces to improve database and application performance. </li><li>Supports the development effort by authoring stored procedures, functions, views and check constraints.</li><li>Up to 50% remote work allowed<br/><br/></li></ul><strong>Qualifications<br/><br/></strong>Requires 8 to 10 years with BS/BA or 6 to 8 years with MS/MA or 3 to 5 years with PhD.<br/><br/><strong>Required Qualifications<br/><br/></strong><ul><li>Requires a Bachelor's degree with 8 years of relevant experience. Additional experience may be considered in lieu of degree.</li><li>Active TS/SCI</li><li>Experience in applying data modeling principles/methods including conceptual, logical &amp; physical data models</li><li>Relational database experience</li><li>2+ years experience with AWS technologies including PostgresSQL and EC2</li><li>ETL experience</li><li>Experience with integrating multiple data feeds into a consolidated data source for access by users via UI and by systems, e.g., via API</li><li>Experience with ER Studio Expertise or other similar modeling tools</li><li>GraphQL experience<br/><br/></li></ul><strong>Desired Qualifications<br/><br/></strong><ul><li>Experience with S3, DynamoDB, DocumentDB, ElasticSearch, Kafka, GeoServer</li><li>DIA experience</li><li>Understanding of the Intelligence Lifecycle and Collection Management mission space</li><li>Familiarity with intelligence discipline data and Collection Management data and processes</li><li>Familiarity with existing IC/Service systems in the Intelligence Lifecycle and Collection Management mission space</li><li>Implementation of data-centricity and data fabric concepts</li><li>Understanding of DoD/IC data standards</li><li>Familiarity with securing/hardening data infrastructure</li><li>Familiarity with IC Audit and Logging </li><li>Current polygraph<br/><br/></li></ul><strong>Target Salary Range<br/><br/></strong>$112,000 - $179,000. This represents the typical salary range for this position based on experience and other factors.<br/><br/><strong>SCA / Union / Intern Rate or Range<br/><br/></strong><strong>EEO<br/><br/></strong>An Equal Opportunity Employer including Disability/Veteran.<br/><br/><strong>Our Values<br/><br/></strong><strong>Benefits<br/><br/></strong>At Peraton, our benefits are designed to help keep you at your best beyond the work you do with us daily. We're fully committed to the growth of our employees. From fully comprehensive medical plans to tuition reimbursement, tuition assistance, and fertility treatment, we are there to support you all the way.<br/><br/><ul><li>Paid Time-Off and Holidays</li><li>Retirement</li><li>Life &amp; Disability Insurance</li><li>Career Development</li><li>Tuition Assistance and Student Loan Financing</li><li>Paid Parental Leave</li><li>Additional Benefits</li><li>Medical, Dental, &amp; Vision Care</li></ul>
</div>",$112000- $179000,Data Modeler
Data Analyst/Modeler,UICGS / Bowhead Family of Companies,12/19/2023,https://www.linkedin.com/jobs/view/3668464939,0,https://media.licdn.com/dms/image/C560BAQHo-bC_UTpfdA/company-logo_100_100/0/1631328247308?e=2147483647&v=beta&t=WqaXHH3zCardmjXMFbrzdj86-V4GhIZKJaeAmJj-3Ws,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Data Analyst/Modeler (SIOP-2023-189927):<br/><br/>Bowhead is seeking a Data Analyst/Modeler to provide support to the Infrastructure Planning Division and the Shipyard Infrastructure Optimization Program (SIOP) under the direction of the Program Executive Officer- Industrial Infrastructure (PEO II) and Program Management Office 555 (PMO 555). This position will be located at the Washington Navy Yard.<br/><br/>The Shipyard Infrastructure Optimization Program (PMO 555), is chartered with the design and execution of the recapitalization and modernization of the infrastructure at Pearl Harbor, Puget Sound, Norfolk and Portsmouth Naval Shipyards to include critical dry dock repairs, restoring needed shipyard facilities and optimizing their placement, replacing aging and deteriorating capital equipment, and implementing technology innovations.<br/><br/><strong>Responsibilities<br/><br/></strong>As a Data Analyst/Modeler, you will be responsible for collecting, updating, analyzing and interpreting large amounts of planning and cost data in support of the SIOP project planning process. You will maintain a current modeling capability to inform the SIOP decision-making process by providing actionable insights and recommendations based on required analysis. You will work with different stakeholders across the organization to identify and solve business problems using data.<br/><br/>You will also explore the potential for more robust capabilities in support of the project planning and forecasting process.<br/><br/>Job duties include but are not limited to:<br/><br/><ul><li> Collect and analyze data from various sources to update the current modeling capability and identify trends and patterns </li><li> Clean, process, and transform data as needed </li><li> Develop and maintain databases, data systems, and data analytics tools </li><li> Generate system documentation (user guides, data tables, data dictionary, etc.) and process documentation (data flows, standard operating procedures, etc.) regarding implementation and operation of the modeling capability </li><li> Create reports and visualizations to communicate data insights to SIOP stakeholders </li><li> Collaborate with PMO-555 stakeholders to identify and answer critical business questions using data </li><li> Develop and implement data-driven solutions to improve business performance </li><li> Facilitate working groups/events to improve use and awareness of the modeling capability </li><li> Continuously monitor data quality and integrity </li><li> Stay up-to-date with industry trends and emerging technologies related to data analytics <br/><br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in a quantitative field such as Mathematics, Statistics, Computer Science or equivalent </li><li> Intermediate to advanced proficiency in Microsoft Excel </li><li> Proficiency in data analysis and visualization tools such as SQL, Tableau, or Power BI </li><li> Basic knowledge of cost estimating and scheduling tools – Microsoft Project, Primavera P6, ACEIT, Crystal Ball, etc. </li><li> Strong analytical and problem-solving skills </li><li> Attention to detail and ability to work with large datasets </li><li> Ability to communicate complex ideas and findings to non-technical stakeholders </li><li> Knowledge of statistical techniques and machine learning is a plus <br/><br/><br/></li></ul>Physical Demands:<br/><br/><ul><li> Must be able to lift up to 25 pounds </li><li> Must be able to stand and walk for prolonged amounts of time </li><li> Must be able to twist, bend and squat periodically <br/><br/><br/></li></ul>SECURITY CLEARANCE REQUIREMENTS: Must be able to obtain a security clearance at the Secret level. US Citizenship is a requirement for Secret clearance at this location.<br/><br/>
</div>",No Salary Info Found,Data Modeler
Analytic/Data Modeler,"Axim Geospatial, an NV5 Company",12/19/2023,https://www.linkedin.com/jobs/view/3725445087,0,https://media.licdn.com/dms/image/C4E0BAQGXCQXkpk8W4Q/company-logo_100_100/0/1640722355385/aximgeo_logo?e=2147483647&v=beta&t=eNhhv11aKr69SyS9C-7oFYFapPjqbt5qiBbcquA7obU,"Springfield, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong><strong>Role Summary:<br/><br/></strong>The Analytic Modeler will coordinate with intelligence clients to understand questions and issues, then determine the best method and approach to create data-driven solutions. They will write scripts, conduct analysis, identify patterns, and use available tools to analyze data, enable automation, and discover hidden patterns to help solve complex problems.<br/><br/><strong>Role:</strong> Analytic/Data Modeler<br/><br/><strong>Work Environment<br/><br/></strong><ul><li> Location is flexible: NGA offices in St. Louis, MO and Springfield, VA </li><li> Travel up to 15% of the time <br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li> Apply mathematical and statistical models via programming languages to large datasets to extract patterns, relationships, and anticipatory likelihoods not apparent through traditional analyses </li><li> Use knowledge of advanced analytic methodologies to increase customer satisfaction and answer intelligence questions </li><li> Support exploitation, intelligence analysis, and product development, to include statistical and trend/pattern/temporal analysis, data manipulation and format conversion, data collection/querying from various systems, data formatting for visualization and presentation, and database design and data entry form development </li><li> Interact with analysts, mission partners, and other contractors on analytical functionality, exploitation, and related support tools </li><li> Assess new analytic tools and standards to facilitate compatibility and efficiencies across toolsets </li><li> Provide database consultation, graphical data visualizations, and recommendations for quantitative data selection and collection <br/><br/></li></ul><strong>Requirements<br/><br/></strong><strong> Qualifications <br/><br/></strong><ul><li> Bachelor’s Degree in geography, data science, imagery analysis, physical science, operations research or military equivalent and related fields; Additional experience can be substituted for education </li><li> 1 - 12 years of experience in Geographic Information Systems (GIS), geography, statistical analysis, data science, business process improvement, or analytic modeling </li><li> Knowledge of Intelligence processes (e.g., targeting, collection, processing, exploitation, dissemination) and Activity Based Intelligence (ABI) </li><li> Experience using quantitative and qualitative techniques to solve complex problems using analytical tools and techniques such as GIS, data visualization, modeling, systems analysis, comparative analysis, or database techniques </li><li> Knowledge of GIS or exploitation software such as ArcGIS, QGIS, Google Earth, RemoteView, SocetGXP, ENVI </li><li> Experience with statistical, data science, modeling and visualization software including Tableau, R, MATLAB, JEMA, or Brewlytics </li><li> Capabilities to script in Python <br/><br/></li></ul><strong>Security Clearance Requirements<br/><br/></strong><ul><li> Active TS/SCI with ability to obtain and maintain a Counter-Intelligence (CI) Polygraph <br/><br/></li></ul><strong>Competencies &amp; Skills<br/><br/></strong><ul><li> Ability to develop algorithms, analytic techniques, and models, create customized exploitation and visualization methodologies or new products </li><li> Demonstrated experience in programming and modeling techniques using HTL5, JavaScript, ArcObjects, Python, Esri Modelbuilder, Oracle, SQL, ArcGIS Server, ArcSDE, ArcIMS, JEMA, or Brewlytics </li><li> Customization of ArcGIS template and Esri Storymap templates, and management of ArcGIS Portals </li><li> Creation of shapefiles, geodatabases, and data retrieval/storage to support intelligence analysis </li><li> Experience automating processing using scripting languages including R, Python, Java, or HTML </li><li> Experience using /NET, Python, C++, and/or JAVA programming for web interface and geodatabase development </li><li> Knowledge and experience using Structured Observation Management (SOM) tools STARE, GOWK, Cedalion, or FCMS, and an understanding of Object-Based Modeling </li><li> Ability to identify and learn the essential elements of information of an intelligence problem, identify sub-processes and dependencies, location process disfunction, develop alternative processes or analysis, share expertise with analysts, and document approaches and methods for GEOINT analysis </li><li> Proficiency using GEOINT services including GovCloud, Amazon Web Services, C2S </li><li> Keen attention to detail </li><li> Proficiency using MS Office Suite <br/><br/></li></ul><strong>About Axim Geospatial<br/><br/></strong>Axim Geospatial’s (Axim) mission is to use our expertise to provide clarity and solutions to help our customers solve the world’s national security, infrastructure, and environmental problems. We are the largest singular provider of end-to-end geospatial services and solutions in the U.S serving the communities in which we live. Our core competencies include: big data services, geomatics, business solutions, cloud services, infrastructure security, analytics and professional services. Our customers include national, state and local government, defense and intelligence, infrastructure, energy, commercial and environmental customers. Axim Geospatial is an NV5 company.<br/><br/>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or status as a protected veteran. U.S. Citizenship is required for most positions.<br/><br/>
</div>",No Salary Info Found,Data Modeler
Data Engineer,Definitive Logic a ManTech Company,12/20/2023,https://www.linkedin.com/jobs/view/3785058078,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Operations/Data Analyst - Excel and SQL - Remote | WFH,Get It Recruit - Finance,12/20/2023,https://www.linkedin.com/jobs/view/3785057804,0,https://media.licdn.com/dms/image/C560BAQGbI2x_cl5lQQ/company-logo_100_100/0/1674478086788?e=2147483647&v=beta&t=duYvqJSFFoaFUoDiaEeKK0Omjxet0YJSZaaMr5rbnmU,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        **Operations Analyst - Hybrid Onsite Role (5 Days per Month)**<br/><br/>We are seeking a highly motivated Operations Analyst to join our collaborative team in a hybrid onsite role. In this position, you will play a crucial role in onboarding new banks and custodial agents, utilizing your expertise in Excel and SQL, with Salesforce experience considered a plus.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Work collaboratively with a dynamic team to onboard new banks and custodial agents.</li><li> Utilize Salesforce-based workflow processes to manage and support various operational tasks.</li><li> Manage the pipeline for new customers, including updating and maintaining a contractual term tracking system for reporting and analytical downstream functions.</li><li> Model and build data queries, and actively participate in cross-functional Data Lake based projects.</li><li> Analyze and prepare data for presentation to clients, ensuring accuracy and reliability.</li><li> Develop, document, and implement procedures focused on transactional processing, cash settlement, and reconciliation.</li><li> Collaborate with third-party vendors and partners to resolve operational issues, effectively communicating key information in a timely manner.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> High proficiency in Excel, Access, SQL, and PowerPoint.</li><li> Proven ability to achieve results by managing expectations of internal and external customers, communicating in a timely fashion, and implementing effective procedures and plans.</li><li> Strong ability to work independently while contributing to a team environment.</li><li> Exceptional attention to detail and the ability to produce accurate work products.</li><li> Proficient in analyzing and writing business requirement documents to enhance technology business platforms.</li><li> Strong analytical and critical thinking skills.</li><li> Excellent oral and written communication skills.</li><li> Experience in the financial services or banking industry, preferably in a back-office operational role. Familiarity with traditional back-office processes and functions specific to the brokerage or banking environment is a plus.<br/><br/></li></ul><strong>About Us<br/><br/></strong>At the company, we prioritize our employees, customers, and products. Our foundation lies in treating our employees and their families well, knowing that their satisfaction directly impacts the quality of service our customers receive. We foster work-life balance by offering a flexible hybrid work environment, robust benefits, and ample career growth opportunities. Join us in a culture that values passion, collaboration, and excellence!<br/><br/>Employment Type: Full-Time
      </div>",No Salary Info Found,Data Modeler
Operations/Data Analyst - Excel and SQL - Remote | WFH,Get It Recruit - Information Technology,12/20/2023,https://www.linkedin.com/jobs/view/3785020480,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are seeking a skilled and enthusiastic Operations Analyst to join our dynamic team. In this role, you will play a crucial part in the onboarding of new banks and custodial agents, collaborating with a team dedicated to operational excellence. If you have a strong background in Excel and SQL, with a bonus for Salesforce experience, and thrive in a hybrid onsite work environment, we invite you to apply.<br/><br/><strong>Responsibilities<br/><br/></strong>Work collaboratively to onboard new banks and custodial agents.<br/><br/>Utilize a Salesforce-based workflow process to manage and support various operational tasks.<br/><br/>Manage the pipeline for new customers, updating and maintaining a contractual term tracking system for reporting and analytical functions.<br/><br/>Model and build data queries, contributing to cross-functional Data Lake projects.<br/><br/>Analyze and prepare data for client presentations.<br/><br/>Develop, document, and implement procedures for transactional processing, cash settlement, and reconciliation.<br/><br/>Collaborate with third-party vendors and partners to resolve operational issues, ensuring timely communication of key information.<br/><br/><strong>Qualifications<br/><br/></strong>High competency in Excel, Access, SQL, and PowerPoint.<br/><br/>Proven ability to achieve results through effective communication and management of internal and external expectations.<br/><br/>Strong independence while maintaining effective teamwork.<br/><br/>Detail-oriented with the ability to produce accurate work.<br/><br/>Experience in analyzing and writing business requirement documents.<br/><br/>Exceptional analytical and critical thinking skills.<br/><br/>Excellent oral and written communication skills.<br/><br/>Financial Services or banking industry experience, preferably in a back-office operational role.<br/><br/><strong>About Us<br/><br/></strong>We are passionate about our employees, customers, and products. Our employees are the foundation of our success, and we prioritize their well-being and work-life balance. Enjoy the flexibility of a hybrid work environment, robust benefits, and exciting career growth opportunities. Join us in delivering the best to our customers while nurturing your professional development.<br/><br/>Employment Type: Full-Time
      </div>",No Salary Info Found,Data Modeler
Technical Data Analyst,Alignity,12/21/2023,https://www.linkedin.com/jobs/view/3790970514,0,https://media.licdn.com/dms/image/C4D0BAQFE1cg9OQhi6A/company-logo_100_100/0/1630465617075/alignity_logo?e=2147483647&v=beta&t=Q-YP-bm5ceT1zDOkJxyrhpGZFsIa6EkdkzfGCuCv31g,"McLean, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Do you love a career where you Experience <strong>, Grow &amp; Contribute at</strong> the same time, while earning at least 10% above the market? If so, we are excited to have bumped onto you.<br/><br/>Learn how we are redefining the meaning of work, and be a part of the team raved by Clients, Job-seekers and Employees.<br/><br/><ul><li>Jobseeker Video Testimonials  </li><li>Employee Glassdoor Reviews <br/><br/></li></ul>If you are a Technical Data Analyst and looking for excitement, challenge and stability in your work, then you would be glad to come across this page.<br/><br/>We are an IT Solutions Integrator/Consulting Firm helping our clients hire the right professional for an exciting long term project. Here are a few details.<br/><br/>Check if you are up for maximizing your earning/growth potential, leveraging our Disruptive <strong> Talent Solution.<br/><br/></strong>Role: Technical Data Analyst<br/><br/>Location: McLean, VA<br/><br/>Onsite Position<br/><br/>Exp: 8+ years<br/><br/><strong>Requirements<br/><br/></strong><ul><li>8+ Years experience working as a Technical Data analyst.  </li><li>Must have Strong SQL knowledge. </li><li>Must have experience working with Agile teams and able to create business and technical user stories in Jira. </li><li>Familiarity with working on the command line, able to execute python scripts, navigate to log directories to analyze logs. <br/><br/></li></ul>BenefitsVisit us at http://alignity.io/careers. Alignity Solutions is an Equal Opportunity Employer, M/F/V/D.<br/><br/>CEO Message: Click Here<br/><br/>Clients Testimonial: Click Here<br/><br/>
</div>",No Salary Info Found,Data Modeler
Data Analyst,Leidos,12/21/2023,https://www.linkedin.com/jobs/view/3790984668,0,https://media.licdn.com/dms/image/D4E0BAQErlxWb6HoHUg/company-logo_100_100/0/1689671151495/leidos_logo?e=2147483647&v=beta&t=9BAJQm1zuhkzTDtsTP7UFfPy5CK-_sWfyHq9T-Ow6Mw,"Odenton, MD","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Are you looking for interesting and meaningful ways to apply your knowledge and talents? Our corporate vision at Leidos is to be the global leader in the development and application of technology to solve our customers' most demanding challenges. And that's where you come in. We need a results-oriented self-starter to join our team as a Data Analyst in support of the NC3 Enterprise Center's (NEC) Systems Engineering and Integration (SE&amp;I) Division at Fort Meade, MD. The SE&amp;I Division serves as the principal enterprise systems engineering, enterprise architecture, and technical authority for the NC3 Enterprise within the Department of Defense. Our customer applies and remains up to date on systems engineering best practices while remaining agile when translating mission and operational requirements into appropriate technical specifications and solutions.<br/><br/><strong>To be considered for this role, a CURRENT DoD is Clearance Required:<br/><br/></strong>You must currently hold a minimum <strong><em>Top Secret</em></strong> clearance and be eligible for SCI (Special Compartmented Investigation)<br/><br/><strong>Targeted Salary: </strong>$70,000.00 -$71,000.00<br/><br/><strong>Location:</strong> On site at Fort Meade, MD with possible occasional telework.<br/><br/><strong>What will you do in this role?<br/><br/></strong><ul><li> Respond to queries from internal and external government customers for NC3 and related data, information and analyses based on information that may be stored across multiple documents, databases, networks, and storage environments.</li><li> Provide data/information retrieval, analysis and visualization support to SE&amp;I’s systems engineering, enterprise architecture and technical standards teams.</li><li> Support data standards, digital modeling, and model-based systems engineering (MBSE) efforts, including the NC3 Digital Mission Engineering Environment (NDMEE).</li><li> Collaborate with enterprise architecture teams to capture user requirements and use cases supporting architecture artifact development.</li><li> Coordinate with the NC3 Enterprise Data Governance Group (DGG) to develop NC3 enterprise data standards, management, storage, and analysis processes.</li><li> Coordinate with the NC3 Configuration Management team to collect, synthesize, evaluate, and produce reports in response to customer data calls.</li><li> Support SE&amp;I leadership through technical analysis, findings documentation, and recommendation development to drive improvements in NC3 enterprise governance and architecture.<br/><br/></li></ul><strong>These Are The Required Qualifications<br/><br/></strong><ul><li> Active Top Secret clearance with SCI eligibility.</li><li> Bachelor's degree in Engineering, Computer Science, or a relevant technical discipline and at least three years of prior relevant experience.</li><li> Experience performing data analysis, including analysis of operational, system design and architecture requirements and performance measurements/trends.</li><li> Knowledge of data visualization principles, data visualization tools, and database management tools and principles.</li><li> Skill and experience preparing professional documents and presentations utilizing Microsoft Office applications (e.g., Word, PowerPoint, Excel, Project, etc.).</li><li> Experience delivering professional oral presentations in both one-on-one and in group settings.</li><li> Experience working independently (with minimal supervision) on projects while managing workloads to meet milestones and project suspense dates.<br/><br/></li></ul><strong>These Are Preferred Qualifications<br/><br/></strong><ul><li> Experience working with Nuclear C3 community stakeholders such as NEC, USSTRATCOM, the Joint Staff, OSD, and U.S. Navy or Air Force units providing NC3 capabilities.</li><li> Knowledge of digital modeling tools (e.g., SparxEA, Cameo).</li><li> Knowledge of data analysis, visualization and natural language processing tools and procedures, including relevant Python tools and models.</li><li> Exceptional verbal and written communications and document preparation skills.</li><li> Working knowledge of workforce collaboration software tools such as Microsoft Teams and SharePoint.</li><li> Working knowledge of digital note-taking software such as Microsoft OneNote.</li><li> Working knowledge of relational database management software such as Microsoft Access and or Oracle.</li><li> Working knowledge and experience with the Agile methodology approach to project management.</li><li> Familiarity with of DoD Architectural Framework (DoDAF) and model-based systems engineering (MBSE) concepts.<br/><br/></li></ul>NEC SE&amp;I<br/><br/><strong>Pay Range<br/><br/></strong>Pay Range $55,250.00 - $99,875.00<br/><br/>The Leidos pay range for this job level is a general guideline only and not a guarantee of compensation or salary. Additional factors considered in extending an offer include (but are not limited to) responsibilities of the job, education, experience, knowledge, skills, and abilities, as well as internal equity, alignment with market data, applicable bargaining agreement (if any), or other law.<br/><br/>#Featuredjob<br/><br/><strong>Original Posting Date<br/><br/></strong>12/20/2023<br/><br/>While subject to change based on business needs, Leidos reasonably anticipates that this job requisition will remain open for at least 3 days with an anticipated close date of no earlier than 3 days after the original posting date as listed above.
      </div>",$70000.00- $71000.00,Data Modeler
Refactor Expert - Python / PostgreSQL / SQL (SqLite),"DataChamps,LLC",12/24/2023,https://www.linkedin.com/jobs/view/3792798840,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Engineer (DE),Zortech Solutions,12/24/2023,https://www.linkedin.com/jobs/view/3787251275,0,https://media.licdn.com/dms/image/C4E0BAQFLYN9bJoNeQg/company-logo_100_100/0/1630602268967?e=2147483647&v=beta&t=VbFirFeWDqzftzmA-xuL4-Rh3UkhihCRtFcB66Ze6Cg,"Paradise Valley, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Role: Data Engineer (DE)<br/><br/></strong><strong>Location: Scottsdale AZ (day 1 onsite)<br/><br/></strong><strong>Duration: Fulltime <br/><br/></strong><strong>Must have skill set: Java , Scala , S3, Glue, Redshift<br/><br/></strong><ul><li>You have 6-8 years of relevant software development experience. </li><li>You have hands-on experience in Java/Scala/Python, Spark, S3, Glue, Redshift. This is critical. </li><li>Highly analytical and data oriented. </li><li>Experience in SQL, NoSql Database </li><li>Data masking of on prem PII data. </li><li>Develop API calls with using secure data transfer. </li><li>Take standard output data to lower environments for pre prod testing! </li><li>Enable secured channels for data models and data science activities. </li><li>Need a solution that can scale to handle millions of data. i.e., masking 10 million records in 15 mins </li><li>You have experience with development tools and agile methodologies.</li></ul>
</div>",No Salary Info Found,Data Modeler
w2::DataStage Developer::Local to AZ/GA,TALENDICA,12/19/2023,https://www.linkedin.com/jobs/view/3788160357,0,https://media.licdn.com/dms/image/C560BAQEdQk4U667qxQ/company-logo_100_100/0/1645047125939/talendica_logo?e=2147483647&v=beta&t=hVUnQqoed1HNspq-ijj8x_1ZBePNMRdmnY0R6kjVYPI,"Chandler, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Hi,<br/><br/></strong><strong>Role</strong>- DataStage Developer in Chandler AZ and Kennesaw GA – Onsite – Local Candidates<br/><br/><strong>Location-</strong> Chandler AZ and Kennesaw GA – Onsite – Local Candidates<br/><br/><strong>Duration : Long term <br/><br/></strong><strong>Job Description<br/><br/></strong><ul><li>7-10 years of experience as DataStage developer.</li><li>Experience with DataStage v11.7 &amp; QualityStage.</li><li>Experience with MS SQL and ETL, Packages and Functions.</li><li>Highly motivated self-starter able to work w/ minimal oversight.</li><li>Strong communication skills with focus on teamwork.</li><li>Proficient with agile development routines, Horizon / CICD.<br/><br/></li></ul><strong>Thanks &amp; Regards,<br/><br/></strong><strong>JIA</strong>|<strong>TALENDICA<br/><br/></strong><strong>SENIOR TECHNICAL RECRUITER<br/><br/></strong><strong>44, Saratoga Ln, Monroe Township, NJ - 08831<br/><br/></strong><strong>Email: </strong><strong>jia@talendica.com<br/><br/></strong><strong>Hangout/Skype: </strong><strong>jia@talendica.com<br/><br/></strong><strong>www.talendica.com<br/><br/></strong><strong>Follow Us On<br/><br/></strong><strong>If you are not interested in receiving our e-mails then please reply with a ""REMOVE"" in the subject line. We are sorry for the inconvenience caused to you.</strong>
</div>",No Salary Info Found,Data Modeler
Data Center Engineer,Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3732382790,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Analyst,Insight Global,12/19/2023,https://www.linkedin.com/jobs/view/3784434934,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Engineer,SnapX.ai,12/19/2023,https://www.linkedin.com/jobs/view/3790031494,0,https://media.licdn.com/dms/image/C560BAQGrI5ZAgEOJ2Q/company-logo_100_100/0/1630666773263/snapxplatform_com_logo?e=2147483647&v=beta&t=ZLMq0RgwhdqNpuxZa98IYOgvdQbNVWudgbncPkkl5SY,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Dear Partner, Good morning,greetings from Snaprecruit LLC!<br/><br/>Submission you please review the below role,If you are available.<br/><br/><br/><br/>AWS, AWS Redshift and infrastructure, AWS Data Lake Formation and Glue components, data security, SQL, and Python</p>
</div>",No Salary Info Found,Data Modeler
Data Quality Analyst,City National Bank,12/19/2023,https://www.linkedin.com/jobs/view/3790365161,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
"ONSITE JOB: Hiring Data Engineer GCP , Phoenix, AZ","Conch Technologies, Inc",12/19/2023,https://www.linkedin.com/jobs/view/3788118349,0,https://media.licdn.com/dms/image/C4E0BAQHKm43b1OSSsw/company-logo_100_100/0/1630593845537/conch_technologies_logo?e=2147483647&v=beta&t=fddpsK_rqbhSRB1GStFAtD-sfi1Bxsv8oh8oupv0EEY,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Hi,<br/><br/>Greetings from Conch Technologies Inc<br/><br/><strong>Position: Data Engineer (GCP AI/ML)<br/><br/></strong><strong>Experience: 9+ years<br/><br/></strong><strong>Location: Phoenix, AZ<br/><br/></strong><strong>Duration: 12+ Months Contract <br/><br/></strong><strong>100% onsite<br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li>9+ Years experience as a GCP</li><li>AI/ML some experience needed</li><li>Good to have experience in Machine Learning</li><li>Good experience in Artificial Intelligence.</li><li>Good Communication Skills.<br/><br/></li></ul><strong>_<br/><br/></strong><strong>Thanks and Regards,<br/><br/></strong><strong>Chanakya </strong><strong>[IT Recruiter]<br/><br/></strong><strong>Direct : 214-247-7117<br/><br/></strong><strong>chanakya@conchtech.com<br/><br/></strong><strong>linkedin.com/in/nameischanikya</strong>
</div>",No Salary Info Found,Data Modeler
Junior Data Analyst,Insight Global,12/19/2023,https://www.linkedin.com/jobs/view/3784057538,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
GIS Developer,"Phoenix Staff, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789019550,0,https://media.licdn.com/dms/image/C560BAQFS4ZNlu_xRdA/company-logo_100_100/0/1660709194786/phoenix_staff_logo?e=2147483647&v=beta&t=v9MgqTey08e5HuF3bTNlfj1Lwgy0bS9KkQs2j4tkqBY,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Title:</strong> GIS Developer <br/> <strong>Location:</strong> Hybrid Schedule, Phoenix, AZ <br/> <strong>Type:</strong> Open to contract or permanent hire</p><p><br/> We are currently seeking a skilled GIS Developer experienced in the Svelte web app framework and/or GIS systems to join our dynamic team. This role involves working on projects where API integration with multiple services is a component. Candidates with a strong Linux background are encouraged to apply. If you are passionate about GIS development, have a keen interest in Svelte, and thrive in a dynamic environment with diverse challenges, we invite you to apply for this exciting opportunity.</p><p><strong><br/> Your role:</strong></p><ul><br/><li>Develop and maintain web front ends using the Svelte framework and adjacent tools.</li><li>Collaborate with cross-functional teams to integrate data products from various sensors in the field with our proprietary hardware.</li><li>Utilize JavaScript and Python for scripting tasks.</li><li>Engage in some level of API integration as part of the overall project requirements.</li><li>Explore and implement innovative solutions, staying abreast of industry trends and emerging technologies.</li></ul><br/><p><strong><br/> What you've got:</strong></p><ul><br/><li>Demonstrated experience with Svelte or a comparable JavaScript framework (e.g., React).</li><li>Familiarity with GIS technologies and tools like ArcGIS or GDAL.</li><li>Proficiency in JavaScript and Python for scripting and tooling.</li><li>Ability to work collaboratively in a team environment.</li><li>Prior experience with API integration is a plus.</li><li>Adaptability to explore and incorporate new technologies, such as AI tools, into development workflows.</li><li>While specific Svelte experience is preferred, individuals with strong GIS backgrounds and proficiency in JavaScript and Python will be considered, especially if they are open to learning and working with Svelte.</li></ul><br/><p><br/> To find more great tech-centric jobs, please visit www.phoenixstaff.com.</p>
</div>",No Salary Info Found,Data Modeler
Data Engineer III - Remote | WFH,Get It Recruit - Information Technology,12/25/2023,https://www.linkedin.com/jobs/view/3787808700,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"La Mesa, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a dynamic and innovative team seeking a skilled Data Engineer III to join us remotely. At our company, we value collaboration, creativity, and a passion for transforming data into meaningful insights. If you thrive in a fast-paced, agile environment and are excited about building solutions that make a real impact, we invite you to explore this opportunity.<br/><br/><strong>Responsibilities<br/><br/></strong>Design and implement features in collaboration with a diverse team of engineers, product owners, data analysts, and business partners using Agile/Scrum methodology.<br/><br/>Develop programs and systems that translate data into meaningful information for analysis.<br/><br/>Build ETL/ELT jobs and workflows to integrate data from various sources.<br/><br/>Install continuous pipelines of filtered information for data analysts/scientists.<br/><br/>Construct data workflows using SQL Server Integration Services (SSIS), Microsoft Azure (Azure Data Factory, Storage Accounts, Synapse), and Databricks.<br/><br/>Collaborate with business stakeholders and product engineering teams to analyze business problems and implement solutions.<br/><br/>Document software architecture, create roadmap plans, and assist in the design, implementation, and maintenance of complex solutions.<br/><br/>Build systems that collect, manage, and convert raw data into usable information for business analysts.<br/><br/>Ensure data accessibility for evaluation and optimization.<br/><br/><strong>Qualifications<br/><br/></strong>Required:<br/><br/>Master's degree in computer science, systems engineering, or a related technical discipline (preferred).<br/><br/>5 years of experience as a Data Engineer/Administrator or in a similar role.<br/><br/>6 additional years of relevant experience may substitute for education.<br/><br/><strong>Preferred<br/><br/></strong>Proficiency in back-end data organization using SQL scripts and SSIS.<br/><br/>Experience with Microsoft Azure, Databricks, and Python or other scripting languages in data pipelines.<br/><br/>Familiarity with Microsoft Power BI.<br/><br/>Ability to work independently and provide technical and non-technical support to multiple users.<br/><br/>Capable of working under pressure, handling multiple tasks simultaneously.<br/><br/>Occasional overtime and weekend availability may be required.<br/><br/><strong>Salary Range<br/><br/></strong>Experience providing services to the federal government is preferred.<br/><br/>Target salary range: $165,001 - $175,000. The estimate displayed represents the typical salary range for this position based on experience and other factors.<br/><br/><strong>COVID Policy<br/><br/></strong>We prioritize the health and safety of our team members. While we do not require COVID-19 vaccinations or boosters, we adhere to customer site vaccination requirements when work is performed at a customer site.<br/><br/>Employment Type: Full-Time
      </div>",$165001- $175000,Data Modeler
Sr. Algorithm Developer,Truvian,12/21/2023,https://www.linkedin.com/jobs/view/3785671227,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Developer SQL,ALLY Energy,12/19/2023,https://www.linkedin.com/jobs/view/3790342031,0,https://media.licdn.com/dms/image/D560BAQHlSsRMz5wFAA/company-logo_100_100/0/1689644287624/allyenergy_logo?e=2147483647&v=beta&t=M5vQMlmX6BcDK_ELXyKGsQYpqgDMapFRNLEX1XhFRZg,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Calpine Corporation is America's largest generator of electricity from natural gas and geothermal resources with operations in competitive power markets. Its fleet of 76 power plants in operation and one under construction represents nearly 26,000 megawatts of generation capacity. Through wholesale power operations and its retail businesses, Calpine serves customers in 22 states, Canada and Mexico. Its clean, efficient, modern and flexible fleet uses advanced technologies to generate power in a low-carbon and environmentally responsible manner.<br/><br/>The company was established on the premise that a strong commitment to the environment is inextricably linked to excellence in power generation and corporate responsibility. Since its founding in 1984, Calpine has led the power industry in its unwavering commitment to environmental stewardship. In addition, its renewable geothermal plants use steam generated deep below the earth's surface to produce clean, renewable electricity.<br/><br/><strong>Job Summary (includes but is not limited to the following, other duties may be assigned)<br/><br/></strong><ul><li>This is not a fully remote position.<br/><br/></li></ul>The SQL Developer is responsible for supporting the Retail Platform team by developing SQL solutions leveraging Microsoft technology platforms. Use of SQL Server database, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS), SQL Server Reporting Services (SSRS), and Power BI will be required.<br/><br/><strong>Job Responsibilities<br/><br/></strong><ul><li>Working with Microsoft SQL Stack e.g. SQL Server 2016 or higher, SSAS, SSIS, SSRS, MDM, Power BI.</li><li>Use of data model concepts, master data management, operational process, SDLC, project management, data profiling, data cleansing/de-duplication processes.</li><li>Create and maintain DAX and MDX queries and perform performance tuning on SSAS.</li><li>Implement data warehousing and associated architecture.</li><li>Data migration with source database to target database mapping.</li><li>Database design with multidimensional modeling.</li><li>Working directly with the business clients.</li><li>Extensive use of written and oral communication skills, particularly the ability to synthesize complex issues/scenarios into easy-to-understand concepts.</li><li>Works closely with the business team, development team, analysis team, and the users to enhance quality and product delivered.</li><li>Responsible for precisely communicating impact, status, priority, progress, and road blocks to management</li><li>Provides guidance in terms of priority and ownership of issues and requests.<br/><br/></li></ul><strong>Job Requirements<br/><br/></strong><ul><li>Undergraduate degree in information systems, computer science, other technical/science degree, or equivalent work experience and technical training is required.</li><li>3+ years of direct experience as a SQL Developer.</li><li>Experience in managing software requests, projects, and internal customers.</li><li>Experience with every phase of the System Development Life Cycle.</li><li>Experience with being the technical liaison between the business users and development.</li><li>Experience with Azure DevOps is desired.</li><li>1 to 2 years of retail energy related experience is highly desired.</li><li>Strong written and verbal communication skills.</li><li>Strong analytical and critical thinking skills.</li><li>Good inter-personal skills combined with a willingness to listen</li><li>Self-motivated, goal oriented, and possess the initiative to learn independently.</li><li>Analytical, advanced decision-making skills, and problem solving abilities.</li><li>Must demonstrate a positive, customer-focused attitude.</li><li>Must be well organized and detail oriented</li><li>Ability to convey technical information in a clear and concise manner to other less technically oriented customers.</li><li>Ability to manage multiple duties at the same time.</li><li>Advanced Proficiency in the Microsoft Office suite and Office 365</li><li>Demonstrated ability to work in ambiguous situations and across organizational boundaries.</li><li>Sitting and standing for long periods of time.<br/><br/></li></ul><strong>Microsoft SQL Technologies<br/><br/></strong><ul><li>Microsoft SQL Server stack (Reporting Services, Integration Services, Analysis Services and Power BI).<br/><br/></li></ul><strong>Relational Database Management Systems<br/><br/></strong><ul><li>Microsoft SQL Server 2016 or newer.<br/><br/></li></ul><strong>Salary Information - Position is eligible for annual bonus.<br/><br/></strong>Salary Range $77,250.10 to $113,943.15<br/><br/><strong>Additional Calpine Information<br/><br/></strong><ul><li>Equal Opportunity Employer of Minorities, Females, Protected Veterans, and Individuals with Disabilities.</li><li>Calpine is committed to Equal Employment Opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment and need special assistance or an accommodation to use our website or to apply for a position, please send an e-mail with your request to hrrecruitment@calpine.com. Determination on requests for reasonable accommodation are made on case-by-case basis.<br/><br/></li></ul>Please view Equal Employment Opportunity Posters provided by OFCCP here
      </div>",$77250.10- $113943.15,Data Modeler
SQL Developer,Calpine,12/19/2023,https://www.linkedin.com/jobs/view/3787644141,0,https://media.licdn.com/dms/image/C560BAQGwMZQTMqgO2A/company-logo_100_100/0/1631398138821?e=2147483647&v=beta&t=sWe2cRHj-o8bFOOhYQgqirAAiW4sWaHT387r5XEBQ7I,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Calpine Corporation is America's largest generator of electricity from natural gas and geothermal resources with operations in competitive power markets. Its fleet of 76 power plants in operation and one under construction represents nearly 26,000 megawatts of generation capacity. Through wholesale power operations and its retail businesses, Calpine serves customers in 22 states, Canada and Mexico. Its clean, efficient, modern and flexible fleet uses advanced technologies to generate power in a low-carbon and environmentally responsible manner.<br/><br/>The company was established on the premise that a strong commitment to the environment is inextricably linked to excellence in power generation and corporate responsibility. Since its founding in 1984, Calpine has led the power industry in its unwavering commitment to environmental stewardship. In addition, its renewable geothermal plants use steam generated deep below the earth's surface to produce clean, renewable electricity.<br/><br/><strong>Job Summary (includes but is not limited to the following, other duties may be assigned)<br/><br/></strong><ul><li>This is not a fully remote position. <br/><br/></li></ul>The SQL Developer is responsible for supporting the Retail Platform team by developing SQL solutions leveraging Microsoft technology platforms. Use of SQL Server database, SQL Server Integration Services (SSIS), SQL Server Analysis Services (SSAS), SQL Server Reporting Services (SSRS), and Power BI will be required.<br/><br/><strong>Job Responsibilities<br/><br/></strong><ul><li>Working with Microsoft SQL Stack e.g. SQL Server 2016 or higher, SSAS, SSIS, SSRS, MDM, Power BI. </li><li>Use of data model concepts, master data management, operational process, SDLC, project management, data profiling, data cleansing/de-duplication processes. </li><li>Create and maintain DAX and MDX queries and perform performance tuning on SSAS. </li><li>Implement data warehousing and associated architecture. </li><li>Data migration with source database to target database mapping. </li><li>Database design with multidimensional modeling. </li><li>Working directly with the business clients. </li><li>Extensive use of written and oral communication skills, particularly the ability to synthesize complex issues/scenarios into easy-to-understand concepts. </li><li>Works closely with the business team, development team, analysis team, and the users to enhance quality and product delivered. </li><li>Responsible for precisely communicating impact, status, priority, progress, and road blocks to management</li><li>Provides guidance in terms of priority and ownership of issues and requests. <br/><br/></li></ul><strong>Job Requirements<br/><br/></strong><ul><li>Undergraduate degree in information systems, computer science, other technical/science degree, or equivalent work experience and technical training is required. </li><li>3+ years of direct experience as a SQL Developer. </li><li>Experience in managing software requests, projects, and internal customers. </li><li>Experience with every phase of the System Development Life Cycle. </li><li>Experience with being the technical liaison between the business users and development. </li><li>Experience with Azure DevOps is desired. </li><li>1 to 2 years of retail energy related experience is highly desired. </li><li>Strong written and verbal communication skills. </li><li>Strong analytical and critical thinking skills. </li><li>Good inter-personal skills combined with a willingness to listen</li><li>Self-motivated, goal oriented, and possess the initiative to learn independently. </li><li>Analytical, advanced decision-making skills, and problem solving abilities. </li><li>Must demonstrate a positive, customer-focused attitude. </li><li>Must be well organized and detail oriented</li><li>Ability to convey technical information in a clear and concise manner to other less technically oriented customers. </li><li>Ability to manage multiple duties at the same time. </li><li>Advanced Proficiency in the Microsoft Office suite and Office 365</li><li>Demonstrated ability to work in ambiguous situations and across organizational boundaries. </li><li>Sitting and standing for long periods of time. <br/><br/></li></ul><strong>Microsoft SQL Technologies<br/><br/></strong><ul><li>Microsoft SQL Server stack (Reporting Services, Integration Services, Analysis Services and Power BI). <br/><br/></li></ul><strong>Relational Database Management Systems<br/><br/></strong><ul><li>Microsoft SQL Server 2016 or newer. <br/><br/></li></ul><strong>Salary Information - Position is eligible for annual bonus.<br/><br/></strong>Salary Range $77,250.10 to $113,943.15<br/><br/><strong>Additional Calpine Information<br/><br/></strong><ul><li>Equal Opportunity Employer of Minorities, Females, Protected Veterans, and Individuals with Disabilities. </li><li>Calpine is committed to Equal Employment Opportunity and providing reasonable accommodations to applicants with physical and/or mental disabilities. If you are interested in applying for employment and need special assistance or an accommodation to use our website or to apply for a position, please send an e-mail with your request to hrrecruitment@calpine.com. Determination on requests for reasonable accommodation are made on case-by-case basis. <br/><br/></li></ul>Please view Equal Employment Opportunity Posters provided by OFCCP here<br/><br/>Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities<br/><br/>The contractor will not discharge or in any other manner discriminate against employees or applicants because they have inquired about, discussed, or disclosed their own pay or the pay of another employee or applicant. However, employees who have access to the compensation information of other employees or applicants as a part of their essential job functions cannot disclose the pay of other employees or applicants to individuals who do not otherwise have access to compensation information, unless the disclosure is (a) in response to a formal complaint or charge, (b) in furtherance of an investigation, proceeding, hearing, or action, including an investigation conducted by the employer, or (c) consistent with the contractor’s legal duty to furnish information. 41 CFR 60-1.35(c)
      </div>",$77250.10- $113943.15,Data Modeler
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789762711,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Catalog and Lineage Central Governance Analyst,PwC,12/20/2023,https://www.linkedin.com/jobs/view/3785061774,0,https://media.licdn.com/dms/image/D4D0BAQH3qXh7nyImoQ/company-logo_100_100/0/1697100791441/pwc_logo?e=2147483647&v=beta&t=egwzMH-OEEIdbRMowwJcaDKwrISS95b4zQiwpJJhhyw,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Specialty/Competency: </strong>IFS - Information Technology (IT)<br/><br/><strong>Industry/Sector: </strong>Not Applicable<br/><br/><strong>Time Type: </strong>Full time<br/><br/><strong>Travel Requirements: </strong>Up to 20%<br/><br/>A career in Products and Technology is an opportunity to bring PwC's strategy to life by driving products and technology into everything we deliver. Our clients expect us to bring the right people and the right technology to solve their biggest problems; Products and Technology is here to help PwC meet that challenge and accelerate the growth of our business. We have skilled technologists, data scientists, product managers and business strategists who are using technology to accelerate change. Our team is responsible for defining and upholding data governance plans. Efforts transform the way the firm manages and capitalizes on its data/maximizes the income potential of data which spans a variety of people, processes, policies, and technologies.<br/><br/>To really stand out and make us fit for the future in a constantly changing world, each and every one of us at PwC needs to be a purpose-led and values-driven leader at every level. To help us achieve this we have the PwC Professional; our global leadership development framework. It gives us a single set of expectations across our lines, geographies and career paths, and provides transparency on the skills we need as individuals to be successful and progress in our careers, now and in the future.<br/><br/><strong>Responsibilities<br/><br/></strong>As a Senior Associate, you'll work as part of a team of problem solvers, helping to solve complex business issues from strategy to execution. PwC Professional skills and responsibilities for this management level include but are not limited to:<br/><br/><ul><li>Use feedback and reflection to develop self awareness, personal strengths and address development areas.</li><li>Delegate to others to provide stretch opportunities, coaching them to deliver results.</li><li>Demonstrate critical thinking and the ability to bring order to unstructured problems.</li><li>Use a broad range of tools and techniques to extract insights from current industry or sector trends.</li><li>Review your work and that of others for quality, accuracy and relevance.</li><li>Know how and when to use tools available for a given situation and can explain the reasons for this choice.</li><li>Seek and embrace opportunities which give exposure to different situations, environments and perspectives.</li><li>Use straightforward communication, in a structured way, when influencing and connecting with others.</li><li>Able to read situations and modify behavior to build quality relationships.</li><li>Uphold the firm's code of ethics and business conduct.<br/><br/></li></ul><strong>Additional Responsibilities<br/><br/></strong>Supporting the identification and management of data domains, data elements, Business Glossary and Data Catalog, assesses and operationalizes the Technical Metadata harvesting and preparing the Data Lineage. Defines optimal Metadata model design as the Metadata owner and driver for optimal utilization of the data management tool - Azure Purview. Enhance and maintain the data catalog, policy and standards library, the End-to-End data lineage, as well as how to operationalize DG culture.<br/><br/><strong>Custom Orgs<br/><br/></strong><strong>Global LoS</strong>:<br/><br/>Internal Firm Services<br/><br/><strong>Basic Qualifications<br/><br/></strong><strong>Job Requirements and Preferences</strong>:<br/><br/><strong>Minimum Degree Required<br/><br/></strong>High School Diploma<br/><br/><strong>Minimum Years Of Experience<br/><br/></strong>2 year(s)<br/><br/><strong>Preferred Qualifications<br/><br/></strong><strong>Degree Preferred</strong>:<br/><br/>Bachelor Degree<br/><br/><strong>Preferred Fields Of Study<br/><br/></strong>Computer and Information Science, Data Processing/Analytics/Science<br/><br/><strong>Additional Educational Preferences<br/><br/></strong>Other related fields of study with relevant experience may be considered.<br/><br/><strong>Preferred Knowledge/Skills<br/><br/></strong>Demonstrates thorough abilities and/or a proven record of success as a team leader:<br/><br/><ul><li>Possessing broad experience participating in data-related projects or programs and working knowledge and experience in Metadata Management and Data Governance Implementation Projects;</li><li>Displaying knowledge of data management and governance policies, standards, metrics, controls, and processes;</li><li>Having knowledge of the legal, compliance, and regulatory issues impacting data along with geographical restrictions on data storage and Data Centers;</li><li>Possessing knowledge and experience of data asset identification, defining data asset ownerships, usage and access control policies;</li><li>Showcasing knowledge and experience in data domain discovery, data classification, taxonomy and hierarchies that support data catalog architecture;</li><li>Exhibiting proven knowledge and working experience in Microsoft Purview;</li><li>Creating new or enhance the existing business glossaries, working with business analysts and other stakeholders to establish concise, understandable definitions that accurately reflect the business purpose and resonate with the various consumers;</li><li>Showcasing thorough understanding of, designing and developing data catalog in Purview that would be the inventory of collective data assets to help data owners, stewards and business users to find relevant data for analytics uses using unisense search;</li><li>Displaying knowledge and understanding of stitching and maintaining data dictionary, business glossary and data catalog;</li><li>Conducting periodic reviews of the data catalogue to corroborate compliance with the DG standards;</li><li>Facilitating the capture of metadata as core change and operational deliverables;</li><li>Demonstrating clarity, knowledge and experience in harvesting technical metadata either through OOTB or custom connectors of Purview while working with business analysts and solution designers;</li><li>Designing, developing and tracking data lineage from source to target including all intermediate transformations and curations layers using Purview;</li><li>Identifying, validating and attesting completeness of data lineage between the point of data element creation (system of record) and the point where it is consumed by business users (trusted data sources) and design processes for implementation to certify Tier 1 CDEs and Reports;</li><li>Possessing ability to create and maintain automated workflows for periodic metadata refresh;</li><li>Complete understanding of the process of sensitive data (PII, PHI, etc.) and making sure the data management standards in-sync with the regulations like GDPR/HIPPA/SPI (as applicable);</li><li>Helping manage the inventory of data-related controls on systems that support segment processes and customers;</li><li>Showcasing thorough understanding of data steward/data owner operating model; </li><li>Ability in designing and rolling out training programs to train the trainer/end-users;</li><li>Being a collaborative team player; and,</li><li>Having a business outcome focused problem-solving mindset.<br/><br/></li></ul>Learn more about how we work: https://pwc.to/how-we-work<br/><br/>PwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.<br/><br/>All qualified applicants will receive consideration for employment at PwC without regard to race; creed; color; religion; national origin; sex; age; disability; sexual orientation; gender identity or expression; genetic predisposition or carrier status; veteran, marital, or citizenship status; or any other status protected by law. PwC is proud to be an affirmative action and equal opportunity employer.<br/><br/>For positions based in San Francisco, consideration of qualified candidates with arrest and conviction records will be in a manner consistent with the San Francisco Fair Chance Ordinance.<br/><br/>Applications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines<br/><br/>For positions in California, Colorado, Hawaii, Nevada, New York State, or Washington State, or for opportunities that will report to a supervisor, office or other work site in New York State, please visit the following link for pay range information: https://pwc.to/payrange-v1-productstechseniorassociate<br/><br/>
</div>",No Salary Info Found,Data Modeler
Data Engineer,National Funding,12/20/2023,https://www.linkedin.com/jobs/view/3785066474,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083991,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $160,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$160000- $173000,Data Modeler
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment Partners LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785064004,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Insurance - Data Analyst - REMOTE,Wahve LLC,12/20/2023,https://www.linkedin.com/jobs/view/3790963546,0,https://media.licdn.com/dms/image/D560BAQHLpAj4KcNwxw/company-logo_100_100/0/1689949451872/wahve_logo?e=2147483647&v=beta&t=ijNXVviKcnM87hQBvAX-WppSZZwnFb7A4YL9Fiqr6Zk,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><em>Put your Insurance Experience to work - FROM HOME!<br/><br/></em></strong>At <strong>Wahve</strong>, we value significant insurance experience and want to revolutionize the way people think about <strong><em>phasing into</em> <em>retirement</em></strong> by offering qualified candidates the opportunity to continue their career working from home. As we say - <strong><em>retire from the office but not from work</em></strong>. Our unique platform provides you with <em>real</em> work/life balance and allows you to customize your own work schedule while continuing to utilize your insurance expertise in <strong><em>a remote, long-term position</em></strong>.<br/><br/><strong>What You’ll Love About Wahve<br/><br/></strong>We created a welcoming place to work with friendly and professional leadership. We are known for the great care we take with our staff and our clients. We are passionate and determined about delivering the best customer service, preserving insurance industry knowledge, and making a difference by the work that we do.<br/><br/><strong>What We Are Seeking<br/><br/></strong>We have assignments available to help our <em>insurance industry</em> clients in <strong>Data Analyst positions. Responsibilities include:<br/><br/></strong><ul><li>Build and maintain data warehouse, new reports, and ad hoc reports. </li><li>Work with user groups to identify reporting issues/enhancements and document business requirements. </li><li>Will serve as a member of a project team and/or work independently on projects. </li><li>Support and train internal users as needed. </li><li>Compile and prepare data for customer analysis. </li><li>Experience in C#, Visual Studio, JavaScript, CSS, and current web technologies such as .NET, ASP, JSON, and XML. </li><li>Experience with ANY of the following technologies: SQL Server Reporting Services (SSRS), SSIS Reporting, Power BI, Dynamics CRM, Dynamics GP, Share point, Excel, Power Query, Power Pivot. </li><li>Ability to compile data results and author commentary on industry studies is a plus. </li><li>Insurance or financial services industry experience required. <br/><br/></li></ul><strong>TO BECOME A WORK-AT-HOME VINTAGE EXPERT, WE REQUIRE<br/><br/></strong><ul><li>25 years of full-time work experience</li><li>Experience working in a data analysis role in the insurance or financial services industry - required<br/><br/></li></ul><strong>Benefits Of Becoming a Wahve Vintage Expert<br/><br/></strong><ul><li>Retire from the office but not from work. </li><li>Eliminate the office stress and the commute. </li><li>Choose the work you would like to do now. </li><li>Customize your schedule - full or part time. </li><li>Continue to earn an income. </li><li>Utilize your years of insurance industry knowledge. </li><li>Be part of our dynamic yet virtual team environment and connect with other experienced insurance professionals like yourself!<br/><br/></li></ul><strong>How To Get Started<br/><br/></strong>Click <strong><em>APPLY NOW</em></strong> to complete our simple preliminary profile. Be sure to include your preferred contact information as one of our Qualification Specialists will connect with you promptly.<br/><br/><strong>WE LOOK FORWARD TO MEETING YOU!</strong>
</div>",No Salary Info Found,Data Modeler
Junior Data Engineer (US),Fitness Matrix Inc,12/25/2023,https://www.linkedin.com/jobs/view/3793120666,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Engineer / Python / Fully Remote,Motion Recruitment,12/21/2023,https://www.linkedin.com/jobs/view/3791482019,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Data Collection Analyst,Troutman Pepper,12/19/2023,https://www.linkedin.com/jobs/view/3751617781,0,https://media.licdn.com/dms/image/D560BAQGq2iMHFI4n0Q/company-logo_100_100/0/1688391402890/troutman_pepper_logo?e=2147483647&v=beta&t=n3vuYnb8VV_Iv4DyBnR4nnrSz0iL49t_e8XOk53JHbs,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are always seeking talented, motivated, growth-minded, and creative individuals. Our firm is committed to providing employee support and advancement, while embracing inclusion and innovation as keys to a stronger future.<br/><br/>We invite you to explore the position below and to submit your application to join our team!<br/><br/>The Data Collection Analyst will support the firm’s lawyers and clients concerning technical aspects related to the preservation, collection, handling, processing, creation, maintenance, and support of client data, evidence, databases, and other related activities.<br/><br/><strong>Essential Duties And Responsibilities<br/><br/></strong><ul><li>Consult with clients, attorneys, and other team members regarding the preservation and collection of data from technology systems.</li><li>Utilize industry-leading software applications to perform data preservation, collection, and extraction activities, such as OpenText EnCase, Access Data FTK, BlackBag MacQuisition, Cellebrite, Oxygen Forensics, PinPoint Labs Harvester, X1 Social Discovery, Pagefreezer, Magnet Axiom, and other software applications common to the legal and technology industries.</li><li>Conduct remote and onsite collection interviews with client representatives.</li><li>Extract relevant data from collection sources as needed.</li><li>Manage data and documents, including maintaining accurate tracking logs for received and loaded data, maintaining a chain of custody, and creating an inventory of collected and received media for each project.</li><li>Conduct thorough analysis of data sources to ensure comprehensive collection and preservation of relevant information.</li><li>Perform quality control checks on collected data to ensure accuracy and adherence to established protocols.</li><li>Stay up to date with emerging technologies and industry trends related to data preservation and collection.</li><li>Assist in the development and implementation of best practices, standard operating procedures, and workflows for data collection processes.</li><li>Work with Project Managers to address matters or project-specific needs.</li><li>Provide application support and troubleshooting assistance to users.</li><li>Document and maintain activities in the project management database, including time spent on projects and project status.<br/><br/></li></ul><strong>Knowledge, Skills And Abilities<br/><br/></strong><ul><li>Ability to travel as necessary to collect data.</li><li>Demonstrated knowledge of emerging technologies and industry trends related to data preservation and collection.<br/><br/></li></ul><strong>Education And/or Experience<br/><br/></strong><ul><li>Education and/or combination of training and relevant experience to perform core responsibilities of the position.</li><li>Experience with industry-leading software applications for data preservation, collection, and extraction activities beneficial, such as OpenText EnCase, Access Data FTK, BlackBag MacQuisition, Cellebrite, Oxygen Forensics, PinPoint Labs Harvester, X1 Social Discovery, Pagefreezer, Magnet Axiom, and other software applications common to the legal and technology industries.<br/><br/></li></ul>The Firm will comply with any applicable city or state workplace mandates in effect in regards to Covid-19.<br/><br/><em>This position description is intended to describe the general content of and requirements for the performance of the job. The statements contained in the position description are not necessarily all-inclusive and additional duties and responsibilities may be assigned as determined by business needs.<br/><br/></em><em>This position description does not constitute a written or implied contract of employment.<br/><br/></em><em>Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br/><br/></em><strong>California Applicants: </strong>Please visit our Privacy Notice and Notice at Collection to learn about our information practices in the Job Application and Employment context.<br/><br/><strong>Equal Employment Opportunity<br/><br/></strong>Troutman Pepper adheres to a policy of equal opportunity and will make all employment decisions, which include hiring, promotion, transfer, demotion, evaluation, compensation and separation, without regard to race, color, religion, sex, age, sexual orientation, gender identity or expression, national origin, pregnancy, citizenship, disability, genetic information, marital or armed forces status and any other classification as protected by law.<br/><br/><strong>Compensation is dependent on several factors, such as position, location, education, training, and/or experience.<br/><br/></strong><strong>Hiring Salary Range<br/><br/></strong>$50,000.00 - $70,000.00<br/><br/>
</div>",$50000.00- $70000.00,Data Modeler
"Staff Data Engineer, Data Products (Contract)",SoFi,12/19/2023,https://www.linkedin.com/jobs/view/3759867882,0,https://media.licdn.com/dms/image/C560BAQH0xjWQVXJr6w/company-logo_100_100/0/1630660955481/sofi_logo?e=2147483647&v=beta&t=FVZG0dNVAhdZ-W3Op_NDxjxwWCaIzunudLIIydaqJQI,"Claymont, DE","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Employee Applicant Privacy Notice<br/><br/></strong><strong>Who we are:<br/><br/></strong>Shape a brighter financial future with us.<br/><br/>Together with our members, we’re changing the way people think about and interact with personal finance.<br/><br/>We’re a next-generation fintech company using innovative, mobile-first technology to help our millions of members reach their goals. The industry is going through an unprecedented transformation, and we’re at the forefront. We’re proud to come to work every day knowing that what we do has a direct impact on people’s lives, with our core values guiding us every step of the way. <strong>Join us to invest in yourself, your career, and the financial world.<br/><br/></strong><strong>Team: <br/><br/></strong>SoFi is seeking an experienced and motivated Staff Data Engineer to drive high standard technical solutions for the Data Products team within the Data Enablement division. The mission of the Data Enablement division is to activate data throughout SoFi, enabling the creation of personalized and delightful experiences for our members. The Data Enablement division is responsible for Data Platform, Data Products, and Data Governance for all of SoFi. As the technical leader for the Data Products group, you will lead the vision and strategy to build foundational and critical data products, such as members' 360, members' time series etc., which are highly leveraged across SoFi for analytical, reporting, and machine learning use-cases. Our goal is to empower all teams at SoFi to make data driven decisions and effectively measure their results by providing high quality, high availability data, and democratized data access through self-service tools.<br/><br/><strong>Role:<br/><br/></strong>A talented, enthusiastic, detail-oriented, and experienced Data Engineer who knows how to take on big data challenges in an agile way. This includes big data design and analysis, data modeling, and development, deployment, and operations of big data pipelines. Leads development of some of the most critical data pipelines and data sets, and expands self-service data knowledge and capabilities. This role requires you to live at the cross section of data and engineering. You should have a deep understanding of data, analytical techniques, and how to connect insights to the business, and you have practical experience in insisting on the highest standards on operations in ETL and big data pipelines.<br/><br/><strong>What you’ll do:<br/><br/><br/></strong><ul><li>Design and develop robust data architectures and data pipelines to support data ingestion, processing, storage, and retrieval. Evaluate and select appropriate technologies, frameworks, and tools to build scalable and reliable data infrastructure.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically.</li><li>Collaborate with cross-functional teams, such as data scientists, software engineers, and business stakeholders, to understand data requirements and deliver solutions that meet business needs. Effectively communicate complex technical concepts to non-technical stakeholders.</li><li>Optimize data engineering systems and processes to handle large-scale data sets efficiently. Design solutions that can scale horizontally and vertically,</li><li>Enforce data governance policies and practices to maintain data integrity, security, and compliance with relevant regulations. Collaborate with data governance and security teams to implement robust data protection mechanisms and access controls.<br/><br/><br/></li></ul><strong>What you’ll need:<br/><br/><br/></strong><ul><li>A bachelor's degree in Computer Science, Data Science, Engineering, or a related field;</li><li>Over 8 years of experience in data engineering and analytics technical strategy. </li><li>Proficiency in data engineering tech stack; Snowflake / PostgreSQL / Python / SQL / GitLab / AWS / Airflow/ DBT and others..</li><li>Proficiency in relational database platforms and cloud database platforms such as Snowflake, Redshift, or GCP</li><li>Strong in Python and/or another data centric language. </li><li>Thorough knowledge of data modeling, database design, data architecture principles, and data operations.</li><li>Strong analytical and problem-solving abilities, with the capability to simplify complex issues into actionable plans.</li><li>Experience in the Fintech industry is advantageous.<br/><br/><br/></li></ul><em><strong>Due to the temporary nature of the engagement, this position is not eligible for visa sponsorship.<br/><br/></strong></em><strong>Compensation And Benefits<br/><br/></strong>The base pay range for this role is listed below. Final base pay offer will be determined based on individual factors such as the candidate’s experience, skills, and location.<br/><br/>To view all of our comprehensive and competitive benefits, visit our <strong>Benefits at SoFi </strong>page!<br/><br/>SoFi provides equal employment opportunities (EEO) to all employees and applicants for employment without regard to race, color, religion (including religious dress and grooming practices), sex (including pregnancy, childbirth and related medical conditions, breastfeeding, and conditions related to breastfeeding), gender, gender identity, gender expression, national origin, ancestry, age (40 or over), physical or medical disability, medical condition, marital status, registered domestic partner status, sexual orientation, genetic information, military and/or veteran status, or any other basis prohibited by applicable state or federal law.<br/><br/>The Company hires the best qualified candidate for the job, without regard to protected characteristics.<br/><br/>Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.<br/><br/>New York applicants: Notice of Employee Rights<br/><br/>SoFi is committed to embracing diversity. As part of this commitment, SoFi offers reasonable accommodations to candidates with physical or mental disabilities. If you need accommodations to participate in the job application or interview process, please let your recruiter know or email accommodations@sofi.com.<br/><br/>Due to insurance coverage issues, we are unable to accommodate remote work from Hawaii or Alaska at this time.<br/><br/><strong>Internal Employees<br/><br/></strong>If you are a current employee, do not apply here - please navigate to our Internal Job Board in Greenhouse to apply to our open roles.
      </div>",No Salary Info Found,Data Modeler
Data Modeler,Customers Bank,12/19/2023,https://www.linkedin.com/jobs/view/3756321662,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Jr PL/SQL Database Developer,"Liberty Personnel Services, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3790916768,0,https://media.licdn.com/dms/image/C4D0BAQHWiMsOZMSj5A/company-logo_100_100/0/1631302210691?e=2147483647&v=beta&t=p9ZoyWf9trkRrK_ERp9edKNUYDKwpQAGdhpMU19-QrI,"King of Prussia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Job Details:<br/><br/>Jr PL/SQL Database Developer<br/><br/>My client has hired me to find for them a Jr PL/SQL Database Developer. In this role you will develop and support PL/SQL code. Any experience with database indexes and sequences would be a plus. If interested please forward your resume in word or pdf format to kevin@libertyjobs.com<br/><br/>#associate<br/><br/>#mid-senior<br/><br/>#pl/sql
      </div>",No Salary Info Found,Data Modeler
"Principal Associate, Data Loss Prevention (DLP) Engineer",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3789004010,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Database Engineer,"TherapyNotes, LLC",12/20/2023,https://www.linkedin.com/jobs/view/3790741562,0,https://media.licdn.com/dms/image/C560BAQHk534swhxYxA/company-logo_100_100/0/1631336152588?e=2147483647&v=beta&t=o_OU5U6n9oRGFMMNBn3vuTa0ALb9DpG4xeI1Vn818to,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><strong>Description<br/><br/></strong></strong><strong>About TherapyNotes<br/><br/></strong>TherapyNotes is a national leader in behavioral health Practice Management and Electronic Health Records (EHR) software. Our software-as-a-service (SaaS) solution is at the forefront of innovation, seamlessly integrating patient scheduling, medical records, billing, and electronic claims to revolutionize how mental health professionals manage their practices.<br/><br/>At TherapyNotes, we are a growing team of passionate and talented individuals. Our team thrives on collaboration and innovation, continually pushing the boundaries of what EHR software can do. We pride ourselves on our ability to adapt to the ever-evolving landscape of healthcare and technology, staying at the forefront of industry trends.<br/><br/>We believe in pushing each other to learn and solve complex problems, fostering an environment where your skills and expertise will flourish. Together, we are shaping the future of behavioral health software, making it easier for clinicians to provide the best possible care to their patients.<br/><br/>If you are passionate about technology, mental health, and making a difference, TherapyNotes is the place where you can realize your potential.<br/><br/><strong>Description<br/><br/></strong>TherapyNotes is seeking an experienced database professional to join our growing team. The right candidate will have extensive experience with PostgreSQL databases, both on-premise and in the cloud. They will be comfortable working in a highly collaborative, DevOps culture working across the technology organization.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Responsible for implementing, and maintaining critical database systems (PostgreSQL) which support a growing 24x7 SAAS platform</li><li>Supports the ongoing database reporting and analytical needs of the organization</li><li>Ensures the database design and operations support the availability, scalability, and recoverability needs of the business</li><li>Performs tuning and capacity management to ensure the database meets the performance needs of the business</li><li>Guides and provides direction to developers and engineers on database development, design principles, query optimization, and index management in a fully automated deployment pipeline</li><li>Ensures all infrastructure solutions and operational activities adhere to the security and operating policies established by the organization</li><li>Provides on-call coverage for production support and other duties as required<br/><br/></li></ul>Requirements<br/><br/><ul><li>BS degree in Information Systems, Data Engineering, Data Sciences or equivalent</li><li>3+ years experience with relational database administration</li><li>3+ years experience administering highly-available PostgreSQL databases</li><li>Proficiency in Linux-based PostgreSQL RDBMS database administration, architecture, concepts, features, and high-availability technologies</li><li>Proficiency in data science principles such as warehousing, business intelligence reporting, and predictive analytics</li><li>Proficiency in query optimization, indexing knowledge, modeling basics, materialized views, triggers, stored procedure development, and partitioning</li><li>Proficiency in SQL and experience in any scripting language (e.g. PowerShell, Bash, Python)</li><li>Experience with .NET database clients using NpgSQL a plus</li><li>Proficiency with DevOps, Infrastructure as Code (IaC) strategies, and variable workload (container) orchestration</li><li>Proficiency with ITIL and/or ITSM principles<br/><br/></li></ul>Competencies<br/><br/><ul><li> Project Management - Develops project plans, coordinates projects, communicates changes and progress, completes projects on time and budget, and manages project team activities.</li><li> Innovation - Displays original thinking and creativity, meets challenges with resourcefulness. generates suggestions for improving work, develops innovative approaches and ideas, and presents ideas and information in a manner that gets others' attention.</li><li> Problem Solving - Identifies and resolves problems in a timely manner, gathers and analyzes information skillfully, develops alternative solutions, and works well in group problem solving situations. <br/><br/></li></ul><strong><strong>Benefits<br/><br/></strong></strong><ul><li>Competitive salary - $75,000-$115,000</li><li>Comp-time and flexible work hours</li><li>Full health, life, disability, and dental insurance</li><li>Retirement plan with company contribution</li><li>Annual company profit sharing</li><li>Personal development/training budget</li><li>Open, collaborative work environment</li><li>Extensive 2-week onboarding plan</li><li>Comprehensive mentorship program</li><li>Company provided refreshments<br/><br/></li></ul>TherapyNotes, LLC is an Equal Employment Opportunity Employer. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. All candidates whom have been given a conditional offer of employment with TherapyNotes, LLC must also undergo a criminal background check.<br/><br/><em><strong>12/20/2023<br/><br/></strong></em>
</div>",$75000- $115000,Data Modeler
System Engineer (Combat) - Intern,Lockheed Martin,12/21/2023,https://www.linkedin.com/jobs/view/3786770884,0,https://media.licdn.com/dms/image/C4E0BAQHF1YKEZdN4LA/company-logo_100_100/0/1668532986109/lockheed_martin_logo?e=2147483647&v=beta&t=MAt3FDVkp1mxAnqi-7a-mmVAi8Lcd_S1_XvT0Y_Z40s,"Mount Laurel, NJ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description:</strong>At Lockheed Martin Rotary and Mission Systems, we are driven by innovation and integrity. We believe that by applying the highest standards of business ethics and visionary thinking, everything is within our reach – and yours as a Lockheed Martin employee. Lockheed Martin values your skills, training, and education. Come and experience your future!<br/><br/>The Systems Engineer will be responsible for analysis, design, integration, and test. Tasking will include development of mission critical software &amp; hardware requirements. The candidate will be responsible for development of requirements using SysML diagrams and constructs. The candidate will be responsible for completion of systems engineering related tasks to meet cost and schedule.<br/><br/><strong>Basic Qualifications<br/><br/></strong>– Pursuing a B.S. in Systems Engineering, Electrical Engineering, Aerospace Engineering, Mechanical Engineering, Computer Science/Engineering, Mathematics, Physics or equivalent.<br/><br/>– Experience in an Agile workflow environment.<br/><br/>– Ability to obtain and maintain a Secret Security Clearance.<br/><br/><strong>Desired Skills<br/><br/></strong><ul><li> Experience with use of Unix, Linux, Python, C++, Java or MATLAB.</li><li> Able to work independently or as a member of a team.</li><li> Understanding of Model-Based System Engineering (MBSE) and associated tools like Rational Rhapsody and/or Cameo<br/><br/></li></ul><strong>Security Clearance Statement: </strong>This position requires a government security clearance, you must be a US Citizen for consideration.<br/><br/><strong>Clearance Level: </strong>Secret<br/><br/><strong>Other Important Information You Should Know<br/><br/></strong><strong>Expression of Interest: </strong>By applying to this job, you are expressing interest in this position and could be considered for other career opportunities where similar skills and requirements have been identified as a match. Should this match be identified you may be contacted for this and future openings.<br/><br/><strong>Ability to Work Remotely: </strong>Onsite Full-time: The work associated with this position will be performed onsite at a designated Lockheed Martin facility.<br/><br/><strong>Work Schedules: </strong>Lockheed Martin supports a variety of alternate work schedules that provide additional flexibility to our employees. Schedules range from standard 40 hours over a five day work week while others may be condensed. These condensed schedules provide employees with additional time away from the office and are in addition to our Paid Time off benefits.<br/><br/><strong>Schedule for this Position: </strong>4x10 hour day, 3 days off per week<br/><br/><strong>Lockheed Martin is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, pregnancy, sexual orientation, gender identity, national origin, age, protected veteran status, or disability status.<br/><br/></strong><strong>The application window will close in 90 days; applicants are encouraged to apply within 5 - 30 days of the requisition posting date in order to receive optimal consideration.<br/><br/></strong>At Lockheed Martin, we use our passion for purposeful innovation to help keep people safe and solve the world's most complex challenges. Our people are some of the greatest minds in the industry and truly make Lockheed Martin a great place to work.<br/><br/>With our employees as our priority, we provide diverse career opportunities designed to propel, develop, and boost agility. Our flexible schedules, competitive pay, and comprehensive benefits enable our employees to live a healthy, fulfilling life at and outside of work. We place an emphasis on empowering our employees by fostering an inclusive environment built upon integrity and corporate responsibility.<br/><br/>If this sounds like a culture you connect with, you’re invited to apply for this role. Or, if you are unsure whether your experience aligns with the requirements of this position, we encourage you to search on Lockheed Martin Jobs, and apply for roles that align with your qualifications.<br/><br/><strong>Experience Level: </strong>Co-op/Summer Intern<br/><br/><strong>Business Unit: </strong>RMS<br/><br/><strong>Relocation Available: </strong>Possible<br/><br/><strong>Career Area: </strong>Systems Engineering: Design and Verification<br/><br/><strong>Type: </strong>Part-Time<br/><br/><strong>Shift: </strong>First
      </div>",No Salary Info Found,Data Modeler
Data Analyst (Remote),Matlen Silver,12/21/2023,https://www.linkedin.com/jobs/view/3789457343,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Modeler
Staff Pipeline Engineer - Pipelines (Houston),Burns & McDonnell,12/24/2023,https://www.linkedin.com/jobs/view/3466668066,0,https://media.licdn.com/dms/image/C4E0BAQEveKxwPamlHA/company-logo_100_100/0/1630564643406/burns__mcdonnell_logo?e=2147483647&v=beta&t=-7SsM3ebmLibRpt7AWCo9tNDqKi0WPyRQQktDUK7ccc,"Houston, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>The Staff Mechanical / Process Engineer will work with the project team to create world class designs for new projects, alterations and redevelopments on a variety of oil and gas projects including pipelines, compressor, meter and pump stations and other areas related to the industry. The Staff Mechanical Engineer will work with the project team throughout the design and construction process, adapting mechanical plans according to budget constraints, design factors or client needs.<br/><br/><ul><li>Perform mechanical design of projects from the conceptual phase through design completion.</li><li>Perform Simulations to get the project moving. The simulations will be performed in most cases using Aspen One program, AFT products, etc.</li><li>Modify and review production drawings for a variety of projects including, but not limited to pipelines, pump and compressor stations, chemical and renewable energy projects.</li><li>Design mechanical components for project needs and requirements that are set forth by the project managers.</li><li>Applies strong knowledge of commonly used mechanical engineering/design concepts, principles, practices, codes, and procedures within the mechanical engineering services industry.</li><li>Research and compile project related data as required by the project managers.</li><li>Update drawings provided by senior engineers to verify corrections are made within multiple CAD related software.</li><li>Compiles information for client presentations, shop drawing review, and contract administration.</li><li>Create Project Specifications (Piping Specificaitons).</li><li>Create datasheets for the procurement packages.</li><li>Create Procurement Packages Request for Quotes, perform bid evaluations and recommend vendors.</li><li>Review production drawings, 3D Model, ISO drawings, etc.</li><li>Work closely with other disciplines (Piping, Elelctrical, I&amp;C, Structural and Civil).</li><li>Review Vendor drawings.</li><li>Attend meetings with clients as needed.</li><li>Performs field inspections, measurements or calculations for public and private clients.</li><li>Field assignment will be possible.</li><li>All other duties as assigned.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Bachelor of Science in Mechanical Engineering or related degree from an ABET accredited program.</li><li>Or Bachelor of Science in Mechanical or related Engineering Technology from an ABET accredited program and successful completion of Fundamentals of Engineering (FE) exam.</li><li>Master of Science degree in Mechanical Engineering may be substituted for 1 year experience.</li><li>4 years to 5 years of mechanical engineering experience, consulting.</li><li>Successful completion (i.e.passing) FE or EIT preferred.</li><li>Strong knowledge in standard engineering techniques and procedures.</li><li>Excellent written and verbal communication skills.</li><li>Ability to work methodically and analytically in a quantitative problem-solving environment and demonstrated critical thinking skills.</li><li>Proficient in standard engineering techniques and procedures.</li><li>Strong computer skills (e.g. Microsoft Office Suite)</li><li>Strong computer skills include AutoCAD, Equipment Sizing Programs.</li><li>Strong attention to detail, facilitation, team building, collaboration, organization and problem-solving skills.<br/><br/></li></ul>EEO/Minorities/Females/Disabled/Veterans<br/><br/><strong>Job</strong> Engineering<br/><br/><strong>Primary Location</strong> US-TX-Houston<br/><br/><strong>Schedule:</strong> Full-time<br/><br/><strong>Travel:</strong> Yes, 15 % of the Time<br/><br/><strong>Req ID:</strong> 225858 <strong>Job Hire Type</strong> Experienced<br/><br/>#T&amp;D<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
Continuous Improvements Engineer,Jobot,12/23/2023,https://www.linkedin.com/jobs/view/3791013834,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer,Nikkiso Clean Energy & Industrial Gases,12/19/2023,https://www.linkedin.com/jobs/view/3770753789,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer,HireStrong,12/19/2023,https://www.linkedin.com/jobs/view/3790324104,0,https://media.licdn.com/dms/image/C560BAQFRSMIMe47YGw/company-logo_100_100/0/1630636259993/hirestrong_logo?e=2147483647&v=beta&t=voHU9aly9pWDUcMx2IrKGo-vym7djOk6KtMLMmOQgHc,"Houston, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><u>Hybrid Work Schedule (Monday/Friday Work From Home)</u></strong></p><p><br/></p><p><br/></p><p><strong>Project Mechanical Engineer specializing in Compressor &amp; Electrolyzer equipment packages </strong>to perform all tasks related to detailed design/engineering/project management and delivery of piston/diaphragm compressor packages and electrolyzers starting from project handover to final shipment and invoicing. A thorough understanding of reciprocating compressor operation fundamentals and major accessory equipment sizing and selection knowledge is essential for this position. Any chemical or process engineering background is needed as it will help with electrolyzer design and engineering.</p><p><strong> </strong></p><p><br/></p><p><strong>Job Qualifications: </strong></p><p>To perform this job successfully, an individual must be able to perform each job responsibility satisfactorily. The requirements listed below are representative of the knowledge, skill, and/or ability preferred. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.</p><p><strong> </strong></p><p><br/></p><p><strong>Education &amp; Experience</strong>:</p><p>• Bachelor of Science in Engineering: Mechanical Engineer / Chemical Engineer</p><p>• 2 + years of engineering experience</p><p>• Experience with reciprocating compressor package and/or electrolyzer package design &amp; engineering</p><p>• Exposure to design/engineering and order execution in a custom engineered oil &amp; gas machinery/product packaging environment</p><p>• Exposure to chemical and/or process equipment packages</p><p>• Process engineering background</p><p>• Exposure to standards such as ASME B31.3, API-618</p><p><br/></p><p><br/></p><p><strong> </strong></p><p><strong>Essential Job Responsibilities</strong>:</p><p>• Detailed design &amp; engineering of compressor &amp; electrolyzer packages.</p><p>• Review of customer provided project specifications.</p><p>• Coordinate preparation of engineering documentation such as P &amp; I drawings, general arrangement drawings, foundation detail and fabrication packages with CAD designers. Ensure that drawings are trued to “as-sold” project scope of supply.</p><p>• Prepare purchase specifications for various accessory equipment such as pressure vessels, heat exchangers, rectifiers, motors, utility &amp; process pumps, control valves, safety valves etc.,</p><p>• Review skid package layout and equipment with respect to customer needs while keeping in mind requirements of operation &amp; maintenance.</p><p>• Engage with fellow team members to ensure that customer comments have been picked up on drawing submittals prior to re-submission.</p><p>• Participate in technical clarification meeting with both customers and accessory equipment suppliers as needed.</p><p>• Engage with company factories to obtain compressor related engineering information.</p><p>• Engage with electrolyzer business team as required to obtain design data required for designing the electrolyzers.</p><p>• Support CAD and Instrument teams as required by identifying missing engineering information and follow-up with other teams/vendors etc. and provide it.</p><p>• Learn and follow company methodology for skid design and manufacturing requirements.</p><p>• Participate in internal and external kick-off meetings, engineering meetings and other meetings with customers.</p><p><br/></p><p><br/></p><p><strong>Engineering Documentation/Project Management Responsibilities: </strong></p><p>• Be self-sufficient to create project specific custom engineering documentation such as QA/QC plans etc.,</p><p>• Be self-sufficient to create project progress reports, documentation excel list, transmittal requests etc. as required.</p><p>• Populate MS excel sheets provided by customer to satisfy documentation scope requirements.</p><p>• Populate MS Excel/MS word customer data sheets to satisfy engineering requirements.</p><p>• Interface with logistics, procurement, and other disciplines including companies/factories to support project needs.</p><p>• Interface with Project Operations team in bi-weekly project schedule and budget update meetings.</p><p>• Review and approve content and documentation in final installation and operation manual.</p><p><br/></p><p><br/></p><p><strong>Procurement Responsibilities: </strong></p><p>• Apply company engineering standards for inquiring all accessory equipment such as pressure vessels, heat exchangers, piping components, oil system components (pumps, filters, valve etc.,), water systems (pumps, filters, valve etc.,), safety valves, control valves etc.,</p><p>• Create and release BOM line item/request for quotation in SAP for equipment listed in A) above.</p><p>• Create bid tabulations from quotes received from sub-suppliers and make purchase recommendations.</p><p><br/></p><p><br/></p><p><strong>Compensation &amp; Benefits: </strong></p><p>• Commensurate compensation bases on education &amp; experiences</p><p>• Company paid 100% premium cost for Medical/Dental/Vision</p><p>• Paid time off package</p><p>• Retirement Plan 401K &amp; <strong>Profit Sharing</strong></p><p>• Life insurance and AD&amp;D</p><p>• Short-Term &amp; Long-Term Disability</p><p>• Employee Assistance Program</p>
</div>",No Salary Info Found,Data Pipeline Engineer
Processing Project Engineer,"fairlife, LLC",12/19/2023,https://www.linkedin.com/jobs/view/3773978179,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer,"Relevant Industrial, LLC",12/19/2023,https://www.linkedin.com/jobs/view/3790342281,0,https://media.licdn.com/dms/image/C560BAQHr6NPjw54xUQ/company-logo_100_100/0/1676660533044/relevantsolutionsllc_logo?e=2147483647&v=beta&t=GfHDYIxD-aH4V9orXuW3U7mnKNUxoMLZ8N_Y2pXJhQ4,"Houston, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>This is a Project Engineer that is responsible for providing technical support and working among the engineering team to implement process automation projects in relation to SCADA (Supervisory Control and Data Acquisition) scope, within the Instrumentation and Automation business unit.</p><p>The Project Engineer will work with the Project Manager and the engineering team for multiple projects of varying scope including SCADA design &amp; software programming, supervise the procurement of materials &amp; assembly, configuring, testing, deploying, assist in startup, commissioning and perform SAT.</p><p>The primary responsibility is to assure that the completed project meets or exceeds the expectations of our clients from the perspectives of functionality and quality.</p><p><br/></p><p><u>Responsibilities for this position include but are not limited to:</u></p><ul><li>Develop the drawings for control panel design and bill of material.</li><li>Design and certification of various standards like UL, IEC and other safety regulative.</li><li>Design of SCADA subsystems for integration into the overall SCADA system.</li><li>Design and release for production and service.</li><li>Hardware engineering includes control panel design, electrical design, skid design.</li><li>Software engineering including control code, HMI/SCADA configuration, network development, etc.</li><li>Develop the SCADA communication data flow and protocols. Including:</li><li>SCADA system design, setup and verification</li><li>Creating custom code using built in SCADA scripting engines</li><li>Creating custom control code using VBA, C and Python programming languages</li><li>Configuring servers and databases</li><li>Configuration, maintenance and querying of SQL servers</li><li>Programming SQL</li><li>Creating custom data reports</li><li>SCADA alarm management configuration and implementation</li><li>PLC/SCADA programming</li><li>Interfaces management (including programming and testing)</li><li>Implementing customer specific applications</li><li>HMI software design</li><li>Compile standard HMI &amp; Application libraries.</li><li>Factory Acceptance Testing (planning, implementation and reporting).</li><li>Work with the engineering team on multiple concurrent projects.</li><li>Act as a direct technical resource for Project Management Team.</li><li>Participate in the development of engineering standards.</li><li>Technically understanding our customer requirements and ensuring that a solution is designed and implemented in a methodical manner utilizing industry best practices.</li><li>Manage and co-ordinate the planning, definition and provision of system engineering project lifecycle deliverables.</li><li>Provide direction of project planning, technical management and implementation.</li><li>Review the work product of the project engineering team to assure conformance to design standards.</li><li>Deliver assigned activities within agreed timescales and budgeted costs.</li><li>Participate in project meetings to assure quality and timeliness of project deliverables.</li><li>Provide regular updates to the Project leadership team on project progress and escalate as necessary to remove issues.</li><li>Interact with customers, both internal &amp; external, to assure performance and quality meets or exceeds expectations.</li><li>Interface with site personnel, IT, vendors, etc. to resolve issues.</li><li>Support systems via remote computer access, providing phone support for on-site operations.</li><li>Assist in providing training on plant SCADA systems.</li><li>Develops plans, specifications and reports for complex projects.</li><li>Occasionally supervises and schedules the work of other team members.</li><li>Resolve design problems that may include performing field investigation or inspections, detailed design work and detailed checking of design computations.</li><li>Drive business case optimization and value engineering initiatives for SCADA offerings.</li></ul><p><br/></p><p>Typical control system platforms used by Relevant include:</p><ul><li>Allen-Bradley Logix family of controllers</li><li>Emerson (formerly GE) PACSystems, Rx3i, RSTi and Versamax</li><li>Emerson PAC Machine Edition</li><li>Emerson PACEdge</li><li>Emerson PACMotion Servos and VFDs</li><li>Emerson Movicon, NEXT SCADA/HMI</li><li>SmartSights-Win911 and XLReporter</li><li>Rockwell Factory Talk HMI/SCADA</li><li>Honeywell Experion HS/LS (C300)</li><li>Honeywell HC-900</li><li>Siemens S7/300 &amp; S7/400</li><li>Siemens SIMATIC HMI/SCADA</li><li>GE PAC Systems / Versamax</li><li>GE Cimplicity/Movicon HMI/SCADA</li></ul><p><br/></p><p>Typical applications / markets supported by Relevant include:</p><ul><li>Warer/Waste Municipal Control System</li><li>Burner Management System</li><li>Power Generation and Distribution</li><li>Natural Gas Distribution</li><li>Chemical Processing</li><li>Pharmaceutical and Biomedical Applications</li><li>Fired Equipment Control (Burner Management, Boiler Control, Combustion Control, Fuel Handling)</li><li>Gas Processing (Wellhead Control, Compression, Amine, Dehy, Refrigeration, fractionation, turbo-expansion, etc.)</li><li>Riser Tension Monitoring (for Spar and TLP type platforms)</li><li>Batch Chemical</li><li>Heat Treat</li><li>Manufacturing</li><li>Power Generation</li><li>Pulp &amp; Paper</li></ul><p><br/></p><p><br/></p><p><u>Education &amp; Experience:</u></p><ul><li>SCADA engineer to have a relevant degree such as bachelor’s and master’s degree in engineering, Electrical Engineering, Computer Science, Science, Technical, Education, Electronics, Computer Engineering, Computer, or Information Technology.</li><li>Total 5 to 10 years of experience in SCADA design, programming and implementation.</li><li>Have experience with programming in VBA, C and/or Python programming languages</li><li>Have experiece with configuring and interfacing with SQL databases</li><li>Have a good knowledge of AutoCAD, (Electrical &amp; Inventor) and any drawing tools.</li><li>Proven track record in programming leadership with PLCs and peripherals such as HMIs and SCADAs.</li><li>Knowledge and proficiency in operation and maintenance of MS Windows based computers, MS Office applications.</li><li>Have knowledge of RTU or telecommunication system.</li><li>Have good skill in Windows Server operating system.</li><li>Working knowledge of national electrical and safety codes and practices.</li><li>Must be self-motivated with the ability to work alone, with multiple teams consisting of operational staff, client managers, vendors, and contractors via on site presence, telephone, and email.</li></ul><p><br/></p><p><br/></p><p><u>Physical Requirements:</u></p><p><br/></p><p>The physical demands and work environment characteristics described herein are representative of those that must be met by an employee to successfully perform the essential functions of the job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essentials functions. While performing the duties of this job, the employee is frequently required to communicate verbally and in writing, sit at the computer for extended periods and multi-task, stand and walk regularly. The noise level is usually quiet to moderate. Noise levels may increase when working in the shop environment; proper PPE will be available.</p>
</div>",No Salary Info Found,Data Pipeline Engineer
Project Engineer,"Relevante, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3774786023,0,https://media.licdn.com/dms/image/D4E0BAQE0JUx9jruC3w/company-logo_100_100/0/1665756798145/relevante_logo?e=2147483647&v=beta&t=Zi9Fg-40Mmx05HDbCCKsgT29Fyynhc5e2ZpyUcFYbWM,"Baltimore, MD","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Salary: $ 82,500.00<br/><br/>We have partnered with a heavy industrial mechanical contractor company in the Baltimore, MD area to provide them with a Project Engineer. Please review the below description and let us know if you are interested.<br/><br/><strong>Prioritized Must Have Skills For The Project Engineer<br/><br/></strong>#1. Must have at least 2yrs of Construction exp either as a Mechanical Contractor or Prime Contractor in an Industrial Environment.<br/><br/>#2. Must have a thorough understanding of Plans and Specifications.<br/><br/>#3. Must be comfortable working on projects alone and be comfortable working directly with Clients.<br/><br/>#3. No more than 3 jobs in the past 10 years.<br/><br/><strong>Responsibilities Of The Project Engineer<br/><br/></strong><ul><li>Daily coordination with the Operations Manager (OM) to support current and upcoming projects in the field. </li><li>Assist with project buy-out for supplied materials, ensuring compliance with client specifications and industry standards. </li><li>Expedite the material deliveries of subcontractors and suppliers in accordance with the project schedule and coordinated with the project team. </li><li>Ensure project specifications are defined, and adhered to. Seek clarification through the RFI process and ensure drawings are up-to-date. </li><li>Manage specific budgets on a project-by-project basis within the company cost control system. </li><li>Accumulate all necessary data for monthly owner and subcontractor applications for payment. </li><li>Assist with pre-construction and progress meetings with clients and subcontractors, as appropriate. </li><li>Assist with estimating new opportunities, to include labor production, material take offs and quotes, and subcontractor pricing. </li><li>Maintain and complete a current record of submittals (when required), approvals and re-submittals. </li><li>Other duties, as assigned. <br/><br/></li></ul><strong>Projects<br/><br/></strong><ul><li>Establish a solid working relationship with each client that is assigned, that is founded on communication and understanding. </li><li>Communicate the work plan, any issues, and progress to the client within the time frame that fits their needs (daily, weekly, etc). </li><li>Communicate daily (or more often as needed) with on-site supervision to discuss the plan, needs, and progress of each job task and project. </li><li>Work with site supervision to develop and execute a construction plan for assigned projects, taking into account material and resource requirements, and working with the operations team to schedule those tasks accordingly. </li><li>Visit the project sites to understand each client’s business, facility layout, and project objectives. </li><li>Communicate all plans, progress, and issues to the PM and OM as they occur. <br/><br/></li></ul><strong>Estimating<br/><br/></strong><ul><li>Understand and execute the MAIC estimating procedure. </li><li>Apply the MAIC estimating procedure to new estimates that are assigned. </li><li>Accurately take off material quantities and solicit vendor quotes. </li><li>Accurately identify subcontractor scopes and solicit vendor quotes. </li><li>Estimate manpower, material costs, subcontractor costs, and equipment costs for each estimate assigned. </li><li>Craft proposal letters to clients, for specific estimates, including clarifications and exclusions. </li><li>Review all estimates with the PM and/or OM. <br/><br/></li></ul><strong>Engineering<br/><br/></strong><ul><li>Understand the mechanical construction environment, hazards, and pitfalls. </li><li>Understand the production capability for each assigned client. </li><li>Understand the installation techniques for rotating equipment.<br/><br/></li></ul><strong>Requirements Of The Project Engineer</strong> <br/><br/><ul><li>B.S. in Mechanical Engineering</li><li>2-5 Years previous construction experience, preferably as a Mechanical Contractor or Prime Contractor in an industrial environment. </li><li>Thorough understanding of plans and specifications.</li><ul><li>Layout drawings (plan and elevation views) </li><li>Process &amp; Flow Diagrams (P&amp;IDs) </li><li>Piping Isometric Drawings </li></ul><li>Scheduling and estimating experience are a plus. </li><li>Self-Starter – Ability to work alone on a project, and also as part of a team. </li><li>Effective written and verbal communication skills and organizational skills.<br/></li></ul><strong>Expectations Of The Project Engineer<br/><br/></strong><ul><li>Check in with assigned jobsite foremen daily (either over the phone, or in person). </li><li>Check in with Operations Manager daily (either over the phone or in person). </li><li>Visit each job site weekly, at a minimum, or as required based on project needs. </li><li>Photograph job progress (where allowed)</li><li>Record subcontractor progress (where applicable)</li><li>Submit salary timesheet to OM for review and approval, weekly. </li><li>Submit mileage reimbursement and expense reimbursement (as applicable).</li><li>FedEx delivery tickets, invoices, and any other paperwork to the Baltimore Office. </li><li>45-50 hours per week, on a weekly salaried basis. <br/><br/></li></ul><strong>Other Key Requirements<br/><br/></strong><ul><li>100% in office role with travel</li><li>No Visa or Sponsorships. No Corp-to-Corp.<br/><br/></li></ul><strong>Benefits Of The Project Engineer<br/><br/></strong><ul><li>Medical Insurance</li><li>Dental Insurance</li><li>Vision Insurance</li><li>Life Insurance</li><li>Short Term / Long Term Disability Insurance</li><li>401 (k) Plan<br/><br/></li></ul>About Relevante, Inc. – the Recruiting Firm Representing the Client for this Job<br/><br/>Relevante is an accounting &amp; technology direct hire recruiting and contract staffing firm. We help our Clients identify and recruit the best talent in the market and help our candidates win engaging and enriching jobs. Our Clients are some of the best companies to work for among F1000 and emerging fast growth companies in the region. Relevante has been consistently ranked as a fast growth company and one of the largest recruiting, accounting, and management consulting firms in the Philadelphia region. To stay connected with our network, please follow us on LinkedIn https://www.linkedin.com/company/relevante.<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
Assistant Project Engineer,PEC - Pacific Energy Concepts,12/20/2023,https://www.linkedin.com/jobs/view/3742698406,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Reliability Engineer - Material Handling,James Hardie,12/20/2023,https://www.linkedin.com/jobs/view/3758120457,0,https://media.licdn.com/dms/image/C4D0BAQEWSRQhpRuixg/company-logo_100_100/0/1630485405014/james_hardie_building_products_logo?e=2147483647&v=beta&t=5iTzJfdWVyYvucvsmj6BUv7fat8CBw2HCdOzrkeJLGg,"Cleburne, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        James Hardie Building Products Inc. is the North American leader in fiber cement home siding and exterior design solutions. Hardie® products offer long lasting beauty and endless design possibilities with trusted protection and low maintenance. The company pioneered modern fiber cement building products and continues to invest in innovation to transform the industry. James Hardie is a high-performance organization, with an unwavering commitment to Zero Harm. The company proudly employs a diverse workforce of over 3,000 employees across operations in North America.<br/><br/><strong>Make your dream career a reality. It’s possible!<br/><br/></strong>This is an exciting opportunity for an individual with a solid maintenance and reliability background to support improving James Hardie’s production results. The person in this role will be responsible for supporting reliability improvements across our ten US locations with a special focus on Precision Maintenance.<br/><br/>The Reliability Engineer will report to the Director of HMOS-Equipment Reliability. Preference would be that the successful candidate for the position will primarily located at one of our western plants. Estimated amount of travel for this position is 50% per month.<br/><br/><strong>What You’ll Do:<br/><br/></strong><ul><li>Provide technical expertise to sites with field application of precision maintenance techniques. Provide training, field coaching and mentoring of maintenance supervisors and craftsmen. </li><li>Deliver a strategic reliability-centered maintenance approach to optimizing asset life and productivity through documented asset strategies. </li><li>Reliability support for Post-Autoclave Process with Line Maintenance systems. </li><li>Develop plan to alleviate long term production challenges of our existing Finishing Lines to meet the needs of increased capacity on our sheet machines. </li><li>Partner and coordinate with Primary Equipment Supplier and Plant Personnel on equipment selection and continuous improvement of our processes. </li><li>Develop maintenance PM requirements through analysis of delay data. </li><li>Conduct criticality assessment on equipment and process lines and develop lubrication strategy. </li><li>Develop and implement best practices for assets to improve the mean time between failures (MTBF). </li><li>Utilize Root Cause Analysis processes to review significant failures, identify corrective action to prevent re-occurrence and refine asset strategy to sustain improvement. </li><li>Mine data to identify reliability improvement opportunities and develop corrective actions focused on delivering Net Hours improvement and cost reduction. </li><li>Develop engineering solutions to repetitive failures and all other problems that adversely affect plant operations. These problems include capacity, quality, cost or regulatory compliance issues. </li><li>Identifies deficiencies in maintenance processes and develop sustainable improvements. </li><li>Provide reliability technical support to Production, Maintenance, Engineering and Procurement activities. <br/><br/></li></ul><strong>What You’ll Bring:<br/><br/></strong><ul><li>Bachelor’s degree in Engineering (mechanical preferred)</li><li>5 or more years of experience with industrial manufacturing processes</li><li>5 or more years of project management skills</li><li>Experience with Material Handling Equipment </li><li>Ability to utilize Microsoft project and other project management tools. </li><li>Ability to lead cross-functional teams. </li><li>Strong technical expertise in applying Precision Maintenance techniques in industrial manufacturing processes. Strong knowledge of Precision Maintenance procedures. </li><li>Knowledge of equipment design and failure modes. Experience with interpreting forensic evidence to identify failure modes. </li><li>Facilitation experience with Root Cause Analysis. </li><li>Strong communication (written, oral and interpersonal) skills. </li><li>Ability to lead and be part of cross functional teams. </li><li>Experience with computer maintenance management systems (CMMS), INFOR BE or equivalent. </li><li>Advanced skills in basic personal computer software (Microsoft applications). </li><li>Previous experience in the development of a manufacturing reliability program is a plus, but not a requirement. <br/><br/></li></ul><strong>What You’ll Receive<br/><br/></strong><ul><li>At James Hardie, we recognize that our success depends on our people. We've worked hard to build a generous and competitive benefits program that demonstrates our commitment to our employees. </li><li>Comprehensive low-cost co-pay Health Insurance; medical, dental, prescription, and vision insurance benefits for every 30+ hour full-time employee. Insurance starts on day one!</li><li>401(k) Retirement plan that will match 100% of employees saved dollars up to the first 6% of your salary</li><li>Paid holidays, paid vacation including Jury Duty and bereavement leave</li><li>Wellness Program</li><li>Employee Assistance Program </li><li>Parental Leave</li><li>Community Involvement &amp; Sustainable Solutions - Fire Resistant Siding to Help Rebuild the Grizzly Flats Community | James Hardie</li><li>And more <br/><br/></li></ul><strong>Apply now and come “home” to Hardie!<br/><br/></strong><em>James Hardie Building Products Inc. is an equal opportunity employer, and all qualified applicants will receive consideration for employment without regard to race, color, gender, sex, age, national origin, religion, sexual orientation, gender identity/expression, genetic information, veteran's status, marital status, pregnancy, disability, or any other basis protected by law.<br/><br/></em>
</div>",No Salary Info Found,Data Pipeline Engineer
Senior Data Engineer,hackajob,12/20/2023,https://www.linkedin.com/jobs/view/3788691027,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Construction Project Engineer - 1627627,RightWorks,12/25/2023,https://www.linkedin.com/jobs/view/3793420109,0,https://media.licdn.com/dms/image/C560BAQELwSaU3RdMbw/company-logo_100_100/0/1656677171108/rightworksinc_logo?e=2147483647&v=beta&t=0wjo3_lSyatFQUjun1YyawzY4Mu8rBHRc2CzsUPvveU,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Who we are:<br/><br/></strong>We are seeking to hire a <strong>Project Engineer in Austin, TX</strong> to oversee the communications and documentation of our modular units inAustin, TX. Reporting to the Project Manager, the Project Engineer is responsible for the coordination of construction submittals and request for information documentation within the modular scope, as well as ensuring frequent progress communication with customers. The Project Engineer will work with the Project Managers and be assigned tasks set by them as needed.<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Primarily function as data keeper of project specific tasks. Control submittal approvals, RFI management, day to day correspondence.</li><li>Assist with material procurement, inventory and confirmation of materials on hand prior to production according to approved submittals.</li><li>Assist with, scheduling, budgeting and implementation of the project</li><li>Assist with the preparation of the schedule of values</li><li>Assist with project planning for approval by management</li><li>Assist with the preparation of project schedules with input from project staff and, if required, assistance from the Scheduling Department</li><li>Assist with change orders with client, architects and engineers</li><li>Complete all required reports</li><li>Assist with preparation of all Subcontracts, Purchase Orders, requisitions, proposals, etc.</li><li>Attend weekly OAC coordination meetings/calls.</li><li>Other duties as assignment by management.<br/><br/><br/></li></ul><strong>Job Requirements:<br/><br/></strong><ul><li>Bachelor’s degree in Building Science/Construction Management preferred</li><li>Must have a minimum of two years of commercial construction experience</li><li>Proficient computer skills in Microsoft Office</li><li>Ability to multi-task in a fast-paced environment</li><li>Strong written and oral communication skills</li><li>Strong analytical skills</li><li>Ability to work in a manufacturing construction environment utilizing degree in respective discipline </li><li>Regular, full-time, predictable onsite attendance per the posted schedule is an essential function of this role </li><li>Lead and promote health and safety work practices as required by regulatory agencies and company policy <br/><br/><br/></li></ul><strong>Benefits:<br/><br/></strong>We offer competitive compensation and excellent benefits, including low cost, high quality medical and dental benefits. In addition, we have an amazing tuition assistance program, a bonus plan, a 401(k) plan with a generous company match, immediate vesting and much more.<br/><br/><ul><li>Offer a 5% end of year company bonus instead of a personal performance bonus</li><li>Excellent pay and bonus potential</li><li>Paid time off and paid holidays off</li><li>Medical, dental, vision and life insurance</li><li>Flexible spending / health savings accounts</li><li>401(k) with company match</li><li>Tuition reimbursement</li><li>Scholarships</li><li>Supportive team atmosphere</li><li>Employee assistance program<br/><br/><br/></li></ul>
</div>",No Salary Info Found,Data Pipeline Engineer
Water/Wastewater Project Engineer,Ardurra,12/19/2023,https://www.linkedin.com/jobs/view/3558374911,0,https://media.licdn.com/dms/image/D560BAQFKRJQqut5eTg/company-logo_100_100/0/1702318387426/ardurra_logo?e=2147483647&v=beta&t=7zWlwWPaV--DCduWc_saIOLyvQlEdVA8vkxSgZofXqc,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Ardurra is seeking a <strong><em>Water/Wastewater Project Engineer </em></strong>to join our staff in <strong>Austin, TX</strong>.<br/><br/><strong>Primary Function<br/><br/></strong>Under general supervision, perform a variety of engineering tasks involving design work, research and preparation of drawings or designs, and construction administration of municipal water and wastewater facilities. Perform assignments of limited scope which require the application of standard techniques, procedures, and criteria in carrying out a sequence of related design engineering tasks. This includes limited experience in utilizing various computer software packages and automated engineering and design tools. The position will expose the successful candidates to a full range of water and wastewater facility projects. Projects may include water/wastewater treatment facility green field projects, process upgrades or rehabilitation projects, water distribution and storage systems, transmission pipelines, wastewater collection systems, pump stations, and other utility related projects.<br/><br/><strong>Primary Duties<br/><br/></strong><ul><li>Gathers data for engineering analyses through phone contacts, written correspondence, and research sources</li><li>Performs calculations and research for designs using engineering formulas and skills in formulating possible results based on different scenario</li><li>Assists in preparation of engineering reports, opinions and recommendations; Maintains completed project files and proper document control</li><li>Conducts experiments and data collection with emphasis on data integrity, quality control and protocol compliance; utilizes data acquisition/recording equipment and instrumentation. Performs field tests &amp; measurements, collects field data and processes data</li><li>Prepares statistical and narrative reports and/or graphs based on outcomes of research, analysis and interpretation of studies</li><li>Assists Project with project concept designs and participates in final project design</li><li>Designs portions of a project under supervision, including evaluating alternatives, conducting engineering studies and design calculations, and performing preliminary/detailed design</li><li>Assists with preparing design drawings, technical specifications, material quantity take-off and developing construction cost for projects</li><li>Assists with the research of funding opportunities/grants for clients and prospective clients; maintains data on funding sources and procedures for future reference</li><li>Provides other duties as may be assigned by the Project Managers/Task Leads to support project team<br/><br/></li></ul><strong>Education And Experience Requirements<br/><br/></strong><ul><li>B.S. degree in Civil Engineering or Environmental Engineering from an ABET accredited program university or college</li><li>8+ years of water/wastewater is required</li><li>PE license in the state of Texas required or ability to obtain within 6 months</li><li>Knowledge, experience, and ability to perform computer tasks with Bluebeam</li><li>Candidate must be self-motivated, able to work independently and with a project team to completion of a task</li><li>An attitude and commitment to being an active participant of our culture is a must</li><li>Excellent written and oral communication skills</li><li>Attention to detail, with a demonstrated capability to meet project budget and deadline</li><li>Strong analytical and problem-solving skills<br/><br/></li></ul><strong>Why Ardurra?<br/><br/></strong>While Ardurra offers competitive compensation and rich benefits programs, it is our culture that truly sets us apart from our peers. We nurture a family-like culture, striving to create a work environment that is enjoyable, challenging and rewarding but also fun. We are acutely focused on developing our staff, whether through our internal Ardurra Academy or through our industry-leading Leadership program. We have made a deliberate and focused commitment to nurture a people-centric culture where people are: valued as individuals; supported in their professional and career development with multiple, varied career paths; provided the tools and resources to be successful, engaged, and satisfied in their work; and positive benefits, time-off programs, and flexibility to help maintain a healthy balance between work and home.<br/><br/>Ardurra is an Equal Opportunity/ Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, gender identity or sexual orientation.<br/><br/><em>NOTICE TO THIRD PARTY AGENCIES:<br/><br/></em>Ardurra does not accept unsolicited resumes from recruiters or employment agencies. In the absence of a signed Agency Agreement, Ardurra will not consider or agree to payment of any referral compensation or recruiter fee. If a resume or candidate is submitted to any hiring manager without a previously signed agreement, Ardurra reserves the right to pursue and hire those candidate(s) without any financial obligation to the recruiter or agency. These candidates will be considered property of Ardurra. We’re not currently looking to add any more agencies to our list of approved vendors, so please do not contact any of our managers or recruitment team with sales calls or details of your candidates.<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
"Sr. Manufacturing Engineer, Drive Unit Stator",Tesla,12/19/2023,https://www.linkedin.com/jobs/view/3737832315,0,https://media.licdn.com/dms/image/C4D0BAQHUcu98SZ2TVw/company-logo_100_100/0/1630576446368/tesla_motors_logo?e=2147483647&v=beta&t=fFZSy_dnN_IDaC_6hHxOobiRkj_4lybAf3Nf5AalKTk,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>What To Expect<br/></strong><strong>The Role<br/><br/></strong>Tesla is seeking a highly motivated Senior Manufacturing Engineer to develop and engineer new processes and high-volume automation equipment with the Stator team in Austin, TX. These production lines include highly automated manufacturing systems to wind, varnish, and assemble stators into completed housing assemblies. The Senior Manufacturing Engineer works closely with Tesla’s internal Product Design, Supplier Industrialization, Operations, and Quality Engineering teams and coordinates cross-functional design activities with equipment suppliers to develop new Drive Unit manufacturing equipment. The Senior Manufacturing Engineers assume full ownership of the design and technical transfer of the line’s tools to Tesla Operations, qualifying them for use with the highest standards of safety, quality, and output.<br/><br/><strong>What You'll Do<br/><br/></strong><li>Generate process flow, failure mode effects analysis, and inspection methodology for new products.</li><li>Manage production line qualification procedures and documentation</li><li>Collaborate with Design, Supplier Industrial Engineering, Quality, and Operations</li><li>Provide design-for-manufacturing feedback to shape next-generation high volume products</li><li>Optimize product flow and line efficiency while reducing Capex and lead-time<br/><br/><br/></li><strong>What You'll Bring<br/><br/></strong><li>Experience with data analysis software (Minitab, JMP)</li><li>Experience generating process and product quality documentation</li><li>Strong hands-on experience with high-volume and pilot manufacturing</li><li>Proven track record of data driven methodology to solve complex problems</li><li>Bachelor's Degree in Mechanical or Mechatronics Engineering, or 5+ years relevant experience<br/><br/><br/></li><strong>Benefits<br/></strong><strong>Compensation and Benefits<br/></strong>Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:<br/><li> Aetna PPO and HSA plans &gt; 2 medical plan options with $0 payroll deduction</li><li> Family-building, fertility, adoption and surrogacy benefits</li><li> Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution</li><li> Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA</li><li> Healthcare and Dependent Care Flexible Spending Accounts (FSA)</li><li> LGBTQ+ care concierge services</li><li> 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits</li><li> Company paid Basic Life, AD&amp;D, short-term and long-term disability insurance</li><li> Employee Assistance Program</li><li> Sick and Vacation time (Flex time for salary positions), and Paid Holidays</li><li> Back-up childcare and parenting support resources</li><li> Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft &amp; legal services, and pet insurance</li><li> Weight Loss and Tobacco Cessation Programs</li><li> Tesla Babies program</li><li> Commuter benefits</li><li> Employee discounts and perks program<br/><br/><br/></li>Tesla
      </div>",$0- $0,Data Pipeline Engineer
"Launch Mechanical Design Engineer, Structural Battery Pack, Battery Engineering",Tesla,12/19/2023,https://www.linkedin.com/jobs/view/3737823691,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
"Rotating Equipment Engineer, Cell Materials Manufacturing",Tesla,12/19/2023,https://www.linkedin.com/jobs/view/3737830585,0,https://media.licdn.com/dms/image/C4D0BAQHUcu98SZ2TVw/company-logo_100_100/0/1630576446368/tesla_motors_logo?e=2147483647&v=beta&t=fFZSy_dnN_IDaC_6hHxOobiRkj_4lybAf3Nf5AalKTk,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>What To Expect<br/></strong>The Cathode maintenance team is expanding its scope of responsibility to include the design, maintenance, installation and management of all aspects of new manufacturing lines in order to support the overall mission of transforming the world to sustainable methods of transportation. You will work closely with internal stakeholders (infrastructure, equipment design team, process design team, automation, purchasing, and program management) and external contractors and vendors in order to deliver an integrated manufacturing solution. Review line layout concepts to finalize rotating equipment scope.<br/><br/><strong>What You'll Do<br/><br/></strong><li>Transform concept layouts / designs into fabrication &amp; installation drawings</li><li>Basic understanding of 3D design and finite element analysis as it pertains to rotating equipment.</li><li>Analyze vibration data on rotating equipment for improvements and repair</li><li>Identify and evaluate resources including design, and repair scopes with respect to rotating equipment.</li><li>Identify impacts to schedule and develop/implement actions to correct</li><li>Be able to work on rotating equipment; pumps, centrifugal compressors, screw compressors, cooling towers, screw feeders, gearboxes and other unique equipment. </li><li>Knowledgeable on basic process instrumentation; level, temperature and pressure transmitters.<br/><br/><br/></li><strong>What You'll Bring<br/><br/></strong><li>Bachelor’s degree or higher in Mechanical Engineering (or equivalent exp)</li><li>4+ years of industry experience in rotating equipment engineering (preferably in a manufacturing environment) (or equivalent exp)</li><li>Proficient in design and maintenance strategies of pumps and compressors</li><li>Knowledge of vibration analysis category I,II and III.</li><li>Proven experience in large scale construction management</li><li>Site safety management with respect to electrical installations (LOTO, commissioning procedures)</li><li>Experience creating project documentation, drawings, inspections, permits, etc<br/><br/><br/></li><strong>Benefits<br/></strong><strong>Compensation and Benefits<br/></strong>Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:<br/><li> Aetna PPO and HSA plans &gt; 2 medical plan options with $0 payroll deduction</li><li> Family-building, fertility, adoption and surrogacy benefits</li><li> Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution</li><li> Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA</li><li> Healthcare and Dependent Care Flexible Spending Accounts (FSA)</li><li> LGBTQ+ care concierge services</li><li> 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits</li><li> Company paid Basic Life, AD&amp;D, short-term and long-term disability insurance</li><li> Employee Assistance Program</li><li> Sick and Vacation time (Flex time for salary positions), and Paid Holidays</li><li> Back-up childcare and parenting support resources</li><li> Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft &amp; legal services, and pet insurance</li><li> Weight Loss and Tobacco Cessation Programs</li><li> Tesla Babies program</li><li> Commuter benefits</li><li> Employee discounts and perks program<br/><br/><br/></li>Tesla
      </div>",$0- $0,Data Pipeline Engineer
"Sr. Quality Engineer, Cell Manufacturing",Tesla,12/19/2023,https://www.linkedin.com/jobs/view/3737832448,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
"Engineering Specialist, Project Manager, or Engineer",Public Utility Commission of Texas,12/19/2023,https://www.linkedin.com/jobs/view/3763393385,0,https://media.licdn.com/dms/image/C4E0BAQHKyU_hbxPIXQ/company-logo_100_100/0/1630595331912/puctx_logo?e=2147483647&v=beta&t=1L3dHgkHGKPoAHJ58uvkr4kvw4Yk1Vp8rFLEcuVtNPk,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Work with us and make a difference in Texas! </strong></p><p>The Public Utility Commission regulates the state’s electric, telecommunication, and water and sewer utilities, implementing respective legislation and offering customer assistance in resolving customer complaints.</p><p><br/></p><p>We are committed to protecting customers, fostering competition, and promoting high quality utility infrastructure.</p><p><br/></p><p>Thank you for your interest in employment with the Public Utility Commission of Texas. We are committed to the recruitment and promotion of a character-driven, competent, productive and diverse workforce. Our employees come from a broad range of professional backgrounds, from attorneys and engineers to administrative support staff, united by their passion to be accountable to the people of Texas and provide equitable, efficient, and effective regulation in an increasingly competitive environment.</p><p><br/></p><p>We understand that motivated, knowledgeable staff are essential for the successful completion of our vital work. If you're ready to join our efforts to serve our fellow Texans by helping electric, water, sewer and telecom utilities attain and maintain compliance, we would love to hear from you. Working at the PUC will not only broaden your professional horizons, it will also make you part of a highly motivated, technically proficient and warmly collegial team of professionals. Apply today!</p><p><br/></p><p><strong>The BENEFITS Of Working At The PUC</strong></p><p>In addition to an affirming work environment and a family-oriented culture, we offer an array of attractive benefits to our employees. A summary of benefits can be found at https://www.puc.texas.gov/HumanResources/Home/Benefits</p><p><br/></p><p><strong>DIVISION – INFRASTRUCTURE </strong></p><p><strong>POSITION TYPE - </strong> This is a hybrid position and is eligible for telecommuting up to four (4) days a week.</p><p><br/></p><p>The Infrastructure Division works to ensure that customers have electricity, water and sewer, and certain telecom service readily available by addressing the ability of utilities and their infrastructure to meet customers’ need for adequate and continuous service. The division has three sections: Engineering, Infrastructure Analysis, and Mapping.</p><p><br/></p><p>The Engineering Section reviews and recommends routes for new electric transmission lines, electric utility requests to build new generating facilities, and requests for electric utility sales, transfers, and mergers. The section analyzes utilities’ cost of facilities, equipment, and supplies, the rate to allocate costs over their useful life, expenses to operate and maintain facilities, and funds set aside for emergency events. The section also addresses electric reliability and service quality issues and complaints about the cost of obtaining utility service.</p><p><br/></p><p>The Infrastructure Analysis Section addresses the need for water and electric utility service area changes as well as water utility purchases. In addition, the section addresses distressed water utilities, including the capital costs and operations and maintenance expenses incurred by temporary managers of those utilities; electric utility fuel and purchased power costs; electric utility energy efficiency programs designed to reduce customer energy use; electric utility advanced metering systems; and telephone area codes and other numbering resource issues.</p><p><br/></p><p>The Mapping Section uses geographic information system software to maintain boundary maps for water, sewer, and electric service areas; review water and sewer maps in applications that add or amend service area boundaries; respond to public and staff requests for electric and water data and maps; and maintain the state’s electricity supply chain map.</p><p><br/></p><p>The division is seeking an <strong>Engineering Specialist, Project Engineer or Engineer</strong> who has a desire to work in the utility regulatory industry, with a strong initiative, and would like to expand their knowledge, skills and experience performing routine to highly advanced engineering work on a broad range of infrastructure issues. Work involves applying engineering principles to evaluate engineering and other technical issues to include identifying, analyzing, and providing recommendations or testimony regarding issues related to facility planning, construction, operations, and maintenance in the electric and water industries, as well as some telecommunications infrastructure issues.</p><p><br/></p><p><strong>ANNUAL SALARY RANGES </strong></p><p><strong>Engineering Specialist III-VI: $70,008 to $100,008</strong></p><p><strong>Project Manager II-V: $75,000 to $115,008</strong></p><p><strong>Engineer III-VI: $80,004 to $115,008</strong></p><p><br/></p><p><strong>Qualifications</strong></p><p>The ideal candidate will have the following required minimum qualifications:</p><p><br/></p><p><strong>ENGINEERING SPECIALIST - all require </strong>graduation from an accredited four (4) year college or university with a bachelor or post-graduate degree in engineering.</p><p><strong>Engineering Specialist III</strong></p><p>No additional experience required.</p><p><strong>Engineering Specialist IV</strong></p><p>A minimum of two (2) years of full-time work experience in engineering related activities, field or system operations, or planning.</p><p><strong>Engineering Specialist V</strong></p><p>A minimum of four (4) years of full-time work experience performing electrical engineering related activities with an electric utility, electric cooperative or municipally owned electric utility.</p><p><strong>Engineering Specialist VI</strong></p><p>A minimum of six (6) years of full-time work experience performing electrical engineering related activities with an electric utility, electric cooperative or municipally owned electric utility.</p><p><br/></p><p><strong>PROJECT MANAGER - all require </strong>graduation from an accredited four (4) year college or university with a bachelor or post-graduate degree in engineering and a Texas Engineer In Training Certification.</p><p><strong>Project Manager II</strong></p><p>No additional experience required.</p><p><strong>Project Manager III</strong></p><p>A minimum of two (2) years of full-time work experience in engineering related activities, field or system operations, or planning.</p><p><strong>Project Manager IV</strong></p><p>A minimum of four (4) years of full-time work experience performing electrical engineering related activities with an electric utility, electric cooperative or municipally owned electric utility <strong>or </strong>seven (7) years of full-time work experience performing electrical engineering related activities with an electric utility, electric cooperative or municipally owned electric utility.</p><p><strong>Project Manager V</strong></p><p>A minimum of six (6) years of full-time work experience performing electrical engineering related activities with an electric utility, electric cooperative or municipally owned electric utility <strong>or </strong>eight (8) years of full-time work experience performing electrical engineering related activities with an electric utility, electric cooperative or municipally owned electric utility.</p><p><br/></p><p><strong>ENGINEER -all require</strong> graduation from an accredited four (4) year college or university with a bachelor or post-graduate degree in engineering, business with coursework in engineering, or related field and an active Professional Engineer (PE) License in Texas.</p><p><strong>Engineer III</strong></p><p>No additional experience required.</p><p><strong>Engineer IV</strong></p><p>A minimum of two (2) years of full-time work experience as a licensed PE performing electrical engineering related activities at an electric utility, electric cooperative or municipally owned electric utility.</p><p><strong>Engineer V</strong></p><p>A minimum of four (4) years of full-time work experience as a licensed PE performing electrical engineering related activities at an electric utility, electric cooperative or municipally owned electric utility.</p><p><strong>Engineer VI</strong></p><p>A minimum of six (6) years of full-time work experience as a licensed PE performing electrical engineering related activities at an electric utility, electric cooperative or municipally owned electric utility.</p><p><br/></p><p><strong>Preferred Qualifications:</strong></p><ul><li>Bachelor or post-graduate degree in electrical engineering.</li><li>Texas Engineer In Training (EIT) Certificate or a Professional Engineer (PE) License in Texas.</li><li>Experience as an expert witness in regulatory hearings.</li><li>Work experience with a regulatory agency. </li><li><br/></li></ul><p><strong>VETERAN’S PREFERENCE</strong></p><p>Veterans, Reservists, or Guardsmen with a Military Occupation Specialty (MOS) or additional duties that fall in the fields listed in the below link who meet the minimum qualifications are encouraged to apply.</p><p><br/></p><p>The MOS codes applicable to this position can be accessed at:</p><p>Military Crosswalk for Engineering Specialist and Engineer: https://hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_EngineeringandDesign.pdf</p><p>Military Crosswalk for Project Manager: https://hr.sao.texas.gov/Compensation/MilitaryCrosswalk/MOSC_ProgramManagement.pdf</p><p><br/></p><p>If you qualify for a Veteran Employment Preference, it is mandatory that you provide the required documentation with your State of Texas Application. Documentation must be provided before a Veteran Preference can be granted. Required documentation is as follows: Veteran – DD Form 214; Surviving Spouse of a Veteran who has not remarried – Marriage Certificate and DD Form 1300; Orphan of a Veteran who was killed during active duty – Birth Certificate and DD Form 1300.</p><p><br/></p><p><strong>A detailed job description can be viewed on our website: https://puc.texas.gov/HumanResources/Home/Jobs</strong></p><p><strong>Salary commensurate with qualifications. The salary of an ERS Retiree or non-contributing member will be 9.5% less than the offered salary.</strong></p><p><br/></p><p><strong>NOTICE TO APPLICANTS </strong></p><p>Applications must contain complete job histories, which includes:</p><ul><li>Job title</li><li>Dates of employment</li><li>Name of employer Supervisor's name and phone number</li><li>Description of duties performed that demonstrates how you meet the minimum qualifications for the position applying for </li></ul><p><strong> Note: Resumes do not take the place of this required information and applications with “See attached"" or ""See resume"" will not be accepted in lieu of a completed application. </strong></p><p><br/></p><p><strong><em>The hiring manager is requesting the following documents be submitted with the State of Texas CAPPS Application: </em></strong></p><ul><li>Resume</li><li>Official or Unofficial College Transcripts (applicants applying for entry level positions with no experience must submit transcripts)</li></ul><p>When submitting your documents, make sure to mark them as <strong>“relevant.”</strong></p><p><br/></p><p><strong>Incomplete applications will not be considered.</strong></p>
</div>",$70008- $100008,Data Pipeline Engineer
"Sr. Manufacturing Engineer, Tabless",Tesla,12/19/2023,https://www.linkedin.com/jobs/view/3737828438,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
"Sr. Mechanical Design Engineer, Motors, Drive Systems",Tesla,12/19/2023,https://www.linkedin.com/jobs/view/3737835347,0,https://media.licdn.com/dms/image/C4D0BAQHUcu98SZ2TVw/company-logo_100_100/0/1630576446368/tesla_motors_logo?e=2147483647&v=beta&t=fFZSy_dnN_IDaC_6hHxOobiRkj_4lybAf3Nf5AalKTk,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>What To Expect<br/></strong>Tesla is in need of Senior Mechanical Design Engineers to design propulsion motors from concept to volume production. Come join the team working on the most important motors in the world.<br/><br/><strong>What You'll Do<br/><br/></strong><li>3D CAD and 2D drawings for stators, rotors and assemblies</li><li>Driving choices and new clean sheet development in: winding technology, magnet technology, steel stamping and lamination joining, electrical insulation systems, interconnections, thermal sensing, speed sensing</li><li>Presenting new designs and status updates to upper managmenet</li><li>Identifying and qualifying suppliers of raw materials, components, and assemblies</li><li>Design validation and durability testing profile development and data analysis</li><li>Carry designs through to high-volume production; DFM, cost reductions, and second sourcing</li><li>Mentoring junior engineers and interns<br/><br/><br/></li><strong>What You'll Bring<br/><br/></strong><li>Evidence of exceptional ability</li><li>Taken multiple motor designs from clean sheet to volume production</li><li>Experience with multiple coil winding and termination technologies</li><li>Experience with multiple magnet technologies</li><li>Worked with an international supply chain</li><li>Automotive design and validation experience</li><li>Expected skills: GD&amp;T, 3D CAD, 2D Drawings, DFMEA, PFMEA, structural and thermal FEA</li><li>Bonus skills: Catia, NVH analysis, electromagnetics design, specification writing, plastic injection molding, bolted joint design<br/><br/><br/></li><strong>Benefits<br/></strong><strong>Compensation and Benefits<br/></strong>Along with competitive pay, as a full-time Tesla employee, you are eligible for the following benefits at day 1 of hire:<br/><li> Aetna PPO and HSA plans &gt; 2 medical plan options with $0 payroll deduction</li><li> Family-building, fertility, adoption and surrogacy benefits</li><li> Dental (including orthodontic coverage) and vision plans, both have options with a $0 paycheck contribution</li><li> Company Paid (Health Savings Account) HSA Contribution when enrolled in the High Deductible Aetna medical plan with HSA</li><li> Healthcare and Dependent Care Flexible Spending Accounts (FSA)</li><li> LGBTQ+ care concierge services</li><li> 401(k) with employer match, Employee Stock Purchase Plans, and other financial benefits</li><li> Company paid Basic Life, AD&amp;D, short-term and long-term disability insurance</li><li> Employee Assistance Program</li><li> Sick and Vacation time (Flex time for salary positions), and Paid Holidays</li><li> Back-up childcare and parenting support resources</li><li> Voluntary benefits to include: critical illness, hospital indemnity, accident insurance, theft &amp; legal services, and pet insurance</li><li> Weight Loss and Tobacco Cessation Programs</li><li> Tesla Babies program</li><li> Commuter benefits</li><li> Employee discounts and perks program<br/><br/><br/></li>Tesla
      </div>",$0- $0,Data Pipeline Engineer
Manufacturing Engineer,Fox Robotics,12/19/2023,https://www.linkedin.com/jobs/view/3788417087,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Manufacturing Engineer III,Bio-Rad Laboratories,12/25/2023,https://www.linkedin.com/jobs/view/3635547506,0,https://media.licdn.com/dms/image/C560BAQGPNGzhLX50iA/company-logo_100_100/0/1630671866021/bio_rad_logo?e=2147483647&v=beta&t=5Uu9lNe7dIyFVJYoeTysXJicT_Fv4Mq0_BiC_T7jL0o,"Richmond, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Bio-Rad is looking for an Engineer to support the manufacturing plant that produces process chromatography resins, liquid buffers, monomer solutions, oils, and other specialized life science products. The individual will be part of the Manufacturing Science and Technology group that consists of a multidisciplinary team of Scientists and Engineers working on developing innovative technologies and continuous improvement projects for the chemical manufacturing site. In this role, you will be part of an entire product development cycle, from early proofs-of-concept to detailed design and validation.<br/><br/>As a Manufacturing Engineer, you will have independent projects and be part of team projects that support current and future business needs. Your projects will include optimizing current processes and equipment and supporting future growth. You will also support other departments on site via troubleshooting equipment and process issues using your engineering knowledge, research, root cause analysis, and using continuous improvement tools. Equipment includes glass-lined reactors with heating systems, semi-automated fill lines, air classifiers, wet sizing units, inline mixing systems, and semi-automated dispense systems among various others.<br/><br/><strong>How You’ll Make An Impact<br/><br/></strong><ul><li>Lead development of innovative manufacturing processes solutions and capabilities including process definition, startup, and qualification. </li><li>Collaborate with R&amp;D, PMO, and Marketing on NPI roadmaps; develop plans, and design experiments to enable new products via manufacturing technology and process development. </li><li>Support day to day manufacturing and maintenance processes ensuring site can achieve business goals, and also author and review URS, IOQ validation documents, and work instructions. </li><li>Participate in the master plan for business continuity and expansion strategy via individual and team projects. </li><li>Will be a member of the process safety management team responsible for auditing, maintaining, and improving the process safety and reliability of the site.<br/><br/></li></ul><strong>What You Bring<br/><br/></strong><ul><li>Education: Bachelor's or Master's degree in Chemical, Industrial, or Electrical Engineering or equivalent practical experience. </li><li>Work Experience: Minimum of 5 years of manufacturing experience, including the development of new manufacturing processes, acceptance testing, startup, and qualification.</li><li>Demonstrated record of delivering innovative manufacturing solutions, Lean/Six Sigma Manufacturing, leading failure analysis investigations and resolutions, and cycle time reductions for high complexity manufacturing processes. </li><li>Able to independently manage multiple cross-functional projects while adhering to ISO 13485 requirements.</li><li>Demonstrated ability to influence the product and process design by proposing improvements and justifying with data. </li><li>Excellent organizational skills and communication skills, able to collaborate with multiple teams on complex projects spanning multiple technologies.<br/><br/></li></ul><strong>Total Rewards Package: </strong>At Bio-Rad, we’re empowered by our purpose and recognize that our employees are as well. That’s why we offer a competitive and comprehensive Total Rewards Program that provides value, quality, and inclusivity while satisfying the diverse needs of our evolving workforce. Bio-Rad's robust offerings serve to enrich the overall health, wealth, and wellbeing of our employees and their families through the various stages of an employee’s work and life cycle.<br/><br/><strong>Benefits:</strong> We’re proud to offer a variety of options, including competitive medical plans for you and your family, free HSA funds, a new fertility offering with stipend, group life and disability, paid parental leave, 401k plus profit sharing, an employee stock purchase program, a new upgraded and streamlined mental health platform, extensive learning and development opportunities, education benefits, student debt relief program, pet insurance, wellness challenges and support, paid time off, Employee Resource Groups (ERG’s), and more!<br/><br/><strong>Compensation: </strong>The estimated base salary range for this position is $111,900 to $153,900 at the time of posting. Actual compensation will be provided in writing at the time of offer, if applicable, and is based on several factors we believe fairly and accurately impact compensation, including geographic location, experience, knowledge, skills, abilities, and other job permitted factors. This position is eligible for a variable annual bonus, which is dependent upon achievement of your individual objectives and Company performance.<br/><br/><strong>Who We Are:</strong> For 70 years, Bio-Rad has focused on advancing the discovery process and transforming the fields of science and healthcare. As one of the top five life science companies, we are a global leader in developing, manufacturing, and marketing a broad range of high-quality research and clinical diagnostic products. We help people everywhere live longer, healthier lives. Recently voted a Best Place to Work, Bio-Rad offers a unique employee experience with collaborative teams that span the globe. Here, you are supported by leadership to build your career and are empowered to drive change that makes an impact you can see.<br/><br/><strong>EEO Statement:</strong> Bio-Rad is an Equal Employment Opportunity/Affirmative Action employer, and we welcome candidates of all backgrounds. Veterans, people with physical or mental disabilities, and people of all race, color, sex, sexual orientation, gender identity, religion, national origin and citizenship status are encouraged to apply.<br/><br/><strong>Agency Non-Solicitation: </strong>Bio-Rad does not accept agency resumes, unless the agency has been authorized by a Bio-Rad Recruiting Representative. Please do not submit resumes unless authorized to do so. Bio-Rad will not pay for any fees related to unsolicited resumes.<br/><br/>
</div>",$111900- $153900,Data Pipeline Engineer
Manufacturing Engineer,Stryker,12/20/2023,https://www.linkedin.com/jobs/view/3790536594,0,https://media.licdn.com/dms/image/C4E0BAQHa7kowBO7CeQ/company-logo_100_100/0/1631319537543?e=2147483647&v=beta&t=mbPNvpZ3COq7NAhA9rdZ9CoyF11uVz2hY0qkmP9IZS8,"Redwood City, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Why engineering at Stryker?<br/><br/>At Stryker we are dedicated to improving lives, with a passion for researching and developing new medical device products. As an engineer at Stryker, you will be proud of the work that you will be doing, using cutting-edge technologies to make healthcare better. Here, you will work in a supportive culture with other incredibly talented and intelligent people, creating industry-leading medical technology products. You will also have growth opportunities as we have a culture that supports your personal and professional development.<br/><br/>Need another reason to apply? <strong>Check out these 8 reasons to join Stryker's engineering team:</strong> https://www.strykercareersblog.com/post/8-reasons-to-join-strykers-engineering-team<br/><br/>We are proud to be named one of the World’s Best Workplaces and a Best Workplace for Diversity by Fortune Magazine! Learn more about our award-winning organization by visiting stryker.com<br/><br/>As the Manufacturing Engineer, you will focus on sustaining existing processes, increasing capacity, reducing scrap, improving safety, and implementing process improvements in a medical device manufacturing environment. You will improve manufacturing processes by leveraging lean principles, good manufacturing practices and six sigma methodologies to reduce costs through the elimination of waste in the value stream. This is an onsite position in San Jose, CA.<br/><br/><strong><strong>Who We Want-<br/><br/></strong></strong><ul><li>Detail-oriented process improvers. Critical thinkers who naturally see opportunities to develop and optimize work processes – finding ways to simplify, standardize and automate</li><li>Collaborative partners. People who build and leverage cross-functional relationships to bring together ideas, data and insights to drive continuous improvement in functions</li><li>Dedicated achievers. People who thrive in a fast-paced environment and will stop at nothing to ensure a project is complete and meets regulations and expectations<br/><br/></li></ul><strong><strong>What You Will Do<br/><br/></strong></strong><ul><li>Sustain existing manufacturing lines, specifically the maintenance of manufacturing fixtures and equipment</li><li>Ensure manufacturing processes run consistently and meet performance targets by reducing costs, maximizing efficiency, and minimizing manufacturing loss</li><li>Lead engineering projects and track project progress, present periodic status updates to key stakeholders and works to resolve obstacles</li><li>Design and build fixtures, equipment and tools as needed to increase efficiency, ergonomics, safety and quality</li><li>Collaborate with other engineers to analyze manufacturing/assembly issues and identify, test and implement the most effective solutions in a timely manner</li><li>Conduct equipment and process validations, qualifications and verifications</li><li>Drive process change by initiating, executing and reviewing Engineering Change Orders</li><li>Foster an environment of continuous improvement and provide support to internal customers in a variety of functional areas</li><li>Collaborate with a cross functional teams to transfer new products into production by providing recommendations regarding product design, assembly techniques and manufacturing processes<br/><br/></li></ul><strong><strong>What You Need<br/><br/></strong></strong><ul><li>Bachelor’s degree in engineering or related discipline, preference of concentration in mechanical, electrical, industrial, or biomedical engineering -required</li><li>CAD experience (CREO, SolidWorks, etc.) - required</li><li>Mechanical/electrical problem-solving skills - required</li><li>Medical device of other highly regulated industry experience - highly preferred</li><li>Proven ability to handle multiple projects and meet deadlines - highly preferred </li><li>Experience with continuous process improvement and applying lean manufacturing techniques - preferred</li><li>Automation experience - preferred</li><li>LabVIEW and/or TestStand experience - preferred<br/><br/></li></ul><strong>About Stryker<br/><br/></strong>Our benefits:<br/><br/><ul><li>12 paid holidays annually </li><li>Health benefits include: Medical and prescription drug insurance, dental insurance, vision insurance, critical illness insurance, accident insurance, hospital indemnity insurance, personalized healthcare support, wellbeing program and tobacco cessation program. </li><li>Financial benefits include Health Savings Account (HSA), Flexible Spending Accounts (FSAs), 401(k) plan, Employee Stock Purchase Plan (ESPP), basic life and AD&amp;D insurance, and short-term disability insurance. <br/><br/></li></ul>For a more detailed overview of our benefits or time off, please follow this link to learn more: US Stryker employee benefits<br/><br/><strong>About Stryker<br/><br/></strong>Stryker is one of the world’s leading medical technology companies and, together with its customers, is driven to make healthcare better. The company offers innovative products and services in Medical and Surgical, Neurotechnology, Orthopaedics and Spine that help improve patient and healthcare outcomes. Alongside its customers around the world, Stryker impacts more than 130 million patients annually. More information is available at stryker.com.<br/><br/>Know someone at Stryker?<br/><br/>Be sure to have them submit you as a referral prior to applying for this position. Learn more about our employee referral program on our referral page<br/><br/>Stryker is driven to work together with our customers to make healthcare better. Employees and new hires in sales and field roles that require access to customer accounts as a function of the job may be required, depending on customer requirements, to obtain various vaccinations as an essential function of their role.<br/><br/>R512042<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
Staff Mechanical Engineer - Mission Critical (Walnut Creek),Burns & McDonnell,12/19/2023,https://www.linkedin.com/jobs/view/3663886496,0,https://media.licdn.com/dms/image/C4E0BAQEveKxwPamlHA/company-logo_100_100/0/1630564643406/burns__mcdonnell_logo?e=2147483647&v=beta&t=-7SsM3ebmLibRpt7AWCo9tNDqKi0WPyRQQktDUK7ccc,"Walnut Creek, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Burns &amp; McDonnell is a company made up of more than 8,000 engineers, architects, construction professionals, scientists, consultants, and entrepreneurs with offices across the country and throughout the world. Burns &amp; McDonnell is 100 percent employee-owned and is proud to be on Fortune’s 2020 list of 100 Best Companies to Work For. Burns &amp; McDonnell has exciting opportunities for those interested in growing their careers in one of the most fast paced, innovative sectors of high tech building design and construction. Project focus would be mission-critical data center projects. This opportunity hires directly into our Mission Critical team and into a multibillion-dollar industry that is growing at an exponential rate. Data Centers are an aggressive market for Burns &amp; McDonnell and are highlighted by several priority articles on our site. Mission Critical is an international practice for Burns &amp; McDonnell that involves exciting, collaborative work across many different departments.<br/><br/>Burns &amp; McDonnell has exciting opportunities for those interested in growing their careers in one of the most fast paced, innovative sectors of high tech building design and construction. Project focus would be mission-critical data center projects. This opportunity hires directly into our Mission Critical team and into a multibillion-dollar industry that is growing at an exponential rate. Data Centers are an aggressive market for Burns &amp; McDonnell and are highlighted by several priority articles on our site. Mission Critical is an international practice for Burns &amp; McDonnell that involves exciting, collaborative work across many different departments.<br/><br/>Position available for a mechanical engineer with experience in a variety of facility mechanical system and subsystems including: studies, layout, specification and design of HVAC, plumbing, fire protection, utilities, infrastructure, and controls. Position will focus on the design of large scale manufacturing facilities.<br/><br/><strong>Additional Duties Include<br/><br/></strong><ul><li>May develop and evaluate plans for major projects.</li><li>May assess feasibility or soundness of proposed applications when data is insufficient or testing is advisable.</li><li>Develop flow diagrams, P&amp;IDs, and sequences of operation as required.</li><li>May coordinate departmental or divisional project studies, reports or project design assignments.</li><li>Progressive design responsibilities.</li><li>Provide leadership, guidance and instruction to less experienced staff members.</li><li>Regularly meets and corresponds with clients or outside personnel.</li><li>Other duties as assigned<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Bachelor's Degree in Mechanical Engineering or related degree from an ABET accredited program. and 3 years of mechanical engineering experience, consulting preferred. Required or</li><li>Bachelor's Degree in Mechanical or related Engineering Technology from an ABET accredited program and successful completion of Fundamentals of Engineering (FE) exam. and 3 years of mechanical engineering experience, consulting preferred. Required or</li><li>Master's Degree in Mechanical Engineering and 2 years of mechanical engineering experience, consulting preferred. Required</li><li>Strong knowledge in standard engineering techniques and procedures.</li><li>Excellent written and verbal communication skills.</li><li>Ability to work methodically and analytically in a quantitative problem-solving environment and demonstrated critical thinking skills.</li><li>Proficient in standard engineering techniques and procedures.</li><li>Strong computer skills (e.g. Microsoft Office Suite)</li><li>Strong computer skills include AutoCAD, BIM (Revit), 3D Rendering Programs, hydraulic analysis, and HVAC analysis programs.</li><li>Strong attention to detail, facilitation, team building, collaboration, organization and problem-solving skills.</li><li>Engineers in Training-EIT Certification Preferred<br/><br/></li></ul><strong>Compensation<br/><br/></strong>$115,000.00 - $160,000.00<br/><br/>The expected compensation range for this position is displayed in compliance with all local/state regulations. The expected compensation range for this position is based on a number of factors, including but not limited to: individual education, qualifications, prior work experience and work location. The total annual compensation package will consist of a base salary and eligibility to participate in our discretionary year-end incentive bonus program.<br/><br/><strong>Benefits<br/><br/></strong>Our extensive benefits package takes care of you so that you can focus on doing great work. From insurance and disability to time off and wellness programs, we provide the tools to meet your needs. As part of being 100% employee-owned, eligible employees participate in our Employee Stock Ownership Plan (ESOP) in addition to our 401(k) retirement program. For more information, please visit the Benefits &amp; Wellness page.<br/><br/>EEO/Minorities/Females/Disabled/Veterans<br/><br/><strong>Job</strong> Mechanical Engineering<br/><br/><strong>Primary Location</strong> US-CA-Walnut Creek<br/><br/><strong>Schedule:</strong> Full-time<br/><br/><strong>Travel:</strong> Yes, 15 % of the Time<br/><br/><strong>Req ID:</strong> 233172 <strong>Job Hire Type</strong> Experienced<br/><br/>#GFS<br/><br/>
</div>",$115000.00- $160000.00,Data Pipeline Engineer
Senior/Staff Software Engineer - Prediction & Behavior ML,Zoox,12/19/2023,https://www.linkedin.com/jobs/view/3004855032,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Senior/ Staff Software Engineer - Simulation Workload Orchestration,Zoox,12/19/2023,https://www.linkedin.com/jobs/view/3584583101,0,https://media.licdn.com/dms/image/C560BAQF2yqp_9BrVew/company-logo_100_100/0/1654722579134/zoox_inc_logo?e=2147483647&v=beta&t=DR5BCLd9DbKbCBgypR0L92OYERM7IXuQw36zdjU1cXw,"Foster City, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Come join us at Zoox to participate in the transportation revolution with building self-driving vehicles! Our mission is to make personal transportation safer, cleaner, and more enjoyable for everyone. Simulation is essential to Zoox’s mission. Zoox uses simulation to develop our driving software, validate safety, and analyze our real-world performance. Our team’s work directly impacts how rapidly and successfully Zoox will achieve its goals.<br/><br/>We are looking for experienced developers (5+ years experience) to build a massively scalable pipeline for orchestrating the execution of simulations and processing of the results. This mission critical pipeline will be highly parallel, manage various stages of execution, ensure correct data flow and coordinate the processing of the results. This is an ideal opportunity for an innovative Software Engineer to build the foundation and the pipeline that can exponentially scale up the execution of the simulations and at the same time meet the diverse needs of processing the results.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Design the simulation execution pipeline for exponential growth, with efficient resource utilization</li><li>Integrate with other systems via message queues</li><li>Collaborate with internal teams for requirements and API design</li><li>Lead/own development of highly scalable features</li><li>Communicate effectively with internal customers</li><li>Ensure correctness and 24x7 stability of the entire system<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Bachelor’s degree in Computer Science or related field</li><li>Experience in coming up with high level design to meet user requirements</li><li>Great communication skills</li><li>Excellent Python skills</li><li>Experience in designing and building complex data processing systems at scale with performance tuning</li><li>Experience in operating a workload/workflow management system (e.g. Slurm, Apache Airflow/Beam/Flink)</li><li>Experience in developing distributed systems using asynchronous communication (e.g. Kafka, Kinesis)</li><li>Experience with data processing frameworks (e.g. Spark, MapReduce, AWS EMR)</li><li>8+ years of experience in a related field<br/><br/></li></ul><strong>Bonus Qualifications<br/><br/></strong><ul><li>Knowledge in AWS, CI/CD tools, Kubernetes</li><li>Experience with data storage and analytics systems (e.g. AWS RDS/DynamoDB, Elasticsearch, Databricks)</li><li>Experience with SQL and data warehouse</li><li>Knowledge in object-oriented programming with languages (e.g. Java, Kotlin, C++)<br/><br/></li></ul><strong>Compensation<br/><br/></strong>There are three major components to compensation for this position: salary, Amazon Restricted Stock Units (RSUs), and Zoox Stock Appreciation Rights. The salary will range from $203,000 - $293,000. A sign-on bonus may be part of a compensation package. Compensation will vary based on geographic location, job-related knowledge, skills, and experience.<br/><br/>Zoox also offers a comprehensive package of benefits including paid time off (e.g. sick leave, vacation, bereavement), unpaid time off, Zoox Stock Appreciation Rights, Amazon RSUs, health insurance, long-term care insurance, long-term and short-term disability insurance, and life insurance.<br/><br/><strong>About Zoox<br/><br/></strong>Zoox is developing the first ground-up, fully autonomous vehicle fleet and the supporting ecosystem required to bring this technology to market. Sitting at the intersection of robotics, machine learning, and design, Zoox aims to provide the next generation of mobility-as-a-service in urban environments. We’re looking for top talent that shares our passion and wants to be part of a fast-moving and highly execution-oriented team.<br/><br/>Follow us on LinkedIn<br/><br/><strong>A Final Note<br/><br/></strong><em>You do not need to match every listed expectation to apply for this position. Here at Zoox, we know that diverse perspectives foster the innovation we need to be successful, and we are committed to building a team that encompasses a variety of backgrounds, experiences, and skills.</em>
</div>",$203000- $293000,Data Pipeline Engineer
Senior Quality Assurance Engineer,Qcells North America,12/19/2023,https://www.linkedin.com/jobs/view/3679306743,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer - Public Infrastructure,Professional Diversity Network,12/19/2023,https://www.linkedin.com/jobs/view/3790070646,0,https://media.licdn.com/dms/image/C4E0BAQHJdwB_b90Z8Q/company-logo_100_100/0/1630623318282/professional_diversity_network_logo?e=2147483647&v=beta&t=cjp774lj6qv8gbhYTV5Y0UAly1WS39wbFy8lpyQ0dWs,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Posting Title:</strong>Project Engineer<br/><br/><strong>Reports To</strong>: Senior Project Manager<br/><br/><strong>Location:</strong>San Francisco, California<br/><br/><strong>Salary Range:</strong>$80,000 to $105,000<br/><br/>Final determination of a successful candidate's starting pay will vary based on a number of factors, including market location and may vary depending on job-related knowledge, skills, education and experience. The pay scale listed for this position is generally for candidates that meet the specified qualifications and requirements listed on this specific job description. We provide a competitive compensation package that recognizes your experience, credentials, and education alongside a robust benefits program to meet your needs. Our compensation reflects the cost of labor across several US geographic markets.<br/><br/><strong>Who We Are<br/><br/></strong>For nearly 70 years, Cupertino Electric, Inc. (CEI) has been powered by people who've built a reputation for delivering high-profile, complex projects. Real, tangible things that alter the landscape and improve lives. But even more than that, we've built a reputation for integrity. We're problem solvers and innovation seekers. We're team players and safety fanatics. And we always-always-do the right thing. Even when no one is looking. Because what we do here is important, but how we do it is everything.<br/><br/><strong>THE COMMERCIAL TEAM<br/><br/></strong>Our strong project management teams, dedicated in-house engineering resources and skilled union field staff work together seamlessly to deliver commercial projects that are as innovative and unique as the clients who build them.<br/><br/><strong>About The Role<br/><br/></strong>We're seeking a Project Engineerready to be on the front lines of a project--giving daily support to the field, project management, and customer teams. Our Project Engineers (PE) are vital in keeping our processes moving along and assists in the execution of project plans. This role will be responsible for specific activities such as coordinating material onsite delivery dates, maintaining RFI, submittals, and change order logs, and will serve as a key point of contact for internal customers.<br/><br/><strong><em>Knowledge:</em></strong>Learns to use professional concepts. Applies company policies and procedures to resolve routine issues.<br/><br/><strong><em>Job Complexity</em>:</strong>Works on problems of limited scope. Follows standard practices and procedures in analyzing situations or data from which answers can be readily obtained. Builds stable working relationships internally.<br/><br/><strong><em>Supervision:</em></strong>Normally receives detailed instructions on all work.<br/><br/><strong>About You<br/><br/></strong>You are willing and excited to learn-with a continuous focus on cultivating a growth mindset. You bring a wide range of skills from being organized to communicating through various channels and collaborating with your team members. You are comfortable taking initiative and ownership of your work. You are not afraid to throw on a pair of boots and your protective personal equipment (PPE)-safety first!<br/><br/><strong>What You Will Gain<br/><br/></strong>At Cupertino Electric you'll be on a career development path to project management. You'll work directly for a project manager or project executive on a team that partners with field, engineering, and design teams. It's ok if you don't have a deep understanding of electrical construction, just be ready to learn and get fired up. You'll have the opportunity to soak up knowledge from everyone you work with - from the journeyman and general foreman to the project team assigning daily tasks. In addition to on-the-job experience and mentoring from your peers, you'll attend vendor off sites, training classes, and other learning opportunities.<br/><br/><strong>Minimum Qualifications<br/><br/></strong><em>Any combination of education and experience that, in the sole judgment and discretion of Company, would likely provide the required knowledge, skills and abilities as well as possession of any required licenses or certifications may qualify.<br/><br/></em><strong>Education:</strong>High School Diploma or GED required. Bachelor's Degree in Construction Management, Business, Engineering, or similar preferred.<br/><br/><strong>Licensure/Certifications:</strong>None required.<br/><br/><strong>Experience:</strong>Zero (0) years of construction or related experience required. Two (2) years of construction or related experience preferred.<br/><br/><strong>Driving Record:</strong>Valid state-issued driver's license and satisfactory driving record.<br/><br/><strong>Travel:</strong>0% - 25%<br/><br/><ul><li>Applicants must be authorized toworkin the United States. This position is noteligiblefor sponsorship.<br/><br/></li></ul><strong>PLEASE NOTE:</strong>CEI will never ask for any money or financial information from applicants during the hiring process. To learn more about ""job scams"" how to avoid them,click here.<br/><br/>CEI is a place where every single person can-and does-have an impact on the work we do and the communities we serve. Here, you can build your own story and grow to your full potential. You can collaborate and celebrate with amazing people. And you'll go home every day knowing you helped contribute to important work that shapes people's lives. Our commercial, data center and energy projects may be complex, but our approach is simple. We build great things and we do it with great people.<br/><br/>The job duties listed are typical examples of work performed by positions in this job classification and are not designed to contain or be interpreted as a comprehensive inventory of all duties, tasks, and responsibilities. Specific duties and responsibilities may vary depending on department, program or project needs without changing the general nature and scope of the job or level of responsibility. Employees may also perform other duties as assigned.<br/><br/>Cupertino Electric, Inc. (CEI) is proud to be an Equal Employment Opportunity and affirmative action employer. We celebrate diversity and do not discriminate based on race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability status, or any other applicable characteristics protected by law.<br/><br/>Cupertino Electric Inc. aims to make cei.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, please contact us at ceijobs@cei.com or 1-(877)-747-4CEI.<br/><br/>PDN-9ad5d363-b1a1-474e-8957-951e08e52b40<br/><br/>
</div>",$80000- $105000,Data Pipeline Engineer
Mechanical Engineer - HVAC,CyberCoders,12/19/2023,https://www.linkedin.com/jobs/view/3737165818,0,https://media.licdn.com/dms/image/C560BAQF7t9X4k2P2hA/company-logo_100_100/0/1630672294143/cybercoders_logo?e=2147483647&v=beta&t=svLLpBE8gsgu2VaDigkqM3UEMeVyCIhMQEUzznif85w,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        If you are a Mechanical Engineer with HVAC/Plumbing design experience, please read on! Industry leading Engineering firm is is looking for an experienced HVAC/Plumbing systems design engineer to join the team!<br/><br/>Top Reasons to Work with Us<br/><ul><li> Competitive compensation based on experience - 100K-130K base salary plus optional overtime </li><li> Excellent benefits package and company culture</li><li> Tons of growth potential and world class projects<br/></li></ul>What You Will Be Doing<br/><ul><li> Design HVAC/Plumbing systems and controls for commercial buildings</li><li> Perform load calculations, energy analysis, equipment selection and layout</li><li> Analyze system operational data and make recommendations for improving system performance</li><li> Ensure adherence to codes and standards<br/></li></ul>What You Need for this Position<br/><br/>BS in Mechanical Engineering<br/><ul><li> PE preferred not required<br/></li></ul>At least 5+ years of professional experience with:<br/><ul><li> Commercial building projects</li><li> Revit, AutoCAD, MS Office.</li><li> Building mechanical codes and ability to perform accurate load calculations</li><li> Sustainable design practices<br/></li></ul>What's In It for You<br/><ul><li> Competitive base compensation from: $100K-$130K</li><li> Vacation/PTO</li><li> Medical</li><li> Dental</li><li> Vision</li><li> Bonus</li><li> 401k<br/></li></ul><strong>Benefits<br/></strong><ul><li> Vacation/PTO</li><li> Medical</li><li> Dental</li><li> Vision</li><li> 401k</li><li> Bonus</li><li> Relocation<br/></li></ul>So, if you are a Mechanical Engineer with HVAC design experience, please apply today!<br/><br/><strong>Email Your Resume In Word To<br/><br/></strong>Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:<br/><br/>Adrian.Jiminez@CyberCoders.com<br/><ul><li>Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : AJ4-1768861 -- in the email subject line for your application to be considered.***<br/></li></ul>Adrian Jiminez - Executive Recruiter - CyberCoders<br/><br/>Applicants must be authorized to work in the U.S.<br/><br/><strong>CyberCoders is proud to be an Equal Opportunity Employer<br/><br/></strong>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br/><br/><strong>Your Right to Work</strong> – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br/><br/>
</div>",$100- $130,Data Pipeline Engineer
Project Engineer,Flatiron Construction,12/19/2023,https://www.linkedin.com/jobs/view/3770792564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Staff Quality Engineer - Customer Quality Experience,Twist Bioscience,12/19/2023,https://www.linkedin.com/jobs/view/3789757198,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Industrial Engineer II,"Americold Logistics, LLC.",12/25/2023,https://www.linkedin.com/jobs/view/3793369799,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Manufacturing Engineer,ACL Digital,12/20/2023,https://www.linkedin.com/jobs/view/3784481084,0,https://media.licdn.com/dms/image/C560BAQFYnXRZomIaNQ/company-logo_100_100/0/1630664946745?e=2147483647&v=beta&t=3IZwAN-SmQ81uttKnydxlBLHHypsa_ktJUTG4HcS7ks,"Tukwila, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Manufacturing Engineer 3 - 66R-Assembly and Installation</strong></p><p><strong>Location- Tukwila, WA (100% onsite) </strong></p><p><strong>Duration: 12 Months (possibility of extension depend upon business need)</strong></p><p><br/></p><p><strong>What is interesting/cool about this position)?</strong></p><p>• ME Designs the aircraft, and then see the plane in production.</p><p>• Get to see the process from start to finish, good visibility.</p><p>• Working on the entire plane, rather than one specific section or part.</p><p><br/></p><p><strong>General Information</strong></p><ul><li>The Company Test &amp; Evaluation (BT&amp;E) Design Build group is looking for Manufacturing Engineer to join our Test and Evaluation team in Tukwila, WA.</li></ul><p><br/></p><p><strong>Job Description Summary:</strong></p><ul><li>Develops and implements production and tooling methodologies.</li><li>Participates on Integrated Product Teams (IPTs) to integrate technical solutions across multiple disciplines.</li><li>Develops, identifies, and implements conceptual designs and maintains the program architecture for build.</li><li>Leads and implements manufacturing plans.</li><li>Conducts producibility and variation analyses to ensure that manufacturing process capability matches requirements.</li><li>Assists in providing producibility information for inclusion in project plans and helps document producibility best practices.</li><li>Analyzes design/build concepts to evaluate producible design/build definitions.</li><li>Resolves technical problems of significant impact to performance, cost, or schedule.</li><li>Coordinates and implements new engineering principles, theories, advanced technologies, and concepts.</li><li>Validates and ensures production readiness of solutions to complex problems.</li><li>Implements lean principles and technologies.</li><li>The Flight Test Manufacturing Engineer is an assembly and installation engineer within Test and Evaluation (BT&amp;E) that supports fabrication planning and installation by providing design review, manufacturing plan authorship, fabrication sourcing (inside and outside of), interface with procurement (including tracking), and support in the lab during the build/installation.</li><li>The primary focus of this position is the lead, manage and support of the design &amp; fabrication efforts located in Tukwila, WA.</li><li>These efforts represent a wide variety of research and production programs primary in support of Commercial airplanes (BCA) and Defense, Space and Security (BDS) programs.</li><li>Manufacturing Engineers are owners of the build plan and ensure compliance to design configuration and process requirements, Manufacturing Engineering performs Design for Manufacturing and Assembly (DFMA) analysis and develops an integrated build plan consisting of work instructions for assembly/fabrication, kitting, tooling, inspection requirements, and other outputs to endure fabrication meets design, test, and program requirements.</li></ul><p><br/></p><p><strong>Position Responsibilities:</strong></p><ul><li>Participates on Integrated Product Teams (IPTs) to integrate technical solutions across multiple disciplines.</li><li>Develops and documents BT&amp;E ME process and tools for Flight test programs, new job practices, techniques, and standards.</li><li>Develops, implements, and maintains various manufacturing plans, Bill of Materials, work instructions and illustrations to define and document as-built configuration.</li><li>Develops and plans manufacturing concepts and strategies to support business objectives.</li><li>Prepares build analyses and cost estimate reports.</li><li>Leads integration of complex suppliers, processes, materials, data, and technology to meet manufacturing and delivery requirements.</li><li>Leads teams performing producibility assessments of design concepts.</li><li>Manage the program work statement making sure it meets the cost and schedules.</li><li>Leads development of complex work statements and sequencing of events to support delivery commitments.</li><li>Lead and work with test Project Management, Design Engineering, and Program IE to develop and maintain integrated build plan.</li><li>Provide build plan and help develop schedule.</li><li>Close coordination with Design engineers and fabrication personnel, Lead coordination with procurement/supplier management personnel across the Systems lab test team and the DB organization.</li><li>Drafts, updates and reviews processes and procedures to support business requirements.</li><li>Works under minimal direction.</li><li>Collaborate with Supplier Management to establish Flight test integration requirements and opportunities.</li><li>Lead the creation of training material and tutorials for Design Build ME team.</li></ul><p><br/></p><p><strong>Basic Qualifications (Required Skills/Experience):</strong></p><ul><li>Bachelor, Master, or Doctor of Science degree from accredited course of study, in engineering, computer science, mathematics, physics or Chemistry.</li><li>5 + years of experience working in a production and/or manufacturing environment.</li><li>3 + years of experience leading or managing projects and/or teams.</li><li>5 + years of experience in a Manufacturing Engineering role.</li></ul><p><br/></p><p><strong>Preferred Qualifications (Desired Skills/Experience):</strong></p><ul><li>3+ years of experience working in a lab test, flight test, or similar test environment.</li><li>Experience in support of commercial and military customers.</li><li>Experience in Project management</li><li>Manufacturing Engineering experience in Flight Test.</li><li>Experience in ME and processes across multiple engineering disciplines</li><li>Experience with PDM, CAPP, CMES, MESci, EPARTs, GOLDesp</li></ul>
</div>",No Salary Info Found,Data Pipeline Engineer
Propulsion Engineer III - - Launch Vehicle Engine Integration and Flight Operations,BLUE ORIGIN,12/19/2023,https://www.linkedin.com/jobs/view/3757354800,0,https://media.licdn.com/dms/image/C510BAQG-nl05kZljeg/company-logo_100_100/0/1631310960783?e=2147483647&v=beta&t=uRSeWiAq8tf9sfetIGtL-z5Xdu3hlNeROpTjO-CYfiA,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Blue Origin, we envision millions of people living and working in space for the benefit of Earth. We’re working to develop reusable, safe, and low-cost space vehicles and systems within a culture of safety, collaboration, and inclusion. Join our diverse team of problem solvers as we add new chapters to the history of spaceflight! <br/><br/>We are a diverse team of collaborators, doers, and problem-solvers who are relentlessly committed to a culture of safety. This position will directly impact the history of space exploration and will require your commitment and detailed attention towards safe and repeatable space flight. Join us in lowering the cost of access to space and enabling Blue Origin’s vision of millions of people living and working in space to benefit Earth.<br/><br/>This role is part of the Blue Origin Engines business unit, where our focus is the design, development, manufacturing and testing of engines and propulsion systems. Built for multiple uses, our family of engines is powering the next generation of rockets for commercial, civil, national security and human spaceflight.<br/><br/>In this position you will work as a member of the Engines Flight Support team which is a customer service center that supports our customer as they integrate, fly, and reuse Blue Origin’s engines. It will be your responsibility to advise our customers as a Subject Matter Expert, both internal and external, as they integrate our engines into the flight vehicle, verify the installation, and certify the installation for flight. Leading up to day-of-launch, EFS will report engine status at Mission and Flight Readiness Reviews and work with a team of responsible engineers (RE) to write, review, and execute launch procedures. You will provide engineering support in launch/mission control during flight, analyze flight data, lead engine subsystem data reviews, and provide feedback on flight data results to the customer base, designers, and component owners for implementation into future engine upgrades. To support post-flight engine refurbishment activities, you will assess hardware health and evaluate engine readiness for flight.<br/><br/>As part of this role, you will use your system engineering skills to lead and support development of the specifications that are used for engine integration into the flight vehicle, development of flight level ConOps, and be a general voice for the Engines group at the launch site.<br/><br/>Aside from direct launch and flight support, you will serve as Engines point of contact for the vehicle customer, lead problem solving efforts and assist to disposition non-conformances. As subject matter expert in launch vehicle and flight operations you will help establish standards to streamline the engine integration and checkout process to minimize schedule impacts and identify, communicate, and mitigate risks.<br/><br/>If required, you will also lead anomaly investigations, mentor younger team members in your areas of expertise and assist functional managers in interviewing and hiring new talent.<br/><br/>We are looking for someone to apply their technical expertise, leadership skills, and dedication to quality to positively impact safe human spaceflight. Passion for our mission and vision is required!<br/><br/><strong>Qualifications:<br/><br/></strong><ul><li>Minimum of a B.S. degree in aerospace/mechanical engineering or physics</li><li>5+ years proven ability in propulsion development, test, or launch/flight operations</li><li>Strong understanding and ability to apply engineering fundamentals including thermodynamics, fluid mechanics and structures</li><li>Prior experience with propulsion and launch vehicle operations ranging from engine integration through mission operations</li><li>Prior Experience in test and flight data analysis</li><li>Solid understanding of cryogenic propellants (liquid hydrogen, liquefied natural gas and liquid oxygen)</li><li>Working knowledge of engine components such as pumps, valves, regulators, actuators and other high pressure and cryogenic fluid system components</li><li>Understands instrumentation including pressure transducers, thermocouples, and accelerometers</li><li>Proven track record to identify and handle risks in a sophisticated dynamic system</li><li>Knowledge of system engineering practices</li><li>Desire to work in a collaborative, fast paced, and multifaceted environment</li><li>Strong written and verbal communication skills</li><li>Willingness to travel to support flight and test activities</li><li>Ability to earn trust, maintain positive and professional relationships, and strengthen our culture of inclusion</li><li>Must be a U.S. citizen or national, U.S. permanent resident (current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.<br/><br/></li></ul><strong>Desired:<br/><br/></strong><ul><li>Advanced degree in aerospace/mechanical engineering or physics</li><li>Experience with liquid rocket engine testing</li><li>Experience with data processing and writing automated data scripts in MATLAB or Python</li><li>Export Control Regulations<br/><br/></li></ul>Compensation range for on site WA applicants is<br/><br/>$111,690—$156,366 USD<br/><br/><strong>Inclusivity Statement<br/><br/></strong>Don’t meet all desired requirements? Studies have shown that some people are less likely to apply to jobs unless they meet every single desired qualification. At Blue Origin, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every desired qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.<br/><br/><strong>Export Control Regulations<br/><br/></strong>Applicants for employment at Blue Origin must be a U.S. citizen or national, U.S. permanent resident (i.e. current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.<br/><br/><strong>Benefits<br/><br/></strong>Benefits include: Medical, dental, vision, basic and supplemental life insurance, paid parental leave, short and long-term disability, 401(k) with a company match of up to 5%, and an Education Support Program.<br/><br/>Paid Time Off: Up to four (4) weeks per year based on weekly scheduled hours, and up to 14 company-paid holidays.<br/><br/>Discretionary bonus: Bonuses are designed to reward individual contributions as well as allow employees to share in company results.<br/><br/>Eligibility for benefits varies by role type, please check with your recruiter for a comprehensive list of the benefits available for this role.<br/><br/><strong>Equal Employment Opportunity<br/><br/></strong>Blue Origin is proud to be an Equal Opportunity/Affirmative Action Employer and is committed to attracting, retaining, and developing a highly qualified, diverse, and dedicated work force. Blue Origin hires and promotes people on the basis of their qualifications, performance, and abilities. We support the establishment and maintenance of a workplace that fosters trust, equality, and teamwork, in which all employees recognize and appreciate the diversity of individual team members. We provide all qualified applicants for employment and employees with equal opportunities for hire, promotion, and other terms and conditions of employment, regardless of their race, color, religion, gender, sexual orientation, gender identity, national origin/ethnicity, age, physical or mental disability, genetic factors, military/veteran status, or any other status or characteristic protected by federal, state, and/or local law. Blue Origin will consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state, and local laws, including the Washington Fair Chance Act, the California Fair Chance Act, the Los Angeles Fair Chance in Hiring Ordinance, and other applicable laws. For more information on “EEO Is the Law,” please see here.<br/><br/><strong>California Applicant Privacy Notice<br/><br/></strong>If you are a California resident, please reference the CA Applicant Privacy Notice here.
      </div>",$111690- $156366,Data Pipeline Engineer
Lunar Turbomachinery Engineer,BLUE ORIGIN,12/19/2023,https://www.linkedin.com/jobs/view/3756330110,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Senior/Staff Software Engineer - Simulation Workload Orchestration,Zoox,12/19/2023,https://www.linkedin.com/jobs/view/3584582525,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Reliability (RAMS) Engineer - Engines (R38317),BLUE ORIGIN,12/19/2023,https://www.linkedin.com/jobs/view/3790357446,0,https://media.licdn.com/dms/image/C510BAQG-nl05kZljeg/company-logo_100_100/0/1631310960783?e=2147483647&v=beta&t=uRSeWiAq8tf9sfetIGtL-z5Xdu3hlNeROpTjO-CYfiA,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Blue Origin, we envision millions of people living and working in space for the benefit of Earth. We’re working to develop reusable, safe, and low-cost space vehicles and systems within a culture of safety, collaboration, and inclusion. Join our diverse team of problem solvers as we add new chapters to the history of spaceflight! <br/><br/>This role is part of the Blue Origin Engines business unit, where our focus is the design, development, manufacturing and testing of engines and propulsion systems. Built for multiple uses, our family of engines is powering the next generation of rockets for commercial, civil, national security and human spaceflight.<br/><br/>As part of a diverse and hardworking engine development team, you will use data to identify factors that drive engine reliability and support initiatives to drive improvements in production, test, and flight reliability.<br/><br/>We are seeking a self-motivated and highly organized individual who can work with minimal guidance and coordinate teams in the successful execution of system safety and reliability activities! This position will directly impact the history of space exploration and will require your dedicated commitment and detailed attention towards safe and repeatable spaceflight!<br/><br/><strong>Responsibilities include but are not limited to:<br/><br/></strong><ul><li>Identify reliability requirements</li><li>Support early trade studies to drive design-for-reliability into the engine architecture in order to achieve reliability requirements</li><li>Develop requirements and design solutions to implement fault tolerance into the engine design</li><li>Develop test requirements that enable to identification of failure modes to be mitigated through re-design, as well as test requirements that demonstrate reliability goals/requirements</li><li>Perform reliability analysis to identify design weaknesses and inform design improvements, such as Failure Modes and Effects Analysis or physics-of-failure assessments<br/><br/></li></ul><strong>Minimum Qualifications:<br/><br/></strong><ul><li>BS in aerospace engineering, mechanical engineering, electrical engineering, materials engineering, computer science, physics, or related technical discipline</li><li>Proven track record of building trust and effective working relationships that improve team performance, deliver results, and contribute to a culture of inclusion</li><li>2+ years of experience in system development/integration or RAMS experience of either liquid rocket engines or avionics for space applications, or 4+ years of system safety, reliability, or RAMS engineering experience in any industry</li><li>Experience with reliability engineering for electrical components and circuit card assemblies</li><li>Knowledge of systems engineering practices throughout the product lifecycle</li><li>Experience in design, development, integration, or testing – preferably with aerospace hardware or sophisticated technical systems</li><li>Experience performing system safety and reliability analyses, such as: Functional Hazard Assessments (FHA), Failure Mode, Effects, and Criticality Analysis (FMECA), Fault Tree Analysis (FTA), Reliability Block Diagrams (RBDs)</li><li>Experience with Weibull analysis and parameter estimation, stress-strength interference analyses, probability distribution estimation, reliability growth modeling, and probabilistic risk analysis</li><li>Experience working with reliability analysis and reliability modeling on a software such as Minitab/Matlab/Saphire/ Reliasoft/ Ansys Sherlock</li><li>Working understanding of configuration management principles and practices</li><li>Strong written and verbal communication and presentation skills</li><li>Must be a U.S. citizen or national, U.S. permanent resident (current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum<br/><br/></li></ul><strong>Preferred Qualifications:<br/><br/></strong><ul><li>PCBA manufacturing and/or avionics design experience</li><li>Proven technical expertise with liquid rocket engines and test facilities</li><li>Experience integrating sophisticated subsystems into a spacecraft, launch vehicle, or test facility</li><li>Experience implementing, customizing or improving system safety policy and procedure for a development engineering environment and transitioning products to operation and production</li><li>Deep understanding of principles and practices for systems engineering</li><li>Proven experience with reliability/life test design (failure modes discovery, life demonstration, and screening)</li><li>Experience with failure reporting and corrective action systems (FRACAS)</li><li>Experience using scripting languages such as VBA and Python to automate processes and analyses</li><li>Experience with systems engineering tools such as DOORS, DNG, or similar</li><li>Experience in reading/viewing mechanical drawings and CAD models in typical CAD softwares such as CreoView/NX.</li><li>Experience working in a safety-critical environment</li><li>Basic project management skills<br/><br/></li></ul>Compensation range for on site WA applicants is<br/><br/>$120,060—$168,084 USD<br/><br/><strong>Inclusivity Statement<br/><br/></strong>Don’t meet all desired requirements? Studies have shown that some people are less likely to apply to jobs unless they meet every single desired qualification. At Blue Origin, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every desired qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.<br/><br/><strong>Export Control Regulations<br/><br/></strong>Applicants for employment at Blue Origin must be a U.S. citizen or national, U.S. permanent resident (i.e. current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.<br/><br/><strong>Benefits<br/><br/></strong>Benefits include: Medical, dental, vision, basic and supplemental life insurance, paid parental leave, short and long-term disability, 401(k) with a company match of up to 5%, and an Education Support Program.<br/><br/>Paid Time Off: Up to four (4) weeks per year based on weekly scheduled hours, and up to 14 company-paid holidays.<br/><br/>Discretionary bonus: Bonuses are designed to reward individual contributions as well as allow employees to share in company results.<br/><br/>Eligibility for benefits varies by role type, please check with your recruiter for a comprehensive list of the benefits available for this role.<br/><br/><strong>Equal Employment Opportunity<br/><br/></strong>Blue Origin is proud to be an Equal Opportunity/Affirmative Action Employer and is committed to attracting, retaining, and developing a highly qualified, diverse, and dedicated work force. Blue Origin hires and promotes people on the basis of their qualifications, performance, and abilities. We support the establishment and maintenance of a workplace that fosters trust, equality, and teamwork, in which all employees recognize and appreciate the diversity of individual team members. We provide all qualified applicants for employment and employees with equal opportunities for hire, promotion, and other terms and conditions of employment, regardless of their race, color, religion, gender, sexual orientation, gender identity, national origin/ethnicity, age, physical or mental disability, genetic factors, military/veteran status, or any other status or characteristic protected by federal, state, and/or local law. Blue Origin will consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state, and local laws, including the Washington Fair Chance Act, the California Fair Chance Act, the Los Angeles Fair Chance in Hiring Ordinance, and other applicable laws. For more information on “EEO Is the Law,” please see here.<br/><br/><strong>California Applicant Privacy Notice<br/><br/></strong>If you are a California resident, please reference the CA Applicant Privacy Notice here.
      </div>",$120060- $168084,Data Pipeline Engineer
Engine Loads Analysis - Principal Engineer,BLUE ORIGIN,12/19/2023,https://www.linkedin.com/jobs/view/3756326716,0,https://media.licdn.com/dms/image/C510BAQG-nl05kZljeg/company-logo_100_100/0/1631310960783?e=2147483647&v=beta&t=uRSeWiAq8tf9sfetIGtL-z5Xdu3hlNeROpTjO-CYfiA,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Blue Origin, we envision millions of people living and working in space for the benefit of Earth. We’re working to develop reusable, safe, and low-cost space vehicles and systems within a culture of safety, collaboration, and inclusion. Join our diverse team of problem solvers as we add new chapters to the history of spaceflight! <br/><br/>This role is part of the Blue Origin Engines business unit, where our focus is the design, development, manufacturing and testing of engines and propulsion systems. Built for multiple use, our family of engines is powering the next generation of rockets for commercial, civil, national security and human spaceflight.<br/><br/>As part of a hardworking team of diverse engineers, you will support the development and qualification of new rocket engines and thrusters for various spaceflight systems. You will impact these systems by providing high quality engineering support through developing and anchoring system and component loads. You will be proficient at cross-discipline interactions to ensure proper loads model assumptions to ensure correct generation of desired outputs. You will need to be excellent at the use of finite element models to generate component and system loads. You will need to be skilled at finite element model reduction techniques and the development of forcing functions from test and historical data.<br/><br/><strong>Responsibilities include but are not limited to:<br/><br/></strong><ul><li>Prediction of loads throughout propulsion systems due to low frequency and static system loads.</li><li>Validation of loads and forcing functions using test data, and generation of forcing functions from development tests.</li><li>Work closely with a variety of systems to understand our test data and provide input into test plans so that proper data is acquired.</li><li>Contribute to the loads and dynamic process and tool development.<br/><br/></li></ul><strong>Minimum Qualifications:<br/><br/></strong><li>Minimum of a B.S. degree in mechanical, aerospace or civil engineering</li>12+ years of experience in the prediction/validation of low frequency (&lt;100hz) structural dynamics and loads<li>Finite Element Modeling experience (FEM)</li><li>NASTRAN and MATLAB proficiency</li><li>Ability to solve a variety of static and dynamic structural problems using physics-based analytical methods (hand calculations, in-house tools, and 3rd party commercial analytical tools)</li><li>Spacecraft and launch vehicle loads experience</li><li>Experience with the following commercial software tools: HYPERMESH, ANSYS, NASTRAN DMAP, ATA’s iMAT (MATLAB Toolbox), PYTHON</li><li>Experience with time domain, frequency domain, and random vibration statistical analysis</li><li>Experience with instrumentation (Accelerometers, strain gauges, pressure transducers, load cells), data acquisition systems, and signal processing</li><li>Experience with modal testing, parameter identification, FEM correlation</li><li>Must be a U.S. citizen or national, U.S. permanent resident (current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.<br/><br/></li>Compensation range for on site WA applicants is<br/><br/>$162,465.75—$227,452.05 USD<br/><br/><strong>Inclusivity Statement<br/><br/></strong>Don’t meet all desired requirements? Studies have shown that some people are less likely to apply to jobs unless they meet every single desired qualification. At Blue Origin, we are dedicated to building a diverse, inclusive, and authentic workplace, so if you’re excited about this role but your past experience doesn’t align perfectly with every desired qualification in the job description, we encourage you to apply anyway. You may be just the right candidate for this or other roles.<br/><br/><strong>Export Control Regulations<br/><br/></strong>Applicants for employment at Blue Origin must be a U.S. citizen or national, U.S. permanent resident (i.e. current Green Card holder), or lawfully admitted into the U.S. as a refugee or granted asylum.<br/><br/><strong>Benefits<br/><br/></strong>Benefits include: Medical, dental, vision, basic and supplemental life insurance, paid parental leave, short and long-term disability, 401(k) with a company match of up to 5%, and an Education Support Program.<br/><br/>Paid Time Off: Up to four (4) weeks per year based on weekly scheduled hours, and up to 14 company-paid holidays.<br/><br/>Discretionary bonus: Bonuses are designed to reward individual contributions as well as allow employees to share in company results.<br/><br/>Eligibility for benefits varies by role type, please check with your recruiter for a comprehensive list of the benefits available for this role.<br/><br/><strong>Equal Employment Opportunity<br/><br/></strong>Blue Origin is proud to be an Equal Opportunity/Affirmative Action Employer and is committed to attracting, retaining, and developing a highly qualified, diverse, and dedicated work force. Blue Origin hires and promotes people on the basis of their qualifications, performance, and abilities. We support the establishment and maintenance of a workplace that fosters trust, equality, and teamwork, in which all employees recognize and appreciate the diversity of individual team members. We provide all qualified applicants for employment and employees with equal opportunities for hire, promotion, and other terms and conditions of employment, regardless of their race, color, religion, gender, sexual orientation, gender identity, national origin/ethnicity, age, physical or mental disability, genetic factors, military/veteran status, or any other status or characteristic protected by federal, state, and/or local law. Blue Origin will consider for employment qualified applicants with criminal histories in a manner consistent with applicable federal, state, and local laws, including the Washington Fair Chance Act, the California Fair Chance Act, the Los Angeles Fair Chance in Hiring Ordinance, and other applicable laws. For more information on “EEO Is the Law,” please see here.<br/><br/><strong>California Applicant Privacy Notice<br/><br/></strong>If you are a California resident, please reference the CA Applicant Privacy Notice here.
      </div>",$162465.75- $227452.05,Data Pipeline Engineer
Quality Engineer III,Honeywell,12/19/2023,https://www.linkedin.com/jobs/view/3787612651,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Senior Quality Engineer - Design Assurance,Protingent,12/19/2023,https://www.linkedin.com/jobs/view/3701386099,0,https://media.licdn.com/dms/image/C4E0BAQE8b2DZldkjpA/company-logo_100_100/0/1630628495305/protingent_logo?e=2147483647&v=beta&t=EPkuzV7uQxpug3FULvXXbH9b0wRPKOjeWhTE7aFyCTY,"Lynnwood, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description</strong><p><br/></p><strong>Position Title: Sr. Quality Engineer - Design Assurance</strong><p><br/></p><strong>Position Description:</strong> Protingent Staffing has an exciting direct hire opportunity for a Sr. Quality Engineer with our client located in Lynnwood, WA.<p><br/></p><strong>Job Description and Responsibilities</strong>:<p><br/></p><ul><li>The Quality Engineer will control and monitor quality to ensure the production of our client’s products are consistent with established industry standards, government regulations, and customer requirements. </li><li>Established procedures and work with minimum supervision to accomplished assigned tasks by working cross-functionally with Engineering, Operations, Suppliers and Customers. </li><li>Apply advanced concepts, practices and procedures of assigned products or programs, and has appreciable latitude for action or decisions. Assignments are broad in nature, usually requiring originality and ingenuity. </li><li>Participate on Product Development programs as the cognizant Quality Design Assurance Engineer. This would include, project meetings, customer reviews, ERB and FRB Member and peer reviews. </li><li>Perform internal audits on development programs for aerospace and electronics sites and ensure audit findings are addressed by site leadership working in cross-functional teams with software engineering, mechanical and electrical design engineering, test engineering, configuration management, etc. </li><li>Assist in providing site support on the Quality Management System to improve processes and local procedures. </li><li>Serve as author of Complex Hardware Plans and/or Software Quality Plans as needed. </li><li>Assist in developing corrective action plans for development programs. </li><li>Identify need for additional training or other personnel requirements to ensure Quality Management System Requirements are met. </li><li>Review life cycle documentation on development programs and monitor the processes and practices that engineering, and manufacturing uses and verifies that they have properly defined and applied their plan to develop and maintain electronic hardware. </li><li>Assist in the drafting of internal procedures and job aids to support QMS. During development programs, facilitate identification of key process characteristics during DFMEA and control plans creation to reduce potential product variation. </li><li>During development programs, facilitate identification of key process characteristics during DFMEA and control plans creation to reduce potential product variation. </li><li>Review and monitor qualification of product and process documentation to ensure only the highest levels of quality are accepted. </li><li>Serve as area focal for development programs quality audits with Defense, Aerospace and Customer Auditors. </li><li>Provide support for failure analysis and reliability testing as required. Engage in FRACAS process to drive lessons learned from field failure and repair data into engineering design improvements. </li><li>Review and approve quality document changes (ECO, deviations). </li><li>Requires approximately 5% travel to support customers. </li></ul><p><br/></p><strong>Required Qualifications:</strong><p><br/></p><ul><li>Bachelor's degree in an Engineering/Life Sciences discipline </li><li>4 to 8+ years’ experience working in Design Assurance / Advanced Product Quality Planning (APQP) ie. QE in Product Development process is required </li><li>Aerospace or Defense Quality Engineering experience is required </li><li>Auditing experience is a hard requirement. Auditing experience resulting in corrective action and review and acceptance of completed RCCA. Demonstration of proper tool applications to support root cause such as 8D problem solving, 5 Why, Six-Sigma, DMAIC, and other Operational Excellence Tools. </li><li>AS9100 QMS experience is required. Knowledge and experience with ISO/AS9100D auditing and enforcement. </li></ul><p><br/></p><strong>Preferred Qualifications:</strong><p><br/></p><ul><li>Knowledge of Embedded Software for Aerospace Applications per DO-178C guidelines, including software planning, requirements management, code generation validation and verification highly preferred. </li><li>Strength in either HW or SW disciplines (ideally both) with experience with DO-178B and DO-178C (Software), or DO-254 (Hardware), RTCA DO-160G (Hardware) depending, all preferred. </li><li>Six Sigma Green Belt is preferred. </li><li>Experience with IBM DOORS is preferred. Rational Change, and Synergy a plus. </li><li>CQE/CQA preferred. </li><li>CMMI preferred. </li></ul><p><br/></p><strong>Nice to Have:</strong><p><br/></p><ul><li>Ability to present findings and evidence of compliance to Certification Authorities (FAA, CAAC, EASA, ANAC) and Customers. </li><li>Good organizational and planning skills. </li><li>Excellent verbal and written communication skills including ability to prepare written reports and detailed audits. </li><li>Ability to focus for long periods of time on detailed tasks. </li><li>Willingness to make decisions which may be unpopular. </li><li>Good word processing (MS Word), spreadsheet (MS Excel), and document management (Adobe Acrobat) software. Microsoft Teams a plus. </li><li>Passion for improvement, following processes, and evidence-based decisions. </li><li>Experience with Scripting languages (e.g., PERL, VB, ASP, etc.), requirements simulation (such as Matlab with Simulink or SCADE), structural coverage analysis tool (like CodeTest, LDRA, etc.) is nice to have. </li><li>Contributes at a high level with minimal supervision. </li></ul><p><br/></p><strong>Job Details:</strong><p><br/></p><ul><li>Job Type-Direct hire </li><li>Location: Lynnwood, WA </li><li>Salary Range: $109,595 - $156,334 </li><li>An offer of employment is contingent on successfully passing a drug test and background check, and applicants who do not successfully pass both the drug test and background check will not be considered for employment. </li><li> ITAR obligations are associated with this role, U.S. citizenship, U.S. legal permanent resident status, or protected person status under 8 U.S.C.</li><li>1324b(a) (1), (3) is required. </li></ul><p><br/></p><strong>About Protingent:</strong> Protingent is a niche provider of top Engineering and IT talent to Software, Electronics, Medical Device, Telecom, and Aerospace companies nationwide. Protingent exists to make a positive impact and contribution to the lives of others as well as our community by providing relevant, rewarding, and exciting work opportunities for our candidates.
      </div>",$109595- $156334,Data Pipeline Engineer
"Software Development Engineer, Project Kuiper",Amazon,12/19/2023,https://www.linkedin.com/jobs/view/3689273540,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer-Battery/Energy Storage,UL Solutions,12/24/2023,https://www.linkedin.com/jobs/view/3739456417,0,https://media.licdn.com/dms/image/C560BAQF6aPtfKvMrgQ/company-logo_100_100/0/1656335537218/ul__logo?e=2147483647&v=beta&t=1yVgwTVWiu_WQXOhzEC5CfsuV7XNmf76rLZtv1KCFx4,"Northbrook, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong>This position is a hybrid role and may require some travel. Individual will manage execution and timely completion of engineering projects by analyzing project scope and determining project specifications, establishing test programs for product investigations, and preparing reports for clients. Participates in the development of UL requirements, test methods, and test equipment. Exercises Project Handler Signature Authority as Project Handler of record responsible for opening, maintenance, completion, and closing of assigned new work engineering projects. May exercise Review Signature Authority as assigned as Reviewer of record responsible for initial review, status review, and final technical review of all new work engineering projects.<br/><br/><ul><li>Independently determines project scope, develops a preliminary plan of investigation, and determines project specifications such as cost, time, and sample requirements by analyzing client input, available supplemental data, and product construction. Projects may include frequent travel to conduct or witness tests at client sites. </li><li>Initiates communication with clients to promote and explain the benefits of new and existing services. Follows up on contacts from clients. Communicates with clients to discuss technical issues, explain UL procedures and requirements, convey project cost, and negotiate completion date and sample requirements. Acts to address client concerns and to resolve client issues. Provides technical assistance to clients in reference to product inspection and follow-up services. </li><li>Establishes appropriate test programs by reviewing files and manufacturer's information, examining samples, and applying UL requirements. Notifies client of any areas in which the product is not in compliance with UL requirements or of any changes in project scope or specifications. </li><li>Coordinates laboratory activities by preparing data sheets and instructions to technicians, scheduling and reviewing work of Laboratory Technicians and support staff and establishing completion dates. Coordinates administrative aspects of project management. Serves as Project Handler of record and may sign as Reviewer of record as assigned. </li><li>Communicates project status and results to clients through frequent contact and by preparing reports. Prepares Follow-Up Service Procedures and information pages. </li><li>Resolves engineering issues associated with Variation Notices by analyzing and reporting on the acceptability of the variations. </li><li>May provide direction as a Primary Designated Engineer or Designated Engineer for specific product categories. </li><li>May directs and review work of assigned staff. May train office, field, and/or laboratory staff and entry-level engineers. Provides technical assistance to laboratory and/or field staff. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>University Degree in Electrical, Fire Protection, Chemical, Mechanical Engineering, or Physics from an ABET accredited program plus four years directly related work experience. </li><li>Detailed knowledge of the technical vocabulary common to the appropriate discipline. </li><li>Working knowledge of conformity standards in use in area of expertise. </li><li>Demonstrated ability to apply project-handling concepts in use in area of expertise. <br/><br/></li></ul><strong>What You'll Experience Working At UL Solutions<br/><br/></strong><ul><li>Mission For UL Solutions, corporate and social responsibility isn’t new. Making the world a safer, more secure and sustainable place has been our business model for the last 127 years and is deeply engrained in everything we do. </li><li>People Ask any UL Solutions employee what they love most about working here, and you’ll almost always hear, “the people.” Going beyond what is possible is the standard at UL Solutions. We’re able to deliver the best because we employ the best. </li><li>Interesting work Every day is different for us here as we eagerly anticipate the next innovation that our customer s create. We’re inspired to take on the challenge that will transform how people live, work and play. And as a global company, in many roles, you will get international experience working with colleagues around the world. </li><li>Grow &amp; Achieve We learn, work and grow together with targeted development, reward and recognition programs as well as our very own UL University that offers extensive training programs for employees at all stages, including a technical training track for applicable roles. </li><li>Total Rewards All employees at UL are eligible for bonus compensation. We provide competitive salaries and a range of benefits designed to look after you. We also provide employees with paid time off including vacation, holiday, sick and volunteer time off. <br/><br/></li></ul><strong>Learn more:<br/><br/></strong>Working at UL Solutions is an exciting journey that twists and turns daily. We thrive in the twists and revel in the turns. This is our every day. This is our normal.<br/><br/>Curious? To learn more about us and the work we do, visit UL.com<br/><br/><strong>About Us<br/><br/></strong>A global leader in applied safety science, UL Solutions transforms safety, security, and sustainability challenges into opportunities for customers in more than 100 countries. UL Solutions delivers testing, inspection and certification services, together with software products and advisory offerings, that support our customers’ product innovation and business growth.<br/><br/>The UL Certification Marks serve as a recognized symbol of trust in our customers’ products and reflect an unwavering commitment to advancing our safety mission.<br/><br/>We help our customers innovate, launch new products and services, navigate global markets and complex supply chains, and grow sustainably and responsibly into the future.<br/><br/>From the adoption of electrification to the enablement of 5G and new mobility, we collectively look toward new frontiers, working for a safer world. Our science is your advantage.<br/><br/><strong>Mission:</strong> Working for a safer world<br/><br/><strong>About The Team<br/><br/></strong>Within our Energy and Industrial Automation (EIA), we provide solutions for safety, security, and performance throughout the energy, power distribution and, automation value chains. We work in a diversity of cutting-edge industries, such as: Power and Automation, Renewable Energy, Field Evaluation Services and Industrial Functional Safety. The impact of our work spreads through many business areas on a global scale yet focused locally through our collaborative team members.<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
Project Engineer-CO/Gas Detectors,UL Solutions,12/23/2023,https://www.linkedin.com/jobs/view/3739453734,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Tunnel Engineer,Delve Underground,12/19/2023,https://www.linkedin.com/jobs/view/3787674804,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Packaging Engineer,Ascendion,12/19/2023,https://www.linkedin.com/jobs/view/3788424419,0,https://media.licdn.com/dms/image/C4D0BAQGHeQsU54NLQA/company-logo_100_100/0/1663258479025/ascendion_logo?e=2147483647&v=beta&t=nTtxrji6TONc1rVJtXkORgZuymUriLo709h9uU2E2sE,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>About Ascendion</strong></p><p>Ascendion is a full-service digital engineering solutions company. We make and manage software platforms and products that power growth and deliver captivating experiences to consumers and employees. Our engineering, cloud, data, experience design, and talent solution capabilities accelerate transformation and impact for enterprise clients. Headquartered in New Jersey, our workforce of 6,000+ Ascenders delivers solutions from around the globe. Ascendion is built differently to engineer the next.</p><p><br/></p><p>We have a culture built on opportunity, inclusion, and a spirit of partnership. Come, change the world with us:</p><ul><li>Build the coolest tech for the world’s leading brand</li><li>Build the coolest tech for the world’s leading brands</li><li>Solve complex problems – and learn new skills</li><li>Experience the power of transforming digital engineering for Fortune 500 clients</li><li>Master your craft with leading training programs and hands-on experience</li></ul><p><br/></p><p><strong>Experience a community of change-makers!</strong></p><p>Join a culture of high-performing innovators with endless ideas and a passion for tech. Our culture is the fabric of our company, and it is what makes us unique and diverse. The way we share ideas, learning, experiences, successes, and joy allows everyone to be their best at Ascendion.</p><p><br/></p><p><strong>Position Details: </strong></p><p><strong>Job Title: Packaging Engineer</strong></p><p><strong>Location: 60661, Chicago, Illinois, United States</strong></p><p><strong> </strong></p><p><strong>Daily Responsibilities:</strong></p><ul><li>Create detailed specifications for Starbucks packaging</li><li>Use engineering principles to lead development of packaging projects through proof of concept, functional development, qualification, and commercialization phases.</li><li>Problem solve, build, test, and learn</li><li>Co-create and work alongside cross functional peers including Project Managers, Sourcing, Product, Quality, and NPI to ensure solutions and projects meet business needs</li><li>Work with packaging suppliers on development of concepts and demonstrate compliance with performance requirements</li><li>Create evaluation plans and work with engineering technicians and third-party laboratories to complete and document evaluation</li><li>Clearly and thoroughly document test results and findings and complete stage gate reviews as required</li></ul><p><br/></p><p><strong> Required background:</strong></p><ul><li>3+ years’ experience in a technical role, preferably with product development or packaging experience</li><li>A strong bias for action, testing, and learning who operates well in a fast-paced environment.</li><li>An abundance of curiosity to learn from our store partners, customers, and internal stakeholders.</li><li>Experience developing test procedures.</li><li>Outstanding ability to communicate ideas and concepts in multiple ways – such as visually, physically, verbally, or in writing to both technical and non-technical stakeholders</li></ul><p><br/></p><p><strong>Salary Range: </strong>The salary for this position is between $70,000 – $90,000 annually. Factors which may affect pay within this range may include geography/market, skills, education, experience, and other qualifications of the successful candidate.</p><p><br/></p><p><strong>Benefits:</strong> The Company offers the following benefits for this position, subject to applicable eligibility requirements: [medical insurance] [dental insurance] [vision insurance] [401(k) retirement plan] [long-term disability insurance] [short-term disability insurance] [5 personal days accrued each calendar year. The Paid time off benefits meet the paid sick and safe time laws that pertain to the City/ State] [10-15 days of paid vacation time] [6 paid holidays and 1 floating holiday per calendar year] [Ascendion Learning Management System]</p><p><br/></p><p><strong>Want to change the world? Let us know.</strong></p><p>Tell us about your experiences, education, and ambitions. Bring your knowledge, unique viewpoint, and creativity to the table. Let’s talk!</p>
</div>",$70000- $90000,Data Pipeline Engineer
Lead Rotating Equipment Engineer,Honeywell,12/19/2023,https://www.linkedin.com/jobs/view/3784448272,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Data Engineer,Inspire11,12/19/2023,https://www.linkedin.com/jobs/view/3483155847,0,https://media.licdn.com/dms/image/D560BAQE1HoZbQA737A/company-logo_100_100/0/1688674385406?e=2147483647&v=beta&t=28ncC6jgUnk4Rf3aryNJtEYayn7-i0B7DAXui6v2930,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Turn it up to 11 as a Data Engineer! <br/><br/></strong>Elevens, as we call ourselves here, are passionately curious, highly collaborative, and unabashedly authentic. At Inspire11, we believe everyone drives change, everyone takes ownership of their career, and no idea is too odd to embrace. Our team learns from each other by pushing the boundaries of what’s possible.<br/><br/>We partner with our clients to define their strategies to optimize their business in all things data and digital. Whether that be modern data architecture, custom application development, or design thinking, and this is just scratching the surface. We are a team of puzzle solvers who take the various pieces that the client already has and assemble them in a way that reveals the bigger picture.<br/><br/>We believe that the most impactful and innovative work includes and fosters a range of diverse perspectives. We’ve created a work environment in which you can expect:<br/><br/><ul><li>Individualized Professional Growth: You will have the opportunity to engage in growing the team and there are ample opportunities to define your path and develop your skillset</li><li>Work life balance: We are respectful of people’s boundaries and have unlimited time off so that our team has time to recharge and do their best work. We understand that our team members have different needs and we do our best to work with their schedules while accommodating client needs </li><li>Vibrant company culture: We love to keep things light-hearted, both within our client work and at companywide events <br/><br/><br/></li></ul><strong>What you can expect in this role:<br/><br/></strong><ul><li>Moving and transforming data optimally between different systems (operational system to prepare for analytics)</li><li>Low-level design, diagramming, documenting, and training of client resources on ETL pipeline solutions</li><li>Data exploration, analysis, and discovering business insights within data as applicable to data transformation</li><li>Creating and designing database objects and configuring the database platform</li><li>Data configuration and change management, DevOps, and Source Control</li><li>Infrastructure – setting up and configuring data and analytics tools and platforms in enterprise environments (AWS, Azure, GCP, hybrid) <br/><br/><br/></li></ul><strong>Tools for success:<br/><br/></strong><ul><li>A minimum of 2 years of professional experience as a data/software engineer (there will be commensurate responsibilities and compensation based on years of experience)</li><li>Programming Background (Python, Spark, Scala, Etc.)</li><li>Strong SQL experience (preferably across more than one database platform)</li><li>Experience with various data ingestion patterns (batch, streaming, API)</li><li>Source control tool experience (Git, SVN, CVS)</li><li>Communication (comfortable talking to a business user)</li><li>Cross-functional team collaboration</li><li>College degree, boot camp, or equivalent training/experience<br/><br/><br/></li></ul>This role requires the willingness and ability to be onsite at the Inspire11 or client location depending on project needs to maximize in-person collaboration and build stronger relationships.<br/><br/>Please note employees must be authorized to work for any employer in the U.S. Inspire11 is unable to sponsor or take over sponsorship of an applicant’s employment visa.<br/><br/><strong>EEOC<br/><br/></strong>Inspire11 is an Equal Opportunity Workplace and an Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, or protected veteran status
      </div>",No Salary Info Found,Data Pipeline Engineer
Packaging Engineer,Home Chef,12/19/2023,https://www.linkedin.com/jobs/view/3779183843,0,https://media.licdn.com/dms/image/C560BAQGHBYJGDOKS7w/company-logo_100_100-alternative/0/1630655173417/relished_logo?e=2147483647&v=beta&t=pa-afOVs7csreTP3f0erYRza8oHLfF7HAPZMm9qzZ5o,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Founded in 2013, Home Chef is the leading meal solutions company with both a retail and online presence. Available online at homechef.com and in retail at more than 2,100 Kroger grocery stores, Home Chef is committed to inspiring and enabling more people to cook simple, delicious meals, no matter how busy they are. Similar to our recipes, we recognize that variety is the spice of life; therefore, our employees also bring their uniqueness and color to our fantastic team. We’re eager to work with humble team players and pragmatic next-level thinkers to innovate on Home Chef’s offerings.<br/><br/><strong>Overview<br/><br/></strong>The Packaging Engineer will manage the design, development, implementation and continuous improvement of new packaging materials within Home Chef’s vast supply chain. From corrugated boxes or plastic film seals to thermal liners and recycled PET, the ideal candidate will bring a formal education in packaging design and couple it with years of experience working in food manufacturing or cold chain shipping. This individual will report directly to the Head of Packaging and be responsible for bringing innovative and sustainable packaging solutions to business while also finding improvement opportunities for existing packaging items within the Home Chef Supply Chain.<br/><br/><strong>Responsibilities<br/><br/></strong><strong> Project Management: <br/><br/></strong><ul><li> Manage packaging projects from initial concepts to implementation in cross-functional settings </li><li> Drive the direction of the project throughout planning and decision making processes </li><li> Serve as the subject matter expert (SME) for the teams / company </li><li> Deliver technical expertise to executives / leaders to help in making business decisions <br/><br/><br/></li></ul><strong>Packaging Optimization<br/><br/></strong><ul><li> Assess and optimize current packaging materials and recommend areas of opportunities </li><li> Conduct feasibility and validation testing of any new packaging changes </li><li> Apply technical knowledge and leadership skills in problem-solving and driving improvements <br/><br/><br/></li></ul><strong>New Product Introduction<br/><br/></strong><ul><li> Manage the optimal design, validation and implementation of new packaging items </li><li> Recommend new packaging options while balancing cost, performance and quality </li><li> Work with vendors in developing and introducing new packaging items </li><li> Oversee and coordinates ship testing and trials of new packaging items at the sites <br/><br/><br/></li></ul><strong>Other<br/><br/></strong><ul><li> Perform Supply Chain special projects as needed </li><li> Manage packaging categories as needed <br/><br/><br/></li></ul>This position requires 20-40% travel.<br/><br/><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Packaging Science, Packaging Engineering, Packaging Design, Mechanical Engineering or related field </li><li> 3-5 years of work experience in the packaging field, strong understanding of CPG and E-commerce industry preferred </li><li> Strong understanding of packaging materials, packaging design, manufacturing capabilities &amp; converting processes </li><li> Good understanding of packaging regulatory requirements, food safety, food manufacturing and related technologies </li><li> Strong negotiating and interpersonal skills with proven ability to develop and maintain internal and external partnerships </li><li> Flexible and ability to work in a fast-paced environment </li><li> Ability to collect and analyze raw data to make recommendations with valid assumptions </li><li> Excellent verbal and written communication skills </li><li> Team management experience is a plus </li><li> Must be willing to travel up to 40% </li><li> Must be available to respond to work related inquiries during weekends if needed <br/><br/><br/></li></ul>Salary Range: $100,000 - $110,000<br/><br/><strong>More About Us<br/><br/></strong><strong>Perks and benefits:<br/><br/></strong><ul><li> Comprehensive Medical, Dental, and Vision Insurance – benefits start the 1st day of the month following your start date </li><li> Company-paid Life Insurance, Short Term Disability, and Long Term Disability </li><li> 401(k) Employer match </li><li> Flexible spending accounts (FSA) for qualified Medical, Dependent Care, Parking, or Transit expenses </li><li> Flexible paid time off (PTO) policy, holidays and sick time </li><li> Generous Parental Leave </li><li> State-of-the-art office in the historic Old Post Office building in downtown Chicago, close to multiple Metra and CTA options, and amenities such as a food court, onsite gym, and communal rooftop space </li><li> Discounts on Home Chef meal kits and at Kroger stores </li><li> Casual dress in a fun, friendly, and collaborative work environment <br/><br/><br/></li></ul>Candidates can experience Home Chef as a customer - enter promo code PEOPLE30 for $30 off your first order!<br/><br/><strong>How We Work Together<br/><br/></strong><strong>We are humble team players.<br/><br/></strong>We are warm and gracious with team members and customers. We seek feedback to improve ourselves - and respectfully listen to and accept input.<br/><br/><strong>We are pragmatic next-level thinkers.<br/><br/></strong>We come up with novel and unique ideas. We explore new strategies to avoid being constrained by conventional thinking.<br/><br/><strong>We take ownership.<br/><br/></strong>We approach ambiguous problems, prepared to dive in, get curious, and learn more. We are results-driven, always challenging ourselves to exceed goals.<br/><br/><strong>Be at Home at Home Chef<br/><br/></strong>We all show up authentically at Home Chef. Our team includes individuals with a variety of identities, backgrounds, and perspectives. You can trust that you’ll be able to bring your whole self to an inclusive and enjoyable workplace.<br/><br/>We welcome people of all races, colors, religions, national origin or ancestry, sex (including sexual identity), age, physical or mental disabilities, pregnancy, veteran or military status, unfavorable discharge from military service, genetic information, sexual orientation, marital status, order of protection status, citizenship status, arrest record or expunged/sealed convictions, or any other legally recognized protected basis under federal, state, or local law.<br/><br/>Home Chef is committed to the full inclusion of all qualified individuals. As part of this commitment, Home Chef will ensure that persons with disabilities are provided reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, or to receive other benefits and privileges of employment, please contact our People team at hr@homechef.com .<br/><br/>Home Chef is an equal opportunity employer.<br/><br/>To view the California Applicant Notice click here
      </div>",$100000- $110000,Data Pipeline Engineer
Project Engineer Data Center Construction (Traveling),The Weitz Company,12/19/2023,https://www.linkedin.com/jobs/view/3691623988,0,https://media.licdn.com/dms/image/C560BAQGLyR02jWBViA/company-logo_100_100/0/1675800413330/the_weitz_company_logo?e=2147483647&v=beta&t=Pk560TZwv4tc2XcT62AXDdnb1WKU-awUPJdJlL8OaZg,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Our Company views employees as our most valuable asset, and the key to our success. We are committed to growing a diverse and inclusive culture that inspires, motivates, and continuously improves. Community involvement, employee empowerment, and strong relationships makes The Weitz Company a great place to work.<p><br/></p>The Weitz Company is currently accepting applications for an outstanding Project Engineer (various levels) to join our Mission Critical business unit.<p><br/></p>This position would be assigned to data center jobsites located in:<p><br/></p><ul><li> Goodyear, AZ</li><li> Leesburg, VA</li><li> Des Moines, IA</li><li> Queretaro, MX</li></ul><p><br/></p>The Project Engineer is responsible for several functions throughout the duration of assigned projects including planning, buyout, management and closeout. This role actively assists the project team in monitoring project status and identifying issues that may impact the project schedule and/or budget. The Project Engineer typically reports to the Project Manager.<p><br/></p><strong>What You'll Do</strong><p><br/></p><ul><li>Organize, review, update, maintain and post construction documents and drawings</li><li>Collaborate with project team to complete requests for information (RFI)</li><li>Review submittals and other project documents for accuracy against plans and specifications</li><li>Assist in preparing inspections, compliance audits and the non-conformance log</li><li>Monitor material and equipment delivery status</li><li>Maintain and distribute accurate project logs (i.e. buyouts, subcontractor material status reports, submittals, RFIs)</li><li>Understand scopes of work to be included in subcontracts and/or purchase order agreements</li><li>Track subcontractor requests for change; solicit pricing and draft change orders within delegated authority</li><li>Understand and assist with project schedule management</li><li>Attend regular project meetings; record and distribute meeting minutes</li><li>Obtain closeout information; gather punch list items; prepare as-built drawings; assist with warranty process</li><li>Perform other duties as assigned</li></ul><p><br/></p><strong>What We're Looking For</strong><p><br/></p>To perform the job successfully, an individual must be able to perform each previously stated duty satisfactorily. The requirements listed below are representative of the knowledge, skills, and ability necessary to succeed in the role.<p><br/></p><ul><li>Education: Industry related college degree is required.</li><li>Experience: A minimum of two (2) years of project engineering experience is required. Previous construction internship experience is preferred. </li><li>Skills: Good engineering and construction management skills are important. Individual must have good communication skills and the ability to communicate effectively with the owner, architect, and The Weitz Company project team. A high level of integrity is required. Good time management and project organization skills are essential. Microsoft Office proficiency is important.</li><li>Systems: Must be proficient in basic computer software programs such as Microsoft Office products (Outlook, Work, PowerPoint, Excel), and must be able to learn project management software (JDE, Procore, Asta, Bluebeam, etc.).</li></ul><p><br/></p><strong>What We Offer</strong><p><br/></p><ul><li>Competitive Pay </li><li>Rewarding Bonus Program</li><li>Comprehensive Benefits Package with Tax-Advantaged HSA and FSA offerings</li><li>Employer-Paid Short- and Long-Term Disability Programs</li><li>Employer-Paid Life Insurance</li><li>Generous Paid Time Off Provisions</li><li>401K Retirement Savings Plan with Company Match</li><li>Tuition Reimbursement</li><li>Fully Paid Parental Leave</li><li>Voluntary Products including Critical Illness Insurance and Accident Insurance</li><li>Corporate Wellness Program with Wellness Time Off and Rewards</li></ul><p><br/></p>Visa sponsorship is not available for this position at this time.<p><br/></p>The Company is an Affirmative Action and Equal Opportunity Employer. All qualified applicants will receive consideration for employment (minorities, females, veterans, individuals with disabilities, sexual orientation, gender identity, or other protected categories in accordance with state and federal laws). The Company is a drug and alcohol-free workplace and background checks are required if applicable. Click here to review our Privacy Notice.<p><br/></p>
</div>",No Salary Info Found,Data Pipeline Engineer
Manufacturing Process Engineer,Michael Page,12/20/2023,https://www.linkedin.com/jobs/view/3789066443,0,https://media.licdn.com/dms/image/D4E0BAQHpnANIG_FYpg/company-logo_100_100/0/1688136319954/michael_page_logo?e=2147483647&v=beta&t=8yzyuGaO6CWTnI9EATyUXLh56hDVvlSRoyfV4JpPkvs,"Elk Grove Village, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>We are seeking a dynamic and experienced Manufacturing Process Engineer to join our team. The successful candidate will play a crucial role in optimizing our manufacturing processes, driving efficiency gains, and contributing to the overall success of our operations. If you are a passionate and innovative engineer with a background in metal fabrication, we invite you to be part of our exciting journey.</p><p><strong>Client Details</strong></p><p>Our client is a leading metal fabrication company committed to delivering high-quality, precision-engineered metal products. With a rich history spanning 85 years, we have established ourselves as an industry leader known for innovation, reliability, and excellence in manufacturing. </p><p>Our state-of-the-art facilities, equipped with cutting-edge technology, enable us to provide customized metal solutions across various industries, including areospace and electrical assembly. From complex structural components to intricate sheet metal designs, our skilled team of craftsmen and engineers collaborates to bring our clients' vision to life. </p><p><strong>Description</strong></p><ul><li>Analyze production data/metrics to identify areas for process improvement as well as future limitations to manufacturing capabilities to ensure future continued success</li><li>Troubleshoot production and machinery issues as needed; work closely with floor personnel as well as other Manufacturing/Quality Engineering staff</li><li>Develop new manufacturing processes as the company gains more business and launches more product lines</li><li>Evaluate and select appropriate materials, tools, and eqipment for metal fabrication processes </li><li>Analyze production line/work cell layouts and optimize using 3D modeling software</li><li>Write work instructions/SOPs for launch of new product</li></ul><p><strong>Profile</strong></p><ul><li>Bachelors degree in Engineering or related field</li><li>3+ years' professional experience in a manufacturing environment</li><li>Experience in an electronics manufacturing setting is preferred, but not required</li><li>Background leading LEAN/Continuous Improvement projects with a track record driving cost savings &amp; throughput increase</li><li>Experience with product testing preferred</li><li>Exposure to New Product Introduction activities - Quality planning, job routing</li><li>Excellent verbal, written, and interpersonal skills</li></ul><p><strong>Job Offer</strong></p><ul><li>Base salary $95,000 - $125,000 depending on level of experience</li><li>Discretionary bonus based on company performance</li><li>3 weeks PTO plus 3 personal days</li><li>Comprehensive benefits</li><li>3.5% 401k match<br/></li></ul><p><em>MPI does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity or expression, national origin, age, disability, veteran status, marital status, or based on an individual's status in any group or class protected by applicable federal, state or local law. MPI encourages applications from minorities, women, the disabled, protected veterans and all other qualified applicants.</em></p>
</div>",$95000- $125000,Data Pipeline Engineer
Construction Project Engineer,The Walsh Group - Walsh Construction & Archer Western,12/20/2023,https://www.linkedin.com/jobs/view/3771445288,0,https://media.licdn.com/dms/image/C4E0BAQG6NABsS_mOgA/company-logo_100_100/0/1630578975686/walsh_construction_logo?e=2147483647&v=beta&t=IdAcMgkm5TaXeUR_k9fhbhlTKkwlHJIK3Ltr5XsHyOA,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>Walsh is currently seeking <strong>Project Engineers </strong>for our <strong>Transportation Division in the Chicagoland area</strong>.<br/><br/>Are you someone who flourishes on solving problems? Do you leverage data to make decisions and recommendations? Are you excited about working on a team collaboratively to solve these problems? Do you enjoy self-perform work? If this sounds like you, then we want to hear from you!<br/><br/>Walsh Project Engineers are bright and caring people who are motivated by a challenge. They get things done because they plan their work and then work their plan. They put the same amount of time into building and maintaining relationships as they do in managing their production.<br/><br/>As a fourth-generation, family-owned business, Walsh recruits individuals who are seeking a small company feel with a large company backing. Walsh is a successful fast-growing company at the forefront of technology and is committed to being the employer of choice to our employees and the builder of choice to our customers.<br/><br/>Walsh is a company where, when you work hard, you <strong>will</strong> be recognized. If this sounds like you, please apply!<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Document control (RFIs, submittals, change orders, claims, etc.) </li><li> Assisting and supporting project team with daily project coordination </li><li> Procurement of construction materials </li><li> Quality Control / Quality Assurance checks </li><li> Coordination of subcontractors </li><li> Survey and project layout </li><li> Weekly pictures for progress reports </li><li> Manage construction equipment </li><li> Safety management </li><li> Project estimating <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> 1-2 years of experience </li><li> Bachelor’s degree preferred </li><li> Previous internship, co-op, or employment experience is a plus </li><li> Specific roles may require relocation <br/><br/></li></ul><strong>The Walsh Group offers competitive wages and benefits, including:<br/><br/></strong><ul><li> Medical, Dental &amp; Vision Insurance </li><li> Generous Vacation Time &amp; Paid US Holidays </li><li> Company 401(k) Matching Contributions </li><li> Flexible Spending Accounts (FSA) </li><li> Employee Assistance Program (EAP) </li><li> Commuter Benefits Program </li><li> Maternity Leave Policy </li><li> Short and Long-Term Disability Insurance </li><li> Term Life and AD&amp;D Insurance <br/><br/></li></ul>If hired by The Walsh Group, you must be in compliance with your employment location’s COVID-19 related requirements, if any.<br/><br/>The Walsh Group, Ltd. Is committed to providing equal opportunity to qualified applicants with disabilities to compete for jobs. To request a reasonable accommodation in completing this application, please contact the Human Resources Department at 312-563-5905 or hr@walshgroup.com .<br/><br/>An Equal Opportunity Employer, Disability/Veteran
      </div>",No Salary Info Found,Data Pipeline Engineer
Environmental Project Engineer,Jobot,12/24/2023,https://www.linkedin.com/jobs/view/3791336083,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Environmental Project Engineer<br/><br/></strong>This Jobot Job is hosted by Brian Perkins<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $80,000 - $110,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>Integrated consulting firm providing engineering and environmental solutions for public and private projects of all sizes. We are committed to solving the challenges of making the Earth a better place to live - community by community, and project by project.<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong>Competitive Salary<br/><br/>Employee Stock Option Plan (ESOP)<br/><br/>401(k) with employer match<br/><br/>401(k) Student Debt Solution program<br/><br/>21 days PTO<br/><br/>Paid Holidays<br/><br/>Educational Financial Assistance<br/><br/>Mentoring Program<br/><br/>Professional Development Program<br/><br/>Opportunities for internal cross-training of engineering disciplines<br/><br/>Health and Dental Insurance<br/><br/>Vision Insurance<br/><br/>Supplemental Accident, Critical Illness, and Hospital Indemnity<br/><br/>Flexible Spending Account<br/><br/>Life and Disability Insurance<br/><br/>Stipend (eligible for opt-out health insurance stipend if other coverage is available/proof of coverage required)<br/><br/>Comfortable Work/Life Balance<br/><br/>Flexibility<br/><br/>Hybrid work schedule<br/><br/><strong>Job Details<br/><br/></strong><strong>Essential Functions<br/><br/></strong>To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The requirements listed are representative of the knowledge, skill and/or ability required. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br/><br/>Collaborates with team members and others to effectively execute assignments. Collects environmental soil, water, air, or other media samples both individually and as part of a field team; operates, calibrates, and maintains necessary field equipment and instruments, performs routine personnel and instrument decontamination; collects or oversees sampling during drilling; prepares and packages samples for shipping to an analytical laboratory; and ships samples for analysis.<br/><br/>Serves as Site Safety Officer, field engineer/scientist/geologist, or other to support environmental project work, after demonstration of site knowledge and position knowledge, including respect of peers. Initiates training as field team leader for larger environmental projects. May be required to direct field technicians and other staff during field work and coordinate work tasks. Collects necessary field data through observation or through basic field data collection techniques using field instruments such as field survey equipment, tape measures, flow meters, turbidity samplers, sieve analyses, cameras, pumps, data loggers, remediation equipment, and other instruments as needed.<br/><br/>Reviews, evaluates, and interprets technical reports, specifications, plans, calculations, construction schedules, and cost estimates for projects. Works with team members to complete environmental investigation and remediation projects, including sampling, drilling, and decontamination tasks.<br/><br/>Communicates technical information with equipment and materials vendors, accurately documents such communications, and applies the information obtained to the relevant project work.<br/><br/>Prepares engineering design calculations, hydro-geological assessments, and construction cost estimates. Determines the feasibility of a project or project feature based on analysis of the prepared calculations, cost estimates, and other collected data.<br/><br/>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$80000- $110000,Data Pipeline Engineer
Databricks / Machine Learning Cloud Engineer,Dice,12/21/2023,https://www.linkedin.com/jobs/view/3788096600,0,https://media.licdn.com/dms/image/C560BAQEYK67Tel_mng/company-logo_100_100/0/1630655500596/dice_logo?e=2147483647&v=beta&t=rllH_-w7fwNGRPjMmwRghSwN8osS0JKW18T_-sIwDn4,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Xoriant Corporation, is seeking the following. Apply via Dice today!<br/><br/><strong>Job Title : </strong><strong>Data Brick Developer/ ML Cloud Engineer<br/><br/></strong><strong>Client Location: Boston, MA (Hybrid 2-3 days a week onsite)<br/><br/></strong><strong>Duration : Long term contract<br/><br/></strong><strong>Education And Experience Qualification<br/><br/></strong><ul><li>Bachelor’s degree in Computer Science, Information Systems, or equivalent education or work experience</li><li>8+ years of IT experience in big data space like Hadoop, data lake, data engineering using Python &amp; Spark programming languages</li><li>Any AWS and/or Databricks certification will be a plus<br/><br/></li></ul><strong>Roles &amp; Responsibilities<br/><br/></strong><ul><li>Recognize the current application infrastructure and suggest new concepts to improve performance</li><li>Document the best practices and strategies associated with application deployment and infrastructure support</li><li>Produce reusable, efficient, and scalable programs, and also cost-effective migration strategies</li><li>Develop Data Engineering and ML pipelines in Databricks and different AWS services, including S3, EC2, API, RDS, Kinesis/Kafka and Lambda to build serverless applications</li><li>Work jointly with the IT team and other departments to migrate data engineering and ML applications to Databricks/AWS</li><li>Comfortable to work on tight timelines, when required.<br/><br/></li></ul><strong>Skill Sets Required<br/><br/></strong><ul><li>Good decision-making and problem solving skills</li><li>Solid understanding of Databricks fundamentals/architecture and have hands on experience in setting up Databricks cluster, working in Databricks modules (Data Engineering, ML and SQL warehouse).</li><li>Knowledge on medallion architecture, DLT and unity catalog within Databricks.</li><li>Experience in migrating data from on-prem Hadoop to Databricks/AWS</li><li>Understanding of core AWS services, uses, and AWS architecture best practices</li><li>Hands-on experience in different domains, like database architecture, business intelligence, machine learning, advanced analytics, big data, etc.</li><li>Solid knowledge on Airflow </li><li>Solid knowledge on CI/CD pipeline in AWS technologies</li><li>Application migration of RDBMS, java/python applications, model code, elastic etc.</li><li>Solid programming background on scala, python</li><li>Experience with Docker and Kubernetes is a plus<br/><br/></li></ul>Databricks / Machine Learning Cloud Engineer
      </div>",No Salary Info Found,Data Pipeline Engineer
Project Engineer II,Judlau OHLA (An OHLA USA Company),12/19/2023,https://www.linkedin.com/jobs/view/3737679342,0,https://media.licdn.com/dms/image/C4E0BAQHvJjfV4YVUiA/company-logo_100_100/0/1630648250845/judlau_contracting_inc__logo?e=2147483647&v=beta&t=rS8UAsfNZUI4X4thMJB5QrY0sGxCYJ6lkJ3F_x2j2JY,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Who is <strong>OHLA USA</strong>?<br/><br/>We are a company who believes in building a better, safer, more sustainable world for generations to come. We are committed to making a difference within our communities, who depend on the safety and reliability of the structures we build and is possible with our main asset, <strong>our people!<br/><br/></strong>OHLA USA brings together the construction industry's most diverse talent who thrive in a collaborative work environment and appreciate challenges and opportunities.<br/><br/>We currently have an opportunity for a <strong>Project Engineer II </strong>in Worcester, MA and Lynn, MA. The Project Engineer is responsible for providing technical engineering and project control support on our heavy civil and transportation construction projects. This role works closely with the Project Manager to implement policies and procedures required for project success. The Project Engineer is expected to maintain a good knowledge of the contract specifications, documents and the scope of work, including subcontracts and purchase orders and to assist in development of project status reports and profit projections on our projects.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Works closely with Project Managers, Superintendents, Foreman and crews on project deliverables. </li><li> Process/manage material deliveries – ensure that materials received are properly inspected for quantity and quality and are in compliance with contract documents. </li><li> Manage and negotiate subcontractor and material contracts. </li><li> Assist in developing and updating the project schedule. </li><li> Coordinate and schedule shop drawings and submittals. </li><li> Maintain a complete and current record of submittals, approvals and resubmittals, including a file of letters of transmittal and dates of each transaction. </li><li> High level of involvement in the operations of our cost control system and analysis of construction costs. </li><li> Participate in monthly forecasting revenue and cost accruals. </li><li> Accumulate all necessary data and prepare monthly pay estimates. </li><li> Process and estimate change orders and requests for information as directed by the Project Manager. </li><li> Follows OHLA USA policies and procedures, including safety policies. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor’s degree in Civil Engineering, Construction Management, or related field </li><li> 5+ years of heavy civil construction experience </li><li> Safety oriented – 10-hour and 30-hour OSHA certificates are preferred </li><li> Strong organizational and time management skills </li><li> Ability to function as a team builder/player </li><li> MBTA experience strongly preferred <br/><br/></li></ul><strong>Additional Benefits Offered By OHLA USA<br/><br/></strong><ul><li> Medical, Dental, &amp; Vision Insurance </li><li> Short- and Long-Term Disability &amp; Life Insurance </li><li> 401(k) retirement plan with employer matching </li><li> Tuition Reimbursement after 1 year of employment </li><li> Personal Time Off Program (PTO) </li><li> Engaging work environment </li><li> And much more!! <br/><br/></li></ul>To learn more about OHLA USA, visit our website www.ohla-usa.com<br/><br/><strong> OHLA ADA Message </strong> : The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions. While performing the duties of this job, the employee will require the ability to freely access all points of a construction site in wide-ranging climates and environments. The employee is occasionally exposed to fumes or airborne particles; toxic or caustic chemicals; Employee is frequently exposed to outside weather conditions. The noise level in the work environment is usually loud noise.<br/><br/><strong> OHLA EEO Message: </strong> OHLA USA and its affiliates are an equal opportunity employer, and all qualified applicants are considered for employment without regard to age, race, color, religion, sex, national origin, sexual orientation, gender identity, veteran status, disability, or any other protected class. <strong> VEV RRA Federal Contracto r <br/><br/></strong>OHLA USA and its subsidiaries (“OHLA”) shall not accept unsolicited resumes from any source other than directly from a candidate. Any unsolicited resumes sent to OHLA or an employee of OHLA, by mail, electronically, or otherwise will be considered OHLA property. OHLA will not pay a fee for any placement resulting from the receipt of an unsolicited resume. OHLA will consider any candidate for whom an Agency has submitted an unsolicited resume to have been referred to by the Agency free of any charges or fees. OHLA Human Resources is the only authorized representative of OHLA to execute any agreements with search firms or staffing agencies. As a condition for payment, a Vendor shall have OHLA USA Inc.’s Personnel Agreement and a Job Order signed by an authorized OHLA HR representative. Verbal or written communications from any employee of OHLA and its subsidiaries shall not be considered binding obligations. All resumes, whether unsolicited or solicited, shall be the property of OHLA.<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
Project Engineer I,Judlau OHLA (An OHLA USA Company),12/19/2023,https://www.linkedin.com/jobs/view/3737681152,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Engineer – Compressor Structures Design Engineer,GE Aerospace,12/19/2023,https://www.linkedin.com/jobs/view/3790370409,0,https://media.licdn.com/dms/image/D560BAQGEU0_PAp08RQ/company-logo_100_100/0/1684425911325/geaerospace_logo?e=2147483647&v=beta&t=hUPcyP3Zi1NxNpMrT3eDn8JcmW89vums-nJj9-QW6nU,"Lynn, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><strong><strong><strong>Job Description Summary</strong></strong></strong> </strong>The T901 Compressor Stator Engineer will own compressor structures hardware including but not limited to the additive combustor case. The T901 program is in the Engineering and Manufacturing Development program phase – an exciting time filled with 20+ engine tests over the next two years and the transition of hardware from development into initial production. In the role of T901 Compressor Structures Engineer, you will work to make decisions about the technical direction of the additive structures hardware, apply engineering concepts to design and manufacturing issues, and resolve issues through immediate action and short-term planning. In addition, you will provide direction and assistance to the T901 compressor module team to meet assigned objectives.<strong> <strong>Job Description</strong> <br/><br/></strong><strong>Roles And Responsibilities<br/><br/></strong><ul><li>Execute, with guidance from senior engineering resources, the analysis, design, test and integration required to define and support assigned components, assemblies or systems that meet business standards and program / product requirements</li><li>Prepare and present technical data to internal and external customers</li><li>Document and communicate results of technical data generated</li><li>Participate on teams assigned to address specific team initiatives and design challenges</li><li>Share engineering information and promote open dialogue</li><li>Prepare invention disclosures to protect the technology that provides a competitive advantage to the business</li><li>Assure proper documentation of technical data generated for the assigned projects and/or tasks consistent with engineering policies and procedures<br/><br/></li></ul><strong>Q u a li f i c atio n s/ R e qu i r e m e n ts:<br/><br/></strong><ul><li>Bachelor’s Degree in Engineering, Physics, Mathematics or Computer Science from an accredited college or university</li><li>Minimum 2 years of experience in an engineering role<br/><br/></li></ul><strong> D </strong><strong>es i r ed Ch a r a c t er i st i c s:<br/><br/></strong><ul><li>Familiarity with design, test and analysis tools and systems</li><li>Strong oral and written communication skills</li><li>Strong interpersonal and leadership skills</li><li>Ability to work independently</li><li>Ability to prioritize and manage multiple projects at a time</li><li>Strong problem-solving skills</li><li>Early adopter of change, adjusting to find faster, simpler approaches that are impactful</li><li>Experience in manufacturing support and/or additive design</li><li>Experience in computer aided design (CAD) programs such as NX, finite element analysis (FEA) such as Ansys, tolerance stack-ups, and other basic mechanical design and stress assessments.<br/><br/></li></ul><em>This role is restricted to U.S. persons (i.e., U.S. citizens, permanent residents, and other protected individuals under the Immigration and Naturalization Act, 8 U.S.C. 1324b(a)(3)) due to access to export-controlled technology. GE will require proof of status prior to employment.<br/><br/></em><strong> <strong><strong><strong>Additional Information</strong></strong></strong> <br/><br/></strong>GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer . Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law.<br/><br/>GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable).<br/><br/><strong>Relocation Assistance Provided: </strong>Yes
      </div>",No Salary Info Found,Data Pipeline Engineer
"Project Engineer – Boston, MA",Stadler,12/19/2023,https://www.linkedin.com/jobs/view/3781909361,0,https://media.licdn.com/dms/image/C4D0BAQHM5bMXC-QFFA/company-logo_100_100/0/1631350661479?e=2147483647&v=beta&t=K15jfInEaOGP9FjML0mWm8PSXN2aeLWPL0V-lN7nhrA,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Stadler has been building trains for over 80 years. With our innovative strength, flexibility and reliability we are a leading manufacturer of rail vehicles today. In addition to our Swiss locations, around 13,000 employees work at several production and engineering sites atover 70 service locations in Europe, North America, and North Africa.<br/><br/>Join our team and help us shape the future of mobility!<br/><br/><strong>Your tasks<br/><br/></strong>As a Project Engineer you must understand the technical functional, operational and commercial requirements affecting the implementation of Train Protection Systems with emphasis on the Signals and Train Control Segment. If you are an experienced Project Engineer who wants to be part of a team that builds high quality, state of the art passenger trains and signaling solutions, this is the career for you!<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li> Oversee and manage any of the numerous technical and administrative aspects of Train Protection System implementation</li><li> Comprehend, communicate and provide direction on all elements of a Train Protection System which include: vehicle on-board train control systems, wayside signal systems and interfaces for communications systems and operations control centers</li><li> Be responsible for management and oversight and direct involvement with project design, testing, construction and system certification</li><li> Ability to develop operations and maintenance documents, maintenance plans, training plans and support other activities in connection with the implementation</li><li> Maintain close oversight of all schedules, report progress, and provide technical summaries of the Program, develop material to present updates to the client, have a ""real-time"" connection to the project</li><li> Respond or report to work as directed by supervisory personnel for emergencies, extreme weather conditions, or any other abnormal conditions that impair service or the safety of service, twenty-four (24) hour, seven (7) day per week basis<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><strong>Your profile</strong> <strong>Qualifications<br/><br/></strong><ul><li> 3 + years of recent experience in railroad or transit signal systems or train control systems infrastructure maintenance and engineering for an organization with similar infrastructure (highway or airline) and work requirements</li><li> Bachelor's degree from an accredited institution in Mechanical or Electrical Engineering or a related field. High school diploma or equivalent (G.E.D) from an accredited institution with the ability to comprehend, communicate and respond to instructions, orders, signs, notices, inquires, etc. in English</li><li> 1-2 years project management experience</li><li> Comprehension of technical materials, test plans and other data used to validate designs and progress through testing to implementation of the system</li><li> Excellent customer service and presentation skills</li><li> Effective analytical, organizational, multi-tasking, conflict resolution and time management skills<br/><br/></li></ul><strong>Our offer<br/><br/></strong><strong>What We Offer<br/><br/></strong>Stadler US employee benefits package includes:<br/><br/><ul><li> Competitive Pay (annual bonus potential)</li><li> Low-cost, comprehensive Medical / Dental / Vision / Rx plans</li><li> 401(k) with generous employer match after 90 days</li><li> Generous Paid Time Off / 9 Paid Holidays / Extended Paid Holiday</li><li> Paid training/career development</li><li> Tuition and training reimbursement</li><li> Paid maternity and parental leave</li><li> Company-paid life and disability insurance</li><li> Referral bonus program</li></ul>
</div>",No Salary Info Found,Data Pipeline Engineer
Project Engineer ( Railway Signaling Infrastructure ),System One,12/20/2023,https://www.linkedin.com/jobs/view/3784461278,0,https://media.licdn.com/dms/image/D4E0BAQG7cuqxm4I9yg/company-logo_100_100/0/1691164675899/system_one_logo?e=2147483647&v=beta&t=KVgCHthlCVZGakCVQ2Q1bWj--02pkY2VNjbewFVdeks,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Please send me your details (resume, work authorization status, current location, availability and compensation expectations) directly to: denis.potapenko@systemone.com for an immediate consideration. Make sure to include both the job title and location of the job if you email me directly.<br/><br/><ul><li> Permanent, full-time job ( direct hire ) offering W2 annual salary with full benefits<br/><br/></li></ul><strong>Project Engineer ( Project Manager )<br/><br/></strong><ul><li> Must understand the technical functional, operational, and commercial requirements effecting the implementation of Train Protection Systems (wayside and carborne train control signaling systems and equipment)</li><li> In charge of the various technical and administrative aspects of Train Protection System implementation for MBTA</li><li> Comprehend, communicate, and provide direction on all elements of a Train Protection System ( rail vehicle on-board / carborne train control systems, wayside signal systems and interfaces for communications systems and operations control centers )</li><li> Has direct involvement with project design, testing, construction, and system certification</li><li> Develop operations and maintenance documents, maintenance plans, training plans, etc.</li><li> Maintain project schedules, report progress and various KPIs, present updates to the client<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's or Master's degree in relevant discipline</li><li> Project Management, Project Engineering experience</li><li> Excellent customer service and presentation skills, effective analytical, organizational, multi-tasking, conflict resolution and time management skills</li><li> Experience working for companies related to railroad or transit signal systems (railway signaling) or train control systems infrastructure maintenance and engineering</li><li> Comprehension of technical materials, test plans and other data used to validate designs and progress through testing to implementation of the system<br/><br/></li></ul><strong>Please send me your details (resume, work authorization status, current location, availability and compensation expectations) directly to: denis.potapenko@systemone.com for an immediate consideration. Make sure to include both the job title and location of the job if you email me directly.</strong>
</div>",No Salary Info Found,Data Pipeline Engineer
Project Engineer,BlueWave,12/20/2023,https://www.linkedin.com/jobs/view/3764309011,0,https://media.licdn.com/dms/image/C560BAQH8uHjlAxGgrQ/company-logo_100_100/0/1630639958002/bluewavesolar_logo?e=2147483647&v=beta&t=umzxzbLxbiogO7bLsYlsRjsnyuIBt3yp8kjPbfm3klE,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>About us:</strong></p><p>BlueWave's mission is to protect our planet by transforming access to renewable energy. As a pioneering renewable energy company that develops and owns solar and battery storage projects, BlueWave has a long track record of success and is developing several gigawatts of solar and battery storage projects throughout the United States to ensure our grid is reliable and efficient in a clean energy future. BlueWave is proud to be a certified B Corp, recognized by B Labs as ""Best in the World"" in Governance.</p><p><br/></p><p><strong>Benefits:</strong></p><p>BlueWave provides employees with a robust benefits package, including unlimited paid time off, dedicated volunteer days, cell phone reimbursement, summer Fridays and 13 paid holidays. In addition, we offer a 401k and Roth 401K option with company match, subsidized health, dental and vision plans, as well as life insurance and long/short-term disability.</p><p><br/></p><p><strong>Inclusion at BlueWave:</strong></p><p>As a mission-driven B Corp, as environmentalists, and as humans, we hold ourselves accountable to creating a workforce that celebrates diversity on our team and within our communities. Our inclusive culture and core values inspire us to develop more innovative, bolder solutions to support our customers and partners in the solar industry. When you join BlueWave, you join a collaborative team doing all that we can to be transparent, sustainable and inclusive as we fight for our shared vision of protecting the planet.</p><p><br/></p><p><strong>About the Role:</strong></p><p><strong><span class=""ql-cursor""> </span></strong>Bluewave is seeking an entry level Execution Project Engineer for our EPC construction projects and will report to the VP, Project Execution. The Project Engineer will be responsible for managing the flow of information on the project including but not limited to detailed budgets, plan reviews, quality control and document management. They will be responsible for maintaining data within the construction management software. Additionally, this team member will review construction design, lead in the identification and resolution of engineering or design conflicts. The successful candidate must have excellent organizational, time management, problem solving, leadership and decision-making skills.</p><p><br/></p><p><strong>WHAT YOU'LL BE DOING:</strong></p><ul><li>Reviewing, analyzing and resolving design/construction problems, discrepancies and interferences with the design team, project leadership, client and contractors as required</li><li>Ensuring that all project engineering activities comply with company and contract requirements and support the development and maintenance of the overall CPM schedule</li><li>Providing technical support for construction effort including participation in design interpretation, application of construction methods, identification, resolution and documentation of design conflicts, constructability reviews, etc., to help determine the most cost effective and schedule efficient method of construction</li><li>Developing, implementing and administering document control functions</li><li>Maintaining all design documents to be current with onsite construction operations</li><li>Submitting tracking project logs, processing, coordination and documentation as required to facilitate project and maintaining official project log and documentation</li><li>Representing the company as required during design review meeting with the design team, project coordination meetings with contractors, etc.</li><li>Assisting in preparing special reports, studies and etc. as requested or in support of project management</li><li>Assisting project leadership with development of scopes of work to create and confirm subcontracts and vendor purchase orders, issue field change directives, and support the validation and substantiation of contractor change order requests</li><li>Enforcing policies, procedures and related work rules as established by Bluewave, the contract and local requirements</li><li>Assisting with compliance of safety program that creates a safe and health work environment through the job site and adheres to OSHA safety and record keeping requirements</li><li>Preparing reports as required, and keeping supervisors informed on progress of overall assigned activities</li><li>Under guidance of Project Manager, monitoring work performance and of subcontractors to ensure project plans and schedules are followed</li><li>Assist coordinate utility activities and owner required obligations</li><li>Utilizing current construction management system to perform record-keeping tasks including, composing daily diaries, maintaining project logs and retrieving RFIs, submittal logs and agreements</li><li>Providing assistance to assigned contractors in scheduling issues</li><li>Meeting minute record keeping</li><li>Monitoring the project pre-plan which includes a CPM schedule, work sequences, manpower utilization, material handling and storage requirements and equipment use</li><li>Responsible for continuously expanding and updating professional knowledge and honing training skills in order to enhance individual and team innovation and productivity</li></ul><p><br/></p><p><strong> MINIMUM REQUIREMENTS:</strong></p><ul><li>BA/BS Engineering, Construction Management or relevant curriculum or demonstrated equivalency of experience and/or education</li></ul><p><br/></p><p><strong>PREFERRED QUALIFICATIONS:</strong></p><ul><li>Internship experience in construction of large-scale projects</li><li>Experience working on a live construction site</li><li>Familiarity with construction documentation such as reports, safety recording keeping, quality control plans, etc.</li><li>Able to follow directions and interact with all levels of management on working construction project</li><li>Proficiency in Microsoft Office products</li><li>Experience engaging with multiple trades on a complex construction project</li></ul>
</div>",No Salary Info Found,Data Pipeline Engineer
Pilot Line Process Engineer - Battery Manufacturing,European Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3790815673,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer,MBTA,12/20/2023,https://www.linkedin.com/jobs/view/3742312760,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Continuous Improvement Engineer,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791627483,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Irving, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/>This Jobot Job is hosted by Forrest Mack<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $95,000 - $120,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>Founded in 1954, our affiliated companies have been pioneers in the supply chain and logistics sectors. Servicing some of the leading food, beverage, pharmaceutical, and retail customers globally, we have established ourselves as a premier third-party logistics company that is people-driven and results-focused. Over the past 60 years, we have been committed to diversifying our operating business by acquiring some of the leading packaging, transportation, and warehousing companies in the United States and masterfully blending them into a strong and value-added business unit that operates today as our family of companies.<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Healthcare and Insurance Plans Comprehensive medical, dental, and vision insurance coverage for employees and their dependents.</li><li> Retirement Plans Contribution plans such as 401(k) or pension plans to help employees save for retirement.</li><li> Paid Time Off (PTO) Vacation, holidays, and other paid time off options for employees to maintain work-life balance.</li><li> Employee Assistance Programs (EAP) Services to support employees with personal or work-related challenges.</li><li> Flexible Spending Accounts (FSAs) and Health Savings Accounts (HSAs) Tax-advantaged accounts to cover eligible healthcare expenses.</li><li> Life and Disability Insurance Coverage to protect employees and their families in case of unforeseen events.</li><li> Wellness Programs Initiatives to promote employee health and well-being, such as fitness programs or wellness incentives.</li><li> Professional Development Training programs, tuition reimbursement, and opportunities for career advancement.</li><li> Work-Life Balance Initiatives Flexible work schedules, telecommuting options, and other programs to support work-life balance.<br/><br/></li></ul><strong>Job Details<br/><br/></strong>Process Analysis and Optimization<br/><br/><ul><li> Conduct thorough analyses of existing logistics processes to identify areas for improvement.</li><li> Develop and implement process optimization strategies to enhance efficiency and reduce operational costs.</li><li> Utilize Lean and Six Sigma methodologies to eliminate waste and streamline workflows.<br/><br/></li></ul>Data-Driven Decision Making<br/><br/><ul><li> Collect and analyze data to identify trends, bottlenecks, and areas for improvement.</li><li> Use statistical methods to draw insights from data and make informed recommendations for process enhancements.<br/><br/></li></ul>Cross-Functional Collaboration<br/><br/><ul><li> Collaborate with cross-functional teams, including operations, supply chain, and technology, to implement continuous improvement initiatives.</li><li> Foster a culture of continuous improvement by providing guidance and support to team members.<br/><br/></li></ul>Performance Metrics Monitoring<br/><br/><ul><li> Establish key performance indicators (KPIs) to measure the success of process improvements.</li><li> Regularly monitor and report on performance metrics, making adjustments as needed to achieve operational goals.<br/><br/></li></ul>Training and Development<br/><br/><ul><li> Provide training sessions to team members on continuous improvement methodologies and tools.</li><li> Foster a culture of learning and development, encouraging employees to contribute ideas for improvement.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Industrial Engineering, Supply Chain Management, or a related field.</li><li> Proven experience in process improvement within the logistics or supply chain industry.</li><li> Strong knowledge of Lean and Six Sigma methodologies.</li><li> Proficient in data analysis and the use of relevant tools (e.g., Minitab, Excel).</li><li> Excellent communication and interpersonal skills.</li><li> Ability to lead and influence cross-functional teams.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$95000- $120000,Data Pipeline Engineer
ASE Dallas Operations Project Engineer (Onsite),Pratt & Whitney,12/20/2023,https://www.linkedin.com/jobs/view/3756052280,0,https://media.licdn.com/dms/image/D4E0BAQEtg2PpCDdBoA/company-logo_100_100/0/1687872730252/pratt__whitney_logo?e=2147483647&v=beta&t=lRFjtqN3CIcX4QW6WP0fIatuX9gbv_C42AabCkK1Dos,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Date Posted:<br/><br/></strong>2023-10-31<br/><br/><strong>Country:<br/><br/></strong>United States of America<br/><br/><strong>Location:<br/><br/></strong>PW132: Dallas 2701 Regent Blvd, Suite 300, Dallas, TX, 75261 USA<br/><br/><strong>Position Role Type:<br/><br/></strong>Onsite<br/><br/>Pratt &amp; Whitney is working to once again transform the future of flight—designing, building and servicing engines unlike any the world has ever seen. And because transformation begins from within, we’re seeking the people to drive it. So, calling all curious.<br/><br/>Come ready to explore and you’ll find a place where your talent takes flight—beyond the borders of title, a country or your comfort zone. Bring your passion and commitment and we’ll welcome you into a tight-knit team that takes our mission personally. Channel your drive to make a difference into shaping an organization and an industry that’s evolving fast to the future.<br/><br/>Innovation through diversity of thought. At Pratt &amp; Whitney, we believe diversity of thought enables creativity, innovation, and a foundation for inclusion. By fostering an inclusive culture, we accept a shared accountability and responsibility to recognize, sponsor, coach, hire and promote talent equally. We welcome our employees to be their whole - best - selves at work because trust, respect and integrity, are a part of our DNA.<br/><br/>At Pratt &amp; Whitney, the difference you make is on display every day. Just look up. Are you ready to go beyond?<br/><br/>This posting is created to serve as general project engineer for the ASE Inspection Cell at the Dallas Inspection Center of Excellence (DICE) facility in Dallas, TX. This site supports various data aggregations, transitions/flow into the DMRO Hub for digital infrastructure development &amp; sustainment. Incubate automated inspection technologies/equipment aimed at improving inspection efficiency, speed, and volume.<br/><br/> <br/><br/>The project engineer will report to ASE Cell Manager.<br/><br/> In this dynamic position, you will apply your Engineering background and knowledge to manage and support the inspection cell, develop, and demonstrate automated inspection capabilities, automation/programming evolution, and help integrate the data captured with the DMRO hub.<br/><br/><strong>Key Responsibilities: <br/><br/></strong><ul><li>Create and manage the outsource Statement-Of-Work (SOW) for various tasks: basic inspection, equipment operation, automation, programming, and other duties within the cell. </li><li>Ensure the onsite team is working to the agreed upon priorities for both basic inspections, equipment operation, and automation/programming efforts. </li><li>Ensure the onsite team has the necessary provisions &amp; tools to complete their SOW deliverables &amp; other tasks. </li><li>Coordinate with team members in the installation of new inspection machines and connecting the machines to the DMRO Hub. </li><li>Support operation, Automation, and programming projects. <br/><br/></li></ul><strong>Basic Qualifications:<br/><br/></strong><ul><li> B.S. in Mechanical Engineering or equivalent with a minimum of 3 years' experience in gas turbine development, manufacturing, quality, or aftermarket support. </li><li>Must be a U.S. Person/Permanent Resident ""Green Card"" holder<br/><br/></li></ul><strong>Preferred Qualifications:<br/><br/></strong><ul><li>MBA preferred but not required.   </li><li>Excellent written and verbal communication skills. </li><li>Demonstrated leadership of a multi-discipline technical team </li><li>Innovative self-starter capable of working independently to resolve onsite issues. </li><li>Experience in quality and/or inspection technology a plus </li><li>Experience in setting up an operations or inspection cell also a plus. <br/><br/></li></ul>What is my role type?<br/><br/>In addition to transforming the future of flight, we are also transforming how and where we work. We’ve introduced role types to help you understand how you will operate in our blended work environment. This role is:<br/><br/>Onsite: Employees who are working in Onsite roles will work primarily onsite. This includes all production and maintenance workers, as they are essential to the development of our engines.<br/><br/>Candidates will learn more about role type and current site status throughout the recruiting process. For onsite and hybrid roles, commuting to and from the assigned site is the employee’s personal responsibility.<br/><br/><strong><em>RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.<br/><br/></em></strong><strong>Privacy Policy and Terms:<br/><br/></strong>Click on this link to read the Policy and Terms<br/><br/><strong>01660303</strong>
</div>",No Salary Info Found,Data Pipeline Engineer
Continuous Improvement Engineer,Kohler Co.,12/19/2023,https://www.linkedin.com/jobs/view/3640079107,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Continuous Improvement Engineer I,Motorola Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3725137605,0,https://media.licdn.com/dms/image/C4D0BAQE4yt5Gz-3KGQ/company-logo_100_100/0/1631305138860?e=2147483647&v=beta&t=CLRtQeTQoWmxLtxX92Zefw5CNLyGFtLJxMZruSOkfHQ,"Richardson, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Overview<br/><br/></strong>At Motorola Solutions, we’re guided by a shared purpose – helping people be their best in the moments that matter – and we’re living up to our purpose every day by solving for safer. Because people can only be their best when they not only feel safe, but are safe. We’re solving for safer - safer communities, safer schools, safer hospitals, safer businesses – safer everywhere. We’re building integrated technologies that help protect people, property and places. We’re connecting public safety agencies and enterprises – enabling the collaboration that’s critical for a more proactive approach to safety and security. We’re committed to solving for safer every day because the work we do here matters.<br/><br/><strong>Department Overview<br/><br/></strong>Continuous Improvement Engineering<br/><br/><strong>Job Description<br/><br/></strong><strong>As a Continuous Improvement Engineer you will:<br/><br/></strong><ul><li>Be responsible for evaluating, designing and implementing manufacturing processes and systems that efficiently make products or provide services. </li><li>Design, redesign or enhance work areas and layouts defining optimal use of resources related to space utilization and materials flow. </li><li>Implement motion and time studies, apply data analysis for problem solving and process improvement creating standardized work. </li><li>Utilize Lean Six sigma methodologies to streamline processes, eliminate waste and reduce variation in order to increase productivity, improve efficiencies, reduce cycle time, lead time and cost. </li><li>Use drafting tools and techniques aided by computer-assisted design software to create the layout of equipment, materials, and workspace to illustrate maximum efficiency. </li><li>Develop best practices and process documentation. </li><li>Collaborate with global engineering initiatives to implement automation and support deployment of manufacturing execution systems (MES) </li><li>Lead, coach and facilitate high impact &amp; high complexity projects. </li><li>Help develop a best in class continuous improvement program evangelizing the lean six sigma culture</li><li>Other duties as assigned<br/><br/></li></ul><strong>Preferred Qualifications:<br/><br/></strong><ul><li>Lean Six Sigma training and knowledge</li><li>Demonstrated skills in solving complex technical problems</li><li>Exceptional interpersonal communication skills, solid engineering skills for process mapping, problem solving, and analytical thinker. </li><li>Strong project management skills preferred. <br/><br/></li></ul><strong>Basic Requirements<br/><br/></strong><strong>Required Skills:<br/><br/></strong><ul><li>Bachelors Degree in Industrial Engineering, or Manufacturing Engineering</li><li>4 years of experience in Electronics, and Manufacturing required. </li><li>Legal authorization to work in the U.S. indefinitely is required. Employer work permit sponsorship is not available for this position. <br/><br/></li></ul><strong>Travel Requirements<br/><br/></strong>Under 10%<br/><br/><strong>Relocation Provided<br/><br/></strong>None<br/><br/><strong>Position Type<br/><br/></strong>Experienced<br/><br/><strong>Referral Payment Plan<br/><br/></strong>Yes<br/><br/><strong>Our U.S. Benefits include:<br/><br/></strong><ul><li>Incentive Bonus Plans</li><li>Medical, Dental, Vision benefits</li><li>401K with Company Match</li><li>9 Paid Holidays</li><li>Generous Paid Time Off Packages</li><li>Employee Stock Purchase Plan</li><li>Paid Parental &amp; Family Leave</li><li>and more!<br/><br/></li></ul><em><strong>EEO Statement<br/><br/></strong></em>Motorola Solutions is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, veteran's status, or, any other protected characteristic.<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
(Global Oil Gas) Project Engineer - Instrumentation & Process Control,MatchaTalent,12/19/2023,https://www.linkedin.com/jobs/view/3789792697,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer - TFS,Exyte,12/19/2023,https://www.linkedin.com/jobs/view/3790724257,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Completions G600 Project Engineer I,Gulfstream Aerospace,12/19/2023,https://www.linkedin.com/jobs/view/3727234674,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
"Sr. Pipeline Integrity Engineer - Dallas, TX","Delek US Holdings, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3647172388,0,https://media.licdn.com/dms/image/C4D0BAQFKCTDAb6eOfQ/company-logo_100_100/0/1630532631223/delek_us_holdings_logo?e=2147483647&v=beta&t=wNRcYJzCYOn2XafVk2jGPT8R4X9wGrRituhM0U_U3k4,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Delek US Holdings, Inc. is a diversified downstream energy company with assets in petroleum refining, logistics, renewable fuels and convenience store retailing. The refining assets consist of refineries operated in Tyler and Big Spring, Texas, El Dorado, Arkansas and Krotz Springs, Louisiana with a combined nameplate crude throughput capacity of 302,000 barrels per day.<br/><br/>The logistics operations primarily consist of Delek Logistics Partners, LP. Delek US Holdings, Inc.and its affiliates own approximately 63% (including the 2 percent general partner interest) of Delek Logistics Partners, LP. Delek Logistics Partners, LP (NYSE:DKL) is a growth-oriented master limited partnership focused on owning and operating midstream energy infrastructure assets.<br/><br/>The convenience store retail business is the largest 7-Eleven licensee in the United States and operates approximately 300 convenience stores in central and west Texas and New Mexico.<br/><br/><strong>Sr. Pipeline Integrity Engineer<br/><br/></strong><strong>Job Summary<br/><br/></strong>The Sr. Pipeline Integrity Engineer will support DKL Operations and Maintenance and be responsible for management and implementation of the Delek Integrity Management Program (IMP) to all midstream facilities including but not limited to pipelines, storage tanks, terminals, piping, and pressure vessels. The Sr. Integrity Engineer falls within the Asset Integrity Management Team and will support other staff including corrosion control, and fixed equipment inspection.<br/><br/><strong>Essential Duties And Responsibilities<br/><br/></strong><ul><li>Enforce and maintain company safety policies and procedures, and ensure compliance with all federal, state, and local laws and regulations. Emphasis with compliance to 49CFR195.452. </li><li>Consistently maintain and demonstrate a high regard for personal safety, and for the safety of company assets, employees, and the general public.</li><li>Accountable for execution of In-Line Inspection (ILI) and data Integration processes for all pipeline assessment projects. These activities include: Assisting with the coordination of GIS data alignment, integration and evaluation of the results, facilitating data integration meetings, and project closeout. </li><li>Provide input to maintain, generate, and improve key integrity assessment-related documents, processes, guides, and procedures.</li><li>Additional responsibilities may include supporting integrity projects (Hydrostatic Pressure Tests, External Corrosion Direct Assessment, In-Line Inspection, etc.) as needed and technically supporting strategically sourced ILI vendor contracts.</li><li>Provide support in determining the most appropriate assessment technology for various pipeline types/conditions and support evaluating new technology where appropriate.</li><li>Supports pipeline integrity reassessment intervals based on ILI results and repairs.</li><li>Collaborate with operations, maintenance, engineering, and other integrity engineers to identify and resolve potential threats or damage to the assets.</li><li>Identify and implement preventive and mitigative actions for midstream assets.</li><li>Collaborate with GIS team and provide technical support for risk model updates.</li><li>Assist in the development of engineering standards, specifications, and policies &amp; procedures required to support optimization of existing assets and troubleshoot operational issues. </li><li>Individual in this role must be proactive and innovative in identifying and mitigating new or emerging threats and issues related to integrity assessment.</li><li>Develop, and maintain positive working relationships with consultants, vendors, suppliers, contractors, and all departments within the company. </li><li>Provide analytics and other information and feedback to management.</li><li>Required to manage assigned budget line items and ensure proper execution with direct project management and accountable oversight</li><li>Assist in annual budgeting and forecast efforts to ensure there is proper funding for Integrity Management Program assessments and initiatives</li><li>Supports all Asset Integrity Management goals and initiatives and cross trains to assist as needed on mainline pipeline assessments, tank inspections and corrosion control initiatives.</li><li>Perform other duties as assigned.<br/><br/></li></ul><strong>CULTURE FIT &amp; IMPACT<br/><br/></strong><strong>Culture Fit &amp; Alignment to Delek's Core Values<br/><br/></strong><ul><li>Consistently adhere to Delek’s policies and procedures and be a positive example for others by demonstrating the Company’s core values of Safety, Integrity, Commitment, Passion for Wining and Excellence, Maximizing Value, and Growth Oriented.<br/><br/></li></ul><strong>Organizational Impact<br/><br/></strong><ul><li>Make decisions and/or take action based on logical assumptions derived from factual information gathered; seek out information from established policies and procedures and/or knowledge experts; seek input from others.<br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><strong>Minimum Education, Skills &amp; Experience<br/><br/></strong><ul><li>University graduate with a four-year Bachelor’s Engineering Degree from an ABET-accredited program.</li><li>+5yrs progressive experience in the oil and gas industry, specifically midstream and/or upstream.</li><li>Understanding of pipelines and DOT/PHMSA regulations 49CFR195 and 49CFR192.</li><li>Understanding of ASME B31.4, B31.8. B31.8S, and B31G.</li><li>Knowledge in corrosion mitigation and mechanical integrity assessment techniques</li><li>Willing to attend and participate industry-sponsored conferences, seminars, training, and </li><li>Up to 25% travel to company locations and facilities for meetings, training, special projects, emergency planning, or information gathering will be required.</li><li>Must maintain a valid driver’s license</li><li>Must be able to obtain a TWIC card</li><li>Must be willing to submit to DOT random drug &amp; alcohol screening<br/><br/></li></ul><strong>Preferred Education/Experience<br/><br/></strong><ul><li>+8yrs progressive experience of hazardous liquids and/or gas midstream pipeline industry experience.</li><li>Direct experience with managing and implementing an Integrity Management Program</li><li>Strong communication skill set and direct experience with effective project management<br/><br/></li></ul>We are an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity or national origin, disability status, protected veteran status, or any other characteristic protected by law. Equal Opportunity Employer/Disabled/Veterans.
      </div>",No Salary Info Found,Data Pipeline Engineer
Senior Project Engineer,Timmons Group,12/19/2023,https://www.linkedin.com/jobs/view/3742548135,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Airframe Design Engineer,TekWissen ®,12/19/2023,https://www.linkedin.com/jobs/view/3784431370,0,https://media.licdn.com/dms/image/D4E0BAQGSbWad5HaJPA/company-logo_100_100/0/1689252430843?e=2147483647&v=beta&t=LaBvLVnGmU9Py31agRxpT9GpjxCITUVv3hmvhG8YUN8,"Fort Worth, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title: Airframe Design Engineer</strong> </p><p><strong>Work Location: 3255 Bell Flight Blvd Fort Worth TX 76118</strong> </p><p><strong>Duration: 12 months</strong> </p><p><strong>Pay Rate : $40.00 - $65.00/hr on W2 </strong></p><p><br/></p><p><strong>Preferred Qualifications: </strong></p><ul><li>Familiarity with Planning, Manufacturing, Procurement and Maintenance processes is preferred </li><li>Experience working with product lifecycle management (PLM) software such as ENOVIA to drive product lifecycle is preferred. </li></ul><p><strong>Position Requirements: </strong></p><ul><li>Multiple levels of experience will be considered with at least 2 years of airframe design. </li><li>Must have working experience and knowledge/background with COMPOSITES. </li><li>Must have proficiency in CATIA V5, V6 or 3DX is required. </li><li>Must have proficiency with general part sizing and familiarity with GD&amp;T is required </li><li>Must have PC proficiency in Microsoft Word, Excel, PowerPoint, and Outlook is required </li><li>Must have excellent organizational, interpersonal, and communication skills (both verbal and written) </li></ul><p><strong>Position Responsibilities: </strong></p><ul><li>Create detail, assembly, and installation airframe 3D models, 2D drawings and engineering bill of materials. </li><li>Review detail, assembly, and installation design definition to ensure compliance with requirements. </li><li>Assignments will involve detail design under the supervision of a technical lead. </li><li>Assist in researching pertinent data and developing solutions for the project or assignment. </li><li>Coordinate with other engineering, manufacturing, or specialty personnel to resolve problems, including execution to program schedule and cost requirements. </li><li>Provide Manufacturing Engineering support during fabrication and assembly of components. </li><li>Support supplier activity. </li><li>Advance the state-of-the-art through creative thought, personal and team research, technical compliance, and strong analysis skills. </li><li>Travel to various suppliers may be expected depending on the assignment. </li></ul><p> </p><p><strong>Description </strong></p><ul><li>We are pioneers. We were the first to break the sound barrier and to design the first functional jetpack. We were aboard NASA’s first lunar mission and brought advanced tiltrotor systems to market. Today, we are defining the future of on-demand mobility. At Bell, we are proud to work for an iconic company with superb talent, rapidly creating novel and coveted vertical lift experiences. </li><li>The Airframe Design Engineer at Bell is responsible for design activities related to the preparation, conversion, and release of engineering data. Also, this position has responsibilities for compliance to company Design Manuals, Best Practices, Customer Specifications, Military Standards, Bell procedures, Program Directives, and annual Compliance requirements. This position is offered at Bell’s main campus in Fort Worth, Texas. </li><li>Our most cherished core value is to Lift Each Other up, creating a diverse and inclusive environment. As a member of our global workforce, you will collaborate with dedicated, enthusiastic teams where differences in experiences, backgrounds, and ideas combined with a strong passion for our products take us above and beyond flight. </li></ul><p><strong>Education Requirements: </strong></p><p>Bachelor's Degree in Engineering is required. Major in Mechanical or Aerospace Engineering is preferred.</p>
</div>",$40.00- $65.00,Data Pipeline Engineer
Construction Project Engineer,TSMC,12/25/2023,https://www.linkedin.com/jobs/view/3777574839,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Mechanical Engineer - Data Center,Olsson,12/20/2023,https://www.linkedin.com/jobs/view/3772676144,0,https://media.licdn.com/dms/image/C4E0BAQFJmPWgtIrKjw/company-logo_100_100/0/1630582397834/olsson_associates_logo?e=2147483647&v=beta&t=bf1GX1MDKcrjqiUAiLpvNSL5gZ4s3e3UM-YswtmUPZ8,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>We are Olsson, a team-based, purpose-driven engineering and design firm. Our solutions improve communities and our people make it possible.<br/><br/>Our most meaningful asset is our people, and we are dedicated to providing an environment where they can continue to learn, grow, and thrive. Our entrepreneurial spirit is what has allowed us — and will continue to allow us — to grow. The result? Inspired people, amazing designs, and projects with purpose.<br/><br/><strong>Job Description<br/><br/></strong>As a Project Mechanical Engineer, you will serve as project manager on small projects, prepare planning and design documents, and process design calculations. You will also coordinate with other Olsson teams, professional staff, technical staff, and clients. This opportunity will be working with one of the largest technology companies in the world. You may travel to job sites for observation and attend client meetings.<br/><br/><strong>Qualifications<br/><br/></strong><strong>You are passionate about:<br/><br/></strong><ul><li>Working collaboratively with others</li><li>Having ownership in the work you do</li><li>Using your talents to positively affect communities<br/><br/></li></ul><strong>You bring to the team:<br/><br/></strong><ul><li>Strong communication skills</li><li>Ability to contribute and work well on a team</li><li>Bachelor's degree in mechanical engineering</li><li>5+ years of mechanical engineering experience</li><li>Licensed PE</li><li>Ability to be a self-starter to take on a variety of tasks to best serve the client and their project work</li><li>Investigation and troubleshooting of problems to find solutions<br/><br/></li></ul><strong>Additional Information<br/><br/></strong>Olsson is a nationally recognized, employee-owned firm specializing in planning and design, engineering, field services, environmental, and technology. Founded in 1956 on the very mindset that drives us today, we’re here to improve communities by making them more sustainable, better connected, and more efficient. Simply put, we work to leave the world better than we found it.<br/><br/>As an Olsson employee, you’ll receive our traditional benefits package (health care, vision, dental, paid time off, etc.), plus you’ll:<br/><br/><ul><li>Become an owner in the company after your first year through our Employee Stock Ownership Plan (ESOP)</li><li>Engage in work that has a positive impact in communities</li><li>Receive an excellent 401(k) match</li><li>Participate in a wellness program promoting balanced lifestyles</li><li>Benefit from a bonus system that rewards performance</li><li>Have the possibility for flexible work arrangements<br/><br/></li></ul>Olsson is an EEO employer. We encourage qualified minority, female, veteran and disabled candidates to apply and be considered for open positions. We do not discriminate against any applicant for employment, or any employee because of race, color, religion, national origin, age, sex, sexual orientation, gender identity, gender, disability, age, or military status.<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
Quality & Continuous Improvement Engineer,Sloan,12/19/2023,https://www.linkedin.com/jobs/view/3774466898,0,https://media.licdn.com/dms/image/C560BAQGa2-clh94L_A/company-logo_100_100/0/1630564200217/sloan_valve_company_logo?e=2147483647&v=beta&t=IuyTgmyYlA4WDzWskCeOh9lPgml1hw4Z1vPufNzLQEs,"Mesa, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Req ID: 11018</p><p><strong> Sloan </strong>is the world’s leading manufacturer of commercial plumbing systems and has been in operation since 1906. We are at the forefront of the green building movement and provide sustainable restroom solutions. We manufacture water-efficient products including flush valves, electronic faucets, soap dispensing and sink systems along with vitreous china fixtures for commercial, industrial and institutional markets worldwide.</p><p><br/></p><p>Sloan has an opening for a Quality &amp; Continuous Improvement Engineer in our Mesa, AZ facility. In this role you will be responsible for the overall quality of products and services out of Sloan Mesa and its strategic partners related to the sink business. This role monitors and maintains the site QMS, work instructions, policies and procedures. You will also manage customer complaints and coordinate repair when necessary -</p><p><br/></p><p><strong>Responsibilities Include</strong></p><ul><li>Troubleshoots and investigates inquiries relating to customer complaints, product warranty issues, and installations. Acts as a liaison between external contacts (ie. customers, contractors, manufacturing reps and Sloan sales and marketing teams) and our internal departments such as Customer Service, Quality, Engineering, Manufacturing and Field Service to identify root cause and develop field service solutions. Coordinates and schedules field service repairs with new or existing third-party contractors and follows up to ensure issues are resolved on time and meets customer expectations. Enters orders for repair as needed into SAP. Keeps key personnel informed of repair status on a regular basis.</li><li>Monitors and maintains the Quality Management System, testing and inspection activities designed to assure that products, processes and services comply to corporate, state, federal and regulatory requirements, standards and practices. Creates, modifies and implements standard work and inspection methods as needed. Makes recommendations for new equipment to assure that new product characteristics are properly measured and assessed. Maintains gage calibration system to support measurement needs. Completes first article and incoming inspection practices. Completes monthly reporting on key performance metrics such as customer complaints with corresponding pareto of root casues, corrective actions, scrap and warranty. Monitors and tracks product quality data, identifies existing trends, drives and facilitates quality improvement efforts, offers suggested conclusions and recommends follow-up actions from engineering, production and supplier quality.</li><li>Manages internal and external nonconforming material (NCR’s), material review board (MRB) and disposition. Assists in the development and implementation of internal and external corrective actions designed to improve, correct or maintain products, processes and service standards, specifications and requirements. Facilitates root cause problem solving using various CAPA tools (ie. 8D, 5 Why, Pareto Charts) to drive resolution. Develops continuous improvement projects and coordinates cross functionally to recommend prioritization to senior leadership.</li><li>Assists with vendor selection and evaluation of regional fabricators and local vendors and provides technical expertise for qualifying, developing, certifying and assisting both internal and external suppliers and vendors. Documents requirements and work instructions to ensure consistency between third party vendors. Responsible for local supplier quality activities while coordinating with the Global Supplier Quality Manager. Coordinates with Supplier Quality to periodically audit internal and external processes and procedures.</li><li>Provides work direction for Inspectors, Technicians and employees assigned to the Quality function.</li></ul><p><br/></p><p><strong>Qualifications</strong></p><ul><li>Bachelor's Degree in Engineering Technology</li><li>4+ Years experience as a Quality Assurance Engineer</li><li>Demonstrated skills in problem solving, time management, and project management. Experience with solid surface and/or stone fabrication a plus.</li><li>Experience with Microsoft Office - Word, Outlook, Excel.</li><li>Excellent communication and problem solving skills. ASQ certification or equivalent experience) preferred</li><li>6 Sigma Green / Black Belt, Minitab and Lean Principles preferred</li></ul><p><br/></p><p><strong> We offer a highly competitive compensation and benefits package, including:</strong></p><ul><li>A choice of Medical (with Health Savings Account), Dental, Vision, Rx Insurance for employees and their eligible dependents</li><li>Company paid Basic Life and AD &amp; D Insurance, Basic Accident Insurance, Disability Insurance, Employee Assistance Program, and Well-being Programs.</li><li>Paid time off, Paid Sick Leave, Paid Vacation time, Paid Sick time, Paid Military Leave, and Paid Volunteer time away from work.</li><li>Dependent Care Flexible Spending Account, Commuter Parking and Transit Accounts, and Tuition Reimbursement benefits.</li><li>401(k) Retirement Savings Plan with a Company match.</li><li>Employee Service Anniversary Awards and Employee Recognition Programs</li></ul><p><strong>Diversity, Equity, Inclusion and Belonging (DEIB)</strong></p><p><strong> YOU Belong at Sloan </strong></p><p>We are intentional in building an inclusive culture that embraces different voices, ideas, and backgrounds. We commit to continuing this ever-growing journey with and for our employees, customers, partners, and community. We are better together when we can be ourselves.</p><p><strong>We Are Proud Partners With the Chicago Cubs</strong></p><p>We are a Legacy Partner of the Chicago Cubs and we are proud to be the organization’s official water efficiency partner! Through this relationship, which includes the naming rights to Sloan Park, the Cubs’ Spring Training facility in Mesa, Arizona, we have had the opportunity to promote our brand and continue our water conservation efforts in the city of Chicago and around the world.</p><p><strong> JOIN AN INDUSTRY LEADER! </strong></p><p><strong>For additional company information please visit our website at www.sloan.com. </strong></p><p><strong>We Are An Equal Opportunity Employer.</strong></p>
</div>",No Salary Info Found,Data Pipeline Engineer
Quality Engineer,Addison Group,12/19/2023,https://www.linkedin.com/jobs/view/3648643761,0,https://media.licdn.com/dms/image/C560BAQGkWEu9IfrLsg/company-logo_100_100/0/1657132506176/addisongroup_logo?e=2147483647&v=beta&t=BAhw6BCez4M9zVVM5rPLIixtzXkEmH355l5lzSkK0Qs,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Location: Phoenix, AZ<br/><br/>Salary: $70,000-$100,000<br/><br/><strong>Job Description<br/><br/></strong>The Quality Engineer works closely with cross-functional representatives from all departments within the company, planning, coordinating, and executing the qualification and maintenance of processes, systems and equipment used in the manufacturing, packaging, testing, storage, and shipment of cadaveric, placenta derived and other specialty tissue allografts for the biomedical industry. The Quality Engineer will write and coordinate the execution of equipment verification and qualification protocols, temperature mapping protocols, shipping validation protocols, qualification and validation protocols and summary reports, package and packaging validation protocols and summary reports, standard operating procedures, controlled forms, deviations, investigations, and corrective and preventive action reports as assigned. The Quality Engineer will be able to work independently with general direction.<br/><br/><strong>Education And Work Experience Requirements<br/><br/></strong>B.S. degree in a scientific and/or engineering discipline (Chemistry, Biology, Physics, Biomedical Engineering/Chemical Engineering, etc.) Minimum of 5 years of quality engineering experience in a regulated environment within a pharmaceutical, medical device, biologic, tissue bank, diagnostic, hospital, or similar organization Minimum of 3 –5 years of experience participating in equipment qualification and process validation protocols and reports, and executing validation protocols Experience in applying statistical methods for quality improvements Experience in design control and process validation, root cause analysis, corrective and preventive action (CAPA) Experience with packaging and sterilization validation preferred<br/><br/><strong>Essential Duties And Responsibilities<br/><br/></strong>Develops, modifies, applies, and maintains quality evaluation and control systems and protocols for processing materials into partially finished or finished materials product. Maintain Quality metrics in databases and prepare trends and graphs as needed Facilitate QC equipment qualifications, quality process optimization, and quality test method validations Actively support Product Development and Manufacturing Engineering projects and validations Review and approve Product Development and Manufacturing Engineering validation protocols and summary reports Responsible for establishing, validating, and implementing QC test method SOPs Participate in internal and external quality audits Develop, execute, and analyze quality-reporting measures Serve as a resource to management and internal departments for problem identification and resolution Design and implement methods for process control, process improvement, testing, and inspection Create and monitor re-validation schedules Experience supporting nonconformance investigations, CAPA, and change control programs. Writes and updates assigned policies, procedures, forms and related documentation, using established document change control processes, and provides training in areas where they are the subject matter expert. Confers with management, production, or marketing staff to discuss project specifications or procedures. Performs any other work-related duties as assigned by supervisor and/or executive management.<br/><br/><strong>Knowledge, Skills, And Abilities Required<br/><br/></strong>Serve as Subject Matter Expert (SME) for all verification and validation activities Develop and oversee verification protocols to verify engineering specifications Develop and oversee validation protocols to validate customer requirements Analyze verification and validation test data Hands on application of Statistical Analysis Document test protocols and reports Test Implementation, Verification &amp; Validation, and Risk Assessment Root Cause Analysis, Development of Corrective Actions Working knowledge of FDA regulatory requirements and all internal quality standards Highly capable of independent and critical thought and action<br/><br/><strong>Physical Environment &amp; Working Conditions<br/><br/></strong>Full Time position (40 hours or more) based in Arizona, with the opportunity for hybrid structure once candidate has become established. Normal hours may include office work, lab work and exposure to sterile environment. Some duties may be performed in aseptic cleanrooms/areas, wearing prescribed PPE, standing for extended periods of time, bending, lifting loads up to 40 pounds, or more with material handling tools, minimal contact with body fluids, which may be considered infectious, to be avoided at all possible times. Such fluids may be present on records received; however, such records should be placed in a plastic sheet for protection.<br/><br/><strong>Equipment &amp; Machines Used</strong> Processing or facilities equipment such as autoclaves, lyophilizers, centrifuges, heat sealers, shaker tables, ultra-low temperature freezers, reagent refrigerators, incubators, sonicators, calipers, gauge blocks, residual moisture analyzers, laminar flow hoods, ISO certified cleanrooms and clean areas, pH meters, and other related equipment. Desktop/laptop computer and general office equipment and software such as MS Office, Word, Excel, PowerPoint, Project and Visio.<br/><br/><strong>Confidentiality Requirement<br/><br/></strong>The Quality Engineer is expected to maintain confidentiality of all donor/recipient information.
      </div>",$70000- $100000,Data Pipeline Engineer
Metrology Engineer,West Pharmaceutical Services,12/19/2023,https://www.linkedin.com/jobs/view/3705206893,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Intelligent Manufacturing Engineer (2023 HC),TSMC,12/19/2023,https://www.linkedin.com/jobs/view/3750655565,0,https://media.licdn.com/dms/image/C560BAQESjKpbeGX8vA/company-logo_100_100/0/1630598291484/tsmc_logo?e=2147483647&v=beta&t=TeCnX2Fg2E5FKfFZLe6xw3k7ZyujJWxtWY17-Sb_MGk,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>Your main responsibilities include:<br/><br/><ul><li> Ensuring that the core infrastructure of the factory can cooperate with the production execution system (Siview) and the material control system (MCS) operation to improve production efficiency and effectively meet organizational objectives. </li><li> Establishing effective planning capabilities to maximize fab capabilities to meet customers’ requirements. </li><li> Connecting the machine and equipment integration applications to collect data and statuses and begin the setup system for management and adjustment. </li><li> Creating or maintaining an effective scheduling system that can provide decision-making logic to enable the fab to achieve production capacity targets while improving the operation control capability of the fab and significantly reduce variability. </li><li> Responding quickly to change priorities and handle multiple projects with potentially overlapping deadlines. </li><li> Managing all members and building team spirit through involvement and effective communication. </li><li> Collaborating with engineering teams to ensure that robotic workstations, detection instruments, and database/informatics tools meet standards and goals promised to customers. </li><li> Additional duties based on business needs, including ERT <br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong>Applicants must be legally eligible to work in the United States and have:<br/><br/><ul><li> A minimum of a B.S. degree in Industrial Engineering, Manufacturing, Production Engineering, Industrial Management, Computer Science, Mechanical and Automation Engineering or related fields. </li><li> Demonstrated knowledge of optimization algorithm, IE, IT, or related fields is required. </li><li> Enthusiasm and dedication with the ability to motivate, lead, and teach a team. </li><li> The ability to be a team player who can multitask and thrive in a very dynamic and fast-paced environment. </li><li> May need to travel to Taiwan for training up to 6 months depends on onboarding schedule. <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li> Experience or knowledge of semiconductor manufacturing is a plus. <br/><br/></li></ul><strong> Work Location </strong> : Phoenix, AZ (On-Site)<br/><br/><strong> Travel </strong> : May require travel dependent on business needs.<br/>
</div>",No Salary Info Found,Data Pipeline Engineer
2024 Equipment Engineer - Western Region,Kiewit,12/19/2023,https://www.linkedin.com/jobs/view/3723911800,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
"Jr. Product Developer, R&D",hims & hers,12/19/2023,https://www.linkedin.com/jobs/view/3774211388,0,https://media.licdn.com/dms/image/C560BAQH6_T0-4GG7mA/company-logo_100_100/0/1630565142482/hims__hers_logo?e=2147483647&v=beta&t=35ghNGmu3LGs5qESh-Jp8QzevAsBkXzizoqFJw7SKcw,"Gilbert, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Hims &amp; Hers Health, Inc. (better known as Hims &amp; Hers) is the leading health and wellness platform, on a mission to help the world feel great through the power of better health. We are revolutionizing telehealth for providers and their patients alike. Making personalized solutions accessible is of paramount importance to Hims &amp; Hers and we are focused on continued innovation in this space. Hims &amp; Hers offers nonprescription products and access to highly personalized prescription solutions for a variety of conditions related to mental health, sexual health, hair care, skincare, heart health, and more.<br/><br/>Hims &amp; Hers is a public company, traded on the NYSE under the ticker symbol “HIMS”. To learn more about the brand and offerings, you can visit hims.com and forhers.com , or visit our investor site . For information on the company’s outstanding benefits, culture, and its talent-first flexible/remote work approach, see below and visit www.hims.com/careers-professionals .<br/><br/><strong>About The Role<br/><br/></strong>We are seeking a dynamic and motivated Junior R&amp;D Product Developer to join our innovative R&amp;D team. As a Junior R&amp;D Product Developer, you will play a crucial role in supporting our innovation pipeline, with technical guidance from the R&amp;D Product Development Manager, and R&amp;D Process Engineer and will plan and execute projects with minimal supervision. The R&amp;D Product Developer will process technical data, interpret results, and write technical reports while applying compounding lab knowledge to analyze, draw conclusions and report results. In this role, you will also lead and manage benchtop sample evaluation through descriptive panels, and interact with cross-functional peers to gather feedback that will drive product development forward for on-time, successful product launches.<br/><br/><strong>You Will<br/><br/></strong><ul><li>Responsible for independently executing benchtop development work using compounding equipment and compounding procedures, with guidance from the R&amp;D Product Developer, and the R&amp;D Process Engineer to deliver consistent, high-quality products that support business objectives and revenue-generating new product launches</li><li>Independently plan and execute benchtop formulation work, analyze test results and effectively translate these into effective next steps that lead to project successes</li><li>Lead design and execution of experiments to evaluate product stability, compatibility, and performance under varying conditions.</li><li>Document experimental procedures, results, and observations accurately and comprehensively in laboratory notebooks and electronic systems.</li><li>Contribute to scoping of new ideas or technical solutions that improve R&amp;D efficiencies and scale up processes. </li><li>Consistently communicate project updates through detailed reports, compounding records, and data collection. </li><li>Support potency testing and formula troubleshooting through data collection and analysis across all formats - tablets, topicals, gummies etc in collaboration with 3rd party labs and technical support partners. Some examples include:</li><li>Manage the product development feedback process through sample distribution, and sample feedback collection for all Rx development programs with cross-functional partners.</li><li>Work closely with sourcing and pharmacy inventory lead to ensure that raw materials are in stock for R&amp;D benchtop and scale-up work</li><li>Build, and maintain current industry knowledge by attending conferences and tradeshows showcasing technical knowledge of non-sterile pharmaceutical compounding</li><li>Deliver fundamental training and information sharing to cross functional partners, including training additional R&amp;D Techs on tablet &amp; liquid compounding via benchtop and R&amp;D scale-up batches</li><li>Operate hand press, R&amp;D scale rotary tablet press and necessary lab equipment for topical batching</li><li>Create hand pressed tablets for creative and executive color evaluation</li><li>Support scale-up batches for liquids, tableting and any other new product forms</li><li>Support buildout and compounding technology transfer from AZ to Ohio R&amp;D lab<br/><br/></li></ul><strong><strong>You Have:<br/><br/></strong></strong><ul><li>Bachelor’s degree in Biology, Biological Science, Chemistry, Food Science, Chemical Engineering, Food Engineering, Cosmetic Chemistry or related fields</li><li>Prior experience in a pharmaceutical research and development role or compounding pharmacy setting strongly preferred</li><li>Strong understanding of pharmaceutical compounding principles, sterile and non-sterile compounding techniques, and relevant regulations.</li><li>Basic knowledge of chemistry, pharmacology, and pharmaceutical formulation.</li><li>Comfortable operating in the fuzzy front-end area of innovation and passionate about creating, rapid prototyping, development, and commercialization of ideas under tight timelines.</li><li>Strong technical skills on product formulation, compounding processes and equipment, ingredient functionality, and product-process interactions.</li><li>Knowledge of Good Laboratory Practices (GLP) and Good Manufacturing Practices (GMP).</li><li>Strong project management/organization and the ability to influence key stakeholders on recommended courses of action.</li><li>Excellent communication skills (both written and oral) and the ability to interact with all company functions including R&amp;D, Marketing, Purchasing and Operations.</li><li>Ability to work independently, assess information and quickly make decisions. </li><li>Strong communication skills and experience communicating effectively verbally and in writing in English</li><li>Ability to manage time and competing priorities, and organize project data.</li><li>Required current registration as a Pharmacy Technician in the State of Arizona.</li><li>Flexibility to travel and complete work remotely if needed<br/><br/></li></ul><strong><strong>Our Benefits (there are more but here are some highlights):<br/><br/></strong></strong><ul><li>Competitive salary &amp; equity compensation for full-time roles</li><li>Unlimited PTO, company holidays, and quarterly mental health days</li><li>Comprehensive health benefits including medical, dental &amp; vision, and parental leave</li><li>Employee Stock Purchase Program (ESPP)</li><li>Employee discounts on hims &amp; hers &amp; Apostrophe online products</li><li>401k benefits with employer matching contribution</li><li>Offsite team retreats<br/><br/></li></ul><strong>Conditions Of Employment<br/><br/></strong><ul><li>This position will require working with Hazardous Drugs (HD) and would require that Personal Protective Equipment (PPE) be worn for the length of working with these drugs. These items would include gloves, respiratory protection, gown and other items as required.</li><li>This position requires medical approval to wear respiratory protection in the form of negative or positive pressure respirators, including N95, full face respirator, SCBA, or Powered Air Purifying Respirator (PAPR).</li><li>Physical exertion required. Including, but not limited to, walking up to 50% of the time, standing up to 100% of the time, squatting and bending up to 20% of the time and lifting up to 80% of the time for up to a twelve hour shift. Must be able to lift up to 50lbs.</li><li>Due to the risk of reproductive capability in handling or compounding certain Hazardous Drugs (HD) associates must be willing to confirm that they understand the potential risks (teratogenicity, carcinogenicity and reproductive effects) of handling hazardous drugs.<br/><br/></li></ul>Outlined below is a reasonable estimate of H&amp;H’s compensation range for this role.<br/><br/>H&amp;H also offers a comprehensive Total Rewards package that includes equity grants of restricted stock (RSU’s) so that H&amp;H employees own a piece of our company.<br/><br/>The actual amount will take into account a range of factors that are considered in making compensation decisions including but not limited to, skill sets, experience and training, licensure and certifications, and location.<br/><br/>Consult with your Recruiter during any potential screening to determine a more targeted range based on the job-related factors. We don’t ever want the pay range to act as a deterrent from you applying!<br/><br/>An estimate of the current salary range for US-based employees is<br/><br/>$50,000 — $75,000 USD<br/><br/>We are focused on building a diverse and inclusive workforce. If you’re excited about this role, but do not meet 100% of the qualifications listed above, we encourage you to apply.<br/><br/>Hims is an Equal Opportunity Employer and considers applicants for employment without regard to race, color, religion, sex, orientation, national origin, age, disability, genetics or any other basis forbidden under federal, state, or local law. Hims considers all qualified applicants in accordance with the San Francisco Fair Chance Ordinance.<br/><br/>Hims &amp; hers is committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations@forhims.com . Please do not send resumes to this email address.<br/><br/>For our California-based applicants – Please see our California Employment Candidate Privacy Policy to learn more about how we collect, use, retain, and disclose Personal Information.
      </div>",$50000- $75000,Data Pipeline Engineer
"Manufacturing Engineer, MES (Onsite)",Axon,12/19/2023,https://www.linkedin.com/jobs/view/3736126783,0,https://media.licdn.com/dms/image/D560BAQGPuSu1XJHMyQ/company-logo_100_100/0/1690906976497/axon_protect_life_logo?e=2147483647&v=beta&t=pLOUTEFSLC3mo6m7AOAcJTAoC5NjBNQw6e6JHPuCLWE,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Join Axon and be a Force for Good.</strong><p><br/></p>At Axon, we’re on a mission to Protect Life. We’re explorers, pursuing society’s most critical safety and justice issues with our ecosystem of devices and cloud software. Like our products, we work better together. We connect with candor and care, seeking out diverse perspectives from our customers, communities and each other.<p><br/></p>Life at Axon is fast-paced, challenging and meaningful. Here, you’ll take ownership and drive real change. Constantly grow as you work hard for a mission that matters at a company where you matter.<p><br/></p><strong>Your Impact </strong><p><br/></p>As a Manufacturing Engineer responsible for the Manufacturing Execution System (MES), you will play a crucial role in improving efficiency, productivity, and quality within our manufacturing environment.. You will work with a team of talented manufacturing engineers to support the Manufacturing Execution System that provides operational metrics related to our equipment, processes and personnel for Axon’s manufacturing facilities.<p><br/></p><strong>What You’ll Do</strong><p><br/></p><strong>Location: Scottsdale, AZ and Phoenix, AZ (multiple facilities)</strong><p><br/></p><strong>Reports to: Manager, Automation Engineering</strong><p><br/></p><strong>Direct Reports: </strong>N/A<p><br/></p><ul><li>Identify opportunities for process improvement and efficiency gains through data analysis and system utilization</li><li>Maintain comprehensive documentation of MES configurations, processes, and procedures</li><li>Provide training and support to manufacturing personnel on MES operation and troubleshooting</li><li>Collaborate with vendors related to MES management and support</li><li>Maintain comprehensive documentation of MES configurations, processes, and procedures</li><li>Work with cross-functional teams to implement process changes based on MES data insights</li><li>Ensure MES platform data accuracy &amp; consistency across multiple facilities</li></ul><p><br/></p><strong>What You Bring</strong><p><br/></p><ul><li>Bachelor’s degree in Mechanical, Industrial or Manufacturing Engineering</li><li>5+ years of engineering experience in a manufacturing environment, preferably discrete, high-volume manufacturing</li><li>Experience with Operational Technology (OT) in a manufacturing environment</li><li>Experience consuming data from Manufacturing Execution Systems (MES)</li><li>Experience with PLCs, SCADA systems, and automation technologies is a plus</li><li>Ability to lead Root Cause Analysis investigations using industry-standard methodologies</li></ul><p><br/></p><strong>Benefits That Benefit You</strong><p><br/></p><ul><li>Competitive salary and 401k with employer match</li><li>Discretionary paid time off</li><li>Paid parental leave for all</li><li>Medical, Dental, Vision plans</li><li>Fitness Programs</li><li>Emotional &amp; Mental Wellness support</li><li>Learning &amp; Development programs</li><li>And yes, we have snacks in our offices</li></ul><p><br/></p><em>Benefits listed herein may vary depending on the nature of your employment and the location where you work.</em><p><br/></p><em>The Pay: Axon is a total compensation company, meaning compensation is made up of base pay, bonus, and stock awards. The starting base pay for this role is between USD 80,000 in the lowest geographic market and USD 130,000 in the highest geographic market. The on target earnings range for this role is between USD 90,000 in the lowest geographic market and USD 150,000 in the highest geographic market. The actual base pay is dependent upon many factors, such as: level, function, training, transferable skills, work experience, business needs, geographic market, and often a combination of all these factors. Our benefits offer an array of options to help support you physically, financially and emotionally through the big milestones and in your everyday life. To see more details on our benefits offerings please visit www.axon.com/careers/benefits (http://www.axon.com/careers/benefits).</em><p><br/></p>Don’t meet every single requirement? That's ok. At Axon, we Aim Far. We think big with a long-term view because we want to reinvent the world to be a safer, better place. We are also committed to building diverse teams that reflect the communities we serve.<p><br/></p>Studies have shown that women and people of color are less likely to apply to jobs unless they check every box in the job description. If you’re excited about this role and our mission to Protect Life but your experience doesn’t align perfectly with every qualification listed here, we encourage you to apply anyways. You may be just the right candidate for this or other roles.<p><br/></p><strong>Important Notes</strong><p><br/></p><em>The above job description is not intended as, nor should it be construed as, exhaustive of all duties, responsibilities, skills, efforts, or working conditions associated with this job. The job description may change or be supplemented at any time in accordance with business needs and conditions.</em><p><br/></p><em>Some roles may also require legal eligibility to work in a firearms environment.</em><p><br/></p><em>Axon’s mission is to Protect Life and is committed to the well-being and safety of its employees as well as Axon’s impact on the environment. All Axon employees must be aware of and committed to the appropriate environmental, health, and safety regulations, policies, and procedures. Axon employees are empowered to report safety concerns as they arise and activities potentially impacting the environment.</em><p><br/></p><em>We are an equal opportunity employer that promotes justice, advances equity, values diversity and fosters inclusion. We’re committed to hiring the best talent — regardless of race, creed, color, ancestry, religion, sex (including pregnancy), national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, genetic information, veteran status, or any other characteristic protected by applicable laws, regulations and ordinances — and empowering all of our employees so they can do their best work. If you have a disability or special need that requires assistance or accommodation during the application or the recruiting process, please email recruitingops@axon.com. Please note that this email address is for accommodation purposes only. Axon will not respond to inquiries for other purposes.</em>
</div>",No Salary Info Found,Data Pipeline Engineer
Sr Industrial Engineer,West Pharmaceutical Services,12/19/2023,https://www.linkedin.com/jobs/view/3707346897,0,https://media.licdn.com/dms/image/C4D0BAQEkhKA34tdEog/company-logo_100_100/0/1635201133735/west_pharmaceutical_services_logo?e=2147483647&v=beta&t=CT5dDmvjyzz8wZ66c294DmSzy8X_RGzK0uQ3M-Q7rgY,"Tempe, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>At West, we’re a dedicated team that is connected by a purpose to improve patient lives that has been at the center of our Company for more than a century. Our story began when Herman O. West solved the problem of supplying penicillin in mass quantities to the US Government during World War 2. Through our work to deliver thousands of life-saving and life-enhancing injectable medicines to millions of patients daily, West’s indelible mark on the healthcare industry has just begun. A name started our story. How will yours help write our future?<br/><br/>There’s no better place to join an inclusive community of professionals with opportunities for lifelong learning, growth and development. Supported by benefit programs, we empower the physical, mental, emotional and financial health of our team members and their families.<br/><br/>We believe in giving back to help those in need in the communities where we live and work. And are equally committed to creating a healthier environment and planet through our sustainability efforts.<br/><br/><strong>Job Summary<br/><br/></strong>In this role, you will apply industrial engineering fundamentals for the development and implementation of new manufacturing processes/systems, capacity expansions, and process optimization initiatives within various manufacturing sites.<br/><br/><strong>Essential Duties And Responsibilities<br/><br/></strong><ul><li> Collaborate with cross-functional teams to implement sustainable manufacturing processes and systems. </li><li> Lead the incorporation of appropriate lean manufacturing tool usage such as Value Stream Mapping, 5S, cycle time studies, line balancing, and standard work into the daily functions of the value stream teams. </li><li> Lead capacity planning processes by managing data collection, capacity modeling, analyzing and prioritizing capacity improvements. </li><li> Develop and present factory layout designs. </li><li> Supports various manufacturing sites with root cause and corrective action (RCCA) of process failures, continuous improvement initiatives, and product-related opportunities. </li><li> Analyze data for problem solving, validation, and identification of improvement opportunities. </li><li> Interact with the manufacturing and business teams to define key performance metrics and create systems for monitoring performance. </li><li> Use simulation tools to perform ""what-if"" analysis to support planning for the impact of changes in operations. </li><li> Promote and support a lean manufacturing environment within all sites. </li><li> Provide a “Customer Service” attitude when interacting with internal and external customers. </li><li> Other duties as assigned. <br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><ul><li> BS in Engineering or other technical degree. </li><li> Minimum 3 years of experience in relevant engineering or operations role within a high-volume manufacturing environment. </li><li> Six Sigma Green Belt. </li><li> Experience with data analytics and statistical process control. </li><li> Experience leading lean manufacturing events and large projects. </li><li> Knowledge of best practices in manufacturing processes, workflows, production equipment, and industrial techniques. </li><li> Self-initiator, ability to work with ambiguity, multi-task, and a passion to grow and develop. <br/><br/></li></ul><strong>Preferred Knowledge, Skills And Abilities<br/><br/></strong><ul><li> Master’s degree in engineering. </li><li> Six Sigma Black Belt. </li><li> Experience in medical device industry or other regulated industry. </li><li> Experience designing and updating layouts using AutoCAD. </li><li> Experience developing data collection systems, reports, and dashboards. <br/><br/></li></ul><strong>Travel Requirements<br/><br/></strong><ul><li> Must be able to travel up to 20% of the time. <br/><br/></li></ul><strong>Physical And Mental Requirements<br/><br/></strong><ul><li> Light – exerting up to 20lbs/9kg of force frequently, and/or negligible amount of force frequently constantly to move objects. If the use of arm and/or leg control requires exertion of force greater than that of sedentary work and if the worker sits most of the time, the job is considered light work. </li><li> Proven ability to work in a virtual environment in a global organization and to effectively prioritize and execute tasks in a high-pressure environment. </li><li> Make independent and sound judgments. </li><li> Multitask, work under time constraints, problem solve, and prioritize. </li><li> Excellent communicator with ability to maintain confidentiality and resolve conflicts and ambiguity. </li><li> Use written and verbal communication skills effectively. Maintain clear communication paths with stakeholders, providing routine project review updates as needed. </li><li> Read and interpret data, information, and documents to analyze and solve problems. </li><li> Solves complex problems analyzing possible solutions using standard methodologies, procedures, experience, judgment, and precedents. </li><li> Learn and apply new information and new skills. <br/><br/></li></ul>West is an equal opportunity employer and we value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sex, gender identity, sexual orientation, age, marital status, veteran status, or disability status. If you have a special need that requires accommodation in order to apply to West, please send an email to Apply.Accommodation@westpharma.com . Where permitted by law, an offer of employment with West Pharmaceutical Services, or any of its subsidiary or affiliate companies, is contingent upon the satisfactory completion of background screening and/or a pre-employment drug screening.
      </div>",No Salary Info Found,Data Pipeline Engineer
Project Engineer,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791631046,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Project Engineer For a Civil Construction Company<br/><br/></strong>This Jobot Job is hosted by Cody Timm<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $60,000 - $70,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>Our client is an employee-owned Civil Construction company that's been in business for over 120 years.<br/><br/>This is an in-office position out of their Santa Fe Springs OR San Diego office. You will report directly to a Project Manager and be working extensively on a 5-year Airport project in San Diego.<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Competitive Base Salary</li><li> Competitive Bonus Package</li><li> Competitive Benefits Package</li><li> Employee Stock Options</li><li> Accelerated Career Growth</li><li> Job Stability<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li> Oversee aspects of civil construction and concrete projects from initial planning to completion, ensuring projects are completed in a timely and cost-effective manner.</li><li> Develop comprehensive project plans, including budgets, timelines, and resource allocation strategies.</li><li> Coordinate and manage project resources, including labor, materials, and equipment.</li><li> Utilize Microsoft Excel to track project progress, manage budgets, and analyze data.</li><li> Work closely with Project Managers to understand their needs and expectations, and to ensure project outcomes meet these expectations.</li><li> Implement strategic planning to improve processes, enhance efficiency, and achieve project objectives.</li><li> Manage and mitigate project risks, and resolve any issues that may arise.</li><li> Ensure all projects comply with safety regulations and quality standards.</li><li> Prepare and present project progress reports to stakeholders and upper management.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li> Minimum of 1 year of Project Engineering or field work in the construction industry.</li><li> Relevant college degree is preferred not required.</li><li> Proficiency in Microsoft Excel and/or other project management software.</li><li> Knowledge of civil construction processes, concrete work, or construction safety regulations.<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$60000- $70000,Data Pipeline Engineer
Senior Project Engineer,Rudolph and Sletten,12/21/2023,https://www.linkedin.com/jobs/view/3741632971,0,https://media.licdn.com/dms/image/D560BAQHHHz8Z_WnMqw/company-logo_100_100/0/1688768298905/rudolph_and_sletten_logo?e=2147483647&v=beta&t=VWW3bYK9YINuBSyOWJklLNOD3TdjYs0ha6g9FzYSHLA,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Rudolph &amp; Sletten, a Tutor Perini Company, is seeking a <strong>Senior Project Engineer</strong> to join our office in San Diego, CA.<br/><br/><strong>About Rudolph &amp; Sletten<br/><br/></strong>In the last six decades, Rudolph and Sletten has built thousands of projects across our five California offices, from research centers designed to cure <em>diseases</em> to institutions that educate future generations to civic facilities and high-tech campuses that move our state forward.<br/><br/>Just like the buildings we construct, our reputation is built to stand the test of time. Our success is due to our diverse, talented personnel, technological expertise, honest estimates, innovative schedules, and ethical business practices.<br/><br/>We're excited to see where the future takes us. Between new building and construction technology, better earth-friendly materials and techniques, all our phenomenal employees, and the amazing people we work with, we’re looking forward to building more award-winning projects for decades to come.<br/><br/>Across California, our notable projects include Kaiser Permanente Redwood City Hospital, San Diego Symphony Rady Shell, UCLA Geffen Hall School of Medicine, Scripps, Encinitas Acute Care Center, DGS Clifford L. Allenby Office Building, and many high-tech Corporate Campuses. At Rudolph and Sletten, you can work on various large, high-profile projects that impact your community.<br/><br/><strong><em>Extraordinary Projects need Exceptional Talent… Let’s Build<br/><br/></em></strong><strong>Description<br/><br/></strong><strong>Rudolph and Sletten</strong> is looking for a Senior Project Engineer to monitor activities at construction job sites. This includes working to ensure construction is progressing as scheduled and contract specifications are adhered to and leading and directing the work of others. This position reports directly to the Project Manager or other assigned supervisors.<br/><br/><strong>Essential Duties And Responsibilities<br/><br/></strong><ul><li>Possesses the ability to successfully prioritize and manage multiple projects</li><li>Inspects construction site daily and works with contractors to schedule deliveries</li><li>Demonstrates understanding of standard concepts, practices and procedures within construction field</li><li>Interprets designs and drawings for crafts installing materials</li><li>Reviews, analyzes and resolves field construction problems, discrepancies and interference within area of discipline with A/E supervision, client, and other contractors as required</li><li>Prepares designs for field build forms, shoring, trays, hangers, pads, etc., as required. Researches vendor data for customized products as needed</li><li>Reviews and approves field design change requests prepared by field and area engineers</li><li>Updates field work procedure documents as required and researches and interprets Codes, technical manuals, journals, etc. as needed</li><li>Reviews A/E supplied drawings and purchases order specifications to ensure that vendor has adequate information to supply required field furnished material, field furnished material has been ordered, and delivery dates support schedule</li><li>Provides technical direction and supervision to engineering personnel. Provides review of A/E design documents for construction feasibility</li><li>Demonstrates advanced knowledge of construction equipment and techniques, drawings, and specifications, building materials and required standards applicable to discipline</li><li>Trains lower level Project Engineers in quality control procedures</li><li>Monitors subcontractor and company progress in resolving quality control issues. Monitors subcontractor compliance with quality control process</li><li>Reviews RFI log status to minimize aging issue impacts</li><li>Reviews submittals for LEED compliance</li><li>Reviews mock-ups and/or shop drawings and insures compliance with work in progress</li><li>Verifies the accuracy of NCR/DR/FOR logs</li><li>Verifies the accuracy of Procurement and Concrete logs</li><li>Demonstrates knowledge of commonly used concepts, practices, and procedures within a particular field</li><li>Demonstrates advanced knowledge of discipline, construction technology, design, applicable codes, standards, etc., required</li><li>Analyzes and resolves complex engineering problems and effectively communicates and interfaces with all levels of personnel</li><li>Relies on instructions and pre-established guidelines to perform the functions of the job</li><li>Utilizes excellent written and oral communications and team skills</li><li>Performs work tasks by receiving direction and then working independently with an interest in quickly learning and applying new skills and abilities</li><li>Demonstrates ability to be dependable, consistent, diligent, and thorough. Exercises creativity and resourcefulness in completing tasks accurately in a compressed time frame</li><li>Performs all other duties as assigned by supervisor</li><li>Ensure compliance with OSHA regulations to include health, safety, and welfare as appropriate<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li>Bachelor's degree in Engineering or Construction Management is required; </li><li>Minimum five (5) years of experience in the field or in a related area. </li><li>Working knowledge of surveying techniques and equipment, assigned discipline design and overall engineering standards is necessary.</li><li>Experience with large commercial projects; healthcare, higher education, corporate campuses, justice, science &amp; technology is desired.</li><li>Ability to communicate well with multiple levels of personnel</li><li>Manage multiple demands simultaneously</li><li>Works well at project sites in the field environment</li><li>Intermediate knowledge of Windows Operating Systems; Excel, Word, Outlook, etc.</li><li>Knowledge of Prolog software or similar software.</li><li>Knowledge of AutoCAD product line.</li><li>Ability to read Blueprints.</li><li> Knowledge of scheduling, estimating and cost software.<br/><br/></li></ul><strong>Expected annual salary range for this job is $95,000 - $120,000 depending on experience and region.<br/><br/></strong><strong><em>Rudolph &amp; Sletten</em></strong><strong> <em>builds extraordinary projects with exceptional talent. Join us and together we will build the future</em></strong>
</div>",$95000- $120000,Data Pipeline Engineer
Mechanical Project Engineer,"University Mechanical & Engineering Contractors, Inc. (CA)",12/19/2023,https://www.linkedin.com/jobs/view/3739140159,0,https://media.licdn.com/dms/image/C4D0BAQHod-ubDPLhoQ/company-logo_100_100/0/1630574820718/university_mechanical_engineering_contractors_inc_ca_logo?e=2147483647&v=beta&t=mNpo0y0hPilmHKHxiKZrYwGpQLysw8KMJf6S4vnyi7s,"El Cajon, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        University Mechanical &amp; Engineering Contractors, Inc. is currently seeking individuals for a full-time position as a <strong>Mechanical Project Engineer</strong> located in our San Diego, CA area. Backed by the strength and stability that comes with almost a century of customer care and ownership, UMEC adheres to the highest safety standards for its employees and clients. UMEC offers industry-leading building information modeling (BIM) capabilities, design/build services, sustainable solutions, commercial HVAC services, and complex mechanical and industrial system installations.<br/><br/><strong>Compensation Range: $64,480 to $90,000.<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li>Project Estimating (Take-Off &amp; Analysis)</li><li>Project Scheduling (Manpower scheduling)</li><li>Manage RFIs (Requests for Information)</li><li>Prepare Submittal Packages</li><li>Manage Flow of Contractor provided submittal data</li><li>Assist in data population of forms</li><li>Prepare Project Progress Billings</li><li>Assist in Technical Analysis, Trouble shooting, and problem solving of HVAC Air Equipment, HVAC Piping Equipment Systems, HVAC &amp; Plumbing Equipment<br/><br/></li></ul><strong>Skills and Experience:<br/><br/></strong><ul><li>Basic working knowledge HVAC &amp; Plumbing Design &amp; System Operation</li><li>Basic working knowledge of Commercial &amp; Industrial construction sequences</li><li>Basic working knowledge of construction estimating</li><li>Basic working knowledge of testing procedures for HVAC systems.</li><li>Basic working knowledge of ASHRAE data &amp; guidelines</li><li>Average proficiency with MS Project scheduling program</li><li>Average proficiency with MS Access or other database programs</li><li>Above average proficiency with MS Excel &amp; Word</li><li>Above average proficiency with Internet</li><li>Above average verbal &amp; writing skills</li><li>Above average organizational skills in handling &amp; archiving technical data<br/><br/></li></ul>Recommended that the candidate have bachelor’s degree in Mechanical Engineering, Construction Management, Other Engineering Disciplines (Civil, Industrial, or Structural), and/or 5 years industry experience as a Construction Project Engineer.<br/><br/>Candidate should be able to demonstrate experience with project administration, project scheduling, productivity analysis, project cost control accounting, plus equipment &amp; material procurement.<br/><br/>Company offers competitive benefits including Employee Stock Purchase Program, 401-K, health, dental, and life and long-term disability. Includes, holiday, sick and vacation pay.<br/><br/>We offer our employees a competitive salary and competitive benefits package and are always looking for individuals with the talent and skills required to contribute to our continued growth and success. Equal Opportunity Employer/Veterans/Disabled<br/><br/><strong>Notice to prospective employees: </strong>There have been fraudulent postings and emails regarding job openings. EMCOR Group and its companies list open positions here. Please check our available positions to confirm that a post or email is genuine.<br/><br/>EMCOR Group and its companies do not reach out to individuals to help with marketing or other similar services. If an individual is contacted for services outside of EMCOR’s normal application process – it is probably fraudulent.<br/><br/>#umecca<br/><br/>
</div>",$64480- $90000,Data Pipeline Engineer
"Project Engineer, Cross Platform",General Atomics,12/19/2023,https://www.linkedin.com/jobs/view/3747515489,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer,Flatiron Construction,12/19/2023,https://www.linkedin.com/jobs/view/3737523512,0,https://media.licdn.com/dms/image/D560BAQG_BcB5vaVN5w/company-logo_100_100/0/1683737952199/flatiron_construction_corporation_logo?e=2147483647&v=beta&t=QbqOnLVSkB_fGGx-XkOEcIB5wpY7RYcp1g5F0hxBVps,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Overview<br/><br/></strong>Great opportunity to join an industry-leading organization that is at the forefront of developing innovative solutions to build critical infrastructure projects. We have an immediate need to hire a Senior Project Engineer. This individual p erforms tasks related to the collection of cost data required to monitor project budget and estimates. The position requires the selection and application of resource monitoring and control principles, techniques and technical knowledge of construction project.<br/><br/><strong>What You Will Be Doing<br/><br/></strong><ul><li> Meets with engineering team to review production schedule and confirm all materials, equipment and resources are readily available for production to continue on schedule and within budget. </li><li> Reviews shop drawings, design specifications, material requirements and project data to ensure quality and contract specification compliance. </li><li> Provides technical input for project work plan and scheduling. Identifying risk elements of production, materials, equipment or process that could negatively impact the budget or schedule. </li><li> Evaluates weekly and monthly production, schedule and budget projections to accurately track project performance. Documents daily activities in Company approved methods and technologies. </li><li> Updates project schedule weekly for owner and management reporting. Attends weekly owner meetings; presents on project production status as needed. </li><li> Perform additional assignments per management’s direction. </li><li> Prepares and manages a three-week work plan. Notifies engineering and project management of any significant schedule changes and develops solutions to mitigate delays and cost. </li><li> Initiates and manages all Requests for Information (RFIs), as needed by project. </li><li> Remits accurate project quantities using assigned project cost coding to ensure project financials are accurately reported. Manages invoicing with Company accounting team regarding materials, equipment and subcontractor needs. </li><li> Supports engineering team with quality assurance as needed. Reviews certificates and permits needed to perform work. Participates in all worksite tours with leadership or external parties. </li><li> Reviews required Job Hazard Analysis (JHAs) to ensure a safe and compliance work environment for all construction personnel. Participates in all weekly safety meetings with field team and project leadership; presents field analysis as needed. </li><li> Assists the estimating team with project schedule, budget and cost parameters by providing technical input as needed. </li><li> Assists the development of design drawings and provides technical input, as needed. </li><li> Coordinates subcontractor work methods, schedule and crews as needed. </li><li> Perform project leadership role during close-out procedures if Project Manager separates from project before close. Reviews close-out checklist with owner and field crews at the end of the project. </li><li> Maintains knowledge of Company values and strategic plan. <br/><br/></li></ul><strong>What We Are Looking For<br/><br/></strong><ul><li> Bachelor's Degree in a related field required. </li><li> 7+ years construction engineering experience required. </li><li> Experience managing construction engineering teams required. </li><li> Proven skill and ability managing engineering teams in a design build or other alternative build project. </li><li> Able to identify and implement growth opportunities in direct reports to build talent development within project team. </li><li> Advanced planning and scheduling skills required. </li><li> Able to drive direct reports and influence non-reporting teams towards a common deliverable. </li><li> Able to set clear expectations for direct reports regarding role and responsibilities. </li><li> Able to delegate and assign work to engineering team to progress the project production forward. </li><li> Able to manage multiple engineering tasks and progress them all towards a common goal. </li><li> Advanced knowledge of contract specifications and quality assurance practices. </li><li> Able to identify budget and project costs and recommend options to mitigate project delays. </li><li> Strong verbal, written and presentation skills. </li><li> Knowledge of design build and other alternative build techniques. </li><li> Knowledge of financial reporting methods, quantity tracking methods and cost coding. </li><li> Knowledge of construction scheduling and production time management preferred. </li><li> Ability to assume responsibility, interface and communicate effectively with others. <br/><br/></li></ul><strong> Why work for us <br/><br/></strong>Some of the benefits you may be eligible for as an employee are:<br/><br/><ul><li> Comprehensive compensation package and paid time off program </li><li> Industry leading 401(k)/RRSP </li><li> Medical/Extended Health Care, Dental, Vison and/or Provincial Medical </li><li> Wellness benefits &amp; Employee Assistance Program </li><li> Tuition Reimbursement Program <br/><br/><br/></li></ul>We are an EEO/AA/ADA/Veterans employer.
      </div>",No Salary Info Found,Data Pipeline Engineer
"Staff Manufacturing Engineer, Consumables",Cue Health,12/19/2023,https://www.linkedin.com/jobs/view/3724689489,0,https://media.licdn.com/dms/image/C560BAQH-5-yeDN-aKA/company-logo_100_100/0/1636951371235?e=2147483647&v=beta&t=sxXLBOdwusZTVvx6giFrJ36p1IetacmTwud74OXJO0Q,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us</strong>:<br/><br/>Cue Health (Nasdaq: HLTH) is a mission-driven healthcare technology company that puts consumers in control of their health information and places diagnostic information at the center of care. Cue Health enables people to manage their health through real-time, actionable, and connected health information, offering individuals and their healthcare providers easy access to lab-quality diagnostics anywhere, anytime, in a device that fits in the palm of the hand. Cue Health’s first-of-its-kind COVID-19 test was the first FDA-authorized molecular diagnostic test for at-home and over-the-counter use without physician supervision. Outside the United States, Cue Health has received the CE mark in the European Union, Interim Order authorization from Health Canada, and regulatory approval from India’s Central Drugs Standard Control Organisation. Cue Health was founded in 2010 and is headquartered in San Diego. For more information, please visit www.cuehealth.com.<br/><br/>Cue Health Inc. is seeking to hire a full-time<strong> Staff Manufacturing Engineer, Consumables. </strong>This role is to establish best-in-class contract manufacturing partnerships to ensure highest product quality and timely delivery. This individual will support this initiative via the managing the implementation, development and sustainment of Cue’s growing supply base with a specific focus on high volume consumables for Cue’s novel test cartridges. Duties will include establishment of component specifications, technical guidance of contract manufacturers, defining process validation requirements, maintaining product quality for foreign and domestic partners. (Position is open to remote individuals)<br/><br/><strong>Responsibilities:<br/><br/><br/></strong><ul><li>Subject matter expert for manufacturing of Cue’s custom molded components, including injection, two-shot, LIM and thermoset molding</li><li>Responsible for defining validation requirements for molding process at Cue’s contract manufacturers</li><li>Lead continuous improvement projects innovative solutions to improve performance, reliability, cost and manufacturability</li><li>Evaluate supplier performance</li><li>Provide guidance on mechanical requirements and manufacturability for new product development</li><li>Establish process controls with a target of six sigma quality</li><li>Maintain 3D models, assemblies and drawings using accepted drafting standards</li><li>Ensure component quality, performance and delivery by managing good supplier relationships</li><li>Maintain a project schedule and keep projects moving forward in a fast-paced environment</li><li>Will have responsibility to manage and mentor others</li><li>Perform other mechanical engineering duties<br/><br/><br/></li></ul><strong>Requirements:<br/><br/><br/></strong><ul><li>Bachelor’s degree in Mechanical Engineering, Manufacturing Engineering or equivalent is required</li><li>Master’s degree or equivalent in Mechanical Engineering or a related field is preferred</li><li>8+ years of post-baccalaureate progressive mechanical, high volume manufacturing experience: including specification development, design for manufacturability, vendor relations, ability to analyze mechanical drawings, specs, and schematics. Provide valuable insights on product development, product design, failure analysis. Also skilled in defining mechanical requirements, designing manufacturing systems, component evaluation and component packaging and layouts; performing component and system testing, writing verification test plans and protocols, and reports</li><li>Working knowledge of statistics, process control, DEMAIC problem solving techniques, medical device quality requirements, 2-D and 3-D modeling, MS Office Suite products</li><li>Experience working with injection molding and high-volume plastics</li><li>Familiarity with a variety of polymers</li><li>Understanding of various part inspection methods, including both non-contact and contact methods</li><li>Ability to travel<br/><br/><br/></li></ul><strong>Environment and Physical Activities/Requirements:<br/><br/><br/></strong><ul><li>You will work in an indoor manufacturing environment, which may occasionally be noisy, subject to climate and humidity requirements, and hazardous substances. This position requires the following physical activities and/or requirements:<br/></li><ul><li>Remaining in a stationary or sedentary position, often standing and/or sitting for prolonged periods of time</li><li>Moving about to accomplish tasks or moving from one worksite to another, including possibly tight or confined spaces</li><li>Reaching, crouching, or stooping</li><li>Repeating motions that may include the wrists, hands, and/or fingers</li><li>Adjusting, moving, carrying, lifting, pushing or pulling objects up to 50 pounds</li><li>Operating machinery, power tools, motor vehicles, and/or heavy equipment</li><li>Ascending or descending ramps, ladders and/or stairs</li><li>Communicating with others to exchange information</li><li>Visual acuity, including peripheral vision<br/><br/><br/></li></ul></ul>Your contribution will set the pace and have an impact in the technology, health, and diagnostic industry. Your work and ideas will be valued and respected, and we hope you will find enjoyment working with a collaborative team on an innovative device. We offer upgraded computer equipment, unlimited snacks, and a competitive salary.<br/><br/>Cue Health Inc. is an equal opportunity employer, consistent with applicable laws. Individuals seeking employment are considered without regards to race, color, religion (including religious accommodations), creed, sex (including pregnancy, childbirth and related medical conditions), gender (including gender identity and expression), sexual orientation, marital status, national origin (including language use restrictions), ancestry, mental and/or physical disability, medical condition (cancer, genetic information and characteristics, requests for medical and family care leave), age, military or veteran status, and any other classification protected by applicable federal, state, and local laws.<br/><br/>The estimated base compensation range for this role is shown below. This range is based upon current market data and other factors, all of which are subject to change. Individual pay will be determined in accordance with a candidate's location, skills, expertise, background, experience, and other relevant factors. Applicants are always welcome to direct questions regarding this range to the Talent Acquisition specialist recruiting for this position.<br/><br/>Base Compensation Range:<br/><br/>$0.00 - $0.02<br/><br/>Pay Rate:<br/><br/>Salary
      </div>",$0.00- $0.02,Data Pipeline Engineer
Staff Mechanical Engineer - Pipelines (California),Burns & McDonnell,12/19/2023,https://www.linkedin.com/jobs/view/3528014289,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Manager / Mechanical Engineer,Salas O'Brien,12/19/2023,https://www.linkedin.com/jobs/view/3667479446,0,https://media.licdn.com/dms/image/C560BAQG_72A8burDdQ/company-logo_100_100/0/1678813550001/salasobrien_logo?e=2147483647&v=beta&t=wC2bgkTr7i5PURkUibtJ7jTHW23Gd3MxD-QwO8zcD-8,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Project Manager: Mechanical </strong></p><p><br/></p><p>At Salas O’Brien, we tell our clients that we’re engineered for impact. This passion for making a difference applies just as much to our team as it does to our projects. That’s why we’re committed to living our values every day: inspiring, achieving, and connecting as shared owners of our success with a focus on a sustainable future.</p><p><br/></p><p>Building for the long-term means that all of our team members can expect to work on amazing projects with a people-first approach to problem solving. It also means that each member of our team has truly limitless potential to build a unique, meaningful, and high-impact career—and they’ll receive great total rewards along the way.</p><p><br/></p><p><strong>About Us:</strong></p><p>Founded in 1975, Salas O’Brien is an employee-owned engineering and professional services firm focused on achieving impact for our clients, our team, and the world. We know that tomorrow’s requirements are today’s opportunities, and we are here to design lasting solutions for pressing challenges.</p><p><br/></p><p>We work across a variety of industries providing integrated engineering and consulting services. Our specialized experience includes design for data centers, healthcare, science and technology, high-rise buildings, clean energy, education, and other building types as well as structural and building sciences, infrastructure asset management, advanced robotics, and more.</p><p><br/></p><p>Our technical expertise is paired with an exceptional team of business development, human resources, finance and accounting, information technology, and marketing professionals, all of whom play a key role in bringing our commitments to life every day.</p><p><br/></p><p><strong>Job Summary:</strong></p><p>Our office in San Diego is looking for a <strong>Project Manager</strong> to work in a fast-paced multi-discipline team environment with primary responsibility to engineer and design projects for healthcare, institutional and industrial clients. The role will entail managing engineering projects, directing designers &amp; other disciplines, as well as personally performing engineering activities.</p><p><br/></p><p><strong>Responsibilities:</strong></p><ul><li>Provide a superior level of technical services to our clients for their projects and technical support requirements, providing technical and project control direction, and mentoring to other engineers and designers</li><li>Identify, formulate, and initiate solutions to complex problems requiring multiple-discipline involvement, along with discipline-specific analytical tools</li><li>Perform work activities on an individual basis or within a project team with limited need for supervision</li><li>Coordinate work activities that affect the quality of project control, scope development, proposals, engineering &amp; design, document control, inspection &amp; testing, and commissioning</li><li>Review and check the work of others. Effectively apply self-checking to their work</li><li>Identify and resolve routine problems that involve the use of conflicting or incomplete information</li><li>Data gathering and site assessments at customer’s facilities</li><li>Develop bidding documents for process equipment, fabrication, and construction</li><li>Ability to review Revit production models and work interactively with support staff in development of project deliverables</li></ul><p><br/></p><p><strong>Qualifications:</strong></p><ul><li>A Bachelor's Degree in Mechanical Engineering</li><li>10-20 years of experience leading and managing projects from start to finish, providing comprehensive HVAC, Control Systems, Plumbing and Fire Protection engineering services</li><li>Client engagement and business development experience</li><li>Advanced expertise with Autodesk software (Revit, Navisworks)</li><li>Ability to comprehend, contribute to, and carry out strategies to manage our relationships with customers, suppliers, and alliance team members</li><li>Experience at a design engineering firm required</li><li>Registration as P.E. preferred</li></ul><p><br/></p><p><strong>Location</strong>: San Diego, CA</p><p><br/></p><p><strong>Travel</strong>: Local travel may be required.</p><p><br/></p><p><strong>Equal Opportunity Employment Statement:</strong></p><p>Salas O’Brien provides equal employment opportunities to all employees and applicants for employment and prohibits discrimination and harassment of any type without regard to race, colour, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state/provincial, or local laws. Salas O’Brien will accommodate the disability-related needs of applicants as required by law.</p>
</div>",No Salary Info Found,Data Pipeline Engineer
Staff Project Engineer Mission Platform Systems,General Atomics,12/19/2023,https://www.linkedin.com/jobs/view/3749966036,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Project Engineer - San Diego,CA Ventures,12/20/2023,https://www.linkedin.com/jobs/view/3790949538,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Mechanical Engineer - Application Engineering,Teikoku USA INC,12/25/2023,https://www.linkedin.com/jobs/view/3793318822,0,https://media.licdn.com/dms/image/C4E0BAQGanPmGKYu59g/company-logo_100_100/0/1631362636059/teikoku_usa_inc_logo?e=2147483647&v=beta&t=rl-fyRoCGS6lXVcvGGQoTwDi4hv-SJ_sJVzOYW1ZRQ0,"Warminster, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>PURPOSE OF POSITION:<br/><br/></strong>To manage the technical application, selection, documentation, commercial pricing, presentation and terms and conditions of sale for Teikoku USA products presented in response to inquiries from existing customers, prospective customers and their agents. Responsible for proper application of, and/or making exceptions to, all specifications and related technical and commercial documents associated with quotations and any orders that result from those quotations. Responsible for the coordination of all commercial and technical requirements of purchase contracts both within Teikoku USA and the parent manufacturing company, Teikoku Electric in Japan, for new pump sales and engineered parts. You will have a direct impact in serving the needs of our customers. You will work with the sales team to take lead on projects and collaborate with other disciplines like design engineering, manufacturing and quality to help Teikoku’s growth.<br/><br/><strong>PRIMARY DUTIES &amp; ESSENTIAL FUNCTIONS:<br/><br/></strong><ul><li>Review incoming inquiries, invitations to bid &amp; specifications and respond directly to the inquirer for prompt handling to assure meeting the proposal due date. </li><li>Evaluate project inquiries for overall commercial, technical and quality assurance scope, assess solutions across all product lines, coordinate preparation of proposals &amp; submit completed proposals in compliance with customers’ requirements or with exceptions/alternatives clearly noted to customers. </li><li>Negotiate proposals, details &amp; purchase contract pricing on behalf of Teikoku USA consistent with company policies and/or in consultation with management. </li><li>Review purchase contracts received from customers as a result of quotations made and prepare sales orders. </li><li>Process incoming orders and assure correlation to proposals &amp; specifications. Manage supporting documentation with order file. </li><li>Organize and/or participate in pre- or post-award meetings. </li><li>Schedule &amp; conduct specification review meetings with appropriate Teikoku USA and/or Teikoku Electric Manufacturing Company personnel. </li><li>Monitor and, if necessary, expedite the manufacturing, testing and inspection of products on order and keep customers informed on this progress to assure on-time delivery. </li><li>Assist sales channels, customers &amp; factory personnel with application, service &amp; product inquiries by maintaining a high level of product knowledge &amp; maintaining a supportive relationship within various company departments and within the sales channel organizations. </li><li>Arrange for transmittal of drawings, curves &amp;/or other documentation &amp; customer’s release as required by the order. </li><li>Review proposals made by sales channel personnel to assure proper application &amp; pricing and advise of any changes. </li><li>Maintain files for proposals, applications, corrosion information, fluid data, etc. as applicable. </li><li>Provide market feedback on product/project opportunities. </li><li>Assist in field service problems &amp; act as technical backup to Aftermarket Sales &amp; Service. </li><li>Other duties at the discretion of the Technical Process Manager. <br/><br/></li></ul><strong>EDUCATION, EXPERIENCE &amp; SPECIAL SKILLS:<br/><br/></strong><ul><li>An engineering degree is required and a commitment to receive training will be mandatory. </li><li>Excellent communication skills (verbal and written) required for all interactions including personal, telephone, email or written memos and letters, both internally &amp; externally with customers</li><li>Superior computer operation skills are required, including advanced skills with application software based in Microsoft Office including but not limited to Excel, Word, and Outlook</li><li>Mobile computing and communication skills are a must. </li><li>Must have a valid driver’s license and able to travel, unaccompanied, via auto &amp; air to customers &amp; sales channel organizations’ facilities<br/><br/></li></ul><strong>PHYSICAL DEMANDS AND WORKING ENVIRONMENT:<br/><br/></strong>The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br/><br/>While performing the duties of this job, the employee is required to stand; use hands to finger, handle, or feel; reach with hands and arms; talk, hear, walk, smell, and climb or balance. Specific vision abilities required by this job include close vision, distance vision, color vision, peripheral vision, depth perception, and ability to adjust focus. Ability to navigate facility.<br/><br/>This company is an Equal Opportunity Employer. We invite resumes from all qualified, interested parties, regardless of race, gender, national origin, sexual orientation, disability, age, or any other protected classification under national of local law.<br/><br/><strong>While this job description is intended to be an accurate reflection of the job requirements, management reserves the right to modify, add, or remove duties from particular jobs and to assign other duties as necessary.<br/><br/></strong><strong>Company Description<br/><br/></strong>Teikoku USA Inc is a subsidiary of Teikoku Electric Mfg. Co., Ltd of Japan and a member of the Teikoku Group of global companies. In 2003, Teikoku USA Inc acquired the Chempump Division of Crane Co. to enhance the company's global strategy for the Western Hemisphere by bringing established canned motor pump manufacturing and service capabilities to the USA operation.<br/><br/>Teikoku USA Inc is headquartered in Warminster, PA, where product management, application engineering, manufacturing and servicing of products are available to support the Teikoku product line. Texas operations, including pump and parts services, are handled at Teikoku USA's Houston facility. Standard Chempump products are manufactured, serviced and supported in Marietta, OH. Highly engineered and Nuclear pumps are also manufactured in Warminster, PA. Both Teikoku and Chempump products can be serviced, with engineering support, in either of these manufacturing facilities.<br/><br/>Teikoku USA Inc is a subsidiary of Teikoku Electric Mfg. Co., Ltd of Japan and a member of the Teikoku Group of global companies. In 2003, Teikoku USA Inc acquired the Chempump Division of Crane Co. to enhance the company's global strategy for the Western Hemisphere by bringing established canned motor pump manufacturing and service capabilities to the USA operation. Teikoku USA Inc is headquartered in Warminster, PA, where product management, application engineering, manufacturing and servicing of products are available to support the Teikoku product line. Texas operations, including pump and parts services, are handled at Teikoku USA's Houston facility. Standard Chempump products are manufactured, serviced and supported in Marietta, OH. Highly engineered and Nuclear pumps are also manufactured in Warminster, PA. Both Teikoku and Chempump products can be serviced, with engineering support, in either of these manufacturing facilities.
      </div>",No Salary Info Found,Data Pipeline Engineer
Salesforce Developer,Global Atlantic Financial Group,12/22/2023,https://www.linkedin.com/jobs/view/3792177532,0,https://media.licdn.com/dms/image/C560BAQH0FqykDhcSBA/company-logo_100_100/0/1631355041627?e=2147483647&v=beta&t=q2TU2acdHIPKzBeidmHvW3dIP3xhCwpFJ3Epy6Yea-o,"Wayne, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        All offices are currently open, and our employees are back 4 or 5 days a week in Hudson Yards, NY and 3 days a week in all other offices. If you have questions on this policy or the application process, please contact recruiting@gafg.com .<br/><br/><strong>Company Overview<br/><br/></strong>Global Atlantic Financial Group is a leader in the U.S. life insurance and annuity industry, serving the needs of individuals and institutions. Global Atlantic is a majority-owned subsidiary of KKR, a leading global investment firm that offers alternative asset management across multiple strategies and capital markets solutions.<br/><br/>Global Atlantic is looking for a diverse team of talented individuals who reinforce our culture of collaboration and innovation. We are dedicated to the career development of our people because we know they are critical to our long-term success. Join our team and come grow with us.<br/><br/><strong>We use Greenhouse as our scheduling tool and communicate through their systems. At times, your email may block our communications. Please be sure to check your SPAM so that you do not miss critical information about our process, including scheduling. <br/><br/></strong><strong>Position Overview<br/><br/></strong>Do you thrive in a fast-paced, highly collaborative environment? Do you have a passion for supporting digital transformations within Salesforce.com? Is understanding business processes and implementing technical requirements to meet those business needs leveraging innovative solutions in your DNA? Are you a proficient in the #1 CRM platform?<br/><br/><strong>Role<br/><br/></strong>Salesforce.com is a core functional area within Global Atlantic Technology, reporting to our CTO. For this exceptional opportunity as Salesforce.com Software Engineer, you will get to solve business challenges leveraging the Financial Service Cloud. This role will focus on the below objectives:<br/><br/><ul><li>Develop Salesforce.com innovative solutions using Configuration or Code on the Salesforce.com Cloud platform to support our business.</li><li>Support our Enterprise initiatives and ensure underlying data is of high quality, governed, and following Salesforce.com Financial Service guidelines.</li><li>Support our Mobile strategy.</li><li>Strengthen security and audit practices.</li><li>Provide support to our reporting and AI efforts.</li><li>Support our end users and day-to-day operations.<br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li>Analyze business requirements.</li><li>Design technical implementation solutions from business requirements.</li><li>Develop and build solutions leveraging Salesforce.com Configuration or Programming Technologies (lightning components, Apex and REST services).</li><li>Test the build products – Unit and Integration testing.</li><li>Participate in troubleshooting and fixing issues in functional testing, UAT testing phases and resolve performance issues using Salesforce debug tools.</li><li>Participate in business and technology discussions for requirements gathering, analysis, prototype build, design reviews and testing.</li><li>Design data models within Salesforce leveraging sound object-oriented architecture.</li><li>Deploy and Support the product solution in the Salesforce.com environment leveraging CICD pipeline.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Excellent programming skills in Java or .NET and good business acumen.</li><li>At least 2 years of experience as a Salesforce.com Software Engineer developing solutions using lighting components, apex and different integration techniques.</li><li>At least 3 years of experience in the Information Technology space.</li><li>Relevant experience in the Financial Services industry.</li><li>Passion for technology and problem solving.</li><li>Proficient with object-oriented designs and SQL.</li><li>Strong work ethics and teamwork.</li><li>Ability to ramp up quickly.</li><li>Excellent communication and interpersonal skills.</li><li>Flexibility.</li><li>Ability to work in a very fast paced environment.</li><li>This postilion is not eligible for visa sponsorship now or in the future.<br/><br/></li></ul>Various jurisdictions have passed pay transparency laws that require companies provide salary ranges for any positions for which they are accepting applications. Global Atlantic has offices in Atlanta, Batesville, Bermuda, Boston, Des Moines, Hartford, Indianapolis, and New York City. <strong>The base salary range posted below is inclusive of the lowest cost of living geography to the highest in which we have a Global Atlantic office. <br/><br/></strong>Global Atlantic’s <strong>base salary range</strong> is determined through an analysis of similar positions in the external labor market. Base pay is just one component of Global Atlantic’s total compensation package for employees and at times we hire outside the boundaries of the salary range. Other rewards may include annual cash bonuses, long-term incentives (equity), generous benefits (including immediate vesting on employee contributions to a 401(k), as well as a company match on your contributions), and sales incentives. Actual compensation for all roles will be based upon geographic location, work experience, education, licensure requirements and/or skill level and will be finalized at the time of offer. Compensation for our more senior positions have a larger component of short-term cash bonus and long-term incentives.<br/><br/>The base salary range for this role is<br/><br/>$82,500 — $157,500 USD<br/><br/><strong> TOTAL REWARDS STATEMENT <br/><br/></strong>Global Atlantic’s total rewards package is reflective of our corporate values, particularly diversity, excellence and innovation, with a focus on inclusion, pay equity, and flexibility. We are proud to support your personal and professional growth and well-being through programs such as educational assistance, virtual physical therapy, remote/onsite fitness reimbursement, a medical second opinion program, pet insurance, military leave, parental leave, adoption assistance, fertility and family planning coverage. We strive to foster a culture of total well-being through community outreach and charitable giving programs.<br/><br/><strong>We Are Active In Our Communities<br/><br/></strong><ul><li>New York: Red Hook Conservancy, Girls Who Invest, Outward Bound, Teach for America, StreetWise Partners,</li><li>Boston: Catie’s Closet, Project Bread, Thompson Island Outward Bound Education Center, Cradles to Crayons, and many others</li><li>Hartford: Braids and Company, Junior Achievement</li><li>Indianapolis: Elevate Indianapolis, Gleaners Food Bank and the Juvenile Diabetes Research Foundation</li><li>Batesville: So Loved Ripley County Foster Closet, Southeastern Indiana YMCA, Batesville Community Education Foundation, Southeastern Indiana Voices for Children, local area youth sports, as well as many others</li><li>Des Moines: United Way of Central Iowa, Meals from the Heartland, Oakridge Neighborhood, Community Support Advocates, and many others</li><li>Wayne: For Pete’s Sake, Chester County Food Bank, Habitat for Humanity Chester County, Brandywine SPCA, as well as others</li><li>Bermuda: Transformational Living Centre for Families<br/><br/></li></ul>Social platforms provide an environment to collaborate with others and participate in friendly competitions towards achieving physical, emotional and financial well-being. Our highly competitive health, retirement, life and disability plans can be tailored to best suit your needs and those of your whole family.<br/><br/>Global Atlantic is committed to creating an inclusive environment where everyone can meaningfully contribute to our success. We are proud to be an equal opportunity employer and we do not discriminate in employment on any basis that is prohibited by federal, state or local laws. More than that, we strive to be inclusive of all backgrounds and experiences, which we feel gives us a competitive advantage in the market and within our firm. All qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, disability, age, or veteran status.<br/><br/>Employees who require an accommodation to perform the essential functions of their job will participate in an interactive process which may include providing documentation. If you are hired and require an accommodation for any protected status, please email benefits@gafg.com .<br/><br/>Please click on the below links to learn more about Global Atlantic.<br/><br/>Global Atlantic Privacy Statement<br/><br/>
</div>",$82500- $157500,Data Pipeline Engineer
Quality Engineer – (NPI),PCI Pharma Services,12/19/2023,https://www.linkedin.com/jobs/view/3730899115,0,https://media.licdn.com/dms/image/D4E0BAQHLec1eqsU8gA/company-logo_100_100/0/1667249491254/pciservices_logo?e=2147483647&v=beta&t=hd6xUyU_-6YeHXiRwRklJoEErN3WFJkgLpP3p0_e4Z4,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Life changing therapies. Global impact. Bridge to thousands of biopharma companies and their patients.<p><br/></p><strong>We are PCI. </strong><p><br/></p>Our investment is in People who make an impact, drive progress and create a better tomorrow. Our strategy includes building teams across our global network to pioneer and shape the future of PCI.<p><br/></p><ul><li>Job Title: Quality Engineer – New Production Introduction (NPI)</li></ul><p><br/></p><strong>Location:</strong> Philadelphia, PA ( Red Lion Road)<p><br/></p><strong>Business Type:</strong> Other<p><br/></p><strong>Department/Function:</strong> Quality - Validations<p><br/></p><strong>Reports to: </strong>Director, Quality Operations or Designee<p><br/></p><strong>FLSA Status:</strong> Exempt<p><br/></p><strong>Summary Of Objective</strong><p><br/></p>The Quality Engineer - New Product Introduction (NPI) is a key, customer-facing role that will be responsible for the onboarding and support of new customer programs for the Philadelphia Site. The QE will be responsible for the transition of new products and processes from engineering to manufacturing and the supply chain. This position will work closely with product engineering to define manufacturing requirements within the New Product Development process including all phases in Design for Assembly (DFA) through to Design for Manufacturing (DFM).<p><br/></p>The QE will interact and collaborate with internal team members, customers, suppliers, and contract service providers. The position will be responsible for driving timeline commitments for new projects. The Quality Engineer will also function as a technical resource in deviations, defect analysis, complaints, establishing sampling plans, assessments, and protocols.<p><br/></p><strong>Essential Duties and Responsibilities:</strong> To perform this job successfully, an individual must be able to perform each essential duty satisfactorily. The essential duties and responsibilities include the following but other duties may be assigned.<p><br/></p><strong>Technical (Product and Process)</strong><ul><li>Drive and support new customer programs throughout the development lifecycle and deliver on the ‘One PCI’ customer experience and program management</li><ul><li>Interact with clients on an as-needed basis to support project milestones, scope changes and business development opportunities.</li><li>Develop and implement product and process workflows to ensure best engineering practices within the quality and engineering teams for DFA/DFM (DFMA) into sustainable engineering and commercial operations.</li><li>Test method transfer or method validation activities.</li><li>Development of sampling plans for OQ/PQ activities (includes Serialization and Sterilization activities).</li><li>Trend manufacturing data and contract service providers results.</li><li>Development of validation/re-qualification protocols.</li><li>Development of Master Batch Records, work instructions and associated manufacturing and packaging documentation.</li></ul></ul><ul><li>Drive root cause analysis of deviations/complaints.</li><li>Support project teams through the selection of correct design / manufacturing concepts and fundamental technology to ensure successful project outcomes.</li><ul><li>Develop work standards and packages as part of project acquisition process and following subsequent project delivery stages, to successfully deliver projects within scope, with quality, and within allocated timeframes and budget.</li><li>Identify opportunities and develop recommendations to improve product and process design.</li><li>Interpret product requirements and design and develop concepts, components, assemblies, and products in compliance with applicable quality system procedures, industry, and business standards.</li><li>Supports the generation of documentation such as Measurement System Analysis (MSA), Control Plans, Process Flow Maps, Inspection plans and techniques, GR&amp;R &amp; test requirements.</li></ul></ul><ul><li>Maintain QE process discipline to achieve project deliverables, including but not limited to, supporting manufacturing strategy, capability analysis, FMEA, tooling selection, risk management, supporting cost modelling, DFM, and process validation/qualification.</li><ul><li>Employ data driven tools and methodologies to implement structured and timely problem.</li><li>Development and/or review of technical specifications<br/></li></ul><strong>Supplier Quality<br/></strong><ul><li>Participate in External Audits of Suppliers/Contract Service Providers.</li><li>Manage internal and external suppliers required to support product design tasks.<br/></li></ul><strong>Leadership<br/></strong><ul><li>Collaborate with the engineering, business development and ancillary groups and wider development, manufacturing, and procurement teams.</li><li>Attention to detail and self-motivation to deliver work to the highest standards.</li><li>Multitasking, planning work, scheduling tasks, coordinating activities, and managing time efficiently.</li><li>Timely problem-solving using data driven tools and methods.</li><li>Presentation of quality standards, process flows, inspection plans, and/or issues both internally to stakeholders and externally to clients with confidence and accuracy.<br/></li></ul><strong>Other - General<br/></strong><ul><li>Attendance to work is an essential function of this position</li><li>Performs other duties as assigned by Manager/Supervisor within commercial operations (sustainment engineering).</li><li>Support the recruitment, coaching, and development of quality engineers to achieve excellence and efficiency when programs are scaled.<br/></li></ul><strong>Special Demands: </strong>The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this job. The employee must be physically capable to perform the duties listed below with or without reasonable accommodations which may be made to enable individuals with disabilities to perform the essential functions<br/><ul><li>Stationary Position: From 1/4 to 1/2 of the day. </li><li>Move, Traverse: From 1/4 to 1/2 of the day. </li><li>Operate, activate, use, prepare, inspect, or place: From 1/4 to 1/2 of the day. </li><li>Install, place, adjust, apply, measure, use, or signal: Up to 1/4 of the day. </li><li>Ascend/Descend or Work Atop: Up to 1/4 of the day. </li><li>Position self (to) or Move (about or to): Up to 1/4 of the day. </li><li>Communicate or exchange information: 3/4 of the day and up.</li><li>Detect, distinguish, or determine: 3/4 of the day and up. </li><li>On an average day, the individual can expect to move and/or transport up to 10 pounds less than 1/4 of the day.<br/></li></ul>This position may have the following special vision requirements.<br/><ul><li>Close Vision ☒ Distance Vision ☒ Color Vision ☒ Peripheral Vision ☒ Depth Perception</li><li>Ability to focus ☐ No Special Vision Requirements <br/></li></ul><strong>Work Environment: </strong>The work environment characteristics described here are representative of those an employee encounters while performing the essential functions of this job. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br/><br/>The following are some environmental conditions that one may be exposed to daily and for various lengths of time.<br/><ul><li>Work is primarily performed at a desk and/or in an office environment. for 1/4 to 1/2 of the day. </li><li>Work is performed in areas with moderate risk or discomfort that may require special safety precautions, such as wearing protective clothing or gear for up to 1/4 of the day. </li><li>The noise level in the work environment is typically, moderate. <br/></li></ul><strong>Qualifications: </strong>The requirements listed below are representative of the knowledge, skill, and/or ability required for the stated position. Reasonable accommodations may be made to enable individuals with disabilities to perform the essential functions.<br/><br/><strong>Required<br/></strong><ul><li>College or Trade Degree required (engineering degree or related scientific degree). Must have a minimum of at least three years of experience in an FDA regulated industry with strong preference to medical device or combination products.</li><li>Demonstrated proficiency with personal computers, business software (e.g., MS Office) and technical software (ERP and eQMS systems). Ability to create, use and interpret scientific tables, charts, and graphs.</li><li>Advanced Computer Skills: Ability to perform the most complex computer tasks and operate various computer programs. </li><li>Full Professional Proficiency: Ability to speak, read, and write fluently and accurately on all levels pertinent to professional needs.</li><li>Analytical ability to drive effective Root Cause Analysis (RCA) and critical thinking for complex problem solving.<br/></li></ul><strong>Preferred<br/></strong><ul><li>Possesses excellent organizational, time management and multi-tasking skills to meet commitments and deadlines.</li><li>Prior experience in technical writing and utilizing root cause analysis tools is required.</li><li>Critical thinking skills along with a strong collaborative approach is required.</li><li>Lean Six Sigma or other formal process improvement skillsets are highly desirable.</li><li>Technical knowledge and experience around Test Method validation, Medical Devices, and Sterilization processes is preferred.<br/><br/></li></ul></ul>Join us and be part of building the bridge between life changing therapies and patients. Let’s talk future<br/><br/><strong>Equal Employment Opportunity (EEO) Statement<br/><br/></strong><em>PCI Pharma Services is an Equal Opportunity/Affirmative Action Employer. We do not unlawfully discriminate on the basis of race, color, religion, age, sex, creed, national origin, ancestry, citizenship status, marital or domestic or civil union status, familial status, affectional or sexual orientation, gender identity or expression, genetics, disability, military eligibility or veteran status, or any other protected status.</em>
</div>",No Salary Info Found,Data Pipeline Engineer
PHL_Project Engineer,PCI Pharma Services,12/19/2023,https://www.linkedin.com/jobs/view/3789794434,0,https://media.licdn.com/dms/image/D4E0BAQHLec1eqsU8gA/company-logo_100_100/0/1667249491254/pciservices_logo?e=2147483647&v=beta&t=hd6xUyU_-6YeHXiRwRklJoEErN3WFJkgLpP3p0_e4Z4,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Life changing therapies. Global impact. Bridge to thousands of biopharma companies and their patients.<br/><br/><strong>We are PCI. <br/><br/></strong>Our investment is in People who make an impact, drive progress and create a better tomorrow. Our strategy includes building teams across our global network to pioneer and shape the future of PCI.<br/><br/>We are looking for a dedicated project engineer to provide technical leadership for new product launches. The Project Engineer will specify, purchase, and commission new equipment, manage capital finances, and provide technical support for new business (Sales/Business Development Support). Secondary tasks include Identifying and mitigating packaging issues for existing business through strong engineering, process improvement methods, and lead continuous improvement activities.<br/><br/>All activities are focused on technical and operational support to the production, maintenance, and support staffs in the areas of process improvement, equipment modification and optimization, safety, and quality improvement, and increasing throughput. This is achieved through individual effort and facilitation of teams, tracking, analysis metrics, strong understanding, utilization of good engineering practices, project management, and the use of Lean Six Sigma techniques. The project engineer should also have excellent organizational and leadership skills to determine staffing projections, equipment needs, equipment purchase, equipment installation, component layout, and line layout.<br/><br/><strong>Essential Duties And Responsibilities<br/><br/></strong><ul><li>Analyze sales requests to determine equipment, tooling, or delivery systems needed.</li><li>Performs engineering review of all components for new jobs to include size, the capability of equipment, and bar codes</li><li>Apply sound engineering principles to design new equipment, production lines, and component layout,, with a goal of designing a process capable of low defects (less than 1%), high uptime (greater than 95%), low waste (less than 1%), and throughput better than estimate</li><li>Conduct and/or participates in customer meetings and attend occasional off-site meetings. Interacts with Sales and customers to determine requirements for new products/orders.</li><li>Participate in internal review meetings to plan new jobs with plant Operations, Maintenance, Quality, Purchasing and Process Engineering</li><li>Prepares SOPs, line layouts, production line diagrams as needed.</li><li>Specify, order, and commission tooling as required for launch activities.</li><li>Management of the Equipment Acquisition and Installation Process Including:</li><li>Specifies equipment needed, prepares RFQs, and obtains quotes from vendors</li><li>Writes CER’s (Capital Equipment Requests) for new equipment, including researching the justification.</li><li>Manage project budget and timeline</li><li>Negotiate and order equipment when approved</li><li>Develop design criteria and equipment specifications, including safety, regulatory and necessary performance criteria</li><li>Writes protocols for URS’ (User Requirement Specifications), FAT’s (Factory Acceptance Tests), &amp; SAT’s (Site Acceptance Tests.</li><li>Oversight of determining OQ parameters to start validation</li><li>Approves validation protocols and MPI’s</li><li>Commissioning of equipment including all necessary change controls and training, including leading FAT &amp; SAT activities</li><li>Prepare equipment/engineering estimates for potential projects (to be submitted to sales)</li><li>Responsible for the administration, implementation, and project management of assigned projects, including using standardized methodology.</li><li>Research current trends and technologies in packaging; evaluates and test new equipment/processes.</li><li>Coordination of outside design, integration, and equipment manufacturing services.</li><li>Work with staff on the development of new equipment performance requirements.</li><li>Assist Validation with OQ and PQ of new packaging business.</li><li>Write and modify SOPs relating to the production area and assist in the training of affected personnel.</li><li>Lead CAPA investigations and actions. Initiate investigation activity and troubleshoot problems in packaging; discovers causes of non-conformance, i.e., slow throughput, poor quality and/or unsafe design.</li><li>Writes and executes engineering protocols as needed.</li><li>Use DOE (Design of experiments) to control variables while testing.</li><li>Apply sound engineering principles to improve existing equipment, packaging design, and processes by reducing waste, increasing throughput, reducing energy consumption, or eliminating human interaction through automation.</li><li>Facilitate cross-functional Lean Six Sigma process improvement teams using a DMAIC method.</li><li>Responsible for the administration, implementation, and project management of new business, including conformance with customer requirements and equipment/process performance criteria.</li><li>Measure and analyze performance metrics of the production area and spearhead initiatives to decrease variability and waste</li><li>This position may require overtime and/or weekend work.</li><li>Knowledge of and adherence to all PCI, cGMP, and GCP policies, procedures, and rules.</li><li>Attendance to work is an essential function of this position</li><li>Performs other duties as assigned by Manager/Supervisor.<br/><br/></li></ul><strong>Required<br/><br/></strong><strong>Qualifications: <br/><br/></strong><ul><li>Bachelor's Degree in engineering or in a related field of study.</li><li>3+ years related experience and/or training.</li><li>College Level Mathematical Skills</li><li>Intermediate Computer Skills: Ability to perform more complex computer tasks and has knowledge of various computer programs. </li><li>Full Professional Proficiency: Ability to speak, read, and write fluently and accurately on all levels pertinent to professional needs.</li><li>Very High Reasoning: Ability to define problems, collect data, establish facts, and draw valid conclusions. Be able to interpret an extensive variety of technical instructions in math or diagram form and deal with several abstract/concrete variables.</li><li>High Standard of Report Writing<br/><br/></li></ul><strong>Preferred<br/><br/></strong><li>Ability to display excellent time management skills.</li><li>Ability to effectively present information to various people as the job requires.</li><li>Ability to display original thinking and creativity.</li><li>Ability to set and achieve challenging goals.</li>Travel as required <br/><br/>Join us and be part of building the bridge between life changing therapies and patients. Let’s talk future<br/><br/><strong>Equal Employment Opportunity (EEO) Statement<br/><br/></strong><em>PCI Pharma Services is an Equal Opportunity/Affirmative Action Employer. We do not unlawfully discriminate on the basis of race, color, religion, age, sex, creed, national origin, ancestry, citizenship status, marital or domestic or civil union status, familial status, affectional or sexual orientation, gender identity or expression, genetics, disability, military eligibility or veteran status, or any other protected status.<br/><br/></em>
</div>",No Salary Info Found,Data Pipeline Engineer
Continuous Improvement Engineer,HB Consultants,12/19/2023,https://www.linkedin.com/jobs/view/3784432013,0,https://media.licdn.com/dms/image/C560BAQEmzKybLl5V5Q/company-logo_100_100/0/1631399558393?e=2147483647&v=beta&t=64DkgiPcVkVSLlm1ojkhELRDSAQvECjwmbI_HQEkh80,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Project Engineer - Continuous Improvement and Process Optimization<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Utilize a systematic approach to identify and close performance gaps through data collection and benchmarking.</li><li> Manage and prioritize continuous improvement projects to achieve Key Performance Indicator targets and Performance Improvement Action Plan initiatives.</li><li> Develop technical expertise to drive continuous improvement in safety, product quality, production, productivity, yield, and manufacturing cost.</li><li> Conduct safety and quality audits and document conditions and improvement activities.</li><li> Prepare routine reports and effectively communicate findings both verbally and in writing.</li><li> Collaborate with other departments, customers, and suppliers to drive improvement initiatives.</li><li> Supervise hourly workforce as required and provide support to other business functions when needed.<br/><br/></li></ul><strong>Minimum Requirements<br/><br/></strong><ul><li> Bachelor's degree in Electrical or Metallurgical Engineering from an accredited college/university.</li><li> Proficient in Microsoft Excel, Word, Access, and PowerPoint.</li><li> Ability to work a varied shift schedule in a multi-level facility operating 24 hours per day.</li><li> 1 year of experience in an industrial setting with some supervisory experience.</li><li> Strong problem-solving abilities and team-building skills.<br/><br/></li></ul><strong>Preferred Requirements<br/><br/></strong><ul><li> 3-5 years of experience in a steel mill.</li><li> 2 years of supervisory experience.</li><li> Advanced skills in Microsoft Excel, Word, Access, and PowerPoint.</li><li> Proficiency in drawing management.<br/><br/></li></ul>Join our team and be a part of driving continuous improvement and process optimization in our organization. If you have a passion for problem-solving, a strong technical background, and a desire to work in a dynamic and fast-paced environment, we would love to hear from you. Apply now to be considered for this exciting opportunity.<br/><br/>Employment Type: Full-Time
      </div>",No Salary Info Found,Data Pipeline Engineer
Continuous Improvement Engineer,Johnson Matthey,12/19/2023,https://www.linkedin.com/jobs/view/3784445763,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Mechanical Design Engineer (HVAC),"Liberty Personnel Services, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3774206659,0,https://media.licdn.com/dms/image/C4D0BAQHWiMsOZMSj5A/company-logo_100_100/0/1631302210691?e=2147483647&v=beta&t=p9ZoyWf9trkRrK_ERp9edKNUYDKwpQAGdhpMU19-QrI,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Job Details:<br/><br/>Ready to make an impact on your career, client projects and the community? My Client is currently seeking an <strong>Sr. Mechanical Designer/ Engineer </strong>to join our its talented staff. Qualified candidates will have:<br/><br/><ul><li>Bachelors Degree in Mechanical Engineering</li><li>PE preferred</li><li>Experience with design engineering for mechanical and HVAC systems preferably with hospital, data center, hotel, or manufacturing projects.</li><li>Proficient in Revit, Trane Trace.</li><li>LEED AP, CEM is a plus</li><li>ASHE, ASHRAE is a plus<br/><br/></li></ul><strong>Great opportunity to work on major projects!<br/><br/></strong><strong>Send a resume to Jason Tract, Liberty Personnel: jason@libertyjobs.com<br/><br/></strong><strong>https://www.linkedin.com/in/jason-tract-902110175/<br/><br/></strong>#ConsultingEngineering<br/><br/><br/><br/>#MidSenior<br/><br/>
</div>",No Salary Info Found,Data Pipeline Engineer
Quality Engineer - New Product Introduction,IntePros,12/20/2023,https://www.linkedin.com/jobs/view/3634855210,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Senior Engineering Practices & Processes Project Engineer,Boeing,12/21/2023,https://www.linkedin.com/jobs/view/3791471053,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data Pipeline Engineer
Senior Performance Engineer - Solar,Jobot,12/22/2023,https://www.linkedin.com/jobs/view/3790107526,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Leading Solar Company offering Salary + Bonus, Unlimited PTO, Company Paid Health Benefits, 401K with Company Match<br/><br/></strong>This Jobot Job is hosted by Robert Donohue<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $110,000 - $120,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>We are a leader in the Renewable Energy (Solar) industry. We are seeking a Senior Performance Engineer to join our growing team.<br/><br/>At this time we are only considering candidates with direct experience working with utility scale solar/renewable Photovoltaic (PV) systems .<br/><br/>This is a remote opportunity - (approximately 10% travel)<br/><br/><strong>Description<br/><br/></strong>The Senior Performance Engineer will serve a crucial role in helping to steer the design and planning of upcoming utility scale PV projects in the company’s pipeline. The Performance Engineer will report to the Lead Performance Engineer. They will both support the company’s pipeline of projects through EPC agreement reviews, creating energy models for internal review and also help to review energy models created by external parties (e.g. independent engineers), running comparative simulations to assist in cost-benefit analyses to ensure the optimal design decisions are being made, and capacity/performance testing support.<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong><ul><li> Salary + Bonus</li><li> Medical, dental, vision – eligible 1st of the month of after start date (BCBS- medical) standard PPO plan is free for employee</li><li> 401k with company match </li><li> Employee Equity Participation Plan</li><li> Unlimited PTO<br/><br/></li></ul><strong>Job Details<br/><br/></strong><strong>Qualifications<br/><br/></strong><ul><li> 4-5 years of engineering experience with at least 2-3 in PV performance engineering with utility scale solar/renewable Photovoltaic (PV) systems </li><li> Prior knowledge of PV devices, system design, technology, and its performance characteristics </li><li> Knowledge of the various meteo databases and be able to recommend the best match for each project site </li><li> Experience with PVSyst and other PV software/models </li><li> Skilled and competent with P50 Production &amp; Insolation analysis techniques </li><li> Ability to analyze, verify, and summarize complex data. </li><li> Proficient in reading and interpreting design documents associated with PV systems. </li><li> Skilled in the use of a personal computer and Microsoft Office Suite (Word, Excel, and Power Point) and experience with analytical computer applications (ex. Tableau, SQL, PVSyst, Excel etc.) </li><li> Experienced working with large quantities of data <br/><br/></li></ul>Nice-to-Haves<br/><br/><ul><li> Experience converting solar CAD layouts to PVCase files for importing into PVSyst</li><li> Preferred – Ability to create and edit energy modeling and PV design analytical tools in Python </li><li> Knowledge related to solar performance and capacity testing standards such as </li><li> ASTM E2848 Standard Test Method for Reporting Photovoltaic Non-Concentrator System Performance </li><li> ASTM E2939 Standard Practice for Determining Reporting Conditions and Expected Capacity for Photovoltaic Non-Concentrator Systems </li><li> IEC 61724 Photovoltaic system performance </li><li> NREL Weather-Corrected Performance Ratio (Weather-Corrected Performance Ratio (nrel.gov)) </li><li> Previous experience with basic SQL database queries and database management </li><li> Basic programing skills <br/><br/></li></ul>Education and Certifications<br/><br/><ul><li> Bachelor’s degree in mechanical or electrical engineering or related field<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$110000- $120000,Data Pipeline Engineer
Junior Data Engineer (US),Fitness Matrix Inc,12/25/2023,https://www.linkedin.com/jobs/view/3793120666,0,https://media.licdn.com/dms/image/D4E0BAQGmk8ZefBUxLg/company-logo_100_100/0/1698352894604/fitness_matrix_inc_logo?e=2147483647&v=beta&t=72cgj7Ot5k670-7oCMGX7QoHQoicVzzbGuWzPstPuXw,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Junior Data Engineer (US) - Onsite<br/><br/></strong><strong>Full-time<br/><br/></strong><strong>$66K - $77K per annum<br/><br/></strong><strong>1+ Year Experience Required<br/><br/></strong><strong>Introduction:<br/><br/></strong>FitnessMatrixInc is a unique approach to health and wellness that is based on the principle of bio-individuality. This means that we believe that everyone is different and has their own unique needs and challenges. We will work with you to understand your biochemistry and develop a personalized plan that is right for you.<br/><br/><strong>Position Summary<br/><br/></strong>Join the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.<br/><br/><strong>Key Responsibilities include:<br/><br/></strong><ul><li>Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. </li><li>Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency </li><li>Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency </li><li>Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data </li><li>Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently </li><li>Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation </li><li>Create/maintain documentation for data processes, data flows, and system configurations </li><li>Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness <br/><br/></li></ul><strong>Characteristics of this role:<br/><br/></strong><ul><li>Team Player: Willing to teach, share knowledge, and work with others to make the team successful. </li><li>Communication: Exceptional verbal, written, organizational, presentation, and communication skills. </li><li>Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. </li><li>Attention to detail: Systematically and accurately research future solutions and current problems. </li><li>Strong work ethic: The innate drive to do work extremely well. </li><li>Passion: A drive to deliver better products and services than expected to customers. <br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><ul><li>2+ years of programming experience in languages such as Python, Java, SQL </li><li>2+ years of experience with ETL tools and database management (relational, non-relational) </li><li>2+ years of experience in data modeling techniques and tools to design efficient scalable data structures </li><li>Skills in data quality assessment, data cleansing, and data validation <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Knowledge of big data technologies and cloud platforms </li><li>Experience with technologies like PySpark, Databricks, and Azure Synapse. <br/><br/></li></ul><strong>Education<br/><br/></strong>Bachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience<br/><br/><strong>Why should we work with Fitness Matrix?<br/><br/></strong>Fitness Matrix Inc is the leading provider of holistic and multidimensional health and wellness services. We offer a comprehensive approach to health and wellness. We take into account all aspects of your life, from your physical fitness and nutrition to your mental, emotional, and spiritual well-being. We use the latest science and technology to develop our programs and services. We are constantly innovating and finding new ways to help our clients achieve their goals. We offer a variety of programs and services to meet your needs and budget.<br/><br/>
</div>",$66- $77,"Software Engineer, Data"
Junior SQL Developer ( US Only),VPNforAndroid,12/25/2023,https://www.linkedin.com/jobs/view/3793150434,0,https://media.licdn.com/dms/image/D4D0BAQGxr6JHWQfm7Q/company-logo_100_100/0/1703085942357/vpnforandroid_logo?e=2147483647&v=beta&t=FLkefdBzaEfaC6oa-y9v-dapg0lzP3ry6mLYT0ugty4,"Denver, CO","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong>Junior SQL Developer (US Only) - Full-time remote work <br/><br/></strong><strong>Years of experience: </strong>1+<br/><br/><strong>Salary:</strong> $55K to $65K<br/><br/>VPNforAndroid is a leading provider of virtual private network (VPN) services. We help people stay safe online by encrypting their internet traffic and routing it through our secure servers. This lets you browse the web privately and securely, even on public Wi-Fi networks.<br/><br/>Description:<br/><br/>As an SQL Developer, you will play a crucial role in designing, implementing, and optimizing database solutions, enabling efficient data storage, retrieval, and manipulation. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet our clients' needs. This is a unique opportunity to work on diverse projects, tackle complex data challenges, and make a significant impact in the world of data.<br/><br/>Responsibilities:<br/><br/>Collaborate with stakeholders to gather data requirements and translate them into efficient SQL queries, stored procedures, and functions.<br/><br/>Design, develop, and maintain database schemas, ensuring data integrity, security, and performance.<br/><br/>Write complex SQL queries for data extraction, transformation, and loading (ETL) processes.<br/><br/>Optimize SQL queries and database performance, identifying and resolving bottlenecks and inefficiencies.<br/><br/>Develop data validation and quality assurance processes to ensure accuracy and reliability.<br/><br/>Collaborate with cross-functional teams to integrate SQL code into applications and reporting systems.<br/><br/>Conduct data analysis to identify trends, patterns, and insights that drive business decisions.<br/><br/>Stay up-to-date with the latest trends and advancements in SQL and database technologies.<br/><br/>Requirements:<br/><br/>Bachelor's degree in Computer Science, Information Technology, or a related field.<br/><br/>Proven experience as an SQL Developer or Database Developer, working with complex databases.<br/><br/>Strong proficiency in SQL and experience with relational databases (e.g., MySQL, Oracle, SQL Server).<br/><br/>Solid understanding of database design principles, data modeling, and normalization.<br/><br/>Proficiency in writing complex SQL queries, stored procedures, and functions.<br/><br/>Experience with performance optimization and tuning of SQL queries and database indexing.<br/><br/>Familiarity with ETL processes and tools (e.g., SSIS, Informatics) is a plus.<br/><br/>Knowledge of data warehousing concepts and dimensional modeling is desirable.<br/><br/>Strong problem-solving skills and the ability to analyze complex data requirements.<br/><br/>Excellent attention to detail and a commitment to delivering high-quality solutions.<br/><br/>Effective communication and collaboration skills to work with cross-functional teams.<br/><br/><strong>Why join VPNforAndroid?<br/><br/></strong>VPNforAndroid isn't just a company; it's a mission to democratize online privacy and security. Join our passionate team and make a real impact on millions of users worldwide. We offer a thrilling blend of cutting-edge VPN technology, a collaborative environment, and the chance to shape the future of online freedom.<br/><br/>Become part of a dynamic team driven by innovation and a shared passion. We push boundaries with the latest tools and techniques, constantly evolving to stay ahead of the curve. And while we're serious about our mission, we don't take ourselves too seriously. We believe in a fun and supportive culture where collaboration thrives and laughter rings out (even virtually!).<br/><br/>Beyond the perks like competitive compensation, comprehensive benefits, and flexible work arrangements, what truly sets us apart is the opportunity to grow alongside a company on the rise. We invest in our people, providing ample chances to learn, hone your skills, and advance your career.<br/><br/>Ready to make a difference in a fun, fast-paced environment? Dive into the world of VPNforAndroid and let's redefine online security together. We can't wait to hear from you!<br/><br/>
</div>",$55- $65,"Software Engineer, Data"
Backend Software Engineer,Mixlab,12/19/2023,https://www.linkedin.com/jobs/view/3784457818,0,https://media.licdn.com/dms/image/C4E0BAQHHkVs6BNmNSA/company-logo_100_100/0/1631344374013?e=2147483647&v=beta&t=EllhlLGqMyoHh-2sV7AnRsxPibfh3ZF9ECMwRrdtJL8,United States,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Mixlab, the fast-growing veterinary compounding pharmacy, is hiring a remote Backend Software Engineer. We’re looking for thoughtful and collaborative engineers who have expertise in building high-quality Rails applications. You’ll work across multiple applications that serve vets, our internal pharmacies, as well as pets and their human companions. We’re excited to see how your unique expertise and talents can help us further optimize our process and tools. We’re looking for candidates who want to grow their engineering skills and help contribute to a culture of collective learning as a team.<br/><br/>Although this is a remote role, candidates must be located in the United States within Eastern-Central Time Zones and be able to travel to our NY/LA pharmacies to meet with our team members on a quarterly basis.<br/><br/>Responsibilities:<br/><br/><ul><li>Lead and define new backend features with a focus on improving efficiencies in both our software and in the business operations we support</li><li>Work with QA and product to test and release new features</li><li>Build features that can be reviewed, tested, released and monitored iteratively in small changesets </li><li>Work with product and design to create engineering implementation plans</li><li>Communicate cross-functionally to help find simple solutions to business problems</li><li>Help determine ways to improve the quality of our applications and tackle tech debt</li><li>Work to automate and improve our development process</li><li>Work to improve the testability and monitoring of our backend applications</li><li>Provide thoughtful code reviews<br/><br/><br/></li></ul>About You:<br/><br/><ul><li>3-6 years working with Ruby on Rails or a similar backend framework</li><li>3-6 years of experience with Postgres or other relational databases</li><li>1-2 years building CI/CD pipelines</li><li>Experience deploying applications</li><li>Experience logging and monitoring backend applications </li><li>Experience with backend unit tests, integration tests, and end-to-end tests</li><li>Ability to work autonomously and set priorities</li><li>Experience building technical consensus on design decisions</li><li>Ability to create and communicate technical project plans</li><li>Ability to take ownership of technical improvements and tech debt improvements </li><li>Willingness to work full stack when needed</li><li>Collaborative, team player with a willingness to receive feedback and learn from others<br/><br/><br/></li></ul>Nice to Have:<br/><br/><ul><li>Experience working full stack </li><li>Familiarity with Javascript and React</li><li>Experience with Netlify, Heroku, and Datadog</li><li>Experience building the early growth of a code base</li><li>Experience launching projects for 100K+ users<br/><br/><br/></li></ul>What We Offer:<br/><br/><ul><li>100% employer-paid health, dental and vision insurance for our employees, effective on the first of the month following your start date</li><li>Flexible paid time off for vacation, holidays and sick time</li><li>Competitive starting wages with the opportunity for rapid career growth, promotion, and wage increases</li><li>Company Stock Options</li><li>Pre-tax commuter benefits, dependent care, HSA and FSA</li><li>Employer-paid short and long-term disability leave, parental leave, and life insurance</li><li>401k with $300/year match</li><li>Referral bonus payouts of up to $1,000 for a successful referral</li><li>Human and pet wellness benefits, including $650/year allowance for routine pet care through Wagmo</li><li>Discounts on many items through Perkspot</li><li>And more!<br/><br/><br/></li></ul>Mixlab is the first modern pet pharmacy that focuses on creating high-quality, custom medications and delightful experiences for pets, their parents and veterinarians. By putting service at the heart of everything we do, we're able to provide the best personalized care for our furry friends, as well as those who care for them. Mixlab is proud to be a PCAB-accredited compounding pet pharmacy. Check us out on Instagram or see our 5 star reviews on Google, Yelp and Facebook!<br/><br/>We are committed to a workplace that thrives on inclusion, diversity, equity, and access (IDEA). As such, all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, or veteran status. Mixlab is also committed to hiring practices that support access, equal opportunity and reasonable accommodation for individuals with disabilities. To request reasonable accommodation for your application or interview, please contact the Mixlab Talent Acquisition team at talent@mixlabrx.com or call 929-207-2659.<br/><br/>Pay ranges at Mixlab are based on competitive market data for our industry and company size. In addition to base pay, our total compensation package for full-time employees includes benefits and equity. We determine individual pay based on qualifications for the role, experience level, and skillset, and we expect offers made to candidates to fall throughout the range advertised.<br/><br/>Compensation at Mixlab is dependent on multiple factors including but not limited to individual qualifications, license, experience, and skillset.
      </div>",$300- $1000,"Software Engineer, Data"
Software Engineer — Frontend,Snorkel AI,12/19/2023,https://www.linkedin.com/jobs/view/3790347582,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Python Developer,Prime Vector Consulting Services LLC,12/19/2023,https://www.linkedin.com/jobs/view/3788428669,0,https://media.licdn.com/dms/image/D4E0BAQEXRr7mmJ9ZHQ/company-logo_100_100/0/1696964890709?e=2147483647&v=beta&t=mSKMlrIsG0XwLRv8krJwt26tXuohlgNWQQe1YBrdT8E,"Hartford, CT","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Title: Python Developer<br/><br/></strong><strong>Location: </strong><strong> Hartford CT/Dallas TX <br/><br/></strong><strong>Duration: Long Term<br/><br/></strong><strong>Job Description<br/><br/></strong><strong><em>Required Qualifications:<br/><br/></em></strong><ul><li>Strong Python experience is a must</li><li>5+ years of hands-on experience in building Data pipe line(ETL/ELT) in a cloud platform</li><li>Working knowledge of Distributed Data Processing.(Beam, Spark, MapReduce)</li><li>GCP knowledge strongly preferred (Cloud experience required, not necessarily GCP)</li><li>5+ years’ of hands on experience of building and operationalizing data processing systems<br/><br/></li></ul><strong>Nice To Have<br/><br/></strong><ul><li>2+ years’ experience working with data platforms (Data warehouse, Data Lake, ODS)</li><li>2+ years’ experience working with tools to automate CI/CD pipelines (e.g., Jenkins, GIT, Control-M)<br/><br/></li></ul><strong>Our product engineering team uses following technology stack <br/><br/></strong><ul><li>Python</li><li>Cloud Data flow/Data proc (Apache Beam)</li><li>Cloud pub sub</li><li>Cloud function</li><li>Whistle map SDK</li><li>Google Health care API/ FHIR store</li><li>Cloud composer<br/><br/></li></ul>**We are an Equal Opportunity Employer**<br/><br/>https://primevcs.com/jobs
      </div>",No Salary Info Found,"Software Engineer, Data"
Python Developer,"TekVivid, Inc",12/19/2023,https://www.linkedin.com/jobs/view/3790025504,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Software Developer(Junior Level),SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784098158,0,https://media.licdn.com/dms/image/C560BAQHPrA2XO9lh7g/company-logo_100_100/0/1663564885547/synergisticit_logo?e=2147483647&v=beta&t=biDnkXeeFcJXgnh87P53V9KGn6j1mqUOEQpisfcfR74,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At SynergisticIT, we're all about making connections. Whatever IT goals you have, our software programmers can help achieve those. Our Software development teams can take up turnkey projects and execute them in an effective and efficient manner. If you are looking to source talent our recruiters will find the ideal IT talent for your company. What's the secret to our success? Well, it all starts with taking quality time to listen to each client's specific needs. After we have a thorough grasp of your IT goals, we can better customize our Developments as per your specific needs. We can also tailor make recruiting programs to exceed your expectations. Since our founding in 2010, SynergisticIT's strategies have earned the company an enviable position in the software development, IT staffing and IT skill enhancement fields. SynergisticIT continues to work with hundreds of satisfied American clients with our software programmers working on our projects and after gaining hands on experience on cutting edge technologies moving to contribute their skills to great clients like Apple, Google, Client, Ebay, Paypal, Kroger, the Walt Disney Company and hundreds more. If you are tired of working with inefficient programmers who take a lot of time to ramp up we want you to try us. Our software programmers can hit the ground running and get you the maximum return on your investment. You have already tried the rest its time you tried the best. SynergisticIT - Home of the Best Data Scientists and Software Programmers in the Bay Area.<br/><br/><strong> Why Us ? <br/><br/></strong>SynergisticIT has a proven track record of successfully skill enhancement and staffing IT employees for some of the world's most iconic brands. Our team takes the time to fully understand every client's needs so we could best meet your IT staffing requirements. The knowledgeable staff at SynergisticIT is always more than happy to work with clients to ensure they reach their software development goals. Besides staffing, SynergisticIT is also committed to helping young IT professionals advance their career with a robust upskill program . Everyone who goes through SynergisticIT's program learns all the skills necessary to succeed in many IT fields ranging from Java to Machine Learning. Additionally, everyone trained at SynergisticIT has been through extensive mock and technical interview screenings to bolster their career prospects. Last, but certainly not least, SynergisticIT takes great care to respect the privacy considerations for every client. All companies who work with SynergisticIT can rest assured their confidential data is protected using the most up-to-date encryption technologies. SynergisticIT also complies with all the latest NDA agreements.<br/><br/><strong> REQUIRED SKILLS For Java /Software Programmers <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis <br/><br/></strong><strong> We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2022 and at Gartner Data Analytics Summit (Florida)-2023 <br/><br/></strong>Oracle CloudWorld Event (OCW) Las Vegas 2022 | SynergisticIT - YouTube<br/><br/><strong> https://www.youtube.com/watch?v=OAFOhcGy9Z8 <br/><br/></strong><strong> https://www.youtube.com/watch?v=EmO7NrWHkLM <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=Yy74yvjatVg <br/><br/></strong>SynergisticIT at Gartner Data and Analytics Summit 2023 - YouTube<br/><br/>For preparing for interviews please visit <strong> https://www.synergisticit.com/interview-questions/ <br/><br/></strong><strong> We are looking for the right matching candidates for our clients <br/><br/></strong><strong> Please apply via the job posting <br/><br/></strong><strong> REQUIRED SKILLS For Java /Full Stack/Software Programmer <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning Positions <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow <br/><br/></strong><strong> If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team. <br/><br/></strong><strong> No phone calls please. </strong> Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates
      </div>",No Salary Info Found,"Software Engineer, Data"
Data Engineer,Accroid Inc,12/19/2023,https://www.linkedin.com/jobs/view/3788129009,0,https://media.licdn.com/dms/image/D4D0BAQGz_di1atu9CQ/company-logo_100_100/0/1683292700129/accroid_inc_logo?e=2147483647&v=beta&t=OvupgW0oZWw8oodQiV4pXMO4DTI0u9OdLiuevK1eX9s,"Ankeny, IA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Onsite<br/><br/></strong><strong>Data Engineer <br/><br/></strong><ul><li>Build and maintain data pipelines utilizing Databricks and ADLS.</li><li>Collaborate with cross-functional teams to understand and fulfill data requirements.</li><li>Deliver outputs that align with defined specifications and meet business objectives.</li><li>Provide expertise in data engineering and contribute to the overall success of data-related projects.</li></ul>
</div>",No Salary Info Found,"Software Engineer, Data"
Data Engineer,Sophinea Corporation,12/19/2023,https://www.linkedin.com/jobs/view/3790308997,0,https://media.licdn.com/dms/image/C4E0BAQHKGcS2SVjMMw/company-logo_100_100/0/1630602935929?e=2147483647&v=beta&t=n6S3niAlq2wKPznT1N5AljnE-ih5chfyLz6xcSmYBBk,United States,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Sophinea, a leading computer software company, is seeking a highly skilled and motivated Data Engineer to join our dynamic team. As a Data Engineer, you will play a crucial role in designing, developing, and maintaining our data infrastructure. You will ensure the accuracy, availability, and security of our data, providing critical insights to drive the company's success.<br/><br/>In this role, you will collaborate with cross-functional teams to identify and implement data solutions that align with our business objectives. You will be responsible for optimizing data pipelines, ensuring efficient data extraction, transformation, and loading processes. Additionally, you will contribute to the development and implementation of data governance policies, ensuring compliance and data integrity.<br/><br/>If you have a passion for data engineering, possess strong analytical and problem-solving skills, and excel in a collaborative environment, we would love to hear from you. Join our innovative team and be part of shaping the future of our data-driven company.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Design, develop, and maintain data pipelines for ETL (Extract, Transform, Load) processes</li><li>Collaborate with cross-functional teams to identify data requirements and implement effective data solutions</li><li>Optimize data models and improve the performance of data stores</li><li>Monitor data quality and implement data validation techniques to ensure accuracy and consistency</li><li>Implement effective data security measures and maintain data privacy standards</li><li>Develop and maintain data governance policies and procedures</li><li>Troubleshoot and resolve data-related issues in a timely manner<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li>Bachelor's degree in Computer Science, Information Systems, or a related field</li><li>Proven experience as a Data Engineer or in a similar role</li><li>Strong knowledge of SQL and data modeling techniques</li><li>Proficiency in at least one programming language, such as Python or Java</li><li>Experience with ETL and data integration tools, such as Apache Kafka or Informatica</li><li>Familiarity with cloud-based data platforms, such as AWS or GCP</li><li>Excellent problem-solving and analytical skills</li><li>Strong communication and collaboration abilities</li><li>Ability to work in a fast-paced and dynamic environment</li><li>Attention to detail and commitment to data accuracy and integrity<br/><br/></li></ul><strong>Benefits<br/><br/></strong><ul><li>Health Care Plan (Medical, Dental &amp; Vision)</li><li>Retirement Plan (401k, IRA)</li><li>Life Insurance (Basic, Voluntary &amp; AD&amp;D)</li><li>Paid Time Off (Vacation, Sick &amp; Public Holidays)</li><li>Short Term &amp; Long Term Disability</li><li>Training &amp; Development</li><li>Work From Home</li></ul>
</div>",No Salary Info Found,"Software Engineer, Data"
"Software Engineer- Littleton, CO",Lockheed Martin,12/20/2023,https://www.linkedin.com/jobs/view/3790900765,0,https://media.licdn.com/dms/image/C4E0BAQHF1YKEZdN4LA/company-logo_100_100/0/1668532986109/lockheed_martin_logo?e=2147483647&v=beta&t=MAt3FDVkp1mxAnqi-7a-mmVAi8Lcd_S1_XvT0Y_Z40s,"Littleton, CO","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The coolest jobs on this planet… or any other… are with Lockheed Martin Space.<br/><br/>At the dawn of a new space age, Lockheed Martin is a pioneer, partner, innovator and builder. Our amazing men and women are on a mission to make a difference in the world and every day we use our unique skills and experiences to create, design and build solutions to some of the worlds’ hardest engineering problems. Our culture encourages employees to dream big, perform with excellence and create incredible products. We provide the resources, inspiration and focus and if you have the passion and courage to dream big, we want to build a better tomorrow with you.<br/><br/>Are you looking to expand your career? Are you looking for an exciting career as a Software Engineer at one of the top Aerospace and Defense Companies? A fulfilling position that challenges your mind grows your skills, and contributes to our Nation’s most critical missions is right in front of you.<br/><br/>Consolidated Analysis Orchestration Services (CAOS) is the preeminent Geospatial-Intelligence program in the world – over 10,000 intelligence analysts and decision-makers worldwide daily rely on CAOS for critical intelligence and geospatial data management. In addition to meeting today’s critical intelligence mission needs, we are working on evolving exciting future automation and artificial intelligence solutions for the National Geospatial-Intelligence Agency (NGA). We need the best engineers on our team to ensure mission success! Think you have the skills, come join the CAOS Team that builds software for the next generation of geospatial intelligence.
      </div>",No Salary Info Found,"Software Engineer, Data"
Jr. Machine Learning Engineer (Remote),SynergisticIT,12/23/2023,https://www.linkedin.com/jobs/view/3786795694,0,https://media.licdn.com/dms/image/C560BAQHPrA2XO9lh7g/company-logo_100_100/0/1663564885547/synergisticit_logo?e=2147483647&v=beta&t=biDnkXeeFcJXgnh87P53V9KGn6j1mqUOEQpisfcfR74,"Round Rock, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Job Market is Challenging due to more than 150,000 Tech Layoffs in 2022 and in 2023 more than 240,000 layoffs so almost 3,90,00 tech employees have been laid off since 2022 and its still going on . The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers. Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. In such a scenario the Job seekers need to differentiate themselves by ensuring to obtain exceptional skills and technologies to be hired by clients as its an employer's market presently and they have a lot of hiring choices.<br/><br/>For more than 12+ years Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers. All Positions are open for all visas and US citizens<br/><br/>We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers. We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few. We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients. Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry We assist in filing for STEM extension and also for H1b and Green card filing to Candidates<br/><br/>We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.<br/><br/>please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers https://www.synergisticit.com/candidate-outcomes/<br/><br/>We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023<br/><br/>Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTube<br/><br/>https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q https://www.youtube.com/watch?v=NVBU9RYZ6UI<br/><br/>https://www.youtube.com/watch?v=EmO7NrWHkLM https://www.youtube.com/watch?v=NVBU9RYZ6UI<br/><br/>https://www.youtube.com/watch?v=OAFOhcGy9Z8<br/><br/>https://www.youtube.com/watch?v=Yy74yvjatVg<br/><br/>For preparing for interviews please visit https://www.synergisticit.com/interview-questions/<br/><br/>We are looking for the right matching candidates for our clients<br/><br/>Please apply via the job posting<br/><br/><strong>REQUIRED SKILLS For Java /Full Stack/Software Programmer<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT</li><li> Highly motivated, self-learner, and technically inquisitive</li><li> Experience in programming language Java and understanding of the software development life cycle</li><li> Project work on the skills</li><li> Knowledge of Core Java , javascript , C++ or software programming</li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience</li><li> Excellent written and verbal communication skills<br/><br/></li></ul>For data Science/Machine learning Positions<br/><br/><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT</li><li> Project work on the technologies needed</li><li> Highly motivated, self-learner, and technically inquisitive</li><li> Experience in programming language Java and understanding of the software development life cycle</li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools</li><li> Excellent written and verbal communication skills<br/><br/></li></ul>Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow<br/><br/>If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.<br/><br/>No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates<br/><br/>At SynergisticIT, we're all about making connections. Whatever IT goals you have, our software programmers can help achieve those. Our Software development teams can take up turnkey projects and execute them in an effective and efficient manner. If you are looking to source talent our recruiters will find the ideal IT talent for your company. What's the secret to our success? Well, it all starts with taking quality time to listen to each client's specific needs. After we have a thorough grasp of your IT goals, we can better customize our Developments as per your specific needs. We can also tailor make recruiting programs to exceed your expectations. Since our founding in 2010, SynergisticIT's strategies have earned the company an enviable position in the software development, IT staffing and IT skill enhancement fields. SynergisticIT continues to work with hundreds of satisfied American clients with our software programmers working on our projects and after gaining hands on experience on cutting edge technologies moving to contribute their skills to great clients like Apple, Google, Client, Ebay, Paypal, Kroger, the Walt Disney Company and hundreds more. If you are tired of working with inefficient programmers who take a lot of time to ramp up we want you to try us. Our software programmers can hit the ground running and get you the maximum return on your investment. You have already tried the rest its time you tried the best. SynergisticIT - Home of the Best Data Scientists and Software Programmers in the Bay Area.<br/><br/>Why Us ?<br/><br/>SynergisticIT has a proven track record of successfully skill enhancement and staffing IT employees for some of the world's most iconic brands. Our team takes the time to fully understand every client's needs so we could best meet your IT staffing requirements. The knowledgeable staff at SynergisticIT is always more than happy to work with clients to ensure they reach their software development goals. Besides staffing, SynergisticIT is also committed to helping young IT professionals advance their career with a robust upskill program. Everyone who goes through SynergisticIT's program learns all the skills necessary to succeed in many IT fields ranging from Java to Machine Learning. Additionally, everyone trained at SynergisticIT has been through extensive mock and technical interview screenings to bolster their career prospects. Last, but certainly not least, SynergisticIT takes great care to respect the privacy considerations for every client. All companies who work with SynergisticIT can rest assured their confidential data is protected using the most up-to-date encryption technologies. SynergisticIT also complies with all the latest NDA agreements.<br/><br/><strong>REQUIRED SKILLS For Java /Software Programmers<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT</li><li> Highly motivated, self-learner, and technically inquisitive</li><li> Experience in programming language Java and understanding of the software development life cycle</li><li> Project work on the skills</li><li> Knowledge of Core Java , javascript , C++ or software programming</li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience</li><li> Excellent written and verbal communication skills<br/><br/></li></ul>For data Science/Machine learning<br/><br/><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT</li><li> Project work on the technologies needed</li><li> Highly motivated, self-learner, and technically inquisitive</li><li> Experience in programming language Java and understanding of the software development life cycle</li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools</li><li> Excellent written and verbal communication skills<br/><br/></li></ul>Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis<br/><br/>We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2022 and at Gartner Data Analytics Summit (Florida)-2023<br/><br/>Oracle CloudWorld Event (OCW) Las Vegas 2022 | SynergisticIT - YouTube https://www.youtube.com/watch?v=OAFOhcGy9Z8<br/><br/>https://www.youtube.com/watch?v=EmO7NrWHkLM https://www.youtube.com/watch?v=NVBU9RYZ6UI<br/><br/>https://www.youtube.com/watch?v=Yy74yvjatVg SynergisticIT at Gartner Data and Analytics Summit 2023 - YouTube<br/><br/>For preparing for interviews please visit https://www.synergisticit.com/interview-questions/<br/><br/>We are looking for the right matching candidates for our clients<br/><br/>Please apply via the job posting<br/><br/><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT</li><li> Project work on the technologies needed</li><li> Highly motivated, self-learner, and technically inquisitive</li><li> Experience in programming language Java and understanding of the software development life cycle</li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools</li><li> Excellent written and verbal communication skills<br/><br/></li></ul>Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow<br/><br/>If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team.<br/><br/>No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates<br/><br/>##################################################
      </div>",No Salary Info Found,"Software Engineer, Data"
Software Engineer (AI/ML),KLA,12/20/2023,https://www.linkedin.com/jobs/view/3757568800,0,https://media.licdn.com/dms/image/C560BAQF6F4zFyo4WzQ/company-logo_100_100/0/1656661447198/klacorp_logo?e=2147483647&v=beta&t=hbo7C2xOJw4BLaUQ3W96GtuJzo-2_4LRmRVxJQ10M5c,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Base Pay Range: $98,500.00 - $167,500.00 Annually<br/><br/>Primary Location: USA-TX-Austin-KLA<br/><br/>KLA’s total rewards package for employees may also include participation in performance incentive programs and eligibility for additional benefits identified below. Interns are eligible for some of the benefits identified below. Our pay ranges are determined by role, level, and location. The range displayed above reflects the minimum and maximum pay for this position in the primary location identified in this posting. Actual pay depends on several factors, including location, job-related skills, experience, and relevant education level or training. If applicable, your recruiter can share more about the specific pay range for your preferred location during the hiring process.<br/><br/><strong>Company Overview<br/><br/></strong>KLA is a global leader in diversified electronics for the semiconductor manufacturing ecosystem. Virtually every electronic device in the world is produced using our technologies. No laptop, smartphone, wearable device, voice-controlled gadget, flexible screen, VR device or smart car would have made it into your hands without us. KLA invents systems and solutions for the manufacturing of wafers and reticles, integrated circuits, packaging, printed circuit boards and flat panel displays. The innovative ideas and devices that are advancing humanity all begin with inspiration, research and development. KLA focuses more than average on innovation and we invest 15% of sales back into R&amp;D. Our expert teams of physicists, engineers, data scientists and problem-solvers work together with the world’s leading technology providers to accelerate the delivery of tomorrow’s electronic devices. Life here is exciting and our teams thrive on tackling really hard problems. There is never a dull moment with us.<br/><br/><strong>Group/Division<br/><br/></strong>Enabling the movement toward advanced chip design, KLA's Measurement, Analytics and Control group (MACH) is looking for the best and brightest research scientists, software engineers, application development engineers and senior product technology process engineers to join our team. The MACH team's mission is to collaborate with our customers to innovate technologies and solutions that detect and control highly complex process variations—at their source—rather than compensate for them at later stages of the manufacturing process. With over 40 years of semiconductor process control experience, chipmakers around the globe rely on KLA to ensure that their fabs ramp next-generation devices to volume production quickly and cost-effectively. Our MACH team develops leading-edge solutions for patterning process analytics and control technologies, thereby providing customers with critical insight at the feature level, field level and cross-wafer analysis. Our teams also develop advanced modeling simulation, data analytics and process control modeling technologies. As a member of the MACH team, you’ll be joining the most sophisticated and successful process-control company in the semiconductor industry--working across functions to solve the most complex technical problems in the digital age.<br/><br/><strong>Job Description/Preferred Qualifications<br/><br/></strong>Software Engineer (AI/ML) may work on a variety of tasks including platform for large scale software system, data management, machine learning model training and inference solutions for KLA products.<br/><br/>Strong analytical capabilities and problems solving skills are crucial. Familiarity with Machine Learning and Deep Learning solutions would be a big plus.<br/><br/>Successful candidates are passionate about software and will have exceptional skills and hands on experience with development in Python, C++, C# or Java. Deep conceptual understanding of multi-threaded and multi process software systems is also necessary.<br/><br/>In addition to the above fundamental software skills, any of the following technical hands-on skills are highly desirable.<br/><br/><ul><li> Data Structures and algorithms</li><li> Traditional machine learning using Random Forest, XG Boost, Logistic Regression.</li><li> Deep Learning for regression, classification and Generative models.</li><li> TensorFlow or Pytorch, NumPy, scikit-learn, and other ML and DL frameworks.</li><li> Distributed systems for data management.</li><li> Distributed computing infrastructure.</li><li> Cloud technologies for storage, containerization and compute clusters.</li><li> GPU architectures and data management.<br/><br/><br/></li></ul>Successful candidates for this position will also demonstrate the following non-technical skills.<br/><br/><ul><li> Capability to formulate creative solutions through analyzing complex data</li><li> Good communication skills</li><li> Strong team player and motivated by team success</li><li> Strong problem-solving skills<br/><br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong>Masters level degree or a PhD degree<br/><br/>The company offers a total rewards package that is competitive and comprehensive including but not limited to the following: medical, dental, vision, life, and other voluntary benefits, 401(K) including company matching, employee stock purchase program (ESPP), student debt assistance, tuition reimbursement program, development and career growth opportunities and programs, financial planning benefits, wellness benefits including an employee assistance program (EAP), paid time off and paid company holidays, and family care and bonding leave.<br/><br/>KLA is proud to be an Equal Opportunity Employer. We do not discriminate on the basis of race, religion, color, national origin, sex, gender identity, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other status protected by applicable law. We will ensure that qualified individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us at talent.acquisition@kla.com to request accommodation.
      </div>",$98500.00- $167500.00,"Software Engineer, Data"
Data Engineer,Visa,12/19/2023,https://www.linkedin.com/jobs/view/3790090038,0,https://media.licdn.com/dms/image/C560BAQEP8_eM4zW8bw/company-logo_100_100/0/1630663392691/visa_logo?e=2147483647&v=beta&t=TzxC8Eby4Etg1Y4aK9Ul8pUVAccJ4Do5GJP4uVtlOBY,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Visa is a world leader in digital payments, facilitating more than 215 billion payments transactions between consumers, merchants, financial institutions and government entities across more than 200 countries and territories each year. Our mission is to connect the world through the most innovative, convenient, reliable and secure payments network, enabling individuals, businesses and economies to thrive.<br/><br/>When you join Visa, you join a culture of purpose and belonging – where your growth is priority, your identity is embraced, and the work you do matters. We believe that economies that include everyone everywhere, uplift everyone everywhere. Your work will have a direct impact on billions of people around the world – helping unlock financial access to enable the future of money movement.<br/><br/><strong>Join Visa: A Network Working for Everyone.<br/><br/></strong><strong>Job Description<br/><br/></strong>Payments has become a very active/hot area in the last couple of years, creating a strong demand for innovation. This will be a very exciting area in the next 5 to 10 years. Not only is VISA a leader in the payment industry and has been for a long time, but it is also quickly transitioning into a technology company that is fostering an environment for applying the latest technology to solve exciting problems in this area.<br/><br/>Visa AI as a Service (VAIaS) operationalizes the delivery of AI and decision intelligence to ensure their ongoing business values. Built with composable AI capabilities, privacy-enhancing computation, and cloud native platforms, VAIaS automates the updates to data, models, and applications. Combined with strong AI governance, VAIaS optimizes the performance, scalability, interpretability and reliability of AI models and services. If you want to be in the exciting payment and AI space, learn fast, and make big impacts, Visa AI as a Service is an ideal place for you!<br/><br/>This position is for a Data Engineer with solid development experience who will focus on creating new capabilities for Visa AI as a Service while maturing our code base and development processes. In this position, you are first a passionate and talented developer that can work in a dynamic environment as a member of Agile Scrum teams. Your strong technical leadership, problem-solving abilities, coding, testing and debugging skills is just a start. You must be dedicated to filling product backlog and delivering production-ready code. You must be willing to go beyond the routine and prepared to do a little bit of everything.<br/><br/>You will be an integral part of the development team, sometimes investigating new requirements and design and at times refactoring existing functionality for performance and maintainability, but always working on ways to make us more efficient and provide better solutions to our end customers. The role is for a self-organized individual with knowledge of web application and web service development. The candidate will perform hands-on activities including design, documentation, development and test of new functionality. Candidate must be flexible and willing to switch tasks based on team’s needs.<br/><br/>This position will be based in Austin, TX. If this sounds exciting, we want to chat and tell you more about our work culture and environment and see if this will be a good fit for both of us.<br/><br/><strong>Essential Functions<br/><br/></strong><ul><li> Collaborate with project team members (Product Managers, Architects, Analysts, Software Engineers, Project Managers, etc.) to ensure development and implementation of new data driven business solutions</li><li> Drive development effort End-to-End for on-time delivery of high quality solutions that conform to requirements, conform to the architectural vision, and comply with all applicable standards</li><li> Responsibilities span all phases of solution development including:</li><li> Collaborate with senior technical staff and PM to identify, document, plan contingency, track and manage risks and issues until all are resolved</li><li> Present technical solutions, capabilities, considerations, and features in business terms. Effectively communicate status, issues, and risks in a precise and timely manner<br/><br/></li></ul>This is a hybrid position. Hybrid employees can alternate time between both remote and office. Employees in hybrid roles are expected to work from the office 2-3 set days a week (determined by leadership/site), with a general guidepost of being in the office 50% or more of the time based on business needs.<br/><br/><strong>Qualifications<br/><br/></strong>Basic Qualifications:<br/><br/><ul><li> Bachelors degree, OR 3+ years of relevant work experience<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li> 2 or more years of work experience</li><li> Exposure to leading-edge areas such as Machine Learning, Big Data, Distributed Systems or SRE. </li><li> Experience in at least one of the following: Golang, Java, or C/C++, Spark</li><li> Familiarity with web service standards and related patterns (REST, gRPC)</li><li> Experience implementing solutions for low-latency, distributed services using open standard technologies. <br/><br/></li></ul><strong>Additional Information<br/><br/></strong><strong>Work Hours:</strong> Varies upon the needs of the department.<br/><br/><strong>Travel Requirements:</strong> This position requires travel 5-10% of the time.<br/><br/><strong>Mental/Physical Requirements:</strong> This position will be performed in an office setting. The position will require the incumbent to sit and stand at a desk, communicate in person and by telephone, frequently operate standard office equipment, such as telephones and computers.<br/><br/>Visa is an EEO Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, sexual orientation, gender identity, disability or protected veteran status. Visa will also consider for employment qualified applicants with criminal histories in a manner consistent with EEOC guidelines and applicable local law.<br/><br/>Visa will consider for employment qualified applicants with criminal histories in a manner consistent with applicable local law, including the requirements of Article 49 of the San Francisco Police Code.<br/><br/><strong>U.S. APPLICANTS ONLY: The estimated salary range for a new hire into this position is 89,600.00 to 114,300.00 USD per year, which may include potential sales incentive payments (if applicable). Salary may vary depending on job-related factors which may include knowledge, skills, experience, and location. In addition, this position may be eligible for bonus and equity. Visa has a comprehensive benefits package for which this position may be eligible that includes Medical, Dental, Vision, 401 (k), FSA/HSA, Life Insurance, Paid Time Off, and Wellness Program.</strong>
</div>",No Salary Info Found,"Software Engineer, Data"
"Senior Software Engineer, Data Science Platform",NVIDIA,12/19/2023,https://www.linkedin.com/jobs/view/3789792672,0,https://media.licdn.com/dms/image/C560BAQFDs6GbpvE3zA/company-logo_100_100/0/1630584931971/nvidia_logo?e=2147483647&v=beta&t=LoUj3FUN8Y9axtbhorghJZo6ep0wi4o5FxBaIXIm5b4,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are looking for a Sr. Data Engineer - Data Science Platform.<br/><br/>At NVIDIA, we pride ourselves on data-driven decision-making, and the data science team is at the heart of this initiative. We are looking for an excellent Sr. Data engineer with extensive data engineering experience for our data science platform supporting NVIDIA's cloud platform services. Our data science platform serves as the basis for advanced real time data analytics, streaming, data lake and sophisticated ML/AI training with offline/online inferencing for NVIDIA's cloud services.<br/><br/><strong>What You’ll Be Doing<br/><br/></strong><ul><li>Design and implement critical high performance, large scale services and libraries</li><li>Build streaming data pipelines for collecting &amp; processing data from multiple data sources: from the point of ingestion to useful insights</li><li>Design and build data Lakehouse architecture for our customers</li><li>Partner with our other engineering and business teams to integrate your amazing innovations and algorithms into our production systems</li><li>Automate everything for measuring, testing, updating, monitoring and alerting the data platform<br/><br/></li></ul><strong>What We Need To See<br/><br/></strong><ul><li>Bachelors or Master’s degree in Computer Science or a related technical field (or equivalent experience)</li><li>5+ years of software engineering experience</li><li>Passion about Big data and large scale distributed systems</li><li>Expert knowledge with building and operating multi-petabyte data lakes</li><li>Experience working with Spark and Trino compute and expertise with open table format such as delta lake and/or iceberg etc</li><li>Excellent SW development skills in one or more: Java/Scala/Python/Go</li><li>Experience with building real time streaming applications with kafka etc</li><li>Strong interpersonal skills including the ability to identify and communicate data driven insights<br/><br/></li></ul><strong>Ways To Stand Out From The Crowd<br/><br/></strong><ul><li>Contributions to open source</li><li>Experience with operating large scale distributed systems with strong SLAs<br/><br/></li></ul>NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing and Visualization. The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services. Our work opens up new universes to explore, enables amazing creativity and discovery, and powers what were once science fiction inventions from artificial intelligence to autonomous cars. NVIDIA is looking for great people like you to help us accelerate the next wave of artificial intelligence.<br/><br/>The base salary range is 144,000 USD - 270,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.<br/><br/>You will also be eligible for equity and benefits . <em> NVIDIA accepts applications on an ongoing basis. <br/><br/></em>NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.<br/><br/>
</div>",No Salary Info Found,"Software Engineer, Data"
"Software Engineer, Python- Firefly",Adobe,12/19/2023,https://www.linkedin.com/jobs/view/3788123694,0,https://media.licdn.com/dms/image/C560BAQFrtK-ioO1rsQ/company-logo_100_100/0/1630645864762/adobe_logo?e=2147483647&v=beta&t=wxfArvhegDxZEB-gLnuqzm1Mqur7kWaVi1bCw9Yjw50,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Our Company<br/><br/></strong>Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.<br/><br/>We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!<br/><br/>Adobe's Applied Science and Machine Learning team is looking for a software engineer to develop evaluation systems for the latest generative models. Evaluation science is a dynamic group of engineers and researchers with expertise spanning software engineering, web development, machine learning, and human-computer interaction. You will have an opportunity to work with the latest AI-supported tools and conceptualize approaches to understand how to make them easier and safer to use for creative professionals and everyday users alike.<br/><br/>An ideal candidate is a Python expert with 3+ years of work experience. You will work closely with machine learning engineers, researchers, and product managers to develop end-to-end systems for evaluating Adobe Firefly, Adobe's suite of generative models.<br/><br/><strong> Main responsibilities : <br/><br/></strong><ul><li> Design core Python modules that interact with state-of-the-art generative models. </li><li> Curate large-scale datasets for model evaluation. </li><li> Create data visualization applications to support image evaluation and drive business decision-making . </li><li> Analyze and improve the efficiency and scalability of the model evaluation systems. <br/><br/></li></ul><strong>Minimum Requirements<br/><br/></strong><ul><li> Expertise in Python . </li><li> Experience with building and interfacing with REST APIs. </li><li> Experience with data visualization technologies, such as Streamlit , d3.js, vega (lite). </li><li> Experience working with CI/CD pipeline. </li><li> Experience with database systems . </li><li> Some experience with Splunk, New Relic <br/><br/></li></ul>A successful teammate will also meet the following criteria:<br/><br/><ul><li> Active participation in design and architecture discussions </li><li> Excellent communication and collaboration skills </li><li> Ability to work independently and take initiatives. </li><li> Familiarity with public cloud technologies such as AWS EC2, S3, and RDS <br/><br/></li></ul>Our compensation reflects the cost of labor across several  U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $124,000 -- $234,200 annually. Pay within this range varies by work location and may also depend on job-related knowledge, skills, and experience. Your recruiter can share more about the specific salary range for the job location during the hiring process.<br/><br/>At Adobe, for sales roles starting salaries are expressed as total target compensation (TTC = base + commission), and short-term incentives are in the form of sales commission plans. Non-sales roles starting salaries are expressed as base salary and short-term incentives are in the form of the Annual Incentive Plan (AIP).<br/><br/>In addition, certain roles may be eligible for long-term incentives in the form of a new hire equity award.<br/><br/>Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.<br/><br/>Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.<br/><br/>Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.
      </div>",$124000- $234200,"Software Engineer, Data"
Python Developer,Galaxy i technologies Inc,12/19/2023,https://www.linkedin.com/jobs/view/3784049155,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Software Engineer,SambaNova Systems,12/19/2023,https://www.linkedin.com/jobs/view/3709873051,0,https://media.licdn.com/dms/image/C560BAQH5t_FzqA7O0w/company-logo_100_100/0/1662998715027/sambanova_logo?e=2147483647&v=beta&t=lVQd0QiVoFkjxObQ1xLsOnJsE4AdZZKvzSn-DRlf_D0,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The era of pervasive AI has arrived. In this era, organizations will use generative AI to unlock hidden value in their data, accelerate processes, reduce costs, drive efficiency and innovation to fundamentally transform their businesses and operations at scale.<br/><br/>SambaNova Suite™ is the first full-stack, generative AI platform, from chip to model, optimized for enterprise and government organizations. Powered by the intelligent SN40L chip, the SambaNova Suite is a fully integrated platform, delivered on-premises or in the cloud, combined with state-of-the-art open-source models that can be easily and securely fine-tuned using customer data for greater accuracy. Once adapted with customer data, customers retain model ownership in perpetuity, so they can turn generative AI into one of their most valuable assets.<br/><br/>If you recently graduated or will graduate within the upcoming academic year with your Bachelor’s/Master’s and are interested in full-time software engineering opportunities with the leading AI startup, please apply below and tell us a little about yourself! If there's a match someone will be in contact.<br/><br/>We are looking especially for engineers with <strong>one or more</strong> of the following interests and skill sets:<br/><br/><ul><li>System Software</li><li>Machine Learning &amp; Applications</li><li>Compilers</li><li>Hardware / Software Co-Design<br/><br/></li></ul><strong>Annual Salary Range and Level<br/><br/></strong>The base salary for this position ranges from $120,000/year up to $145,000/year. This range is based on role, level, and location and reflects the salary target for new hires in the US. Individual pay within the range will depend on a number of factors, including a candidate’s job-related qualifications, skills, competencies and experience, and location.<br/><br/><strong>Benefits Summary For US-Based Full-Time Direct Employment Positions<br/><br/></strong><strong>(The Recruiter will provide benefit details for non-US-based roles)<br/><br/></strong>SambaNova offers a competitive total rewards package, including the base salary, plus equity and benefits. We cover 95% premium coverage for employee medical insurance, and 77% premium coverage for dependents and offer a Health Savings Account (HSA) with employer contribution. We also offer Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life, and AD&amp;D insurance plans in addition to Flexible Spending Account (FSA) options like Health Care, Limited Purpose, and Dependent Care. Our library of well-being benefits available to you and your dependents includes a full subscription to Headspace, Gympass+ membership with access to physical gyms, One Medical membership, counseling services with an Employee Assistance Program, and much more.<br/><br/><strong>Submission Guidelines<br/><br/></strong>Please note that in order to be considered an applicant for any position at SambaNova Systems, you must submit an application form for each position for which you believe you are qualified.<br/><br/><em>If you are a new, recent (within the last two years), or upcoming college graduate and are interested in opportunities with SambaNova Systems, please apply through our university job listings.<br/><br/></em><strong>EEO Policy<br/><br/></strong>SambaNova Systems is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard basis of age (40 and over), color, disability, gender identity, genetic information, marital status, military or veteran status, national origin/ancestry, race, religion, creed, sex (including pregnancy, childbirth, breastfeeding), sexual orientation, and any other applicable status protected by federal, state, or local laws.<br/><br/>Customers turn to SambaNova to quickly deploy state-of-the-art generative AI capabilities within the enterprise. Our purpose-built enterprise-scale AI platform is the technology backbone for the next generation of AI computing.<br/><br/>Headquartered in Palo Alto, California, SambaNova Systems was founded in 2017 by industry luminaries, and hardware and software design experts from Sun/Oracle and Stanford University. Investors include SoftBank Vision Fund 2, funds and accounts managed by BlackRock, Intel Capital, GV, Walden International, Temasek, GIC, Redline Capital, Atlantic Bridge Ventures, Celesta, and several others. Visit us at sambanova.ai. Follow SambaNova Systems on Linkedin.
      </div>",$120000- $145000,"Software Engineer, Data"
ML Framework Software Development Engineer - Generative AI,AMD,12/19/2023,https://www.linkedin.com/jobs/view/3748871085,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Senior Software Engineer (BlackLocus),The Home Depot,12/19/2023,https://www.linkedin.com/jobs/view/3789844811,0,https://media.licdn.com/dms/image/C4E0BAQHzR2llYqUBtg/company-logo_100_100/0/1630656428961/the_home_depot_logo?e=2147483647&v=beta&t=NH5wv1AXmlH4oUpVAOaSorm4nU1y-uttFDDEbY5Veps,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Position Purpose<br/><br/></strong>BlackLocus is building cloud-based analytic tools to optimize and automate retail merchandising decisions such as pricing, assortment, space and fulfillment. By applying machine learning and revenue management techniques, the BlackLocus platform enables intelligent retail software to identify opportunities for competitive advantage. The company was a venture-funded startup, founded by Carnegie Mellon alumni and entrepreneurs with a passion for creative deployment of new technology. Acquired by The Home Depot in December of 2012, we operate with autonomy as a remote product lab.<br/><br/><strong>Job Summary<br/><br/></strong>BlackLocus is seeking creative, thoughtful coders to join our development team. Our people solve interesting, challenging problems while working closely with data scientists and business analysts. We build tools to make business actions simple even from large data sets. Our data mining and machine learning pipeline, as well as our user-facing applications, are built primarily in Java, Python, and JavaScript. Our services and tools are entirely cloud-deployed.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>80% Delivery &amp; Execution: Write clean, maintainable, high-quality code; Establish best practices across development projects; Help take new products from prototype to deployment; Solve problems with production systems and automate operations as much as possible</li><li>Stay current with advancements in technology and advocate for the appropriate use of those advancements in our own stack; End to end responsibility on projects of increasing complexity</li><li>20% Mentoring: Mentor other engineers via design and code review<br/><br/></li></ul><strong>Direct Manager/Direct Reports<br/><br/></strong><ul><li>This role reports to the Director of Engineering BlackLocus.</li><li>This role has no direct reports.<br/><br/></li></ul><strong>Travel Requirements<br/><br/></strong><ul><li>Typically requires overnight travel less than 10% of the time.<br/><br/></li></ul><strong>Physical Requirements<br/><br/></strong><ul><li>Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.<br/><br/></li></ul><strong>Working Conditions<br/><br/></strong><ul><li>Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>Must be eighteen years of age or older.</li><li>Must be legally permitted to work in the United States.</li><li>Experience writing quality code in any language appropriate to the problem</li><li>Experience collaborating with a diverse group of people.</li><li>Knowledge in algorithms, data structures, and complexity analysis</li><li>Experience with technical design and can speak to reasoned design decisions and tradeoffs</li><li>Experience with persistent data stores and their query languages</li><li>Bachelor's of Science in Computer Science or equivalent experience and self-education<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Experience with either Java or Python as your preferred language.</li><li>Experience developing creative solutions to challenging problems in a self-directed, lean environment.<br/><br/></li></ul><strong>Minimum Education<br/><br/></strong><ul><li>The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.<br/><br/></li></ul><strong>Preferred Education<br/><br/></strong><ul><li>No additional education<br/><br/></li></ul><strong>Minimum Years Of Work Experience<br/><br/></strong><ul><li>4<br/><br/></li></ul><strong>Preferred Years Of Work Experience<br/><br/></strong><ul><li>No additional years of experience<br/><br/></li></ul><strong>Minimum Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Preferred Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Certifications<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Competencies<br/><br/></strong><ul><li>Ability to identify and document business requirements</li><li>Ability to communicate to a wide variety of audiences, both business and technical</li><li>Ability to understand existing business processes and assist with efforts to (re-)engineer processes</li><li>Strong project management skills, including strong process orientation, ability to work and lead cross functional teams, strategic thinking and creative problem solving skills.</li><li>Ability to establish priorities and procedures for accomplishing work within established deadlines; ability to lead multiple projects and manage toward deadlines and deliverables</li><li>Strong communication skills both written and verbal</li></ul>
</div>",No Salary Info Found,"Software Engineer, Data"
Python Developer,Tata Consultancy Services,12/19/2023,https://www.linkedin.com/jobs/view/3767949334,0,https://media.licdn.com/dms/image/C4D0BAQFPP1NRP4F5dQ/company-logo_100_100/0/1656657978597/tata_consultancy_services_logo?e=2147483647&v=beta&t=Ao4Ihtw2eg1ymYGPB7E4AEHoNQ83oX6bP1DrQIiqR1s,"Austin, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Should be strong in Python programming<br/><br/>Experience in working with various interfaces (like communicating the robot with external devices and application code to run the automated testing) Machine Learning experience is preferred<br/><br/>Experience in Data Movement, Data Transformation<br/><br/>Good knowledge on Cloud platform<br/><br/>
</div>",No Salary Info Found,"Software Engineer, Data"
Python Engineer - Remote | WFH,Get It Recruit - Information Technology,12/24/2023,https://www.linkedin.com/jobs/view/3787269817,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"Rochester, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a dynamic and globally recognized tech firm, committed to driving innovation in the open-source space. Our flagship product, Ubuntu, is celebrated for its developer-friendly approach and enterprise-grade capabilities. We operate across the entire open-source spectrum, collaborating with diverse teams, ecosystems, and communities.<br/><br/><strong>Position Overview<br/><br/></strong>We are actively seeking skilled Python Developers to join our versatile team. As a Python Developer at our company, you will play a pivotal role in crafting high-quality, idiomatic Python code that contributes to the success of our products. Whether you're experienced or just starting out in your Python journey, if you have a passion for open-source software and cutting-edge technologies, we invite you to apply.<br/><br/><strong>Responsibilities<br/><br/></strong>Write high-quality, well-designed, and well-tested Python software.<br/><br/>Collaborate proactively with a globally distributed team.<br/><br/>Display technical leadership within Canonical and in open-source communities.<br/><br/>Debug issues and produce high-quality code to address them.<br/><br/>Contribute to technical documentation to ensure clarity and comprehensiveness.<br/><br/>Enjoy the flexibility of working from home, with global travel opportunities twice a year for company events.<br/><br/><strong>What We're Looking For<br/><br/></strong>Strong academic background, either through high school and university achievements.<br/><br/>Undergraduate degree in Computer Science or STEM, or a compelling narrative about your alternative path.<br/><br/>Drive, initiative, and a history of exceeding expectations.<br/><br/>Well-organized, self-starting, and able to deliver to schedule.<br/><br/>Professional manner in interactions with colleagues, partners, and the community.<br/><br/>Experience in writing thoroughly designed, modern, maintainable Python.<br/><br/>Conscientiousness, attention to detail, and a focus on performance.<br/><br/>Proficient written and spoken English.<br/><br/><strong>Experience With Linux (Debian Or Ubuntu Preferred).<br/><br/></strong>Additional Skills (Optional, but advantageous):<br/><br/>Experience with container technologies such as LXD, Docker, and Kubernetes.<br/><br/>Understanding of build systems and toolchains, including cross-compilation.<br/><br/>Proficiency in additional languages, particularly Golang or Rust, C or C++.<br/><br/>Deep quality and test engineering expertise.<br/><br/>Web or Flutter front-end experience.<br/><br/>Familiarity with REST and gRPC APIs.<br/><br/>SQL and NoSQL data store expertise.<br/><br/>Experience with public clouds or OpenStack.<br/><br/>Knowledge of Debian/Ubuntu packaging.<br/><br/>Background in systems programming or scalable web services.<br/><br/>Performance engineering and security experience.<br/><br/><strong>What We Offer<br/><br/></strong>Competitive compensation, reviewed annually, and performance-driven annual bonus.<br/><br/>Distributed work environment with twice-yearly team sprints in person.<br/><br/>Personal learning and development budget of USD 2,000 per year.<br/><br/>Recognition rewards for outstanding contributions.<br/><br/>Annual holiday leave and comprehensive maternity/paternity leave.<br/><br/>Employee Assistance Programme.<br/><br/>Opportunity to travel to new locations for company events.<br/><br/>Priority Pass and travel upgrades for long-haul company events.<br/><br/><strong>About Canonical<br/><br/></strong>Canonical is a pioneering tech company leading the global transition to open source. As the publisher of Ubuntu, a pivotal open-source project and the platform for AI, IoT, and the cloud, we are shaping the future. Join us for a remote-first working experience, where you'll be challenged to think differently, work smarter, learn new skills, and elevate your game.<br/><br/><strong>Equal Opportunity Employer<br/><br/></strong>We take pride in fostering a workplace free from discrimination. Diversity of experience, perspectives, and background creates a better work environment and better products. Your application will receive fair consideration, regardless of your identity.<br/><br/>Employment Type: Full-Time<br/><br/>
</div>",No Salary Info Found,"Software Engineer, Data"
Senior Software Engineer - ML - Ad Serving,StubHub,12/24/2023,https://www.linkedin.com/jobs/view/3739484369,0,https://media.licdn.com/dms/image/C560BAQEeUqY1MzhaLw/company-logo_100_100/0/1655126776940/stubhub_logo?e=2147483647&v=beta&t=XZG8_R4MWHRdVBfjbOSlsNVjONDiiXSCPgcYIiSbInc,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About the Opportunity: <br/><br/></strong>In order to transform how millions of users explore, interact with, and participate in live events worldwide, StubHub is seeking Senior Software Engineers to design and develop next-generation technologies and complex features. As a Senior Software Engineer, you will be at the forefront of tackling significant, ambiguous, and non-trivial challenges as a core contributor and innovator, bringing creative technical solutions to life. In order to ensure our company's success, our Senior Software Engineers must demonstrate initiative and enthusiasm for the problems they tackle. StubHub is committed to being a phenomenal and inclusive place to work. As a Senior Software Engineer, you will also be an advocate and mentor for your team members, displaying leadership qualities and being an example for those around you.<br/><br/>This is a hybrid work opportunity, that is located in New York, NY.<br/><br/><strong>About the team:<br/><br/></strong>T he ad serving team is responsible for delivering highly relevant and personalized ads to millions of potential customers globally. Our cross functional team consists of software engineers, data scientists and domain experts who collaborate closely to build the most informed products possible. The work we do is at the forefront of the organization's growth strategy, so we're always striving to improve the quality of our ads and systems to help our customers find more of the events they love.<br/><br/><strong>What You've Done<br/><br/></strong><ul><li>5-6+ years of professional experience in software development </li><li>Extensive experience developing robust, mission-critical systems using multiple general-purpose programming languages (e.g., C/C++, Java, C#, Objective-C) </li><li>Demonstrated expertise in building software with one or more of the following: Infrastructure, Databases, Data Processing, Machine Learning, Distributed Systems, Security, and Privacy </li><li>Previous experience designing and developing solutions to complex problems with significant business impact </li><li>A strong understanding of how their systems interact with the broader production environment, including dependencies and platform primitives</li><li>Proven ability to learn other coding languages, platforms, frameworks, and tools </li><li>Experience owning projects from the initial idea all the way to production </li><li>Experience mentoring junior engineers<br/><br/><br/></li></ul><strong>What You'll Do<br/><br/></strong><ul><li>Design, develop, test, deploy, and maintain impactful improvements across all StubHub’s platforms and products, resulting in high-quality outcomes </li><li>Collaborate with team members to ensure best practices across our code </li><li>Manage individual initiative priorities, deadlines, and deliverables with your technical expertise </li><li>Mentor other team members and help many increase their technical capabilities, fostering a culture of inclusion, results-oriented execution, open innovation, and limitless creativity <br/><br/><br/></li></ul><strong>What We Offer<br/><br/></strong><ul><li>Accelerated Growth Environment: Immerse yourself in an environment designed for swift skill and knowledge enhancement, where you have the autonomy to lead experiments and tests on a massive scale.</li><li>Top Tier Compensation Package: Enjoy a rewarding compensation package that includes enticing stock incentives, aligning with our commitment to recognizing and valuing your contributions.</li><li>Flexible Time Off: Embrace a healthy work-life balance with unlimited Flex Time Off, providing you the flexibility to manage your schedule and recharge as needed.</li><li>Comprehensive Benefits Package: Prioritize your well-being with a comprehensive benefits package, featuring 401k, and premium Health, Vision, and Dental Insurance options.</li><li>Perks for Your Palate: Delight in the workplace perks, including free weekly lunches, a diverse selection of office snacks, and the convenience of cold-brew and kombucha kegs.</li><li>Team-Building Events: Engage in vibrant team events that foster camaraderie and collaboration, creating an atmosphere where your professional and personal growth are celebrated.<br/><br/><br/></li></ul>The anticipated gross annual base salary range for this role is $200,000 – $275,000 per year. Actual compensation will vary depending on factors such as a candidate’s qualifications, skills, experience, and competencies. Base annual salary is one component of StubHub’s total compensation and competitive benefits package, which also includes equity, 401(k), paid time off, paid parental leave, and comprehensive health benefits.<br/><br/><strong>About Us<br/><br/></strong>StubHub is the world’s leading marketplace to buy and sell tickets to any live event, anywhere. Through StubHub in North America and viagogo, our international platform, we service customers in 195 countries in 33 languages and 49 available currencies. With more than 300 million tickets available annually on our platform to events around the world -- from sports to music, comedy to dance, festivals to theater -- StubHub offers the safest, most convenient way to buy or sell tickets to the most memorable live experiences. Come join our team for a front-row seat to the action.<br/><br/>For California Residents: California Job Applicant Privacy Notice found here<br/><br/><strong>We are an equal opportunity employer and value diversity on our team. We do not discriminate on the basis of race, color, religion, sex, national origin, gender, sexual orientation, age, disability, veteran status, or any other legally protected status.</strong>
</div>",$200000- $275000,"Software Engineer, Data"
Python Developer,"TekVivid, Inc",12/19/2023,https://www.linkedin.com/jobs/view/3790025504,0,https://media.licdn.com/dms/image/D560BAQGbC91FFZpYNg/company-logo_100_100/0/1688395859274/tekvividinc_logo?e=2147483647&v=beta&t=U3VJ5Cj0VXWXZggVjMv_MWoLBg2sChfDLCUhunGJ_xg,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>JOB DESCRIPTION<br/></strong><br/>QRL (Quant Risk Libraries) implements risk models to ensure that the bank's lending portfolios have adequate capital during crisis. We use mathematical modeling and the latest technologies to build loss forecasting and stress testing pipelines. Our systems are responsible for calculating risk on some of the largest portfolios in Citi. We are a diverse group of professionals with backgrounds in Physics, Engineering and Computer Science. You will work alongside experienced colleagues to further develop your analytical and quantitative skills. You will build skills in building products from the ground up for solving real life problems and develop a career as a risk model expert.<br/><br/><br/><br/><strong>Position Description<br/></strong><br/>· Designing and implement a framework for model driven computations on a graph<br/><br/>· Designing and building infrastructure APIs for grid computing, data storage and access<br/><br/>· Unit testing, reliability and improving the quality of our compute pipelines<br/><br/>· Learn about Python, its ecosystem, community and best practices<br/><br/>· Ideas on improving our model and data platform and help implement them You will need:<br/><br/>· Bachelors or Masters in Computer Science/Computer Engineering or related field<br/><br/>· Strong grasp of computing fundamentals: data structures, algorithms, OS, programming languages.<br/><br/>· Fluency in Python and working knowledge of a compiled language like C/C++/Java<br/><br/>· Exposure to Numerical libraries (Pandas/Numpy) and data processing<br/><br/>· 2+ years developing Python, C or C++ packages and API development<br/><br/>· Ability for abstraction and conceptualization, reasoning about program behavior at different levels of abstraction from hardware to applications.<br/><br/><br/><br/><strong>Required Skills:<br/></strong><br/>· Experience with web services and Flask/Django ecosystem<br/><br/>· Experience with large scale scientific computing and algorithm development<br/><br/>· Long term interest in finance, financial experience is required<br/><br/>· Experience contributing to Open-Source project</p> <p> </p>
</div>",No Salary Info Found,"Software Engineer, Data"
"Software Engineer, Front-End (Retain and Expand)",Grammarly,12/19/2023,https://www.linkedin.com/jobs/view/3724653310,0,https://media.licdn.com/dms/image/C560BAQFroT18wpIblQ/company-logo_100_100/0/1669669290715/grammarly_logo?e=2147483647&v=beta&t=ztA7DBsCxjynNbw6oGlEHqtgqJneLWUJ1rfYbYVi91A,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>Grammarly is excited to offer a </em><em>remote-first hybrid working model</em><em>. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.<br/><br/></em><em>All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków. </em><em>This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.<br/><br/></em><em>Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.<br/><br/></em><strong>The opportunity <br/><br/></strong>Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.<br/><br/>To achieve our ambitious goals, we’re looking for a Front-End Software Engineer to join the Retain and Expand team. This team is focused on driving growth within our Grammarly Business accounts by helping teams onboard, connect to value, and expand within their organization. The person in this role will contribute to key features and experiments that will directly impact Grammarly’s customers and revenue goals. They will collaborate closely with product managers, designers, and data scientists, and they will have the opportunity to tackle both technical and product challenges. They will be joining a team that is at the forefront of accelerating the growth and expansion of Grammarly into our largest Enterprise accounts.<br/><br/>Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.<br/><br/><strong>Your impact<br/><br/></strong>As a Front-End Software Engineer for Retain and Expand, your work will be highly impactful and visible, and you will be helping Grammarly expand into our largest Enterprise accounts.<br/><br/><strong>In This Role You Will<br/><br/></strong><ul><li>Drive business impact by building and shipping new features while collaborating cross-functionally with product managers, designers, and data scientists.</li><li>Contribute to technical decisions and make trade-offs based on execution speed, maintainability, and user experience.</li><li>Master the business growth domain and understand the needs of our largest Enterprise customers.<br/><br/></li></ul><strong>We’re Looking For Someone Who<br/><br/></strong><ul><li>Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.</li><li>Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.</li><li>Is able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub where the team is based.</li><li>Has a growth mindset and is focused on delivering measurable business impact.</li><li>Has a strong command of modern front-end technologies.</li><li>Can quickly adapt to new codebases, written in different languages and paradigms.</li><li>Cares about the end user experience and strives to ensure high quality.<br/><br/></li></ul><strong>Support for you, professionally and personally<br/><br/></strong><ul><li>Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.</li><li>A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs. <br/><br/></li></ul><strong>Compensation And Benefits<br/><br/></strong>Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:<br/><br/><ul><li>Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)</li><li>Disability and life insurance options</li><li>401(k) and RRSP matching </li><li>Paid parental leave</li><li>Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days </li><li>Home office stipends</li><li>Caregiver and pet care stipends</li><li>Wellness stipends</li><li>Admission discounts</li><li>Learning and development opportunities<br/><br/></li></ul>Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.<br/><br/>Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.<br/><br/><strong>United States<br/><br/></strong>Zone 1: $144,000 – $253,000/year (USD)<br/><br/>Zone 2: $130,000 – $228,000/year (USD)<br/><br/>Zone 3: $122,000 – $215,000/year (USD)<br/><br/>Zone 4: $115,000 – $202,000/year (USD)<br/><br/><strong>Canada<br/><br/></strong>Zone 1: $120,000 – $182,000/year (CAD)<br/><br/>Zone 2: $102,000 – $155,000/year (CAD)<br/><br/><strong>We encourage you to apply<br/><br/></strong>At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).<br/><br/><em>Please note that EEOC is optional and specific to US-based candidates.<br/><br/></em>#NA<br/><br/><em>All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.<br/><br/></em>
</div>",$144000- $253000,"Software Engineer, Data"
Data and Analytics Engineer,Jetty,12/19/2023,https://www.linkedin.com/jobs/view/3788131758,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Cloud Data Engineer,Talener,12/19/2023,https://www.linkedin.com/jobs/view/3748836564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Software Developer(Junior Level),SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784098158,0,https://media.licdn.com/dms/image/C560BAQHPrA2XO9lh7g/company-logo_100_100/0/1663564885547/synergisticit_logo?e=2147483647&v=beta&t=biDnkXeeFcJXgnh87P53V9KGn6j1mqUOEQpisfcfR74,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At SynergisticIT, we're all about making connections. Whatever IT goals you have, our software programmers can help achieve those. Our Software development teams can take up turnkey projects and execute them in an effective and efficient manner. If you are looking to source talent our recruiters will find the ideal IT talent for your company. What's the secret to our success? Well, it all starts with taking quality time to listen to each client's specific needs. After we have a thorough grasp of your IT goals, we can better customize our Developments as per your specific needs. We can also tailor make recruiting programs to exceed your expectations. Since our founding in 2010, SynergisticIT's strategies have earned the company an enviable position in the software development, IT staffing and IT skill enhancement fields. SynergisticIT continues to work with hundreds of satisfied American clients with our software programmers working on our projects and after gaining hands on experience on cutting edge technologies moving to contribute their skills to great clients like Apple, Google, Client, Ebay, Paypal, Kroger, the Walt Disney Company and hundreds more. If you are tired of working with inefficient programmers who take a lot of time to ramp up we want you to try us. Our software programmers can hit the ground running and get you the maximum return on your investment. You have already tried the rest its time you tried the best. SynergisticIT - Home of the Best Data Scientists and Software Programmers in the Bay Area.<br/><br/><strong> Why Us ? <br/><br/></strong>SynergisticIT has a proven track record of successfully skill enhancement and staffing IT employees for some of the world's most iconic brands. Our team takes the time to fully understand every client's needs so we could best meet your IT staffing requirements. The knowledgeable staff at SynergisticIT is always more than happy to work with clients to ensure they reach their software development goals. Besides staffing, SynergisticIT is also committed to helping young IT professionals advance their career with a robust upskill program . Everyone who goes through SynergisticIT's program learns all the skills necessary to succeed in many IT fields ranging from Java to Machine Learning. Additionally, everyone trained at SynergisticIT has been through extensive mock and technical interview screenings to bolster their career prospects. Last, but certainly not least, SynergisticIT takes great care to respect the privacy considerations for every client. All companies who work with SynergisticIT can rest assured their confidential data is protected using the most up-to-date encryption technologies. SynergisticIT also complies with all the latest NDA agreements.<br/><br/><strong> REQUIRED SKILLS For Java /Software Programmers <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis <br/><br/></strong><strong> We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2022 and at Gartner Data Analytics Summit (Florida)-2023 <br/><br/></strong>Oracle CloudWorld Event (OCW) Las Vegas 2022 | SynergisticIT - YouTube<br/><br/><strong> https://www.youtube.com/watch?v=OAFOhcGy9Z8 <br/><br/></strong><strong> https://www.youtube.com/watch?v=EmO7NrWHkLM <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=Yy74yvjatVg <br/><br/></strong>SynergisticIT at Gartner Data and Analytics Summit 2023 - YouTube<br/><br/>For preparing for interviews please visit <strong> https://www.synergisticit.com/interview-questions/ <br/><br/></strong><strong> We are looking for the right matching candidates for our clients <br/><br/></strong><strong> Please apply via the job posting <br/><br/></strong><strong> REQUIRED SKILLS For Java /Full Stack/Software Programmer <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning Positions <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow <br/><br/></strong><strong> If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team. <br/><br/></strong><strong> No phone calls please. </strong> Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates
      </div>",No Salary Info Found,"Software Engineer, Data"
Senior Software Engineer,Proxima,12/19/2023,https://www.linkedin.com/jobs/view/3784460258,0,https://media.licdn.com/dms/image/D4E0BAQGQHef5H748XA/company-logo_100_100/0/1665158978182/proxima_logo?e=2147483647&v=beta&t=2WbdfJ73F1yxWdxPXct_dNT6aT_Utvf6qwnmjxdT0qk,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Proxima<br/><br/>Proxima is more than just a business to us; it's a vision of transforming the consumer technology landscape and giving B2C businesses the data they need to make informed decisions that drive highly performant actions. We are empowering our customers to achieve their greatest potential with innovative, data-driven solutions.<br/><br/>We are a first-of-its-kind data intelligence solution that leverages artificial intelligence and a proprietary database of over 60 million (and growing) unique shopper personas to enable businesses to achieve greater scale, efficiency, and financial success across their acquisition, retention, and operational strategies. We’re on a mission to help maximize their performance with AI-powered solutions that have traditionally been out of reach for most companies. We believe profitable growth starts with better data.<br/><br/><strong>About The Role<br/><br/></strong>The Senior Software Engineer will be joining a growing team as we build out our next generation platform. The ideal candidate has been in the industry for at least 7-12 years and has a proven track record of success in leading a team. This person should demonstrate a high level of expertise in full stack development and AWS cloud services, and will play a key role in creating the technical roadmap through designing, developing and implementing solutions across our tech stack - AWS, Node.js, React, Serverless, Lambda, PostgreSQL, and more.<br/><br/>This person will be the go-to expert for various areas of the Proxima platform, proactively identifying problems, challenges and solutions. If you are a curious and resourceful team leader, who wants to create an impact with an incredibly passionate and collaborative team, this role is for you!<br/><br/>What You'll Do<br/><br/><ul><li>Contribute to the Proxima technical roadmap by researching, designing, architecting and implementing complex solutions and features</li><li>Architect and build APIs, backend integrations, and web apps</li><li>Collaborate with our Product, Design and Customer/Sales teams to weigh in on the scope, feasibility, design and implementation of new features</li><li>Implement and follow best practices in software development, code versioning, software testing, and dev ops</li><li>Be an expert and leader in coding standards and support and mentor junior developers</li><li>Contribute to our engineering team and culture by leading tech presentations and discussions</li><li>Troubleshoot, debug and improve usability as well as upgrade existing systems</li><li>Consistently work to become a better engineer, such as researching new technologies and approaches to solve problems and improve existing systems</li><li>Produce functional, technical, and user documentation that describes the specifications, data flows, and user interfaces as needed<br/><br/><br/></li></ul>What We Need<br/><br/><ul><li>7-12+ years of professional experience within an engineering team required</li><li>Experience leading a project or team, including responsibility for quality output from other people</li><li>Strong knowledge of AWS, with ability to lead company’s technology choices/usage</li><li>Experience working at a SaaS and/or B2B startup or small business, highly preferred</li><li>Proven experience mentoring other engineers, reviewing code and unit tests</li><li>Extensive experience in backend and/or frontend development, using JavaScript, HTML5, CSS3, Node.js, React, AWS, and PostgreSQL</li><li>A passion for best practices in engineering and coding, and an interest in continuous learning</li><li>Ability to understand business requirements and translate those into technical solutions</li><li>Experience in implementing solutions and features in a fast-paced environment</li><li>Strong collaboration skills; experience working cross-functionally with Product, Design and Customer Success teams</li><li>Bachelor’s Degree in Computer Science or other relevant education required</li><li>Remote candidates based in the US are welcome to apply<br/><br/><br/></li></ul>Why You'll Love Working Here<br/><br/>We can promise:<br/><br/><ul><li> Competitive salary in a fast-growing, close-knit, &amp; motivated team</li><li> Unlimited PTO so you can take the time you need</li><li> Health, dental, and vision insurance for you and your dependents</li><li> Annual membership to OneMedical and Teledoc</li><li> Summer Fridays from July 4th Weekend to Labor Day each year</li><li> 401k program</li><li> 12 weeks Paid Parental Leave benefits</li><li> Subsidized ClassPass membership</li><li> Commuter pre-tax benefits</li><li> Learning &amp; Development Stipend</li><li> HSA and FSA pre-tax benefits</li><li> Pet-Friendly Office Space in the Heart of Soho<br/><br/><br/></li></ul>We value diversity and inclusivity. We are an equal opportunity employer and do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.<br/><br/>The base salary range represents the low and high end of the anticipated salary range for this position. The actual base salary offered for this position will depend on numerous factors including individual performance, skills and experience. The base salary is just one component of Proxima’s compensation package which includes a wide range of medical, dental, vision and other benefits, as well as equity.
      </div>",No Salary Info Found,"Software Engineer, Data"
Software Engineer,Proxima,12/19/2023,https://www.linkedin.com/jobs/view/3784456828,0,https://media.licdn.com/dms/image/D4E0BAQGQHef5H748XA/company-logo_100_100/0/1665158978182/proxima_logo?e=2147483647&v=beta&t=2WbdfJ73F1yxWdxPXct_dNT6aT_Utvf6qwnmjxdT0qk,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Proxima<br/><br/>Proxima is more than just a business to us; it's a vision of transforming the consumer technology landscape and giving B2C businesses the data they need to make informed decisions that drive highly performant actions. We are empowering our customers to achieve their greatest potential with innovative, data-driven solutions.<br/><br/>We are a first-of-its-kind data intelligence solution that leverages artificial intelligence and a proprietary database of over 60 million (and growing) unique shopper personas to enable businesses to achieve greater scale, efficiency, and financial success across their acquisition, retention, and operational strategies. We’re on a mission to help maximize their performance with AI-powered solutions that have traditionally been out of reach for most companies. We believe profitable growth starts with better data.<br/><br/><strong>About The Role<br/><br/></strong>The Software Engineer will join a growing team and touch every part of the Proxima source code. They will tackle new challenges, building frontend and backend technologies including web apps, Node.js APIs, and distributed backend systems. The ideal candidate will have 4-7+ years of extensive professional experience implementing solutions across our tech stack - AWS, Node.js, React, Serverless, Lambda, PostgreSQL, and more. Responsibilities will be flexible based on the company needs as well as your skills and interest.<br/><br/>If you love teamwork but are also comfortable with independent projects and want to create an impact with an incredibly passionate and collaborative team, this role is for you!<br/><br/>What You'll Do<br/><br/><ul><li>Architect and build the Proxima platform by creating and maintaining APIs, backend integrations, and web apps</li><li>Collaborate with our Product, Design and Customer/Sales teams to weigh in on the scope, feasibility, design and implementation of new features</li><li>Unit test your code, and manage your own deployments</li><li>Implement and follow best practices in software development, code versioning, software testing and dev ops</li><li>Troubleshoot, debug and improve usability as well as upgrade existing systems</li><li>Contribute to discussions on architectures and team best practices</li><li>Consistently work to become a better engineer, such as researching new technologies and approaches to solve problems and improve existing systems</li><li>Produce functional, technical, and user documentation that describes the specifications, data flows, and user interfaces as needed<br/><br/><br/></li></ul>What We Need<br/><br/><ul><li>5-10+ years of professional experience within an engineering team</li><li>Knowledge of AWS services such as Lambda, DynamoDB, Kinesis, RDS, SQS, and API Gateway</li><li>Experience working at a SaaS and/or B2B startup or small business, highly preferred</li><li>Extensive experience in backend and/or frontend development, using JavaScript, HTML5, CSS3, Node.js, React, AWS, and PostgreSQL</li><li>A passion for best practices in engineering and coding, and an interest in continuous learning</li><li>Ability to understand business requirements and translate those into technical solutions</li><li>Experience in implementing solutions and features in a fast-paced environment</li><li>Strong collaboration skills; experience working cross-functionally with Product, Design and Customer Success teams</li><li>Bachelor’s Degree in Computer Science or other relevant experience required</li><li>Remote candidates based in the US are welcome to apply<br/><br/><br/></li></ul>Why You'll Love Working Here<br/><br/>We can promise:<br/><br/><ul><li> Competitive salary in a fast-growing, close-knit, &amp; motivated team</li><li> Unlimited PTO so you can take the time you need</li><li> Health, dental, and vision insurance for you and your dependents</li><li> Annual membership to OneMedical and Teledoc</li><li> Summer Fridays from July 4th Weekend to Labor Day each year</li><li> 401k program</li><li> 12 weeks Paid Parental Leave benefits</li><li> Subsidized ClassPass membership</li><li> Commuter pre-tax benefits</li><li> Learning &amp; Development Stipend</li><li> HSA and FSA pre-tax benefits</li><li> Pet-Friendly Office Space in the Heart of Soho<br/><br/><br/></li></ul>We value diversity and inclusivity. We are an equal opportunity employer and do not discriminate based on race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.<br/><br/>The base salary range represents the low and high end of the anticipated salary range for this position. The actual base salary offered for this position will depend on numerous factors including individual performance, skills and experience. The base salary is just one component of Proxima’s compensation package which includes a wide range of medical, dental, vision and other benefits, as well as equity.
      </div>",No Salary Info Found,"Software Engineer, Data"
Software Engineer (Core Java),The Cypress Group,12/19/2023,https://www.linkedin.com/jobs/view/3675621230,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
"Software Engineer: Intern Opportunities, CTJ",Microsoft,12/24/2023,https://www.linkedin.com/jobs/view/3708145695,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Software Engineer,Anicca Data Science Solutions,12/23/2023,https://www.linkedin.com/jobs/view/3792559686,0,https://media.licdn.com/dms/image/C560BAQG07JeJjWWiPQ/company-logo_100_100/0/1631439208776/aniccadata_logo?e=2147483647&v=beta&t=59zXcFDVjB_ae_i4Gymtf1DeCSer6DGyjI3doUm7JBg,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities:<br/><br/></strong><ul><li>Collaborates with appropriate stakeholders to determine user requirements for a scenario.</li><li>Drives identification of dependencies and the development of design documents for a product, application, service, or platform.</li><li>Creates, implements, optimizes, debugs, refactors, and reuses code to establish and improve performance and maintainability, effectiveness, and return on investment (ROI).</li><li>Leverages subject-matter expertise of product features and partners with appropriate stakeholders (e.g., project managers) to drive a workgroup's project plans, release plans, and work items.</li><li>Acts as a Designated Responsible Individual (DRI) and guides other engineers by developing and following the playbook, working on call to monitor system/product/service for degradation, downtime, or interruptions, alerting stakeholders about status and initiates actions to restore system/product/service for simple and complex problems when appropriate.</li><li>Proactively seeks new knowledge and adapts to new trends, technical solutions, and patterns that will improve the availability, reliability, efficiency, observability, and performance of products while also driving consistency in monitoring and operations at scale.<br/><br/><br/></li></ul><strong>Requirements:<br/><br/></strong><ul><li>Experience in C# &amp; C++, ASP.net or similar language software.</li><li>Knowledge of Kernel Debugging, Networking and Linux Network Booting. </li><li>Experience with scripting languages like PowerShell or Python.</li><li>Solid debugging, testing, and problem-solving skills.</li><li>Proficient in SQL/MySQL for database management.</li><li>Experience with developing large-scale distributed services.</li><li>Knowledge of Azure DevOps, Kusto, Cosmos DB, CIS.<br/><br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Azure 204 Certification. </li><li>Immediate Joiners <br/><br/><br/></li></ul><strong>Work Location: </strong>Bellevue/Atlanta<br/><br/><strong>Benefits:<br/><br/></strong><ul><li>Paid Time Off</li><li>Medical/Dental/Vision Insurance</li><li>401(k) plan with up to a 4% company-match<br/><br/><br/></li></ul>Flexible work from home options available.
      </div>",No Salary Info Found,"Software Engineer, Data"
Software Engineer - Backend,Databricks,12/19/2023,https://www.linkedin.com/jobs/view/3624837186,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Software Engineer,DocuSign,12/19/2023,https://www.linkedin.com/jobs/view/3757475434,0,https://media.licdn.com/dms/image/D560BAQFQdYL8UYYabQ/company-logo_100_100/0/1688410161925/docusign_logo?e=2147483647&v=beta&t=_RRxaZ7_BvNofAdU7Qm4r1z2AoNAL3d3kshSko4Bm1Q,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Overview<br/><br/></strong>DocuSign helps organizations connect and automate how they agree. Our flagship product, eSignature, is the world’s #1 way to sign electronically on practically any device, from virtually anywhere, at any time. Today, more than a million customers and a billion users in over 180 countries use DocuSign to accelerate the process of doing business and simplify people’s lives.<br/><br/>What you'll do<br/><br/>We are looking for a Software Engineer for the Integrations team, to help us build and scale the next generation of the platform and customer facing features. As a senior member of the team, you will help drive the architecture and development of all the services to build a state of the art integration solution. You will work with your team to build a top-tier software organization that is responsible for delivering SaaS products that meet the needs of our wide range of customers and their workflows. You are results-driven, believe in winning together, and always looking for continuous improvement. Our team focuses on distributed decision making that rewards ownership, transparency, and collaboration.<br/><br/>This position is an individual contributor role reporting to the Senior Manager, Engineering.<br/><br/><strong>Responsibility<br/><br/></strong><ul><li>Be responsible for delivering products that delight customers while managing the health of the code base through continuous refactoring and management of technical debt</li><li>Work with your team to deliver software best practices, automated test strategies, and flatten the cost of change for our software products and services</li><li>Think about how to solve problems at scale and build fault-tolerant systems</li><li>Develop high-quality, ship-ready code that is covered by a full test suite</li><li>Contribute to a web-scale service that follows microservice principles and is deployed using containerized cloud technologies to allow customer administrators the ability to manage their contract assets</li><li>Work with Product Management and other developers to understand and translate marketing requirements into design requirements and provide estimates for development</li><li>Work as part of a cross-site development team to drive the design, implementation, testing, and release of products<br/><br/></li></ul>Job Designation<br/><br/><strong>Hybrid:</strong> Employee divides their time between in-office and remote work. Access to an office location is required. (Frequency: Minimum 2 days per week; may vary by team but will be weekly in-office expectation)<br/><br/>Positions at DocuSign are assigned a job designation of either In Office, Hybrid or Remote and are specific to the role/job. Preferred job designations are not guaranteed when changing positions within DocuSign. DocuSign reserves the right to change a position's job designation depending on business needs and as permitted by local law.<br/><br/>What you bring<br/><br/><strong>Basic <br/><br/></strong><ul><li>5+ years of development experience or equivalent</li><li>Bachelor’s or Master’s in Computer Science, Electrical Engineering, Information Systems, Informatics, or equivalent</li><li>Experience with data structures, algorithms, operating systems, and distributed systems fundamentals</li><li>Experience working with C#, Node.js, Java, or other modern programming languages<br/><br/></li></ul><strong>Preferred<br/><br/></strong><ul><li>Experience building cloud-native services using REST APIs, microservice-based architectures, and containerized technologies (e.g. K8S, and Docker)</li><li>Experience designing, developing, troubleshooting, and debugging multi-regional web-services</li><li>Strong organizational, problem-solving, and communication skills</li><li>Experience developing large-scale cloud services, including troubleshooting and performance tuning</li><li>Experience in high-scale distributed systems and fault-tolerant design</li><li>Experience with agile and test-driven development methodologies</li><li>Experiences with the entire software development lifecycle, including version control (git), CICD pipelines, testing, and regional cloud deployments</li><li>Ability to work in a dynamic, fast-moving environment, prioritize your work, and manage your own time<br/><br/></li></ul>Wage Transparency<br/><br/>Based on applicable legislation, the below details pay ranges in the following locations:<br/><br/>California: $130,500 - $208,050 base salary<br/><br/>Washington and New York (including NYC metro area): $123,700 - $184,275 base salary<br/><br/>This role is also eligible for bonus, equity and benefits.<br/><br/><strong>Global Benefits Provide Options For The Following<br/><br/></strong><ul><li>Paid Time Off: earned time off, as well as paid company holidays based on region</li><li>Paid Parental Leave: take up to six months off with your child after birth, adoption or foster care placement</li><li>Full Health Benefits Plans: options for 100% employer paid and minimum employee contribution health plans from day one of employment</li><li>Retirement Plans: select retirement and pension programs with potential for employer contributions</li><li>Learning and Development: options for coaching, online courses and education reimbursements</li><li>Compassionate Care Leave: paid time off following the loss of a loved one and other life-changing events<br/><br/></li></ul>Life at DocuSign<br/><br/><strong>Working here<br/><br/></strong>DocuSign is committed to building trust and making the world more agreeable for our employees, customers and the communities in which we live and work. You can count on us to listen, be honest, and try our best to do what’s right, every day. At DocuSign, everything is equal.<br/><br/>We each have a responsibility to ensure every team member has an equal opportunity to succeed, to be heard, to exchange ideas openly, to build lasting relationships, and to do the work of their life. Best of all, you will be able to feel deep pride in the work you do, because your contribution helps us make the world better than we found it. And for that, you’ll be loved by us, our customers, and the world in which we live.<br/><br/><strong>Accommodation<br/><br/></strong>DocuSign provides reasonable accommodations for qualified individuals with disabilities in job application procedures. If you need such an accommodation, including if you need accommodation to properly utilize our online system, you may contact us at accommodations@docusign.com.<br/><br/>If you experience any technical difficulties or issues during the application process, or with our interview tools, please reach out to us at taops@docusign.com for assistance.<br/><br/>Applicant and Candidate Privacy Notice<br/><br/>States Not Eligible for Employment<br/><br/>This position is not eligible for employment in the following states: Alaska, Hawaii, Maine, Mississippi, North Dakota, South Dakota, Vermont, West Virginia and Wyoming.<br/><br/>Equal Opportunity Employer<br/><br/>It's important to us that we build a talented team that is as diverse as our customers and where all employees feel a deep sense of belonging and thrive. We encourage great talent who bring a range of perspectives to apply for our open positions. DocuSign is an Equal Opportunity Employer and makes hiring decisions based on experience, skill, aptitude and a can-do approach. We will not discriminate based on race, ethnicity, color, age, sex, religion, national origin, ancestry, pregnancy, sexual orientation, gender identity, gender expression, genetic information, physical or mental disability, registered domestic partner status, caregiver status, marital status, veteran or military status, or any other legally protected category.<br/><br/>EEO Know Your Rights poster<br/><br/>
</div>",$130500- $208050,"Software Engineer, Data"
"Software Engineer, Backend",Pinterest,12/19/2023,https://www.linkedin.com/jobs/view/3754695910,0,https://media.licdn.com/dms/image/C4E0BAQFRQ_U_kwuaGw/company-logo_100_100-alternative/0/1630647144993/pinterest_logo?e=2147483647&v=beta&t=AxrepS3HmBmZy3CWaza9oVygQcCyKcIrZy1IvzpyRMo,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong><strong>About Pinterest</strong>:<br/><br/></strong>Millions of people across the world come to Pinterest to find new ideas every day. It’s where they get inspiration, dream about new possibilities and plan for what matters most. Our mission is to help those people find their inspiration and create a life they love. In your role, you’ll be challenged to take on work that upholds this mission and pushes Pinterest forward. You’ll grow as a person and leader in your field, all the while helping Pinners make their lives better in the positive corner of the internet.<br/><br/>Creating a life you love also means finding a career that celebrates the unique perspectives and experiences that you bring. As you read through the expectations of the position, consider how your skills and experiences may complement the responsibilities of the role. We encourage you to think through your relevant and transferable skills from prior experiences.<br/><br/><em>Our new progressive work model is called PinFlex, a term that’s uniquely Pinterest to describe our flexible approach to living and working. Visit our </em><em>PinFlex</em><em> landing page to learn more. <br/><br/></em>We are looking for inquisitive, well-rounded Backend engineers to join our Core and Monetization engineering teams. Working closely with product managers, designers, and backend engineers, you’ll play an important role in enabling the newest technologies and experiences. You will build robust frameworks &amp; features. You will empower both developers and Pinners alike. You’ll have the opportunity to find creative solutions to thought-provoking problems. Even better, because we covet the kind of courageous thinking that’s required in order for big bets and smart risks to pay off, you’ll be invited to create and drive new initiatives, seeing them from inception through to technical design, implementation, and release.<br/><br/><strong><strong>What You’ll Do:<br/><br/></strong></strong><ul><li>Build out the backend for Pinner-facing features to power the future of inspiration on Pinterest</li><li>Contribute to and lead each step of the product development process, from ideation to implementation to release; from rapidly prototyping, running A/B tests, to architecting and building solutions that can scale to support millions of users</li><li>Partner with design, product, and backend teams to build end-to-end functionality</li><li>Put on your Pinner hat to suggest new product ideas and features</li><li>Employ automated testing to build features with a high degree of technical quality, taking responsibility for the components and features you develop</li><li>Grow as an engineer by working with world-class peers on varied and high impact projects<br/><br/><br/></li></ul><strong><strong>What We’re Looking For:<br/><br/></strong></strong><ul><li>2+ years of industry backend development experience, building consumer or business facing products</li><li>Proficiency in common backend tech stacks for RESTful API, storage, caching and data processing</li><li>Experience in following best practices in writing reliable and maintainable code that may be used by many other engineers</li><li>Ability to keep up-to-date with new technologies to understand what should be incorporated</li><li>Strong collaboration and communication skills<br/><br/><br/></li></ul><strong><strong>Backend Core Engineering Teams:<br/><br/></strong></strong><ul><li>Community Engagement</li><li>Content Acquisition &amp; Media Platform</li><li>Core Product Indexing Infrastructure</li><li>Shopping Catalog </li><li>Trust &amp; Safety Platform</li><li>Trust &amp; Safety Signals</li><li>User Understanding<br/><br/><br/></li></ul><strong><strong>Backend Monetization Engineering Teams: <br/><br/></strong></strong><ul><li>Ads API Platform</li><li>Ads Indexing Platform</li><li>Ads Reporting Infrastructure</li><li>Ads Retrieval Infra</li><li>Ads Serving and ML Infra</li><li>Measurement Ingestion</li><li>Merchant Infra <br/><br/><br/></li></ul>This position is not eligible for relocation assistance.<br/><br/>At Pinterest we believe the workplace should be equitable, inclusive, and inspiring for every employee. In an effort to provide greater transparency, we are sharing the base salary range for this position. The position is also eligible for equity. Final salary is based on a number of factors including location, travel, relevant prior experience, or particular skills and expertise.<br/><br/><em>Information regarding the culture at Pinterest and benefits available for this position can be found here.<br/><br/></em>US based applicants only<br/><br/>$106,113—$219,063 USD<br/><br/><strong><strong>Our Commitment To Diversity:<br/><br/></strong></strong>Pinterest is an equal opportunity employer and makes employment decisions on the basis of merit. We want to have the best qualified people in every job. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic under federal, state, or local law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you require an accommodation during the job application process, please notify accessibility@pinterest.com for support.<br/><br/><strong><strong>Our Commitment To Diversity:<br/><br/></strong></strong>Pinterest is an equal opportunity employer and makes employment decisions on the basis of merit. We want to have the best qualified people in every job. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, protected veteran status, or any other characteristic under federal, state, or local law. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. If you require an accommodation during the job application process, please notify accessibility@pinterest.com for support.<br/><br/>
</div>",$106113- $219063,"Software Engineer, Data"
"Software Engineer, Data Platform",Lyft,12/19/2023,https://www.linkedin.com/jobs/view/3716407381,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Software Engineer II,Microsoft,12/19/2023,https://www.linkedin.com/jobs/view/3763839747,0,https://media.licdn.com/dms/image/C560BAQE88xCsONDULQ/company-logo_100_100/0/1630652622688/microsoft_logo?e=2147483647&v=beta&t=4ft1hh_UdO2TMuqRWlFPHTTr2B3BN0E2LmTE6tEYwJI,"Redmond, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Our world is rapidly transforming. The amount of data each of us consume and create is ever increasing. In fact, the total amount of content in the world is doubling every two years now. People spend 20% of their time looking for information and 60% of people claim to be missing key pieces of data to make decisions daily. All of us must manage an ever-increasing number of processes and systems often while on the go and multitasking. On the OneDrive and SharePoint team, we believe cutting edge technology can help our customers thrive in an information dense world.<br/><br/>We are excited about transforming our customers into “AI natives” where technology augments their ability to achieve more with the files, web pages, news, and other content that people need to get their task done efficiently by providing them timely and actionable notifications that understand their intents, context and adapts to their work habits. We are building a large-scale distributed system on top of SharePoint, O365 Substrate, Azure, a micro-services architecture, Machine Learning and more. As a <strong>Software Engineer II</strong> on our team, you'll approach our problem space with empathy for the change our customers are undergoing with the cloud. We achieve more through partnerships with and providing notification capabilities to many apps across O365 delivering billions on notifications, functioning as scenario and customer experts. We’ll continue to embrace the Microsoft philosophy of an inclusive culture and growth mindset, so we bring fresh perspective to this area of our product portfolio.<br/><br/>Microsoft’s mission is to empower every person and every organization on the planet to achieve more. As employees we come together with a growth mindset, innovate to empower others, and collaborate to realize our shared goals. Each day we build on our values of respect, integrity, and accountability to create a culture of inclusion where everyone can thrive at work and beyond.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Builds knowledge, shares new ideas, and shares pinpoints of engineering tool gaps to improve software developer tools to support other programs, tools, and applications to create, debug, and maintain code for complex product features. </li><li> Helps to identify internal tools and creates tools that will be useful for creating the product, determining if methods are still applicable for the current solution.</li><li>Runs code in simulated, or other non-production environments to confirm functionality and error-free runtime for products with little to no oversight.</li><li>Contributes to efforts to ensure the correct processes are followed to achieve a high degree of security, privacy, safety, and accessibility. </li><li>Checks for visible evidence to demonstrate compliance for product areas.</li><li>Applies best practices to reliably build code that is based on well-established methods while also applying best practices for new code development. </li><li>Demonstrates and maintains an up-to-date understanding of both global and local regulations for technologies and system applications to ensure regulations are met.</li><li>Maintains communication with key partners across the Microsoft ecosystem of engineers.</li><li>Considers partners across teams and their end goals for products to drive and achieve desirable user experiences and fitting the dynamic needs of partners/customers through product development.</li><li>Other: Embody our Culture and Values <br/><br/></li></ul><strong>Qualifications<br/><br/></strong>Required Qualifications:<br/><br/><ul><li>Bachelor's Degree in Computer Science or related technical field AND 2+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#, Java, JavaScript, or Python</li><ul><li>OR equivalent experience</li></ul><li>2+ years experience with developing large high-scale micro services, with service-oriented development and cloud-based systems. <br/></li></ul><strong>Other Requirements<br/><br/></strong>Ability to meet Microsoft, customer and/or government security screening requirements are required for this role. These requirements include but are not limited to the following specialized security screenings:<br/><br/><ul><li>Microsoft Cloud Background Check: This position will be required to pass the Microsoft Cloud background check upon hire/transfer and every two years thereafter. <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>1+ years experience working with cross functional teams <br/><br/></li></ul>Software Engineering IC3 - The typical base pay range for this role across the U.S. is USD $94,300 - $182,600 per year. There is a different range applicable to specific work locations, within the San Francisco Bay area and New York City metropolitan area, and the base pay range for this role in those locations is USD $120,900 - $198,600 per year.<br/><br/>Certain roles may be eligible for benefits and other compensation. Find additional benefits and pay information here: https://careers.microsoft.com/us/en/us-corporate-pay<br/><br/>Microsoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.
      </div>",$94300- $182600,"Software Engineer, Data"
"Software Development Engineer: Entry-Level, 2024",Qumulo,12/19/2023,https://www.linkedin.com/jobs/view/3737053849,0,https://media.licdn.com/dms/image/C560BAQFrP0R-BreLIw/company-logo_100_100/0/1630568149260/qumulo_logo?e=2147483647&v=beta&t=xWycR0cuniRCDnzbhDS53Vx9TpQLwFzP9_0jaFRj98k,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About The Company<br/><br/></strong>Qumulo is the leading file data platform for multi cloud environments, providing outstanding freedom, control, and real-time visibility for file data at substantial scale. Fortune 500 companies, major film studios, and the largest research facilities in the world trust Qumulo to help them innovate with their most important digital files. The Qumulo experience makes file data management simple with continuous new features, a single solution for all workloads, and access to customer success specialists on your schedule.<br/><br/>At Qumulo, we are building an open and collaborative culture where people can do their best work with customers as our magnetic field. We act as owners, we share by default, we are data driven and experimental and as an inclusive workplace, we encourage and celebrate multiple points of view. As part of our culture we believe diversity drives innovation.<br/><br/><strong>About The Position<br/><br/></strong>At Qumulo, we've built a truly outstanding modern file data platform from scratch. Our software runs natively in the public cloud or in private data centers, allowing our customers to truly Scale Anywhere. It’s incredibly exciting work and there is a lot more to do to make our full vision reality. As a new Engineer at Qumulo you will join a feature team and immediately begin writing, testing and deploying production code. Your work will take an innovative product to the next level, see that effort fuel customer innovation, and grow the Qumulo business.<br/><br/>We hire committed, adaptive engineers with a diverse set of backgrounds and who we can depend on to solve problems head on. Our engineers work collaboratively both within the product development organization and across the company to ship a continuously integrated and deployed code base. Engineers at Qumulo work alongside people who have an appetite for collaborative coding environments. It's a community where individual engineers have a voice. Our teams are given the charter to design and build the features that deliver clear value to our customers.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Collaborate with team members on design, code reviews, and pair programming</li><li>Collaborate with team members and area leads on architecture and design of new/updated features</li><li>Contribute to feature development and testing using C, Rust and Python</li><li>Define and implement customer-facing features and internal improvements</li><li>Help debug and fix test failures and product or service issues<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Ability to write well-factored and well-tested code</li><li>Strong grasp of algorithms and data structures, with some experience in distributed systems, database concepts, concurrent programming, or operating systems concepts</li><li>At least one class, internship or personal project using C, C++, Rust, Java, or Go</li><li>Willingness to work collaboratively with a team to solve complex problems</li><li>Finishing a BS or BA in Computer Science or Computer Engineering or equivalent experience<br/><br/></li></ul>Qumulo is an Equal Opportunity Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, disability, military status, or national origin or any other characteristic protected under federal, state, or applicable local law.<br/><br/><ul><li>Please note that employment at Qumulo is contingent upon completion of a satisfactory background check.<br/><br/></li></ul>For more information on our Applicant and Employee Privacy Notice please click on the link below:<br/><br/><strong>http://qumulo.com/applicant-employee-privacy-notice</strong>
</div>",No Salary Info Found,"Software Engineer, Data"
"Software Engineer - New Grad, Distributed Data Systems (2024 Start)",Databricks,12/19/2023,https://www.linkedin.com/jobs/view/3685320555,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Entry Level Software Engineer,SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784098161,0,https://media.licdn.com/dms/image/C560BAQHPrA2XO9lh7g/company-logo_100_100/0/1663564885547/synergisticit_logo?e=2147483647&v=beta&t=biDnkXeeFcJXgnh87P53V9KGn6j1mqUOEQpisfcfR74,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Job Market is Challenging due to more than 150,000 Tech Layoffs in 2022 and in 2023 more than 240,000 layoffs so almost 3,90,00 tech employees have been laid off since 2022 and its still going on . The effect of this has led hundreds of thousands of laid off Tech employees competing with existing Jobseekers.<strong> Entry level Job seekers struggle to get responses to their applications, are getting ghosted after interviews. </strong>In such a scenario the Job seekers need <strong> to differentiate themselves by ensuring to obtain exceptional skills and technologies to be hired by clients as its an employer's market presently and they have a lot of hiring choices.<br/><br/></strong>For more than 12+ years Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.<br/><br/>All Positions are open for all visas and US citizens<br/><br/>We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers.<br/><br/>We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like <strong> apple, google, Paypal, western union, Client, visa, walmart lab</strong>s etc to name a few.<br/><br/>We have an excellent reputation with the clients. Currently, We are looking for <strong> entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers</strong> for full time positions with clients.<br/><br/>Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry<br/><br/><strong> We assist in filing for STEM extension and also for H1b and Green card filing to Candidates <br/><br/></strong>We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.<br/><br/><strong> please check the below links to see success outcomes of our candidates</strong> and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers<br/><br/><strong> https://www.synergisticit.com/candidate-outcomes/ <br/><br/></strong><strong> We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023 <br/><br/></strong>Oracle CloudWorld Event (OCW) Las Vegas 2023/ 2022 | SynergisticIT - YouTube<br/><br/><strong> https://youtu.be/Rfn8Y0gnfL8?si=p2V4KFv5HukJXTrn <br/><br/></strong><strong> https://youtu.be/-HkNN1ag6Zk?si=1NRfgsvL_HJMVb6Q <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=EmO7NrWHkLM <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=OAFOhcGy9Z8 <br/><br/></strong><strong> https://www.youtube.com/watch?v=Yy74yvjatVg <br/><br/></strong>For preparing for interviews please visit <strong> https://www.synergisticit.com/interview-questions/ <br/><br/></strong><strong> We are looking for the right matching candidates for our clients <br/><br/></strong><strong> Please apply via the job posting <br/><br/></strong><strong>Required Skills<br/><br/></strong><strong> REQUIRED SKILLS For Java /Full stack/Software Programmer <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning Positions <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow <br/><br/></strong><strong> If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements. <br/><br/></strong><strong> No phone calls please. </strong> Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates
      </div>",No Salary Info Found,"Software Engineer, Data"
Junior SQL Developer  (US),Patterned Learning Career,12/24/2023,https://www.linkedin.com/jobs/view/3793029048,0,https://media.licdn.com/dms/image/D4D0BAQGaHaR8NJdTNA/company-logo_100_100/0/1702321277719/patterned_learning_ai_career_logo?e=2147483647&v=beta&t=O1x4uQGAgo3QG6K7tOhb6yIeEJo4nKewDo8Dd6krT3I,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong>Junior SQL Developer (US) - Remote Job, 1+ Year Experience<br/><br/></strong><strong>Annual Income:</strong> $65K - $73K<br/><br/><strong>About us:</strong> Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.<br/><br/>Job Description:<br/><br/>As an SQL Developer, you will play a crucial role in designing, implementing, and optimizing database solutions, enabling efficient data storage, retrieval, and manipulation. You will collaborate with cross-functional teams to understand data requirements and deliver effective solutions that meet our clients' needs. This is a unique opportunity to work on diverse projects, tackle complex data challenges, and make a significant impact in the world of data.<br/><br/>Responsibilities:<br/><br/><ul><li>Collaborate with stakeholders to gather data requirements and translate them into efficient SQL queries, stored procedures, and functions. </li><li>Design, develop, and maintain database schemas, ensuring data integrity, security, and performance. </li><li>Write complex SQL queries for data extraction, transformation, and loading (ETL) processes. </li><li>Optimize SQL queries and database performance, identifying and resolving bottlenecks and inefficiencies. </li><li>Develop data validation and quality assurance processes to ensure accuracy and reliability. </li><li>Collaborate with cross-functional teams to integrate SQL code into applications and reporting systems. </li><li>Conduct data analysis to identify trends, patterns, and insights that drive business decisions. </li><li>Stay up-to-date with the latest trends and advancements in SQL and database technologies. <br/><br/></li></ul>Requirements:<br/><br/><ul><li>Bachelor's degree in Computer Science, Information Technology, or a related field. </li><li>Proven experience as an SQL Developer or Database Developer, working with complex databases. </li><li>Strong proficiency in SQL and experience with relational databases (e.g., MySQL, Oracle, SQL Server). </li><li>Solid understanding of database design principles, data modeling, and normalization. </li><li>Proficiency in writing complex SQL queries, stored procedures, and functions. </li><li>Experience with performance optimization and tuning of SQL queries and database indexing. </li><li>Familiarity with ETL processes and tools (e.g., SSIS, Informatica) is a plus. </li><li>Knowledge of data warehousing concepts and dimensional modeling is desirable. </li><li>Strong problem-solving skills and the ability to analyze complex data requirements. </li><li>Excellent attention to detail and a commitment to delivering high-quality solutions. </li><li>Effective communication and collaboration skills to work with cross-functional teams. <br/><br/></li></ul><strong>Why Patterned Learning LLC?<br/><br/></strong>Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.<br/><br/>The pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.<br/><br/>
</div>",$65- $73,"Software Engineer, Data"
AI Engineer,goodfin,12/21/2023,https://www.linkedin.com/jobs/view/3789253614,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Senior Software Engineer,Eleven Recruiting,12/19/2023,https://www.linkedin.com/jobs/view/3763326343,0,https://media.licdn.com/dms/image/D560BAQHaskhtPZ_a5w/company-logo_100_100/0/1688514314328/11recruiting_logo?e=2147483647&v=beta&t=NFSA6wQg_AmouBb0OzH-1iQgFzyBzOyzmsibOKIeA2k,"El Segundo, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>About Eleven Recruiting</strong></p><p>We are a specialized technology staffing agency supporting professional and financial services companies. Why do we stand out in technology staffing? We listen and act as advisors for our candidates on how they can best add value, find interesting projects, and pave a path for career advancement. We advocate for best pay, diversity in tech, and best job-fit for every candidate we place.</p><p><br/></p><p>And our client, a global investment firm, is seeking a Senior Software Engineer to join their team!</p><p><br/></p><p>Senior Software Engineer will spearhead the development of crucial applications. This role is centered around innovating new applications built to scale with modern technology, as well as modernizing our existing application portfolio.</p><p><br/></p><p><strong> Responsibilities: </strong></p><ul><li>Lead the development and innovation of critical applications, focusing on scalability, efficiency, and utilizing cutting-edge technologies.</li><li>Architect and implement solutions that enhance and modernize our existing applications, aligning them with contemporary technical standards.</li><li>Drive the use of cloud-native principles in either Azure or AWS environments to ensure high scalability and resilience of applications.</li><li>Engage in technical design, including database diagramming and system architecture, to create robust and efficient software solutions.</li><li>Collaborate with various teams to integrate cloud data technologies and optimize application performance.</li><li>Work closely with stakeholders to align technological developments with business objectives.</li><li>Mentor and foster the professional growth of IT team members, promoting a culture of continuous learning and improvement.</li></ul><p><br/></p><p><strong>Qualifications:</strong></p><ul><li>Expertise in at least one of the following programming languages: C#/.NET, Java, or Golang.</li><li>Proficiency in cloud services (Azure, AWS) and their application in enterprise environments.</li><li>Familiarity with Python, particularly in the context of data processing or cloud environments.</li><li>Understanding of cloud data technologies and their application in business software.</li><li>Excellent communication and collaborative skills.</li><li>BS/MS in Computer Science, Engineering, or a related discipline.</li><li>Highly Desired: Experience with message-oriented middleware technologies such as Kafka, Redis, or Confluent.</li><li>Highly Desired: Strong foundation in technical design, system architecture, and database diagramming.</li></ul><p><br/></p><p>Location: Los Angeles, CA</p><p>Seniority Level: Mid-Senior level</p><p>Employment Type: Full-Time</p><p>Job Function: Information Technology</p><p>Industry: Financial Services</p><p>Salary: $90-$120/hr</p>
</div>",$90- $120,"Software Engineer, Data"
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789086620,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $160,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$160000- $173000,"Software Engineer, Data"
Data and Platform Engineer,"Honda of America Mfg., Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3790802092,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Software Developer - Remote | WFH,Get It Recruit - Information Technology,12/20/2023,https://www.linkedin.com/jobs/view/3785601014,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Back End Infrastructure Developer and Engineer,Pearpop,12/20/2023,https://www.linkedin.com/jobs/view/3789090660,0,https://media.licdn.com/dms/image/C560BAQEuMIOckaO-GA/company-logo_100_100/0/1658588179114/pearpop_logo?e=2147483647&v=beta&t=bpBmfORXwUD_kFH0oCkt0pCJEVOsjKnrEenl_N2MSyc,"Los Angeles, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>About Pearpop</strong></p><p>Pearpop, the leading Creator Marketing Platform, is revolutionizing the way creators and brands collaborate. With a community of over 200,000 creators and counting, Pearpop is dedicated to helping creators earn a living doing what they love, while providing brands with instant and direct access to relevant, authentic, and brand-safe creators across all major social media platforms. In 2022, Pearpop was recognized as ""Best Influencer Marketing Platform"" by DIGIDAY and named to FAST COMPANY's ""Most Innovative Companies"" List in Social Media.</p><p><br/></p><p><strong>Working at Pearpop</strong></p><p>We're bringing together a smart and passionate team of creative builders to join us as we are a growth stage, high-performance startup. In addition to competitive salaries, we have all the good stuff – equity, generous health and dental insurance, 401(k), and unlimited PTO. This is an in-person role based in our headquarters in Los Angeles; fully-stocked with snacks, beverages, cold brew, and all the good stuff! </p><p> </p><p><strong>Software and Infrastructure Engineer</strong></p><p>We are looking for a back-end developer with a deep passion for building amazing products for an emerging industry, a track record of writing powerful and maintainable code, and a reputation of being reliable and efficient. The candidate should be a hands-on developer in a current role that involves coding, development, and working with cloud infrastructures such as AWS and GCP. As a Software and Infrastructure Engineer, you will have regular contact and discussion with business personnel as well as other employees throughout the organization, including onsite and offsite business and technology team members. </p><p><br/></p><p><strong>Key Responsibilities</strong></p><ul><li>Design, implement, test, validate, and present proposals for multi-tier distributed software solutions</li><li>Build world class APIs to support a suite of growing product offerings</li><li>Expand and optimize our technical environment on AWS and GCP</li><li>Develop and maintain multi-service infrastructures on AWS and GCP</li><li>Jointly develop solutions with the Pearpop Product team</li><li>Quickly troubleshoot and resolve issues</li><li>Handle software requirement analysis and facilitate requirement documentation</li><li>Conduct thorough unit testing on all software solutions</li></ul><p><br/></p><p><strong>What You Bring to the Table</strong></p><p>Must have experience with</p><ul><li>7+ years of experience </li><li>Node.js, JavaScript, MySql, React, NextJS, and Docker</li><li>API Design &amp; Microservices Architecture</li><li>Information architecture and data model design</li><li>Continuous Integration methodologies ( we use Github actions )</li><li>Experience with environments on AWS utilizing AWS API Gateway, Lambdas, RDS, and Cloudfront</li><li>Experience with GCP including GCP Cloud Actions</li><li>Experience using serverless.com framework or Sequelize ORM a plus</li></ul><p><br/></p><p><strong>Compensation: </strong>$110,000 - $230,000 </p><p><br/></p><p><em>Pearpop is an equal opportunity employer. We are committed to creating an inclusive and welcoming environment. All employment is decided on the basis of qualifications, merit, and business need. Pearpop celebrates and embraces diversity.</em></p>
</div>",$110000- $230000,"Software Engineer, Data"
Software Engineer,Jada Systems Inc,12/21/2023,https://www.linkedin.com/jobs/view/3789912240,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Data Engineer,Motion Recruitment Partners LLC,12/21/2023,https://www.linkedin.com/jobs/view/3786725550,0,https://media.licdn.com/dms/image/C4E0BAQGbIGAVD9Ugtg/company-logo_100_100/0/1630587145865/motion_recruitment_partners_llc_logo?e=2147483647&v=beta&t=alBjyOtSVLguJoyqNF0DXJ9Pwg7PtTJhNsISoDSt9QU,"Burbank, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Dice is the leading career destination for tech experts at every stage of their careers. Our client, Motion Recruitment Partners, LLC, is seeking the following. Apply via Dice today!<br/><br/>Looking for someone with a strong background working as a data engineer pulling and extracting data, as well as building pipelines &amp; distributed systems. The ideal candidate will have strong experience with Python, PySpark, SQL, and AWS.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>Experience with Python programming </li><li>Experience with PySpark </li><li>Strong AWS experience </li><li>Comfortable working within several SQL databases </li><li>Experience with one or more data warehousing technology <br/><br/></li></ul>What You Will Be Doing<br/><br/>Tech Breakdown<br/><br/><ul><li>50% Building Pipelines with PySpark </li><li>50% Data cleaning and integration <br/><br/></li></ul>Daily Responsibilities<br/><br/><ul><li>100% Hands On <br/><br/></li></ul>The Offer<br/><br/><ul><li>Competitive base salary and equity offered <br/><br/></li></ul><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical &amp; Dental Insurance </li><li>Health Savings Account (HSA) </li><li>401(k) with 3% match </li><li>Unlimited Paid Time Off </li><li>Pre-tax Commuter Benefit </li><li>Unlimited remote access </li><li>Flexible work from home schedule (onsite 2-3 days/month) </li><li>On-site Gym <br/><br/></li></ul>Applicants must be currently authorized to work in the United States on a full-time basis now and in the future.
      </div>",No Salary Info Found,"Software Engineer, Data"
Data Engineer,"VMC Soft Technologies, Inc",12/21/2023,https://www.linkedin.com/jobs/view/3789298488,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
"Data Engineer, Data Platform",Grammarly,12/25/2023,https://www.linkedin.com/jobs/view/3656898066,0,https://media.licdn.com/dms/image/C560BAQFroT18wpIblQ/company-logo_100_100/0/1669669290715/grammarly_logo?e=2147483647&v=beta&t=ztA7DBsCxjynNbw6oGlEHqtgqJneLWUJ1rfYbYVi91A,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>Grammarly is excited to offer a </em><em>remote-first hybrid working model</em><em>. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.<br/><br/></em><em>All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków. </em><em>This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.<br/><br/></em><em>Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.<br/><br/></em><strong>The opportunity <br/><br/></strong>Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.<br/><br/>To achieve our ambitious goals, we’re looking for a Data Engineer to join our Data Engineering Platform team. This person will build highly automated, low latency core datasets that will help data engineers and end users across Grammarly to work with analytical data at scale.<br/><br/>Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.<br/><br/><strong>Your impact<br/><br/></strong>As a Data Engineer on our Data Engineering Platform team, you will:<br/><br/><ul><li>Drive improvements to make our analytics effortless by creating and adjusting core data models and storage structures, all while understanding the needs of our users. </li><li>Make analytical data and metrics usable within a few minutes of real world events occuring, and build streaming processes for the output derived events and aggregate data.</li><li>Model structure, storage, and access of data at very high volumes for our data lakehouse.</li><li>Improve developer productivity and self-serve solutions by contributing components to our stream data processing framework(s).</li><li>Own data engineering's infrastructure-as-code for provisioning services that allow our engineers to deploy mature software installations within a few hours.</li><li>Build a world-class process that will allow our systems to scale.</li><li>Mentor other back-end engineers on the team and help them grow.</li><li>Build and contribute to AWS high-scale distributed systems on the back-end.<br/><br/></li></ul><strong>We’re Looking For Someone Who<br/><br/></strong><ul><li>Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.</li><li>Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.</li><li>Is able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub where the team is based.</li><li>Has experience with Python, Scala, or Java.</li><li>Has experience with designing database objects and writing relational queries</li><li>Has experience designing and standing up APIs and services.</li><li>Has experience with system design and building internal tools.</li><li>Has experience handling applications that work with data from data lakes.</li><li>Has at least some experience building internal Admin sites.</li><li>Has good knowledge of and at least some experience with AWS (or, alternatively, has deep expertise in Azure or GCE and is willing to learn AWS in a short time frame).</li><li>Can knowledgeably choose an open source or third-party service to accomplish what they need or, alternatively, can devise a quick and simple solution on their own.<br/><br/></li></ul><strong>Support for you, professionally and personally<br/><br/></strong><ul><li>Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.</li><li>A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs. <br/><br/></li></ul><strong>Compensation And Benefits<br/><br/></strong>Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:<br/><br/><ul><li>Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)</li><li>Disability and life insurance options</li><li>401(k) and RRSP matching </li><li>Paid parental leave</li><li>Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days </li><li>Home office stipends</li><li>Caregiver and pet care stipends</li><li>Wellness stipends</li><li>Admission discounts</li><li>Learning and development opportunities<br/><br/></li></ul>Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.<br/><br/>Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.<br/><br/><strong>United States<br/><br/></strong>Zone 1: $167,000 - $242,000/year (USD)<br/><br/>Zone 2: $150,000 – $218,000/year (USD)<br/><br/>Zone 3: $142,000 – $206,000/year (USD)<br/><br/>Zone 4: $134,000 – $194,000/year (USD)<br/><br/><strong>We encourage you to apply<br/><br/></strong>At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).<br/><br/><em>Please note that EEOC is optional and specific to US-based candidates.<br/><br/></em>#NA<br/><br/><em>All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.<br/><br/></em>
</div>",$167000- $242000,"Software Engineer, Data"
SOFTWARE ENGINEER,The Christian Post,12/24/2023,https://www.linkedin.com/jobs/view/3791388764,0,https://media.licdn.com/dms/image/C4E0BAQGL9uO9iZcg5A/company-logo_100_100/0/1630585505443/the_christian_post_logo?e=2147483647&v=beta&t=TSQlztTAS3udTZwi_-Sqn4MBCTQpk_witMG-6jkNUqo,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Software Engineer<br/><br/>(Washington DC),<br/><br/><ul><li>Dsgn, dvlp, &amp; maint machine learning systems that can find popular content, text classifiers that can distinguish content quality &amp; categories, &amp; recommendation systems that generate user-oriented content. (30% of time)</li><li>Dsgn, dvlp, &amp; maint search engines that find the best-matched content w/keywords &amp; other signal data, &amp; support personalized search. (30% of time).</li><li>Dsgn, dvlp, &amp; maint content mgmt systems that present content to end-users &amp; allow administrators to mng content. (15% of time)</li><li>Dsgn, dvlp, &amp; maint web crawlers that collect news, books, blogs, videos, podcasts, &amp; other data from the internet. (15% of time)</li><li>Dsgn, dvlp, &amp; maint data processing systems that clean &amp; re-categorize crawled data into well organized data. (10% of time). Must have a Mstrs deg in IT, Comp Sci or reltd field + 2 yrs exp as a Software Engineer, + 1 yr on proficiency in JavaScript, Python, or PyTorch machine learning framework. Email resume to The Christian Post at hr@christianpost.com.</li></ul>
</div>",No Salary Info Found,"Software Engineer, Data"
Entry Level Software Developer,SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784094795,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Data Engineer,ASCENDING Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3790307654,0,https://media.licdn.com/dms/image/C4D0BAQG4H6mBuWVGQw/company-logo_100_100/0/1631372273839/ascendingllc_logo?e=2147483647&v=beta&t=HqSlWBYB2Htxq8mAj5GFZEzDCI-FyaW7xdBt4yqDPEo,"Fairfax, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Full-time, 100% Remote<br/><br/>Available for W-2 or 1099 Individual. <br/><br/></strong>Our client, one of the largest Amazon Web Services (AWS) partners for data services, is looking for a true Mid level Big Data Engineer to contribute to join their team of technologists to build and contribute to large-scale, innovative projects. Technological and career growth opportunities are a natural and every day part of the working environment.<br/><br/><strong>Responsibilities:<br/><br/></strong><ul><li>Analyze system requirements and design responsive algorithms and solutions.</li><li>Use big data and cloud technologies to produce production quality code.</li><li>Engage in performance tuning and scalability engineering.</li><li>Work with team, peers and management to identify objectives and set priorities.</li><li>Perform related SDLC engineering activities like sprint planning and estimation.</li><li>Work effectively in small agile teams.</li><li>Provide creative solutions to problems.</li><li>Identify opportunities for improvement and execute.<br/><br/></li></ul><strong>Requirements:<br/><br/></strong><ul><li>Minimum 4 years of proven professional experience working in the IT industry.</li><li>Bachelor's in Computer Science or related domain.</li><li>Experience with cloud based Big Data technologies.</li><li>Experience with big data technologies like Hadoop, Spark and Hive.</li><li>AWS experience (S3 and EMR).</li><li>Proficiency in Hive / Spark SQL / SQL. Experience with Spark.</li><li>Experience with one or more programming languages like Scala &amp; Python &amp; Java.</li><li>Ability to push the frontier of technology and independently pursue better alternatives.<br/><br/></li></ul>Thanks for applying!<br/><br/>Powered by JazzHR<br/><br/>Hv70rUP3Sg
      </div>",No Salary Info Found,"Software Engineer, Data"
"Software Engineer (DS, DE, DevOps aspects)",Tequarian Corp.,12/19/2023,https://www.linkedin.com/jobs/view/3790010781,0,https://media.licdn.com/dms/image/D4E0BAQHNccxvxyLRFg/company-logo_100_100/0/1681793192383/tequarian_corp_logo?e=2147483647&v=beta&t=F0Ft2FE2l6LZryqDatuYlMgefdH9ykwPEM4-9i6aY18,"Springfield, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Security Clearance: </strong>Active Top Security Clearance</p><p><strong>Description:</strong></p><p>We are looking for a Software Engineer with strong full-stack experience to “own” the whole project. This position has the autonomy and freedom to set technical direction, engage with the customer, and build the roadmap for the product. In this position, the Software Engineer also works with interesting datasets that have direct mission impact. This position also has direct engagement with end-users.</p><p>Come join our team!</p><p><strong>Roles &amp; Responsibilities:</strong></p><ul><li>Consult with stakeholders to understand their business needs and identify potential process improvements</li><li>Write well-documented and maintainable code using good software engineering practices</li><li>Deliver new features to the customer upon request (frontend and/or backend features)</li><li> Integrate new algorithms into larger software modules, performing integration tests and other CI/CD functions before deployment</li><li>Manage Docker containers as part of deployments to test and production environments</li><li>Prioritize development tasks and issues using agile methodology and the Atlassian Tool Suite (JIRA, Confluence, Bitbucket)</li></ul><p><strong>Required Qualifications:</strong></p><ul><li>Active Top Security Clearance</li><li>Proficiency in one or more of the following languages: Python, TypeScript, JavaScript, and SQL</li><li>Experience developing REST APIs with web frameworks based in Node.js or Python (e.g. Fastify, Aiohttp, or similar)</li><li>Experience working with relational databases and writing/maintaining SQL scripts for data-driven web applications.</li><li>Ability to manage Docker containers or use similar containerization technologies to ensure reliable and secure deployments.</li><li>Ability to test your code using a combination of unit and integration tests.</li><li>Experience maintaining and upgrading servers as needed.</li><li>Excellent verbal and written communication skills to consult with customers, understand their business needs, and identify potential process improvements.</li><li>Maximum 36 hours on site per week with potential for hybrid work some weeks.</li></ul><p><strong>Desired:</strong></p><ul><li> Active TS / SCI clearance with CI-Poly</li><li> Experience with Oracle database services</li><li> Experience writing backend REST API code using Fastify (Node.js) and Aiohttp (Python) web frameworks</li><li>Experience in frontend UI development using JavaScript/TypeScript, or a frontend framework (e.g., React, Angular, Vue)</li><li> Experience working with CI/CD pipelines using Gitlab, Jenkins, or similar tools</li><li>Experience with Kubernetes, or similar container orchestration tools</li><li>Experience working with NumPy, Pandas, scikit-learn, or similar data science / analytics libraries</li><li>Experience retraining machine learning models on new data and validate updated metrics</li><li>Annually review and calibrate predictive models and pipelines</li><li>Explore and analyze new/unstructured data sources and deliver insights to customers</li></ul>
</div>",No Salary Info Found,"Software Engineer, Data"
"Senior Software Engineer, Backend (SQL, Python)",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788649078,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Python Data Engineer,"Logic20/20, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3789083990,0,https://media.licdn.com/dms/image/D560BAQEovQVnyz6Ewg/company-logo_100_100/0/1690416645830/logic20_20_inc__logo?e=2147483647&v=beta&t=IgKM0xTeIid2FOvpn1svXQYD8yfsnnE7JrlQIOEdCJQ,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Logic20/20 invests in being a “Best Company to Work For,” where talented people come together to deliver exceptional solutions. We bring clarity, insights, and optimization to enterprise organizations spanning technology, telecommunications, utilities, healthcare, and more.<br/><br/>We thrive as <strong>One Team</strong>, built on values:<br/><br/><ul><li>We Foster a Culture of We by prioritizing connection and collaboration. </li><li>We Drive toward Excellence by investing in professional growth and cultivating thought leadership. </li><li>We Act with Integrity by doing the right thing and bringing our best selves to the table. <br/><br/></li></ul>To make it all possible, we’ve created programs, resources, and benefits that promote connection and help you evolve your career.<br/><br/><strong>Job Description<br/><br/></strong>We are looking for a Data Engineer to join our Advanced Analytics practice to work on interesting projects to help our clients scale their data solutions to make data-driven decisions.  <br/><br/>As a Data Engineer, you’ll work closely with the client to understand both their business processes and analytics needs to design and build data pipelines and cloud data solutions. You will have the opportunity to guide your client through best practices in data lake, data processing, and data pipeline design to help them achieve their business goals.<br/><br/>You will collaborate with your team including analysts, dashboard developers, and technical project managers to design solutions and work together to deliver a world-class solution.  <br/><br/>The ideal candidate will have the balance of technical skills and business acumen to help the client better understand their core needs while understanding technical limitations. <br/><br/><strong>About you:<br/><br/></strong><ul><li>Collaborative partner who can patiently communicate at the appropriate level to both business and technology teams to understand business needs and pain points</li><li>Creative in meeting the client’s core needs with their technology  </li><li>Determined and able to manage obstacles while maintaining a positive outlook </li><li>Self-driven lifelong learner passionate about learning new data tools and best practices  <br/><br/></li></ul><strong>What we offer our consultants:   <br/><br/></strong><ul><li>Working on challenging, impactful projects that push the edge of technology </li><li>Experience working with both large enterprise clients and mid-sized clients  </li><li>Progressive responsibilities that encourage ownership and practice leadership  </li><li>Opportunity to learn and gain experience in complimentary skills such as meeting facilitation, big data processing, project management, data science, and visual analytics  </li><li>Training and certification opportunities to support your career now and after Logic20/20  </li><li>Various opportunities to give back to the community through company-sponsored events  <br/><br/></li></ul><strong>About The Team<br/><br/></strong>The Logic20/20 Advanced Analytics team is where skilled professionals in data engineering, data science, and visual analytics join forces to build simple solutions for complex data problems. We make it look like magic, but for us, it’s all in a day’s work. As part of our team, you’ll collaborate on projects that help clients spin their data into a high-performance asset, all while enjoying the company of kindred spirits who are as committed to your success as you are. And when you’re ready to level up in your career, you’ll have access to the training, the project opportunities, and the mentorship to get you where you want to go.<br/><br/>“We build an environment where we really operate as one team, building up each other’s careers and capabilities.” – Adam Cornille, Senior Director, Advanced Analytics<br/><br/><strong>Qualifications<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>5+ years of data engineering experience </li><li>Strong experience designing and developing ETL and data pipelines with Python</li><li>Experience working with AWS Data Analytics stack: Amazon Athena, AWS Glue, etc. </li><li>Experience working with businesses to understand the appropriate data model (relational, tabular, transactional) for their data solution </li><li>Understanding of data modeling (such as Kimball, Inman, Data Vault design approaches) </li><li>Excellent foundation of consulting skills: analytical, written and verbal communication, and presentation skills </li><li>Demonstrated ability to identify business and technical impacts of user requirements and incorporate them into the project schedule  </li><li>Deep experience designing and building ELT jobs to move and transform data from various source types and performing exploratory data analysis, data cleansing, and aggregation <br/><br/></li></ul><strong>Preferred:<br/><br/></strong><ul><li>Experience with Terraform, Star schema, and PySpark</li><li>Experience working in the utility industry<br/><br/></li></ul>Additional Information<br/><br/>All your information will be kept confidential according to EEO guidelines.<br/><br/>Compensation range: $140,000 - $173,000 annually, depending on experience<br/><br/><strong>About Logic20/20<br/><br/></strong>To learn more about Logic20/20, please visit: https://www.logic2020.com/careers/life-at-logic<br/><br/><strong>Core Values <br/><br/></strong>At Logic20/20, we are guided by three core values: Drive toward Excellence, Act with Integrity &amp; Foster a Culture of We. These values were generated and agreed upon by our employees—and they help us pursue our goal of being one of the best companies to work for and to work with. Learn more at https://www.logic2020.com/company/our-values.<br/><br/><strong>Logic20/20 Benefits<br/><br/></strong>Why Logic20/20? It’s our goal to be one of the best companies to work for. One piece of the puzzle is an evolving set of benefits that extend past medical, dental, and 401(k).<br/><br/>You will have<br/><br/><ul><li>PTO &amp; Paid Holidays – Worry-free time off to recharge and pursue your personal goals </li><li>Community &amp; Committees – As part of our “Culture of We,” Logic20/20 invests in providing many social, interest, and learning opportunities </li><li>Referral Programs &amp; Bonuses – Employee, project, and sales referral programs with paid incentives <br/><br/></li></ul><strong>Equal Opportunity Statement <br/><br/></strong>We believe that people should be celebrated: for their talents, ideas, and skills, but most of all, for what makes them unique. We prohibit harassment and/or discrimination based on age, race, creed, color, religion, sex, national origin, ancestry, disability status, veteran status, sexual orientation, gender identity or expression, genetic information, marital status, citizenship status, or any other basis as protected by federal, state, or local law.<br/><br/>To learn more about our DE&amp;I initiatives, please visit: https://www.logic2020.com/company/diversity-equity-inclusion<br/><br/><strong>Privacy Policy <br/><br/></strong>During the recruitment and hiring process, we gather, process, and store some of your personal data. We consider data privacy a priority. For further information, please view our company privacy policy.
      </div>",$140000- $173000,"Software Engineer, Data"
Software Engineer (Python),Criterion Systems,12/20/2023,https://www.linkedin.com/jobs/view/3790455532,0,https://media.licdn.com/dms/image/C560BAQGEcr6IomRT2A/company-logo_100_100/0/1677688224187/criterion_systems_logo?e=2147483647&v=beta&t=gLGQiIn2JaVL26fwQWiZAN72PRjSINn7mqBHLSfEUag,"Sterling, VA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Criterion Systems, we developed a different kind of business—a company whose real value is a reputation for excellence built upon the collective skills, talents, perspectives, and backgrounds of its people. By accepting a position with Criterion Systems, you will join a group of professionals with a collaborative mindset where we share ideas and foster professional development to accomplish our goals. In addition to our great culture, we also offer competitive compensation and benefit packages, company-sponsored team building events, and advancement opportunities. To find out more about how Criterion can help you take your career to the next level please visit our website www.criterion-sys.com. <strong>Criterion Systems is a Military/Veteran Friendly Company therefore we encourage Veterans to apply.<br/><br/></strong>We are seeking a mission-focused <strong>Software Engineer with Python experience </strong>to support and contribute to our government customer’s success in <strong>Sterling, Virginia</strong>!<br/><br/>***<strong>ACTIVE SECURITY CLEARANCE REQUIRED</strong>***<br/><br/>This position is on a program that is at the forefront of developing and operating Geospatial Intelligence analysis software. This team builds and maintains an exceptionally powerful platform enabling our users to address challenging real-world problems by converting disparate data into actionable information. They work directly with operational users to design, develop, and maintain capabilities that empower analysts to create actionable intelligence from the massive volumes of Geospatial Intelligence data to give our intel and combat organizations the decision advantage over our near-peer adversaries.<br/><br/>As a Software Developer, you will work collaboratively to enhance the analysis system by leveraging proprietary features and integrating capabilities from diverse systems. Additionally, you will collaborate in the design, development, testing, and integration providing frequent user interaction and feedback on the value you bring to the mission.<br/><br/><strong>Required Experience, Education, Skills &amp; Technologies<br/><br/></strong><ul><li>An active Top Secret or TS/SCI security clearance, preferably with CI polygraph.</li><li>Seven (7) or more years of experience in software development (analysis, design, development, testing, deployment, maintenance) required. </li><li>Bachelor’s degree or equivalent experience in a related field in lieu of a degree. </li><li>Understanding of the Software Development Life Cycle (SDLC). </li><li>Must have demonstrated experience developing with modern languages such as Python, Ruby, Clojure, Java, JavaScript, etc. </li><li>Python programming language experience is highly preferred. </li><li>Experience designing, developing, documenting, testing, and debugging software that contains logical and mathematical solutions to problems. </li><li>Demonstrated experience using rapid prototyping and Agile-based software development methodologies.<br/><br/><br/></li></ul><strong>Preferred Experience, Education, Skills &amp; Technologies<br/><br/></strong><ul><li>Experience with Computer Vision (CV). </li><li>Understanding of machine learning concepts. </li><li>Experience integrating multiple applications. </li><li>Experience developing and implementing software enhancements to mission systems in other Government agencies. </li><li>Experience building scalable solutions to mission problems. </li><li>Experience with development in microservice-based architectures. </li><li>Experience with Docker, Kubernetes, Redis, Kafka, SciPy, NumPy, Pandas. </li><li>AWS API experience. </li><li>AWS Certification (Developer, DevOps, and/or Architect, etc.) </li><li>CompTIA Security + certification<br/><br/><br/></li></ul><strong><em>Security Clearance Level<br/><br/></em></strong><ul><li>Top Secret or TS/SCI required, Polygraph preferred<br/><br/><br/></li></ul><strong><em>Certification<br/><br/></em></strong><ul><li>AWS Certification (Developer, DevOps, and/or Architect, etc.) preferred</li><li>CompTIA Security + certification preferred<br/><br/><br/></li></ul><strong><em>Work Schedule<br/><br/></em></strong><ul><li>Full-time on-site at designated facility<br/><br/><br/></li></ul><strong>Benefits Offered<br/><br/></strong><ul><li>Medical, Dental, Vision, Life Insurance, Short-Term Disability, Long-Term Disability, 401(k) match, Tuition/Training Assistance, Parental Leave, Paid Time Off, and Holidays.<br/><br/><br/></li></ul><em>Criterion Systems, LLC and its subsidiaries are committed to equal employment opportunity and non-discrimination at all levels of our organization. We believe in treating all applicants and employees fairly and make employment decisions without regard to any individual’s protected status race, ethnicity, color, national origin, ancestry, religion, creed, sex/gender, gender identity/gender expression, sexual orientation, physical and mental disability, marital/parental status, pregnancy (including childbirth, lactation, and related medical conditions), age, genetic information (including characteristics and testing), military and veteran status, or any other characteristic protected by law. For our complete EEO/AA and Pay Transparency statement, please visit </em><em>https//careers-criterion-sys.icims.com/.</em>
</div>",No Salary Info Found,"Software Engineer, Data"
Data Solutions Engineer,Analytica,12/20/2023,https://www.linkedin.com/jobs/view/3785044139,0,https://media.licdn.com/dms/image/C4E0BAQGyzLU9Qb95hw/company-logo_100_100/0/1658342420509/analytica_inc_logo?e=2147483647&v=beta&t=wF68HG0sSTrJ2mQejOakqwBKKS6YFrqcLmgQHiH6iOI,"Washington, DC","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>ANALYTICA is seeking a <strong>Data Solutions Engineer</strong>to support a federal government client in the DC metro area (Note - your work location is REMOTE). In this assignment, you will be a team member serving the client in advancing the customers use data, metadata, as well as explore new technologies to better meet those needs.<br/><br/>This is a mission that takes some serious smarts, intense curiosity and a background in developing data solutions across the data lifecycle.<br/><br/>Analytica has been recognized by Inc. Magazine as the fastest-growing private US small business. We work with U.S. government customers in health, civilian, and national security missions. As a core member you’ll work with a diverse team of professionals to solution matters, architect nuisances, and come up with alternatives. We offer competitive compensation with opportunities for bonuses, employer paid health care, training and development funds, and 401k match.<br/><br/><strong>Responsibilities include (But Are Not Necessarily Limited To):</strong></p><ul><li>Research, design, build, optimize and maintain reliable, efficient, and accessible data models, systems and pipelines/APIs etc.</li><li>Support, with guidance, the analytic and/or operational use of data.</li><li>Align closely with Enterprise partners in data science, architecture, governance, infrastructure, and security to apply standards and optimize production environments and practices.</li><li>Collaborate with business owners to optimize data collection, movement, storage, and usage to data process and data quality.</li><li>Convert concepts &amp; ideas into workable prototypes (custom or COTS products) for client reviews and acceptance.</li><li>Translate business needs into:<ul><li>data architecture solutions development within supported data systems.</li><li>data orchestration pipelines (source to target analysis &amp; recommendations), data sourcing, cleansing, augmentation and quality control processes within supported data systems.</li><li>Prototype, test and integrate new data tools (i.e. data features and functionality) as defined by the product owners and business teams</li></ul></li></ul><p>Competency and skill set will determine level of placement within the posted job family.<br/><br/><strong>Qualifications:</strong></p><ul><li>Bachelor’s degree incomputer science, information systems management or similarly related degree.</li><li>7+ years of professional data solutions development and implementation experience with:<ul><li>AWS (Glue, Athena, API Gateway)</li><li>SQL, NoSQL</li><li>Data developments with modeling tools such as Neo4J, Erwin, Embarcadero, transforming logical, physical, conceptual, reverse engineering &amp; forward engineering.</li><li>Development with Alation and/or EASparx</li><li>Data Movement tools such as Informatica &amp; others…</li><li>Unit testing</li><li>RESTful API Development</li><li>Desire and willingness to learn new data tools</li></ul></li><li>​​​Has an Agile mindset and iterative development process background<ul><li>Help promote a culture of diversity and inclusion within the department and the larger organization</li><li>Value different ideas and opinions</li><li>Listen courageously and remain curious in all that you do</li></ul></li><li>CMS data experience a must</li><li>CMS Public Trust clearance, EUA highly preferred</li></ul><p><strong>Valuable Experience:</strong></p><ul><li>AWS CDK and/or other AWS services (or comparable cloud data solutioning tools)</li><li>Experience with Git and CICD pipelines</li><li>Relational database design</li><li>Microservices / Containers (Docker, Kubernetes)</li><li>Informatica Intelligent Cloud Services (IICS)</li><li>Prior experience with CMS, preferably within clinical quality or standards area</li></ul><p><br/><strong>About</strong><strong>ANALYTICA</strong>: Analytica is a leading consulting and information technology solutions provider to public sector organizations supporting health, civilian, and national security missions. Founded in 2009 and headquartered in Bethesda, MD., the company is an established8(a) small businessthat has been recognized by<em>Inc. Magazine</em>each of the past three years as one of the 250 fastest-growing companies in the U.S. Analytica specializes in providing software and systems engineering, information management, analytics &amp; visualization, agile project management, and management consulting services. The company is appraised by the Software Engineering Institute (SEI) atCMMI® Maturity Level 3and is anISO 9001:2008 certifiedprovider.<br/><br/>As a federal contractor, Analytica is required to verify that all employees are fully vaccinated against COVID-19. If you receive an offer and are unable to get vaccinated for religious or medical reasons, you may request a reasonable accommodation.<br/><br/></p>
</div>",No Salary Info Found,"Software Engineer, Data"
Software Engineer - entry level,"Constellation Technologies, Inc",12/20/2023,https://www.linkedin.com/jobs/view/3785088930,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Full Stack Web Developer - US Residents Only,Team Remotely Incorporation,12/25/2023,https://www.linkedin.com/jobs/view/3793399916,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Junior Software Development Engineer - US Residents Only,Team Remotely Incorporation,12/25/2023,https://www.linkedin.com/jobs/view/3793398967,0,https://media.licdn.com/dms/image/D4D0BAQFKPwUb2y1chw/company-logo_100_100/0/1702987730303?e=2147483647&v=beta&t=-X5LVvheBqm_7DpHnmichw7-gf09NLhB7Tq6GJJcKm8,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong> Junior Software Development Engineer - US Residents Only, 1 year experience, remote)<br/><br/></strong>Team Remotely Inc. is a staffing and recruitment agency that offers a comprehensive solution for talent acquisition, including sourcing, vetting, pay rolling, and managing talent. Whether you need contract staffing, direct hire, direct sourcing, talent pools, or diversity initiatives, our model can support your hiring strategy.<br/><br/><strong> Hiring Type:</strong> Full-Time<br/><br/><strong> Base Salary:</strong> $60K-$70K Per Annum.<br/><br/><strong> How to Apply:</strong> Please visit teamremotely.com to learn more &amp; apply.<br/><br/><strong>Description:<br/><br/></strong>As a Junior Software Development Engineer, you will play a crucial role in the design, development, and maintenance of our software applications. You will work closely with senior engineers and collaborate with cross-functional teams to deliver high-quality solutions. This is an exciting opportunity to kick-start your career in software development and contribute to innovative projects in a supportive and collaborative environment.<br/><br/><strong>Responsibilities:<br/><br/></strong>Collaborate with the development team to understand project requirements and objectives<br/><br/>Participate in the entire software development lifecycle, from design to deployment<br/><br/>Write clean, efficient, and maintainable code following best practices and coding standards<br/><br/>Contribute to the development of both front-end and back-end components<br/><br/>Collaborate with designers to ensure a visually appealing and user-friendly interface<br/><br/>Integrate APIs and web services to enable seamless communication between different systems<br/><br/>Conduct testing and debugging to ensure the functionality and performance of applications<br/><br/>Participate in code reviews and provide constructive feedback to improve code quality<br/><br/>Stay up-to-date with the latest software development trends and technologies<br/><br/>Document technical specifications and project details<br/><br/><strong>Qualifications:<br/><br/></strong>Bachelor's degree in Computer Science, Software Engineering, or a related field (or equivalent work experience)<br/><br/>Solid understanding of software development principles and best practices<br/><br/>Proficiency in at least one programming language (e.g., Java, C++, Python, Ruby)<br/><br/>Familiarity with front-end development languages such as HTML, CSS, and JavaScript<br/><br/>Knowledge of relational databases and SQL<br/><br/>Understanding of version control systems (e.g., Git)<br/><br/>Strong problem-solving and analytical skills<br/><br/>Excellent communication and collaboration abilities<br/><br/>Ability to work independently and within a team<br/><br/>Eagerness to learn and adapt to new technologies<br/><br/><strong>Preferred Qualifications:<br/><br/></strong>Experience with software development projects (personal or professional)<br/><br/>Familiarity with front-end frameworks/libraries like React, Angular, or Vue.js<br/><br/>Knowledge of back-end frameworks (e.g., Spring, Django, Ruby on Rails)<br/><br/>Exposure to cloud platforms such as AWS, Azure, or Google Cloud<br/><br/>Understanding of Agile development methodologies<br/><br/>Basic understanding of software testing principles and methodologies<br/><br/><strong>Benefits:<br/><br/></strong>Flexible vacation, unlimited paid holidays, and paid sick days<br/><br/>401(k) with up to 2% employer match<br/><br/>Health, vision, and dental insurance<br/><br/><strong> Why work with Team Remotely?<br/><br/></strong>Team Remotely Inc. is a staffing platform offering a seamless experience for employers and candidates. Employers can post job openings and specify their requirements, while candidates can create profiles and upload resumes.<br/><br/>The team of Team Remotely continuously learns and adapts based on previous successful placements, constantly improving its matching capabilities. This ensures that the recommendations provided by Team Remotely are tailored and accurate, increasing the likelihood of a successful match between employers and candidates. By providing intelligent and data-driven solutions, they strive to enhance the efficiency and effectiveness of the hiring process, ultimately helping companies find the best talent and individuals find their dream jobs.<br/><br/>
</div>",$60- $70,"Software Engineer, Data"
Software Engineer,KBX,12/19/2023,https://www.linkedin.com/jobs/view/3755153315,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
"Software Engineer, Android - Slack (Multiple Levels)",Slack,12/19/2023,https://www.linkedin.com/jobs/view/3735168310,0,https://media.licdn.com/dms/image/C560BAQG-22OtXJPGpA/company-logo_100_100/0/1630564800006/slack_logo?e=2147483647&v=beta&t=hh7A44UywJviR0xMjwHJFgL-Ye-BjNBBqXkyzuQD_VE,Greater Phoenix Area,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.<br/><br/></em>Job Category<br/><br/>Software Engineering<br/><br/>Job Details<br/><br/><strong>About Salesforce<br/><br/></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/><strong>About Slack<br/><br/></strong>Slack is your Digital HQ – a place where work flows between your people, systems, partners, and customers. From Fortune 100 companies to corner markets, millions of people around the world use Slack to connect their teams, unify their systems, and drive their business forward.<br/><br/>Slack breaks down communication silos inside and beyond your organization by bringing teams and tools together around common goals, projects and processes in channels and in Slack Connect. It removes the limits of physical walls, giving people the flexibility to do their best work where, when and how they prefer with features like huddles and clips. And it empowers everyone to automate common tasks with apps and workflows. In this digital-first era, Slack’s mission is to make people’s work lives simpler, more pleasant, and more productive.<br/><br/>A taste of our scale and reach:<br/><br/><ul><li>Slack delivers 300k+ messages per second</li><li>77% of the fortune 100 use Slack</li><li>150+ countries have daily active users in Slack </li><li>To date, 1.79 trillion messages have been sent on Slack </li><li>2.65 billion actions are taken in Slack each day</li><li>Slack has 200k+ paid customers</li><li>Users are spending a combined 243 million minutes per week in Huddles</li><li>We're looking for people who are passionate about crafting phenomenal Android applications.<br/><br/></li></ul>You've been around for a few API levels and you know how to delight Android users. You've got an eye for the alluring Android design our users expect and an attention to detail down to the very last density independent pixel. You know your way around the View hierarchy and are eager to partner with Product and Design to craft efficient, performant, and delightful user experiences. You like building for the long term and value patterns and structures that allow for maximum flexibility in a constantly evolving product.<br/><br/>We are looking for feature, infrastructure, and performance engineers to take our Slack Android app to the next level. As an Android Engineer, you will work with a cross-disciplinary team, using your extensive knowledge of building applications across a wide array of Android devices to make the Slack experience on Android be the best it can possibly be.<br/><br/>Slack on Android is used by millions of people every week - we need engineers who want to make that experience as enjoyable as possible.<br/><br/>Slack has a positive, diverse, and supportive culture; we look for people who are curious, inventive, and work to be a little better every single day. In our work together we aim to be smart, humble, hardworking and above all, collaborative.<br/><br/><strong>What You Should Have:<br/><br/></strong><ul><li>At least 4+ years of mobile engineering experience, ideally in a team environment</li><li>A related technical degree required</li><li>Experience developing with Kotlin</li><li>Extensive understanding of Android framework components and their respective lifecycles</li><li>Strong computer science fundamentals: data structures, algorithms and programming languages</li><li>Experience working closely with product teams, designers, and other developers to create a truly delightful mobile experience</li><li>Current and detailed knowledge of the capabilities of different Android API levels</li><li>Experience developing highly performant Java code and view layouts and the ability to diagnose performance bottlenecks</li><li>A disciplined approach to development, testing, documentation and code structure in a team environment</li><li>A familiarity with the Android tool ecosystem for development, testing, debugging, and performance benchmarking</li><li>An excellent understanding of best practices for concurrency and threading</li><li>A constant desire to improve, learn more and take things higher<br/><br/></li></ul><strong>Bonus Points<br/><br/></strong><ul><li>Experience using Slack and a keen interest in making it better</li><li>Experience building design systems to create reusable and scalable components</li><li>A passion for creating accessible applications</li><li>A passion for building and maintaining outstanding open source projects or otherwise adding to the Android community</li><li>Experience with reactive programming (e.g. RXJava)<br/><br/></li></ul><strong>Benefits &amp; Perks<br/><br/></strong>Check out our benefits site which explains our various benefits, including wellbeing reimbursement, generous parental leave, adoption assistance, fertility benefits, and more!<br/><br/><strong>Salesforce Information<br/><br/></strong>Check out our Salesforce Engineering Site.<br/><br/><strong>*IN SCHOOL OR GRADUATED WITHIN THE LAST 12 MONTHS? PLEASE VISIT FUTURE FORCE FOR OPPORTUNITIES</strong>*<br/><br/>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com .<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce .<br/><br/>﻿Salesforce welcomes all.<br/><br/>For Colorado-based roles, the base salary hiring range for this position is $133,400 to $254,700.<br/><br/>Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.
      </div>",$133400- $254700,"Software Engineer, Data"
Data Scientist/Engineer - Junior,SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784400083,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Data Engineer,SnapX.ai,12/19/2023,https://www.linkedin.com/jobs/view/3790031494,0,https://media.licdn.com/dms/image/C560BAQGrI5ZAgEOJ2Q/company-logo_100_100/0/1630666773263/snapxplatform_com_logo?e=2147483647&v=beta&t=ZLMq0RgwhdqNpuxZa98IYOgvdQbNVWudgbncPkkl5SY,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Dear Partner, Good morning,greetings from Snaprecruit LLC!<br/><br/>Submission you please review the below role,If you are available.<br/><br/><br/><br/>AWS, AWS Redshift and infrastructure, AWS Data Lake Formation and Glue components, data security, SQL, and Python</p>
</div>",No Salary Info Found,"Software Engineer, Data"
Data Engineer,Trident Consulting,12/20/2023,https://www.linkedin.com/jobs/view/3785060493,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Data Engineer,FinTech LLC,12/20/2023,https://www.linkedin.com/jobs/view/3785602219,0,https://media.licdn.com/dms/image/C510BAQFobT67_rqX5Q/company-logo_100_100/0/1631354807936?e=2147483647&v=beta&t=CXbQEnqxvT96ZgdqitGhoNB0NNM99yTZMM41grqF724,"Scottsdale, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong><span><span>About Client:<br/></span></span></strong><span><span> The client is a global technology, consulting, and digital solutions company with problem-solving abilities and an emphasis on developing ingenious solutions that allow its clients to remain competitive, profitable, and secure in an evolving business environment.<br/>Client anticipates and leads change to remain in the leader’s quadrant for profitable growth, driven by partnerships with globally leading hyperscales like AWS, Google Cloud, and Microsoft. It has built strong capabilities in new as well as existing technologies such as cloud, data, and digital, pioneering new frontiers.<br/><br/><br/><br/><strong>Rate Range: $65-$70/Hr on C2C all-inclusive<br/><br/><br/><br/>Job Description:</strong></span></span></p><ul><li><span><span>We are seeking a talented and experienced Data Engineer to join our dynamic team. </span></span></li><li><span><span>As a Data Engineer, you will be responsible for designing, developing, testing, and maintaining data processing pipelines that handle both batch and real-time data from various sources. </span></span></li><li><span><span>The ideal candidate will have a strong foundation in building frameworks for data ingestion, making critical technical decisions, and ensuring the scalability, reliability, and security of our data infrastructure.</span></span></li></ul><strong><span><span>Responsibilities:</span></span></strong><ul><li><span><span>Build frameworks for data ingestion pipeline for a variety of data sources: batch and real-time</span></span></li><li><span><span>Participate in technical decisions</span></span></li><li><span><span>Design, develop, test, and maintain data processing pipelines</span></span></li><li><span><span>Design and build scalable, reliable data infrastructure with paramount focus on data quality, security, and privacy techniques</span></span></li></ul><strong><span><span>Required skills:</span></span></strong><ul><li><span><span>Proficient in Java, Python or Scala</span></span></li><li><span><span>Cloud experience</span></span></li><li><span><span>Experience with relational SQL and NoSQL databases</span></span></li><li><span><span>Experience with Spark, Kafka</span></span></li><li><span><span>Strong analytical and communication skills: verbal and written.</span></span></li></ul><p> <br/><br/><br/><span><span><strong>About ApTask:<br/></strong>Join ApTask, a global leader in workforce solutions and talent acquisition services, as we shape the future of work. We offer a comprehensive suite of offerings, including staffing and recruitment services, managed services, IT consulting, and project management, providing unparalleled opportunities for professional growth and development. As a member of our dynamic team, you'll have the chance to connect businesses with top-tier professionals, optimize workforce performance, and drive success for our clients across diverse industries. If you are passionate about excellence, collaboration, and innovation, and aspire to make a meaningful impact in the world of work, come join us at ApTask and be a part of our mission to empower organizations to thrive.<br/><br/>Applicants may be required to attend interviews in person or by video conference. In addition, candidates may be required to present their current state or government issued ID during each interview.<br/><br/></span></span><strong><span><span>Candidate Data Collection Disclaimer:<br/></span></span></strong><span><span>At ApTask, we prioritize safeguarding your privacy. As part of our recruitment process, certain Personally Identifiable Information (PII) may be requested by our clients for verification and application purposes. Rest assured, we strictly adhere to confidentiality standards and comply with all relevant data protection laws. Please note that we only collect the necessary information as specified by each client and do not request sensitive details during the initial stages of recruitment.<br/><br/></span></span><span><span>If you have any concerns or queries about your personal information, please feel free to contact our compliance team at </span></span><span><span>businessexcellence@aptask.com </span><span>.</span></span></p>
</div>",$65- $70,"Software Engineer, Data"
Python Developer,SysMind,12/20/2023,https://www.linkedin.com/jobs/view/3784498734,0,https://media.licdn.com/dms/image/D560BAQGV-8_omihQqw/company-logo_100_100/0/1683913496651/sysmindindia_logo?e=2147483647&v=beta&t=OK3DLdlx_OcIBawqaxx8LLMQWMnZIPLLymaxRtLb4O0,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Requirement<br/><br/></strong><strong>Must Have:<br/><br/></strong><ul><li>Minimum 5 years of extensive experience in design, build and deployment of Python &amp; PySpark based applications</li><li>Experience designing, developing, deploying, testing in Databricks and Delta Lake.</li><li>Experience with Python, PySpark</li><li>Experience with AWS services S3, Step functions, Lambda, Airflow</li><li>Strong experience with Oracle, PL/SQL, Stored Procedures</li><li>Exposure to numpy, pandas libraries</li><li>Hands-on experience writing complex SQL queries, exporting and importing large amounts of data using utilities.</li></ul>
</div>",No Salary Info Found,"Software Engineer, Data"
"Web Developer Python Phoenix, AZ ( Onsite day 1 )","Conch Technologies, Inc",12/21/2023,https://www.linkedin.com/jobs/view/3789298935,0,https://media.licdn.com/dms/image/C4E0BAQHKm43b1OSSsw/company-logo_100_100/0/1630593845537/conch_technologies_logo?e=2147483647&v=beta&t=fddpsK_rqbhSRB1GStFAtD-sfi1Bxsv8oh8oupv0EEY,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Hi,<br/><br/>Greetings from Conch Technologies Inc<br/><br/><strong>Position: Python Developer ( Python with data structures and good in Orchestration of CI/CD)<br/><br/>Location: Phoenix, AZ ( Onsite day 1 )<br/><br/>Duration: 12+ Months Contract<br/><br/></strong>Python<br/><br/>Bash scripting<br/><br/>Data manipulation, test scripting<br/><br/>Linux environments<br/><br/><strong>Thanks and Regards,<br/><br/></strong><strong>Chanakya </strong><strong>[IT Recruiter]<br/><br/></strong><strong>Direct : 214-247-7117<br/><br/></strong><strong>chanakya@conchtech.com<br/><br/></strong><strong>linkedin.com/in/nameischanikya</strong>
</div>",No Salary Info Found,"Software Engineer, Data"
Data Engineer III - Remote | WFH,Get It Recruit - Information Technology,12/25/2023,https://www.linkedin.com/jobs/view/3787808700,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"La Mesa, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a dynamic and innovative team seeking a skilled Data Engineer III to join us remotely. At our company, we value collaboration, creativity, and a passion for transforming data into meaningful insights. If you thrive in a fast-paced, agile environment and are excited about building solutions that make a real impact, we invite you to explore this opportunity.<br/><br/><strong>Responsibilities<br/><br/></strong>Design and implement features in collaboration with a diverse team of engineers, product owners, data analysts, and business partners using Agile/Scrum methodology.<br/><br/>Develop programs and systems that translate data into meaningful information for analysis.<br/><br/>Build ETL/ELT jobs and workflows to integrate data from various sources.<br/><br/>Install continuous pipelines of filtered information for data analysts/scientists.<br/><br/>Construct data workflows using SQL Server Integration Services (SSIS), Microsoft Azure (Azure Data Factory, Storage Accounts, Synapse), and Databricks.<br/><br/>Collaborate with business stakeholders and product engineering teams to analyze business problems and implement solutions.<br/><br/>Document software architecture, create roadmap plans, and assist in the design, implementation, and maintenance of complex solutions.<br/><br/>Build systems that collect, manage, and convert raw data into usable information for business analysts.<br/><br/>Ensure data accessibility for evaluation and optimization.<br/><br/><strong>Qualifications<br/><br/></strong>Required:<br/><br/>Master's degree in computer science, systems engineering, or a related technical discipline (preferred).<br/><br/>5 years of experience as a Data Engineer/Administrator or in a similar role.<br/><br/>6 additional years of relevant experience may substitute for education.<br/><br/><strong>Preferred<br/><br/></strong>Proficiency in back-end data organization using SQL scripts and SSIS.<br/><br/>Experience with Microsoft Azure, Databricks, and Python or other scripting languages in data pipelines.<br/><br/>Familiarity with Microsoft Power BI.<br/><br/>Ability to work independently and provide technical and non-technical support to multiple users.<br/><br/>Capable of working under pressure, handling multiple tasks simultaneously.<br/><br/>Occasional overtime and weekend availability may be required.<br/><br/><strong>Salary Range<br/><br/></strong>Experience providing services to the federal government is preferred.<br/><br/>Target salary range: $165,001 - $175,000. The estimate displayed represents the typical salary range for this position based on experience and other factors.<br/><br/><strong>COVID Policy<br/><br/></strong>We prioritize the health and safety of our team members. While we do not require COVID-19 vaccinations or boosters, we adhere to customer site vaccination requirements when work is performed at a customer site.<br/><br/>Employment Type: Full-Time
      </div>",$165001- $175000,"Software Engineer, Data"
Embedded Software Engineer,Actalent,12/25/2023,https://www.linkedin.com/jobs/view/3793419300,0,https://media.licdn.com/dms/image/D560BAQExWVK4Gj-SZw/company-logo_100_100/0/1688476636332/actalentservices_logo?e=2147483647&v=beta&t=AApvYhiR6sAw0SW6NmuRXtsmeV4n0urrtV0AsOOFudU,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<ul><li>Description:* As an experienced member of the team, you will be responsible for identifying top level requirements and participate in all phases of embedded software development, from concept and design to development and maintenance. You will work with other members of the team to support hardware bring-up and debug, and develop both prototype and production software. You must be comfortable leading software and architecture design reviews, ensuring high development standards are met and team best practices are followed:</li><li>Have in-depth knowledge with real-time embedded software philosophies and practices</li><li>Knowledge of Linux kernel internals (process scheduler, memory management, concurrency/synchronization, memory allocation, file systems) and networking subsystems architecture</li><li>Strong debugging skills in kernel context</li><li>Experience with exercising/validation of system from user space, and knowledge of user space API</li><li>Develop embedded software in assembly, C/C++, Rust or other languages, code for microcontrollers (including hardware drivers).</li><li>Knowledge of low-level communications, PCIe, Ethernet, SPI and I2C would be desirable.</li><li>Review schematics, logic analyzer, and embedded software (bare-metal) trouble-shooting techniques</li><li>Skills:*</li><li>Firmware</li><li>C/C++</li><li>Embedded Linux</li><li>Microcontroller</li><li>Embedded C</li><li>Embedded Software</li><li>Linux</li><li>Additional Skills &amp; Qualifications:*</li><li>Writing the code on the ARM cores sitting on an FPGA (writing on the FPGA with VHDL)</li><li>Knowledge and experience with timing distribution and things around firmware for RF processing (FPGA firmware) for burst detection</li><li>This side is more terminal side of the teams doing antennae control protocol</li><li>Someone that is on the mac layer, phase array antennae, mobile platforms, iridium,</li><li>Embedded Linux environment that goes on the ARM controllers 2 main products; Ground terminals satellite terminals (modem + data) &amp; Optical Terminal is the 2nd on the satellite talking to other satellites.<br/><br/></li></ul>Diversity, Equity &amp; Inclusion<br/><br/>At Actalent, diversity and inclusion are a bridge towards the equity and success of our people. DE&amp;I are embedded into our culture through:<br/><br/><ul><li>Hiring diverse talent</li><li>Maintaining an inclusive environment through persistent self-reflection</li><li>Building a culture of care, engagement, and recognition with clear outcomes</li><li>Ensuring growth opportunities for our people<br/><br/></li></ul>Actalent is an equal opportunity employer.<br/><br/><strong>About Actalent<br/><br/></strong>Actalent connects passion with purpose. We help visionary companies advance their engineering and science initiatives through access to specialized experts that drive scale, innovation, and speed to market. With a network of almost 30,000 engineering and sciences consultants and more than 4,500 clients across the U.S., Canada, Asia, and Europe, Actalent serves many of the Fortune 500. An operating company of Allegis Group, the global leader in talent solutions, Actalent launched as a new specialized engineering and sciences services and workforce solutions brand in 2021.
      </div>",No Salary Info Found,"Software Engineer, Data"
Software Engineer (Remote Option),"Gnostech, LLC",12/19/2023,https://www.linkedin.com/jobs/view/3784425366,0,https://media.licdn.com/dms/image/C4D0BAQHBXWYKlPQaPQ/company-logo_100_100/0/1630535954045/gnostech_logo?e=2147483647&v=beta&t=BIQseV2mMagDhVdMJwImF2qBkepawtgPv8wI_Q7vpJY,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        A Software Engineer is needed to support various software development tasks. The applicant will work as part of a team responsible for learning to design or modify new and existing software applications - both external and internal to our organization. The applicant will also be tasked to interact with other personnel from the Software Development Team, as well as Software Test and Cybersecurity Team members to design, develop, document, and test applications and software.<br/><br/><strong>Overview<br/><br/></strong><em>Location<br/><br/></em><ul><li>San Diego, California</li><li> Option to work remotely <br/><br/></li></ul><em>Job Title<br/><br/></em><ul><li> Software Engineer <br/><br/></li></ul><em>Salary<br/><br/></em><ul><li> Commensurate with industry position, depending on experience <br/><br/></li></ul><em>Shift<br/><br/></em><ul><li> Typical: Monday through Friday 9am to 5pm <br/><br/></li></ul><em>Travel <br/><br/></em><ul><li> Less than 5% <br/><br/></li></ul><em>Work Authorization<br/><br/></em><ul><li> Applicants must be authorized to work for ANY employer in the U.S. We are unable to sponsor or take over sponsorship of an employment Visa. <br/><br/></li></ul><strong>Position Responsibilities<br/><br/></strong><ul><li> Contribute to the design, development and on time delivery of applications, components and/or systems </li><li> Participate in design reviews to provide input on functional requirements, product designs, schedules, or potential problems </li><li> Implement application enhancements and architectural improvements for existing products </li><li> Create technical documents as required </li><li> Follow and execute test plans, scenarios, scripts, and procedures. Document test procedures to ensure repeatability and compliance with standards </li><li> Document software defects using a bug tracking system, and report defects to software lead. </li><li> Maintain source code in a version control system </li><li> Understand and follow secure coding standards </li><li> Work productively with other team members on small to large scale projects <br/><br/></li></ul><strong>Minimum Security Clearance<br/><br/></strong><ul><li> Must be eligible and pass security screening to obtain DoD Secret Clearance </li><li> U.S. Citizenship is required to obtain a U.S. government issued security clearance <br/><br/></li></ul><strong>Required Qualifications And Skills<br/><br/></strong><ul><li> Proficiency in software design, development, and testing. </li><li> Experience and technically proficient with: Java Springboot Framework and Angular </li><li> Experience with MySQL/MariaDB </li><li> Knowledge of cloud computing technologies and current computing trends. </li><li> Ability to identify, define and resolve problems, collect data, establish facts, and draw valid conclusions <br/><br/></li></ul><strong>Additional Desired Qualifications, Skills, Certifications<br/><br/></strong><ul><li> Experienced and technically proficient with Helm and microservices </li><li> Experience with No-SQL Databases </li><li> Experience with containerized technologies (e.g., Docker, Kubernetes, etc.) </li><li> Comfortable working in a fast-paced, emerging growth environment </li><li> Strong oral, written communication skills <br/><br/></li></ul><strong>Education And Training Required<br/><br/></strong>Bachelor's degree (in Engineering, Computer Science, Math, or related field)<br/><br/><strong>Minimum Years Of Experience<br/><br/></strong><ul><li>2+<br/><br/></li></ul><strong>Diversity, Equity, and Inclusion<br/><br/></strong>Gnostech, LLC is committed to creating an equitable and inclusive workplace and we can only achieve this together.<br/><br/>====================================================================================<br/><br/>Gnostech is an Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, age, protected veteran status, or disability status. For more information, please visit www.eeoc.gov<br/><br/>If you require assistance to complete this application, please contact the Staffing Coordinator at 321-368-2567.<br/><br/>If this position requires a government clearance, the applicants selected will be subject to a government security investigation and must meet eligibility requirements for accessing classified information.
      </div>",No Salary Info Found,"Software Engineer, Data"
TDL Test Systems Engineer,Technology Unlimited Group,12/19/2023,https://www.linkedin.com/jobs/view/3790029061,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Data Engineer / Background in SQL / Migrate to AWS,Motion Recruitment,12/19/2023,https://www.linkedin.com/jobs/view/3789762711,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        A market leader in the analytics space, specifically focusing on analytics for the entertainment space is hiring a Senior Data Engineer to join their team of 5. This role will be a lot of new development and migrations as they are moving their SQL based pipelines over to Python, AWS, and Spark so strong SQL experience is a big plus. This company processes tens of billions of rows of data every year and has almost 20TB of processing data. The main tech stack for this role is SQL, Python, AWS, and Spark experience. This team also uses Glue, Power BI, Anthem, EMR, PySpark, and any experience working with marketing metrics/analysis is a plus. You will be building new capabilities for their analytics teams, integrating big data tools and moving to AWS within their pipelines.<br/><br/>This role is looking for someone to work PST hours. If you are local to Southern California that is a big plus but not required as this role is 100% fully remote. This is a small team so they ideally need someone open to wearing a few different hats who can interact with various teams within the organization so good communication is a must.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>5+ years professional Data Engineering Experience </li><li>Background in DBA/SQL Development </li><li>5 years of experience building ETL pipelines with Python, AWS, and Spark/PySpark </li><li>Experience working with large amounts of data <br/><br/></li></ul>Desired Skills &amp; Experience<br/><br/><ul><li>Bachelors in STEM field </li><li>Excellent written and verbal communication skills </li><li>Any experience with Glue, Power BI, Anthem, or EMR </li><li>Experience working with marketing metrics data <br/><br/></li></ul>The Offer<br/><br/><strong>You Will Receive The Following Benefits<br/><br/></strong><ul><li>Medical Insurance </li><li>Dental Benefits </li><li>Vision Benefits </li><li>Paid Sick Time </li><li>Paid Time Off </li><li>401(k) with match </li><li>Annual Bonus </li><li>Remote PST time <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future.<br/><br/><strong>Posted By:</strong> Cassi Benson
      </div>",No Salary Info Found,"Software Engineer, Data"
Software Developer - React,"The Marlin Alliance, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3790083500,0,https://media.licdn.com/dms/image/C560BAQHvQ-HmFZNHaA/company-logo_100_100/0/1648150922077/the_marlin_alliance_inc_logo?e=2147483647&v=beta&t=c37t9EoPx2f7w9xIWYjmBSh139GEQf2MHTFdskm1dvI,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Marlin Alliance, Inc. is seeking a <strong>Software Developer</strong> with React experience to join our team in San Diego, CA. This position supports our Navy customer and requires the ability to obtain a US Secret security clearance.<br/><br/>Established in 2002, The Marlin Alliance is seeking to hire highly skilled individuals to support mission critical projects within the Navy. We are looking for motivated individuals to lead and support digital transformation, data science and analytics, and automation projects for variety of Navy clients. Individuals must be able to function in a fast-paced work environment and able to adapt quickly to rapidly changing requirements and technologies. Using your comprehensive knowledge of various technologies, you will design, develop, and implement solutions to support Navy mission owners in their digital transformation journey.<br/><br/><strong>Required Qualifications<br/><br/></strong><ul><li>Excellent problem solver</li><li>Experienced in React 15+</li><li>Takes pride in writing clean reusable code</li><li>At least one major project involving React under your belt</li><li>Experience with version control software such as Git<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Experienced in Scrum</li><li>Experience contributing to open-source projects</li><li>Experience with a static typed language such as C#, C, C++, or Java</li><li>Experience working on both Front-End and Back-End technologies such as web frameworks and databases</li><li>Bachelors or higher in CS or related field<br/><br/></li></ul><strong>Work Environment And Mental/Physical Demands<br/><br/></strong>The physical demands described here are representative of those that must be met by an employee to successfully perform the essential functions of this position. Reasonable accommodations may be made to enable individuals with disabilities to perform the functions.<br/><br/><ul><li>Typical office environment with no unusual hazards.</li><li>The noise level in the work environment is usually moderate.</li><li>Constant sitting while using the computer terminal.</li><li>Constant use of sight abilities while reviewing documents.</li><li>Constant use of speech/hearing abilities for communication.</li><li>Occasional reaching, stooping, kneeling, or crouching may be required.</li><li>Occasional lifting, up to 20 pounds.</li><li>A constant state of mental alertness.</li><li>Frequent work under deadlines.<br/><br/></li></ul><strong>Job Classification<br/><br/></strong>Associate I<br/><br/>$60,000 - $100,000<br/><br/><strong>Disclaimer<br/><br/></strong>This job description in no way states or implies that these are the only duties to be performed by the employee(s) incumbent in this position. Employees will be required to follow any other job-related instructions and to perform any other job-related duties requested by any person authorized to give instructions or assignments. All duties and responsibilities are essential functions and requirements and are subject to possible modification to reasonably accommodate individuals with disabilities.<br/><br/>To perform this job successfully, the incumbents will possess the skills, aptitudes, and abilities to perform each duty proficiently. Some requirements may exclude individuals who pose a direct threat or significant risk to the health or safety of themselves or others. The requirements listed in this document are the minimum levels of knowledge, skills, or abilities.<br/><br/>This document does not create an employment contract, implied or otherwise, other than an “at-will” relationship.<br/><br/>An Equal Opportunity Employer/Protected Veterans/Individuals with Disabilities
      </div>",$60000- $100000,"Software Engineer, Data"
SQL Developer,Calpine,12/19/2023,https://www.linkedin.com/jobs/view/3787644141,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
"Staff Full Stack Engineer / Backend Engineer, Qualcomm AI SW Stack",Qualcomm,12/20/2023,https://www.linkedin.com/jobs/view/3790960708,0,https://media.licdn.com/dms/image/C560BAQHHmRgEadFrdA/company-logo_100_100/0/1630670148265/qualcomm_logo?e=2147483647&v=beta&t=WFF9wUPa7gLQ3kIyq8FbxOX8XEuseLFqsm7AfqbL0hA,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company<br/><br/></strong>Qualcomm Technologies, Inc.<br/><br/><strong>Job Area<br/><br/></strong>Engineering Group, Engineering Group &gt; Machine Learning Engineering<br/><br/><strong>General Summary<br/><br/></strong>In this position you will be responsible for contributing to the software design and development of the next generation Qualcomm AI Stack SDKs and associated tools.<br/><br/>You will have the opportunity to show your passion for software design and development with your analytical, design, programming, and debugging skills. All Qualcomm employees are expected to actively support diversity on their teams, and in the Company.<br/><br/><strong>Minimum Qualifications<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Engineering, Information Systems, or related field and 4+ years of Hardware Engineering, Software Engineering, Systems Engineering, or related work experience.<br/><br/><br/><br/></li></ul>OR<br/><br/>Master's degree in Computer Science, Engineering, Information Systems, or related field and 3+ years of Hardware Engineering, Software Engineering, Systems Engineering, or related work experience.<br/><br/>OR<br/><br/>PhD in Computer Science, Engineering, Information Systems, or related field and 2+ years of Hardware Engineering, Software Engineering, Systems Engineering, or related work experience.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Design and develop robust APIs to support web-based clients.</li><li>Design and develop system architecture for different services.</li><li>Optimize web applications for performance and scalability.</li><li>Design and implementation of data storage solutions.</li><li>Implementation of security and data protection.</li><li>Interact with cross functional technology teams, understand requirements, and propose solutions.</li><li>Take ownership in design and follow product lifecycle approaches to deliver features.</li><li>Troubleshoot applications, fix bugs, and make enhancements for existing components.</li><li>Participate in code and design reviews.<br/><br/><br/><br/></li></ul><strong>Qualifications<br/><br/></strong><strong>Ideal candidates for this position will demonstrate the following:<br/><br/></strong><ul><li>4+ years industry experience in building modern web based or desktop applications.</li><li>Strong experience in designing RESTful APIs.</li><li>Strong foundation in relational and non-relational database database designs and implementation. (MySQL/PostgreSQL, MongoDB / SQLite).</li><li>Strong foundation with Python and Python based web-frameworks (Django, Flask, FastAPI)</li><li>Strong understanding of asynchronous and parallel programming</li><li>Familiar with a number of common microservice based technologies (ElasticSearch, RabbitMQ, Graphana, NGINX)</li><li>Experience in writing highly secure web applications.</li><li>Strong foundation in writing and maintaining unit and integration tests (pytest, Postman, Jest).</li><li>Familiarity with web technologies/platforms like NodeJS, Angular (or comparable JavaScript framework).</li><li>Experience working with containerization technologies such as Docker</li><li>Some experience with plugin development in IDEs such as Visual Studio Code, WebStorm, Eclipse, etc</li><li>Good knowledge on various UI frameworks and design patterns.</li><li>Familiarity building various JavaScript graphs, plots, responsive and Realtime UI components.</li><li>Ability to make complex technical and design decisions for building scalable UI applications.</li><li>Familiarity with web UI testing frameworks like Spectron, Jasmine, Selenium, Karma etc. </li><li>Comfort working in an agile, iterative software development process.<br/><br/><br/><br/></li></ul><strong>Preferred<br/><br/></strong><ul><li>Programming/debugging skills in more than one programming languages (C/C++, Java, Python, JavaScript, TypeScript)</li><li>Experience with Docker Compose, Kubernetes, Helm.</li><li>Familiarity with Object Relational Model(ORM) concepts and usage</li><li>Some experience working with deep learning models training / inference pipelines.</li><li>Experience with one or more ML / AI frameworks (Tensorflow, Pytorch, OnnxRuntime, etc).</li><li>Linux software development</li><li>Experience with Android or other embedded systems and developing tools for embedded platforms.</li><li>Ability to collaborate across a globally diverse team and multiple interests<br/><br/><br/><br/></li></ul>Although this role has some expected minor physical activity, this should not deter otherwise qualified applicants from applying. If you are an individual with a physical or mental disability and need an accommodation during the application/hiring process, please call Qualcomm’s toll-free number found here for assistance. Qualcomm will provide reasonable accommodations, upon request, to support individuals with disabilities as part of our ongoing efforts to create an accessible workplace.<br/><br/>Qualcomm is an equal opportunity employer and supports workforce diversity.<br/><br/><strong>To all Staffing and Recruiting Agencies</strong>: Our Careers Site is only for individuals seeking a job at Qualcomm. Staffing and recruiting agencies and individuals being represented by an agency are not authorized to use this site or to submit profiles, applications or resumes, and any such submissions will be considered unsolicited. Qualcomm does not accept unsolicited resumes or applications from agencies. Please do not forward resumes to our jobs alias, Qualcomm employees or any other company location. Qualcomm is not responsible for any fees related to unsolicited resumes/applications.<br/><br/><strong>EEO Employer: Qualcomm is an equal opportunity employer; all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, Veteran status, or any other protected classification.<br/><br/></strong>Qualcomm expects its employees to abide by all applicable policies and procedures, including but not limited to security and other requirements regarding protection of Company confidential information and other confidential and/or proprietary information, to the extent those requirements are permissible under applicable law.<br/><br/><strong>Pay Range<br/><br/></strong>$148,500.00 - $222,500.00<br/><br/>The above pay scale reflects the broad, minimum to maximum, pay scale for this job code for the location for which it has been posted. Even more importantly, please note that salary is only one component of total compensation at Qualcomm. We also offer a competitive annual discretionary bonus program and opportunity for annual RSU grants (employees on sales-incentive plans are not eligible for our annual bonus). In addition, our highly competitive benefits package is designed to support your success at work, at home, and at play. Your recruiter will be happy to discuss all that Qualcomm has to offer!<br/><br/>If you would like more information about this role, please contact Qualcomm Careers.<br/><br/><strong>3056811</strong>
</div>",$148500.00- $222500.00,"Software Engineer, Data"
"Test Engineer, Software or Software Development Engineer in Test",Leidos,12/20/2023,https://www.linkedin.com/jobs/view/3790929096,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Full-Stack Software Engineer - Remote,Get It Recruit - Information Technology,12/20/2023,https://www.linkedin.com/jobs/view/3785061317,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Junior Data Engineer (US),Fitness Matrix Inc,12/25/2023,https://www.linkedin.com/jobs/view/3793120666,0,https://media.licdn.com/dms/image/D4E0BAQGmk8ZefBUxLg/company-logo_100_100/0/1698352894604/fitness_matrix_inc_logo?e=2147483647&v=beta&t=72cgj7Ot5k670-7oCMGX7QoHQoicVzzbGuWzPstPuXw,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Junior Data Engineer (US) - Onsite<br/><br/></strong><strong>Full-time<br/><br/></strong><strong>$66K - $77K per annum<br/><br/></strong><strong>1+ Year Experience Required<br/><br/></strong><strong>Introduction:<br/><br/></strong>FitnessMatrixInc is a unique approach to health and wellness that is based on the principle of bio-individuality. This means that we believe that everyone is different and has their own unique needs and challenges. We will work with you to understand your biochemistry and develop a personalized plan that is right for you.<br/><br/><strong>Position Summary<br/><br/></strong>Join the fast-paced, innovative, and collaborative environment focused on providing an AIOps platform that enhances the intelligence of the CVS Health infrastructure. Work closely with subject matter experts and colleagues to build and scale out machine learning and AI solutions that will detect, predict, and recommend solutions to correct issues before system impact and enhance the efficiency, reliability, and performance of CVS Health’s IT operations.<br/><br/><strong>Key Responsibilities include:<br/><br/></strong><ul><li>Data pipeline development: Designed, implemented, and managed data pipelines for extracting, transforming, and loading data from various sources into data lakes for processing, analytics, and correlation. </li><li>Data modeling: Create and maintain data models ensuring data quality, scalability, and efficiency </li><li>Develop and automate processes to clean, transform, and prepare data for analytics, ensuring data accuracy and consistency </li><li>Data Integration: Integrate data from disparate sources, both structured and unstructured to provide a unified view of key infrastructure platform and application data </li><li>Utilize big data technologies such as Kafka to process and analyze large volumes of data efficiently </li><li>Implement data security measures to protect sensitive information and ensure compliance with data and privacy regulation </li><li>Create/maintain documentation for data processes, data flows, and system configurations </li><li>Performance Optimization- Monitor and optimize data pipelines and systems for performance, scalability and cost-effectiveness <br/><br/></li></ul><strong>Characteristics of this role:<br/><br/></strong><ul><li>Team Player: Willing to teach, share knowledge, and work with others to make the team successful. </li><li>Communication: Exceptional verbal, written, organizational, presentation, and communication skills. </li><li>Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. </li><li>Attention to detail: Systematically and accurately research future solutions and current problems. </li><li>Strong work ethic: The innate drive to do work extremely well. </li><li>Passion: A drive to deliver better products and services than expected to customers. <br/><br/></li></ul><strong>Required Qualifications<br/><br/></strong><ul><li>2+ years of programming experience in languages such as Python, Java, SQL </li><li>2+ years of experience with ETL tools and database management (relational, non-relational) </li><li>2+ years of experience in data modeling techniques and tools to design efficient scalable data structures </li><li>Skills in data quality assessment, data cleansing, and data validation <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Knowledge of big data technologies and cloud platforms </li><li>Experience with technologies like PySpark, Databricks, and Azure Synapse. <br/><br/></li></ul><strong>Education<br/><br/></strong>Bachelor’s degree in Computer Science, Information Technology, or related field, or equivalent working experience<br/><br/><strong>Why should we work with Fitness Matrix?<br/><br/></strong>Fitness Matrix Inc is the leading provider of holistic and multidimensional health and wellness services. We offer a comprehensive approach to health and wellness. We take into account all aspects of your life, from your physical fitness and nutrition to your mental, emotional, and spiritual well-being. We use the latest science and technology to develop our programs and services. We are constantly innovating and finding new ways to help our clients achieve their goals. We offer a variety of programs and services to meet your needs and budget.<br/><br/>
</div>",$66- $77,"Software Engineer, Data"
Software Engineer / Data Management / Remote,Motion Recruitment,12/21/2023,https://www.linkedin.com/jobs/view/3791476870,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,"Software Engineer, Data"
Data Analyst / Software Developer - Remote | WFH,Get It Recruit - Information Technology,12/20/2023,https://www.linkedin.com/jobs/view/3785023314,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"Fort Washington, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a reputable consulting firm based in Pennsylvania, is actively seeking dynamic individuals to join our team. We specialize in providing innovative Information Technology (IT) and Consulting services to FDA-regulated life sciences companies, focusing on program/project management, process analysis, automated business process improvements, data analytics, and implementation of IT solutions.<br/><br/><strong>Job Responsibilities<br/><br/></strong>As a Business/Data Analyst and Software Developer at QSE7, you will play a pivotal role in delivering exceptional services to our pharmaceutical, consumer healthcare, and medical device clients. Your responsibilities will include:<br/><br/>Assessing and enhancing key quality and compliance business processes.<br/><br/>Facilitating cross-functional ideation and voice-of-customer (VOC) sessions to identify improvement opportunities.<br/><br/>Analyzing current-state data and designing future-state data models.<br/><br/>Automating business processes using Microsoft SharePoint, Power Apps, and Power Automate.<br/><br/>Developing sophisticated data analytics reports with Microsoft BI and Tableau.<br/><br/>Analyzing data to identify trends and recommending proactive solutions.<br/><br/>Providing project management services, including documentation, risk mitigation, and status communication.<br/><br/>Collaborating with cross-functional teams to ensure timely issue resolution.<br/><br/><strong>Qualifications / Experience<br/><br/></strong>B.A. or B.S. degree required.<br/><br/>Deep technical expertise in Microsoft Excel, SharePoint, PowerApps, Power Automate, and Power BI; VBA programming skills a plus.<br/><br/>3-to-5 years of professional work experience; experience in the life sciences or other federally regulated industry is a significant plus.<br/><br/>Quantitative data analysis experience.<br/><br/>Excellent verbal and written communication skills.<br/><br/>Leadership and motivation skills.<br/><br/>Ability to work independently and collaboratively in a problem-solving environment.<br/><br/>Efficient provision of consulting services from a remote home office.<br/><br/><strong>About QSE7<br/><br/></strong>Founded in 2016, our company is dedicated to offering intuitive and high-quality IT and Consulting services to FDA-regulated life sciences companies. Our commitment lies in bringing automation and efficiency to our clients' processes through comprehensive solutions based on Microsoft technologies, including Excel, MS Teams, SharePoint, Power BI, and Power Automate.<br/><br/>Join our team and be part of an organization that values innovation, collaboration, and excellence. Apply now to contribute your skills and expertise to our mission of enhancing efficiency in the life sciences industry.<br/><br/>Employment Type: Full-Time
      </div>",No Salary Info Found,"Software Engineer, Data"
Senior Software Engineer (Full stack/Back end),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3789243209,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Senior Software Engineer (Full stack/Back end) Do you enjoy working with technology and solving complex business problems? Are you looking for a collaborative and inclusive work environment? At Capital One, we are a diverse group of individuals who are passionate about using data and emerging technologies. We are seeking Full Stack Software Engineers who want to be part of a major transformation at Capital One. What You’ll Do: - Collaborate with Agile teams to design, develop, test, implement, and support technical solutions using full-stack development tools and technologies. - Stay updated with tech trends, experiment with new technologies, and participate in technology communities. Mentor other members of the engineering community. - Contribute to Cloud Operations by ensuring that AWS services in our Capital One environment are well-managed, secure, and cost-effective. Create automated tools and APIs to support operational needs and automate controls for a secure cloud environment. - Support all LOBs and Cloud network services users for cloud-related issues, engaging across the incident lifecycle to drive issue resolution. Basic Qualifications: - Bachelor’s Degree. - At least 4 years of experience in software engineering. Preferred Qualifications: - 5+ years of experience in Python, JavaScript, Java, TypeScript, or Go. - 2+ years of experience with AWS, GCP, Microsoft Azure, or another cloud service. - 2+ years of experience with computer networking. - AWS Solutions Architect - Associate certification. - 2+ years of experience in Agile practices. Capital One offers a comprehensive set of health, financial, and other benefits to support your well-being. For more information, visit our Capital One Careers website. We are an equal opportunity employer committed to diversity and inclusion in the workplace. We do not discriminate based on factors such as sex, race, age, disability, genetic information, sexual orientation, gender identity, citizenship, immigration status, veteran status, or any other protected characteristic. If you require an accommodation during the application process, please contact Capital One Recruiting at 1-800-304-9102 or RecruitingAccommodation@capitalone.com. For technical support or questions about our recruiting process, please email Careers@capitalone.com.
      </div>",No Salary Info Found,"Software Engineer, Data"
Data Engineer,Hyperloop Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3788678577,0,https://media.licdn.com/dms/image/D4E0BAQE5-wtGV9fWBQ/company-logo_100_100/0/1683619007636/hyperlooprecruitment_logo?e=2147483647&v=beta&t=4GRFib2T7ZuyTWESWmNt0g2NBzu40ZTgn23wPDBKEO8,"North Wales, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Data Engineer/Science<br/><br/></strong><strong>Circa 70k<br/><br/></strong><strong>North Wales<br/><br/></strong><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>The Client<br/><br/></strong>We’re representing a multi-billion pound Data Analytics and Software house who’re experience a period of high growth. They’re revolutionising their channel bringing new insights to their tracking software and work with the main players in global performance.<br/><br/>The role sits in the R&amp;D channel and at the crossover of software, hardware, data science and AI. You’ll help come up with new solutions to hard problems, create novel products and support the dev team in building and maintaining core software.<br/><br/>We’re looking for a hybrid Data Science/Engineer to join the team as their first specialist Data employee to leverage the extensive data volume we harvest<br/><br/><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>The Role<br/><br/></strong>As the companies first Data Specialist you’ll be confident working autonomously and help shape the companies Data profile. The role offers the chance to really shape the long term direction of the Data Dept with your decision making influential to the companies plans to scale<br/><br/><strong>Requirements<br/><br/></strong><ul><li>Strong coding skills, Python, Java </li><li>AWS experience</li><li>Ability to create data pipelines and storage in AWS</li><li>Ability to analyse large data sets and present findings</li><li>(nice to have) AI skills<br/><br/></li></ul><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>Benefits<br/><br/></strong><ul><li>Competitive salary, contributory pension scheme</li><li>Hybrid working.</li><li>International travel available</li><li>20% bonus scheme</li><li>Electric Vehicle Salary Sacrifice scheme (after 6 months of joining)<br/><br/></li></ul><strong>AWS - Python - AI - CICD</strong>
</div>",No Salary Info Found,"Software Engineer, Data"
SQL Developer,ASRC Federal,12/20/2023,https://www.linkedin.com/jobs/view/3784028695,0,https://media.licdn.com/dms/image/C560BAQHxmVaAQgviLw/company-logo_100_100/0/1657031094616/asrc_federal_logo?e=2147483647&v=beta&t=rXjR6fj8x3ewgZKxzzurRILYeXnXOwjZIHQMFT9Y2hY,"Moorestown, NJ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        ASRC Federal Mission Solutions is a premier provider of systems engineering, software engineering, system integration and project management services for real-time, mission-critical defense systems.<br/><br/>We are seeking for a highly motivated SQL Developer to support the continued development and sustainment of the Operations and Infrastructure Systems and Tools in support of the development effort for these defense systems in Moorestown, NJ.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Design, develop, and maintain SQL databases and related applications</li><li>Collaborate with software development team members to understand data requirements and translate them into efficient data model</li><li>Create and optimize SQL queries, stored procedures, functions, and triggers for data extraction, manipulation, and reporting purposes</li><li>Perform data analysis and profiling to identify and resolve data quality issues</li><li>Develop and implement database security measures to protect sensitive data</li><li>Monitor and optimize database performance, including query performance tuning, indexing, and database schema design</li><li>Conduct regular backups and ensure data integrity and availability</li><li>Collaborate with cross-functional teams to troubleshoot and resolve database-related issues</li><li>Provide technical support and guidance to end-users regarding SQL queries and database usage</li><li>Stay up to date with the latest industry trends and technologies related to SQL development<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li>Bachelor degree (in Engineering, Computer Science, Math, Information Systems, or related field) or equivalent related work experience</li><li>US Citizenship and ability to obtain and maintain a Secret security clearance</li><li>0-2 years experience and strong proficiency in SQL programming and database design principles</li><li>Proficiency in database management systems such as Microsoft SQL Server and PostgreSQL</li><li>Familiarity with data integration and ETL processes</li><li>Knowledge of database security and data privacy regulations</li><li>Experience with performance tuning and query optimization techniques</li><li>Excellent problem-solving and analytical skills</li><li>Strong attention to detail and ability to work independently</li><li>Effective communication and collaboration skills</li></ul>
</div>",No Salary Info Found,"Software Engineer, Data"
Software Engineer II,M&T Bank,12/20/2023,https://www.linkedin.com/jobs/view/3790954249,0,https://media.licdn.com/dms/image/C4D0BAQFdBokFRoHX4g/company-logo_100_100/0/1631340952916?e=2147483647&v=beta&t=ZDBu1XKQVJspTTO9al1GBSiDfG_fWy-aQlg0RX9Er4I,"Wilmington, DE","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Title: Software Engineer II<br/><br/></strong><strong>Location</strong>: 301 West 11th Street, Wilmington, DE 19801<br/><br/><strong>Job Description:<br/><br/></strong>Develop and support software for multiple in-house applications which integrate with leading vendor products to provide market competitive products, utilizing backend systems using either SQL or Oracle, and frontend systems: either Angular 8, Jasmine, or Bootstrap; complete and oversee the most complex systems analysis, design and software development efforts using Java or one of the following .Net technologies: C#, .net CORE, ASP.net, and MVC design; confer with other Development, Operations and Technology departments in overall systems development direction from technical analysis to user acceptance testing; prepare and review test data and execute detailed test plans and complete any required debugging within Web APIs, including REST, JSON, SOAP and SML; evaluate and understand highly complex interrelationships and effects among programs, interfacing applications, platforms, and source control systems (GIT, TFS or SVN); prepare thorough, clear technical and functional specifications and update systems documentation; prepare charts, tables and diagrams to assist in analyzing problems.<br/><br/><strong>Requirements:<br/><br/></strong>Bachelor’s degree (or foreign equivalent) in Computer Science, Software Engineering, or a related technical field, and five (5) years of experience developing software using Java or one of the following .Net technologies: C#, .net CORE, ASP.net and MVC design; utilizing backend using either SQL or Oracle; and frontend systems: either Angular 8, Jasmine, or Bootstrap; using Web APIs including REST, JSON, SOAP and SML; using source control systems (GIT, TFS or SVN). In lieu of a Bachelor’s degree, employer will accept a Master’s degree in Computer Science, Software Engineering, or a related technical field, and one (1) year in the above experience.<br/><br/><strong>Salary Range:</strong> $140,046- $145,046 per year<br/><br/>Please visit the benefits summary on our careers site for more details: https://www3.mtb.com/careers/benefits.<br/><br/><strong>Location:<br/><br/></strong>Wilmington, Delaware, United States of America
      </div>",$140046- $145046,"Software Engineer, Data"
Sr. Data Engineer (Hybrid),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788642988,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Job Title: Senior Data Engineer (Hybrid) Location: Plano, Texas, United States We are looking for motivated individuals to join our team of passionate data engineers in creating Capital One's next generation of data products and capabilities. In this role, you will be responsible for building data pipeline frameworks, developing data APIs, and transforming complex analytical models into scalable solutions. You will collaborate with Product Owners and customers to deliver data products in a collaborative and agile environment. Responsibilities: - Develop sustainable data-driven solutions using the latest data technologies to meet the needs of our organization and business customers. - Adapt and master new technologies quickly to contribute to various initiatives. - Break down complex data issues and resolve them efficiently. - Build robust systems with long-term maintenance and support in mind. - Share knowledge with the broader team. - Understand complex multi-tier, multi-platform systems. Basic Qualifications: - Bachelor's Degree. - At least 4 years of experience in application development (Internship experience does not apply). Preferred Qualifications: - Master's Degree. - 6+ years of experience in application development (Python, SQL, Scala, or Java). - 4+ years of experience in big data technologies. - 4+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud). - 4+ years of experience with distributed data/computing tools (MapReduce, Hadoop, Hive, EMR, Kafka, Spark, Gurobi, or MySQL). - 4+ years of experience working on real-time data and streaming applications. - 4+ years of experience with NoSQL implementation (Mongo, Cassandra). - 4+ years of data warehousing experience (Redshift or Snowflake). - 4+ years of experience with UNIX/Linux including basic commands and shell scripting. - 4+ years of experience with Agile engineering practices. Salary Information: - New York City (Hybrid On-Site): $161,900 - $184,800 for Senior Data Engineer. - Candidates hired to work in other locations will be subject to the pay range associated with that location. Benefits: At Capital One, we offer a comprehensive and inclusive set of health, financial, and other benefits to support your overall well-being. To learn more about our benefits, please visit the Capital One Careers website. Eligibility may vary based on employment status. Equal Opportunity Employer: Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We welcome applicants from all backgrounds and prohibit any form of discrimination based on sex, race, age, disability, religion, sexual orientation, gender identity, veteran status, or any other protected characteristic, as outlined by applicable laws. We promote a drug-free workplace and consider qualified applicants with a criminal history in accordance with the requirements of the law. Accommodation: If you require accommodation during the application process, please contact Capital One Recruiting. We will ensure that your needs are met confidentially and reasonably. Technical Support: For technical support or questions about Capital One's recruiting process, please email Careers@capitalone.com. Note: Capital One Financial is made up of different entities. Positions posted in Canada are for Capital One Canada, positions in the United Kingdom are for Capital One Europe, and positions in the Philippines are for Capital One Philippines Service Corp. (COPSSC). Capital One does not endorse or guarantee third-party products or services available through this site. [Employee Inquiry Form] [Apply Now] We appreciate your interest in joining Capital One. Please fill out the form below so that we may contact you regarding your application: Full Name: Email: Phone Number: Location: Resume/CV: (Attach file) Additional Information: Thank you for your application. We will be in touch shortly. For General Inquiries: Phone: 1-800-304-9102 Email: RecruitingAccommodation@capitalone.com
      </div>",$161900- $184800,"Software Engineer, Data"
Senior Data Engineer,Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788479916,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>HTML Formatted Response: Senior Data Engineer Job Application Senior Data Engineer Job Application Name:<br/><br/>Email:<br/><br/>Phone:<br/><br/>Upload Resume:<br/><br/>Bullet Points: - Position: Senior Data Engineer - Location: Plano, Texas, United States - About the company: Capital One is a diverse and inclusive company that solves real customer problems using technology - Responsibilities: - Collaborate with Agile teams to design, develop, test, implement, and support technical solutions - Work with a team of experienced developers in machine learning, microservices, and full stack systems - Use programming languages like Java, Scala, Python, and databases like RDBMS and NoSQL - Stay updated on tech trends, learn new technologies, and mentor other engineers - Collaborate with product managers to deliver cloud-based solutions for financial empowerment - Perform unit tests, code reviews, and optimize code performance - Basic Qualifications: - Bachelor's Degree - 4+ years of application development experience - 1+ year of big data technologies experience - Preferred Qualifications: - 5+ years of application development experience in Python, SQL, Scala, or Java - 2+ years of experience with a public cloud (AWS, Microsoft Azure, Google Cloud) - 3+ years of experience with distributed data/computing tools - 2+ years of experience in real-time data and streaming applications - 2+ years of experience with NoSQL databases - 2+ years of data warehousing experience - 3+ years of experience with UNIX/Linux and Agile engineering practices - Compensation: - New York City (Hybrid On-Site): $161,900 - $184,800 - San Francisco, California (Hybrid On-Site): $171,500 - $195,800 - Benefits: Capital One offers comprehensive health, financial, and other benefits. Learn more at the Capital One Careers website. - Diversity and Inclusion: Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. - Application Process: Fill out the form above with your name, email, phone, and resume to apply for the position. Thank you for your interest in the Senior Data Engineer position at Capital One.
      </div>",$161900- $184800,"Software Engineer, Data"
Back-End Software Engineer,"AttainX, Inc.",12/20/2023,https://www.linkedin.com/jobs/view/3790584993,0,https://media.licdn.com/dms/image/C560BAQFzej5lAU9f5Q/company-logo_100_100/0/1631346647521?e=2147483647&v=beta&t=cwhbCARsrNEDj-tVuPWkgUnNwNH24mXjs1qTnINO96c,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong><strong>Job Title: </strong>Senior Software Engineer<br/><br/><strong>Citizenship: </strong>US Citizen or Permanent Resident<br/><br/><strong>Clearance:</strong> Must be eligible to obtain a Public Trust<br/><br/><strong>Location:</strong> 100% Remote<br/><br/>AttainX is seeking a highly skilled and experienced Senior Back-End Software Engineer to join our dynamic team at supporting the Federal Government. As a Software Engineer, you will work as part of a team to support the rebuild/refresh of applications currently in use by the Federal Government.<br/><br/><strong>Primary Responsibilities<br/><br/></strong><ul><li>Perform backend software design and development and system integration. </li><li>Responsible for scoping, requirements, systems analysis, software design, development, testing, and deployment</li><li>Translates system requirements into technical design. </li><li>Lead and participate in projects of various sizes. <br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>B.S. degree in computer science or equivalent experience. </li><li>7+ years of experience in systems analysis, software engineering, database design. </li><li>Experience in software development projects as contributor and as technical lead. </li><li>Demonstrate solid problem-solving, relationship-building, communication, and coordination skills. </li><li>Independent Learner: Learn and apply technologies and business processes quickly and effectively. </li><li>Assertive and able to collaborate well with users, technical staff, and management. <br/><br/></li></ul><strong>Requisite Experience:<br/><br/></strong><ul><li>Java 8+ / Scala / Kotlin </li><li>Spring, Reactive Spring experience preferred (familiarity with Reactive Streams, Spring Data R2DBC, Spring WebFlux) </li><li>Spring Boot </li><li>Gradle </li><li>GraphQL </li><li>GCP (especially PubSub / Cloud Storage / Cloud SQL for PostgreSQL) </li><li>gRPC </li><li>Domain Driven Design and Event Sourcing </li><li>Message/Event-Driven Architectures </li><li>Relational databases, especially PostgreSQL (familiarity with document-based datatypes such as JSON/JSONB preferred), including database versioning tools such as Liquibase. </li><li>Reactive / Functional Programming (experience with Java Vavr / Immutables libraries preferred). </li><li>Kubernetes <br/><br/></li></ul><strong>Desired Experience:<br/><br/></strong><ul><li>jOOQ </li><li>Akka </li><li>ES6/TypeScript/React<br/><br/></li></ul>AttainX has been supporting DoD and Civilian agencies for more than 12 years. We are an EDWOSB, WOSB and 8(a) small business. Over the last 3 years we have achieved significant company growth, increased our contracts portfolio and hold the “Best in Class” contract vehicles, GSA MAS and OASIS Small Business and 8(a) Pools 1, 2 and 3. In addition, we are prime on several Agency Specific IDIQ’s and BPA’s with the National Oceanic and Atmospheric Administration, Department of Energy, Navy, Health and Human Service and the Defense Intelligence Agency.<br/><br/>AttainX is a mature company dedicated to quality and best practices for the services we provide. We understand personnel is essential in ensuring our customers Mission and Goals are met. We continue to maintain a retention rate, well above the industry average. AttainX does this by offering a competitive compensation plan and a leadership dedicated<br/><br/><strong>EEO Commitment:<br/><br/></strong>AttainX is an equal employment opportunity/affirmative action employer, we are committed to providing a workplace that is free from discrimination based on race, color, ethnicity, religion, sex, national origin, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, pregnancy, genetic information, or any other status protected by applicable federal, state, local, or international law. These protections also extend to applicants. Follow the links below to find out more;<br/><br/>EEO is Law Poster<br/><br/>EEO is Law Supplement<br/><br/>Pay Transparency Nondiscrimination Provision<br/><br/><strong>Accommodations:<br/><br/></strong>If you are an individual with a disability and would like to request a reasonable workplace accommodation, please send an email to AttainX HR to indicate the specifics of the assistance needed.<br/><br/><strong>Physical Demands:<br/><br/></strong>While performing duties of the job, incumbent will be exposed to Normal demands associated with an office environment. Ability to work on computer for long periods, and communicate<br/><br/>with individuals by telephone, email, and face to face. This position requires incumbent to have the ability to stand, walk, sit, use hands to finger, handle or feel objects, tools, or controls, reach<br/><br/>with hands and arms, talk, and hear. Employee must be able to lift and/or move up to 10 pounds. Specific vision abilities required by job include close vision, distance vision, color vision, peripheral vision, depth perception and the ability to adjust and focus.<br/><br/><strong>Work Environment:</strong> The noise level in the work environment is usually moderate.
      </div>",No Salary Info Found,"Software Engineer, Data"
"Senior Software Engineer, ML Platform Infrastructure",Upstart,12/23/2023,https://www.linkedin.com/jobs/view/3762981581,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Machine Learning Engineer,PubMatic,12/22/2023,https://www.linkedin.com/jobs/view/3741372441,0,https://media.licdn.com/dms/image/C4D0BAQFzbRQTefiFaw/company-logo_100_100/0/1631326637962?e=2147483647&v=beta&t=PCglwajU_vhDr6pXnCg029OzYELijYQRVN5z2ivXL7U,"Redwood City, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>We are immediately hiring a <strong>Machine Learning Engineer </strong>to join our growing team in <strong>Redwood City </strong>on a hybrid schedule.</p><p><br/></p><p>Reporting to the Director of Machine Learning, you will partner with Product and Engineering teams to solve problems with Machine Learning to identify trends and opportunities for the business.</p><p><br/></p><p>The ideal candidate will apply quantitative analysis, modeling and data mining to help drive informed product decisions for PubMatic + get things done.</p><p><br/></p><p><strong><u>Responsibilities</u></strong></p><p><br/></p><ul><li>Perform deep dive analysis to understand and optimize the key product KPIs</li><li>Apply statistics, modeling, and machine learning to improve the efficiency of systems and relevance algorithms across our business application products</li><li>Conduct data analysis to make product recommendations and design A/B experiments</li><li>Partner with Product and Engineering teams to solve problems and identify trends and opportunities</li><li>Collaborate with cross-functional stakeholders to understand their business needs, formulate and complete end-to-end analysis that includes data gathering, analysis, ongoing scaled deliverables and presentations</li></ul><p><br/></p><p><strong><u>Qualifications</u></strong></p><p><br/></p><ul><li>BA/BS or MS degree with emphasis on coursework of a quantitative nature (e.g., Statistics, Computer Science, Engineering, Mathematics, Data Sciences)</li><li>2+ years of applied work experience with design + implementation of Machine Learning models for solving business problems with statistical packages, such as R, MATLAB, Python (NumPy, Scikit-learn + Pandas) or MLlib</li><li>Experience with articulating product questions and using statistics to arrive at an answer</li><li>Experience with scripting in SQL - extracting large data sets and design of ETL flows</li><li>Work experience in an inter-disciplinary/cross-functional field</li><li>Deep interest and aptitude in data, metrics, analysis, trends and applied knowledge of measurement, statistics and program evaluation</li><li>Distinctive problem-solving skills and impeccable business judgment</li><li>Capable of translating analysis results into business recommendations</li></ul><p><br/></p><p><strong>Compensation and Benefits</strong>:</p><p>Base Salary Range: $<strong>145,000 </strong>- $<strong>195,000</strong></p><p><br/></p><p>In accordance with applicable law, the above salary range provided is PubMatic’s reasonable estimate of the base salary for this role. The actual amount may vary, based on non-discriminatory factors such as location, experience, knowledge, skills and abilities. In addition to salary PubMatic also offers a bonus, restricted stock units and a competitive benefits package.</p><p><br/></p><p><strong><u>Additional Information</u></strong></p><p><br/></p><p><strong>Return to Office</strong>: PubMatic employees around the world have returned to our offices via a hybrid work schedule (3 days “in office” and 2 days “working remotely”) that is intended to maximize collaboration, innovation, and productivity among teams and across functions.</p><p><br/></p><p><strong>Benefits</strong>: Our benefits package includes the best of what leading organizations provide such as, paid leave programs, paid holidays, healthcare, dental and vision insurance, disability and life insurance, commuter benefits, physical and financial wellness programs, unlimited DTO in the US (that we actually require you to use!), reimbursement for mobile expenses, and fully stocked pantries plus in-office catered lunches 4 days per week.</p><p><br/></p><p><strong>Diversity and Inclusion</strong>: PubMatic is proud to be an equal opportunity employer; we don’t just value diversity, we promote and celebrate it. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status.</p>
</div>",No Salary Info Found,Data and AI Engineer
"Data Scientist I, Revenue",Tinder,12/19/2023,https://www.linkedin.com/jobs/view/3757776367,0,https://media.licdn.com/dms/image/C560BAQGXi3o84QXQnw/company-logo_100_100/0/1652919833346/tinder_incorporated_logo?e=2147483647&v=beta&t=cZmqs0_oJdRPowgL0ZHdjXAGJyNoPke1Ll0QRJ0oxgI,"West Hollywood, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Our Mission<br/><br/></strong>As humans, there are few things more exciting than meeting someone new. At Tinder, we’re inspired by the challenge of keeping the magic of human connection alive. With tens of millions of users, hundreds of millions of downloads, 2+ billion swipes per day, 20+ million matches per day, and a presence in 190+ countries, our reach is expansive—and rapidly growing.<br/><br/>We work together to solve complex problems. Behind the simplicity of every match, we think deeply about human relationships, behavioral science, network economics, AI and ML, online and real-world safety, cultural nuances, loneliness, love, sex, and more.<br/><br/><strong>The Team<br/><br/></strong>The Data Science &amp; Analytics team thrives on data-driven insights to make more informed decisions through our insights into our member’s behavior, preferences, and common trends. We take ownership over the integrity of our data and work to improve data literacy across Tinder.<br/><br/>We are seeking a passionate and motivated <strong>Data Scientist I</strong> to join our growing Revenue team. In this role you will partner with Revenue, Product, Marketing, Engineering, and Finance to accelerate improvements to our platform. The ideal candidate is both passionate about the intersection of online dating and economics and comfortable digging deep into financial data to uncover trends and patterns. This role will operate under the Revenue branch of Tinder and will focus on data related to finance, pricing, and paid-feature<br/><br/>conversion.<br/><br/>Where you'll work:<br/><br/>This position can be located in Los Angeles or San Francisco, CA.<br/><br/><strong>In this role, you will: <br/><br/></strong><li>Digest large, complex transaction datasets into distilled analytics that help the business identify new opportunities. </li><li>Quickly investigate KPI movements in an evolving global dataset, disentangling correlation and causation to communicate resolutions efficiently. </li><li>Collaborate closely with strategy and finance teams to study worldwide online dating trends and provide detailed market research to guide pricing decisions.</li><li>Drive ownership of your own projects while balancing speed of execution and business value</li><li>Be an authority on where and how to organize our data and readily share insights with data scientists, product managers, and finance leaders as well as at a company level.</li><li>Define and operationalize the detailed tracking of company-wide, team-specific, and product-specific performance metrics via rollout tables, dashboards, and automated reporting.<br/><br/><br/></li><strong>Skills Required: <br/><br/></strong><li>Expertise with SQL and data visualization tools (e.g., Tableau, Mode, Databricks)</li><li>Ability to join multiple tables and data sources into an aggregated form that drives business understanding</li><li>Ability to design and execute complex A/B tests and statistical experiments on large datasets</li><li>Experience with a scripting language (Python, R, and/or Spark) and respective data analysis libraries</li><li>Eagerness to improve our data infrastructure and how we report analytics to the broader organization</li><li>Comfort using descriptive statistics</li><li>Curiosity of how things work, from both a business and technical perspective</li><li>A collaborative growth mindset with a dedication to community-based projects and partnerships</li><li>Experience working on data related to finance and/or subscription business models is a plus<br/><br/><br/></li><strong>As part of the team, you'll enjoy: <br/><br/></strong><li>Unlimited PTO (with no waiting period), 10 annual Wellness Days</li><li>Time off to volunteer and charitable donations matched up to $15,000 annually </li><li>Comprehensive health, vision, and dental coverage</li><li>100% 401(k) employer match up to 10%, Employee Stock Purchase Plan (ESPP)</li><li>100% paid parental leave (including for non-birthing parents), family forming benefits, and Milk Stork, which provides access to breast milk shipping for business travel, surrogacy, and employee relocation</li><li>Investment in your development: mentorship through our MentorMatch program, access to 6,000+ online courses through Udemy, and an annual $3,000 stipend for your professional development</li><li>Investment in your wellness: access to mental health support via Modern Health, BetterHelp, and Insight Timer; paid concierge medical membership, pet insurance, fitness membership subsidy, and commuter subsidy</li><li>Free subscription to Tinder Gold<br/><br/><br/></li>$115,000 - $130,000 a year<br/><br/>Factors such as scope and responsibilities of the position, candidate's work experience, education/training, job-related skills, internal peer equity, as well as market and business considerations may influence base pay offered. This salary range is reflective of a position based in West Hollywood. This salary will be subject to a geographic adjustment (according to a specific city and state), if an authorization is granted to work outside of the location listed in this posting.<br/><br/><strong>Commitment to Inclusion<br/><br/></strong>At Tinder, we don’t just accept difference, we celebrate it. We strive to build a workplace that reflects the rich diversity of our members around the world, and we value unique perspectives and backgrounds. Even if you don’t meet all the listed qualifications, we invite you to apply and show us how your skills could transfer. Tinder is proud to be an equal opportunity workplace where we welcome people of all sexes, gender identities, races, ethnicities, disabilities, and other lived experiences. Learn more here: https://www.lifeattinder.com/dei
      </div>",$15000- $3000,Data and AI Engineer
Machine Learning Engineer 5 - Globalization,Netflix,12/19/2023,https://www.linkedin.com/jobs/view/3724622897,0,https://media.licdn.com/dms/image/C4E0BAQEVb0ZISWk8vQ/company-logo_100_100/0/1631355051964?e=2147483647&v=beta&t=_82G5gJfq-rmofKHPHZOMBYvtHfTF8Z2qA_zAUvcVV4,United States,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Netflix, our mission is to entertain the world by connecting our members to an extensive library of stories from all over the globe. We are revolutionizing international storytelling as we deliver billions of hours of movies and TV shows per month to 200+ million members across 190+ countries in 30+ languages.<br/><br/>The Globalization Data Science and Engineering team is at the forefront of removing language barriers and providing a stellar member experience to all our members regardless of their language preferences. We are responsible for the translation and cultural adaptation of all aspects of member interaction, including beautiful localized user interfaces, subtitles, and dubbing of award-winning Netflix originals.<br/><br/>We are looking for an experienced Machine Learning Engineer to design and develop systems and infrastructure for algorithms that power high quality localization at scale. In this rare opportunity, you will have the chance to shape visions for algorithmic strategies and lead executions of ML engineering solutions for localization and global entertainment. You will partner with a talented cross-functional team of scientists, engineers, product managers, and domain experts to deliver business impact with these strategies and solutions.<br/><br/><br/><strong>Responsibilities<br/><br/><br/></strong><ul><li>Act as tech lead for identifying impactful Machine Learning (ML) opportunities and proposing algorithmic strategies in greenfield areas under a multi-modal setting</li><li>Be a thought leader for stakeholders and cross-functional collaborators to define and drive multi-year roadmaps for ML systems and infrastructure that can support growing business needs in global markets</li><li>Mentor, brainstorm with and enable other scientists and engineers to transform ML and Deep Learning (DL) research into scalable engineering solutions integrated into production workflows</li><li>Build and foster strong communities of ML engineering collaboration, innovation and best practices internally and externally</li><li>Uplevel the greater team through sharing knowledge and guiding thought on the adoption of new ML methodologies<br/><br/><br/><br/></li></ul><strong>About You<br/><br/><br/></strong><ul><li>Extensive experience in ML engineering for production grade systems that require skills in large-scale distributed data processing and model training</li><li>Experience leading ML initiatives with a proven track record of bringing clarity to and leading ambitious roadmaps for algorithmic strategies in collaboration with business stakeholders</li><li>MS or PhD in ML, Computer Science or related fields</li><li>Broad knowledge of ML and DL research especially for text and speech</li><li>Familiarity with common ML and DL frameworks such as PyTorch or Tensorflow</li><li>Exceptional communication and collaboration skills coupled with strong business acumen</li><li>Comfortable with ambiguity; able to take ownership, and thrive with minimal oversight and process</li><li>Netflix culture resonates with you<br/><br/><br/></li></ul><em>We are an equal opportunity employer and celebrate diversity, recognizing that diversity of thought and background builds stronger teams. We approach diversity and inclusion seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, ancestry, national origin, caste, sex, sexual orientation, gender, gender identity or expression, age, disability, medical condition, pregnancy, genetic makeup, marital status, or military service.<br/><br/></em>Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000.<br/><br/>Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.<br/><br/>Netflix is a unique culture and environment. Learn more here.
      </div>",$150000- $750000,Data and AI Engineer
"Staff Data Scientist, AI",Asana,12/19/2023,https://www.linkedin.com/jobs/view/3736991568,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
AI Engineer (Python),Open Systems Technologies,12/19/2023,https://www.linkedin.com/jobs/view/3772606379,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
ML Framework Software Development Engineer - Generative AI,AMD,12/19/2023,https://www.linkedin.com/jobs/view/3748871085,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Machine Learning Engineer (L5) - Content & Media ML Foundations,Netflix,12/19/2023,https://www.linkedin.com/jobs/view/3789759610,0,https://media.licdn.com/dms/image/C4E0BAQEVb0ZISWk8vQ/company-logo_100_100/0/1631355051964?e=2147483647&v=beta&t=_82G5gJfq-rmofKHPHZOMBYvtHfTF8Z2qA_zAUvcVV4,"Los Gatos, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Netflix is revolutionizing the entertainment industry with world-class technology. We serve 247+ million members across 190+ countries, delivering great movies &amp; TV shows every month in 30+ languages. To meet our members’ entertainment needs, Netflix has invested in scaled Content Production &amp; Promotion workflows. With assistance from creative supervision and member feedback data, we have built tools &amp; processes that use technologies like Computer Vision, Graphics, Machine Learning &amp; Generative Algorithms to enable our creators to tell the best version of the story they want while allowing our studio to scale further.<br/><br/>The Content &amp; Media ML Foundations team, within Data Science and Engineering, is responsible for foundational R&amp;D initiatives shaping the future of content production and promotion at a global scale. Using rich multi-modal data (text, video, audio, images), we build ML models and capabilities (such as customized generative methods and multi-modal embeddings enabling unique content understanding), that are high leverage and unlock impact across Netflix.<br/><br/>We are looking for an experienced ML Engineer to join the team.<br/><br/><br/><strong>Responsibilities<br/><br/><br/></strong><ul><li>Develop and deploy robust, scalable ML systems that are critical to advancing Netflix’s content understanding, production and promotion workflows.</li><li>Transform research prototypes into high-quality production code, ensuring systems are maintainable, scalable and performant.</li><li>Collaborate with machine learning scientists, data engineers, machine learning platform engineers to define project roadmaps, ensure alignment of goals and drive strong execution.</li><li>Manage the full lifecycle of model development across ETL, training, evaluation, deployment, continuous monitoring and improvement.</li><li>Efficiently and cost-effectively scale up ML solutions to handle Netflix-sized data.</li><li>Stay abreast of the latest developments in the field by attending conferences, reading research papers and implementing promising novel ideas that can impact Studio workflows.</li><li>Engage with the ML community, internal and external, to learn, to teach, to contribute to building a great Netflix brand in ML.<br/><br/><br/><br/></li></ul><strong>About You<br/><br/><br/></strong><ul><li>You have a strong foundation in machine learning and deep learning, including embedding methods, supervised and unsupervised learning, and deep learning architectures. You have a track record of deploying ML systems at scale.</li><li>Hands on experience with training large generative models across multiple modalities (text, images, videos).</li><li>Advanced degree (MS or PhD) in Computer Science, Electrical Engineering, or a related technical field with a focus on machine learning, artificial intelligence or computer vision.</li><li>Minimum 5 years of relevant industry experience in designing and implementing ML models, particularly in the areas of natural language processing, audio and video understanding.</li><li>Strong programming skills in Python and experience with ML/DL frameworks such as Tensorflow, Keras or PyTorch.</li><li>You have a strong track record of solving complex problems with innovative solutions. You are able to both develop novel algorithms and to adapt existing methods from the literature to new challenges.</li><li>You are an excellent communicator, capable of explaining complex technical details to both technical and non-technical audiences.</li><li>You are collaborative and thrive in fast-paced dynamic environments, contributing positively to the team and company culture.<br/><br/><br/></li></ul>Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000.<br/><br/>Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here.<br/><br/>Netflix is a unique culture and environment. Learn more here.
      </div>",$150000- $750000,Data and AI Engineer
AI/ML Engineer,ShortList Recruitment Limited,12/20/2023,https://www.linkedin.com/jobs/view/3779165673,0,https://media.licdn.com/dms/image/C4E0BAQFffdm9acC5hQ/company-logo_100_100/0/1673884706560/shortlist_recruitment_limited_logo?e=2147483647&v=beta&t=k3sAd6S8FXRHzUiA_Hwm3tu4C97_RhnOa2V5pjCjksU,United States,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>AI/ML Engineer | Remote | Multiple Openings</strong></p><p><br/></p><p><strong>Overview:</strong></p><p>ShortList have partnered with a growing start-up who are making a major breakthrough in Fintech using Artificial Intelligence. We are looking for motivated AI/ML Engineers that are looking to make a huge impact in the Financial Sector. </p><p><br/></p><p><strong>Role Description: </strong></p><p>The AI/ML Engineer will be an integral part of their team. You will be responsible for building out, maintaining, and optimizing the ML systems that power the AI, as well as the core infrastructure, data pipelines and improvement features. You will have the autonomy to work on the full end-to-end pipeline alongside a team of Researchers, Product and Software Engineers, from research discovery to deployment, dealing with real-world, high stake problems. </p><p><br/></p><p><strong>What we are looking for:</strong></p><ul><li>Exceptional knowledge of AI systems and the experience of putting models into production. </li><li>Core expertise in working with LLM's and Research models.</li><li>Track record of published work and personal projects, focused on generating new ideas in AI.</li><li>Experience owning end-to-end ML projects, from generating ideas through to execution.</li><li>Ability to work autonomously in a fast-paced environment.</li><li>Advanced Degree in Computer Science, Mathematics or Related field. </li></ul><p><br/></p><p>If you are interested, APPLY NOW for immediate consideration, or send me an email at harry.barnett@shortlist.tech with your resume.</p>
</div>",No Salary Info Found,Data and AI Engineer
AI Backend Developer,PETADATA,12/20/2023,https://www.linkedin.com/jobs/view/3789077415,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Data Scientist Engineer- USA Only,Phoenix Recruitment LLC,12/25/2023,https://www.linkedin.com/jobs/view/3793399922,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Machine Learning Engineer - Product,Nextdoor,12/21/2023,https://www.linkedin.com/jobs/view/3789254709,0,https://media.licdn.com/dms/image/C560BAQEz4eJn3nBsLA/company-logo_100_100/0/1654723721648/nextdoor_com_logo?e=2147483647&v=beta&t=xm1OQjdwT9GHxmO2PvpQUr434twFLSGPj3yByMazVYI,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>#TeamNextdoor<br/><br/></strong>Nextdoor is where you connect to the neighborhoods that matter to you so you can belong. Our purpose is to cultivate a kinder world where everyone has a neighborhood they can rely on.<br/><br/>Neighbors around the world turn to Nextdoor daily to receive trusted information, give and get help, get things done, and build real-world connections with those nearby — neighbors, businesses, and public services. Today, neighbors rely on Nextdoor in more than 305,000 neighborhoods across 11 countries.<br/><br/><strong>Meet Your Future Neighbors<br/><br/></strong>At Nextdoor, machine learning is one of the most important teams we are growing. Machine learning is starting to transform our product through personalization, driving major impact across different parts of our platform including newsfeed, notifications, ads relevance, connections, search, and trust. Our machine learning team is lean but hungry to drive even more impact and make Nextdoor the neighborhood hub for local exchange. We believe that ML will be an integral part of making Nextdoor valuable to our members. We also believe that ML should be ethical and encourage healthy habits and interaction, not addictive behavior. We are looking for great engineers who believe in the power of the local community to empower our members to make their communities great places to live.<br/><br/>At Nextdoor, we offer a warm and inclusive work environment that embraces a hybrid employment experience, providing a flexible experience for our valued employees.<br/><br/><strong>The Impact You’ll Make<br/><br/></strong><ul><li>You will be part of a scrappy and impactful team building data-intensive products, working with data and features, building machine learning models, and sharing insights around data and experiments. You will be working closely with the product team and the Data Science team on a daily basis. Finally, you will help build the foundational patterns that ML engineers will use for years to come as we ramp up our effort to introduce machine learning into our platform</li><li>Collect and gather datasets to build machine learning (ML) models that make real-time decisions for the Nextdoor platform</li><li>Analyze datasets and and use important features to build low-latency models for decisions that need to be made quickly</li><li>Deploy ML models into production environments and integrate them into the product</li><li>Run and analyze live user-facing experiments to iterate on model quality by measuring impact on business metrics</li><li>Collaborate with other engineers and data scientists to create optimal experiences on the platform</li><li>Participate in in-person Nextdoor events, trainings, off-sites, volunteer days, and other team building exercises</li><li>Build in-person relationships with team members and contribute to the KIND culture that Nextdoor values <br/><br/></li></ul><strong>What You’ll Bring To The Team<br/><br/></strong><ul><li>B.S. in Computer Science, Applied Math, Statistics, Computational Biology or a related field</li><li>5+ years of industry/academic experience of applying machine learning at scale</li><li>Experience building ML models for consumer facing products</li><li>Proven engineering skills, with experience of writing and maintaining high-quality production code</li><li>Ability to work with and analyze large amounts of data</li><li>Ability to succeed in a dynamic startup environment</li><li>Experience with recommendation systems, deep learning models, feed/notification relevance, knowledge graph, Ads or NLP will be a big plus</li><li>Experience mentoring junior engineers and planning roadmaps<br/><br/></li></ul><strong>Rewards<br/><br/></strong>Compensation, benefits, perks, and recognition programs at Nextdoor come together to create one overall rewards package.<br/><br/>The starting salary for this role is expected to range from $186,000 to $262,000 on an annualized basis, or potentially greater in the event that your 'level' of proficiency exceeds the level expected for the role. Compensation may also vary by geography.<br/><br/>We also expect to award a meaningful equity grant for this role. With equal quarterly vesting, your first vest date would be within the first 3 months of your start date.<br/><br/>Overall, total compensation will vary depending on your relevant skills, experience, and qualifications.<br/><br/>We have you covered! Nextdoor employees can choose between a variety of great health plans. We cover 100% of your personal monthly premium for health, dental, and vision – and provide a OneMedical membership for concierge care.<br/><br/>At Nextdoor, we empower our employees to build stronger local communities. To create a platform where all feel welcome, we want our workforce to reflect the diversity of the neighbors we seek to serve. We encourage everyone interested in our purpose to apply. We do not discriminate on the basis of race, gender, religion, sexual orientation, age, or any other trait that unfairly targets a group of people. In accordance with the San Francisco Fair Chance Ordinance, we always consider qualified applicants with arrest and conviction records.<br/><br/>For information about our collection and use of applicants’ personal information, please see Nextdoor's Personnel Privacy Notice, found here.<br/><br/>
</div>",$186000- $262000,Data and AI Engineer
Senior Software Engineer - Machine Learning Engineering,Discord,12/19/2023,https://www.linkedin.com/jobs/view/3754196569,0,https://media.licdn.com/dms/image/C560BAQF4M0IT6_BcsA/company-logo_100_100/0/1630641421267/discord_logo?e=2147483647&v=beta&t=ICXew1rSLaD4tsvlgQT4vi6rJTd_H4RqMhdBYEAD1TA,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>At Discord, we believe everyone can find a place where they belong. Our mission is to help make it easy for everyone to connect and engage with friends, communities and content on Discord. We use Machine Learning to make Discord feel smart and delightful. We are working on augmenting user experiences with personalized recommendations, smart notifications, and Generative AI. <br/><br/></strong><strong>We are a machine learning engineering team that works across the stack to deliver production ML systems. If you’ve worked with applied ML teams and building things from scratch sounds exciting to you, read on!<br/><br/></strong><strong>What You'll Do:<br/><br/></strong><ul><li>Build and iterate on new ML-driven products to foster creativity, discovery and engagement on Discord </li><li>Build robust, high-scale low latency machine learning systems that power personalized experiences for millions of users every day </li><li>Build generalizable serving infrastructure using MLOps stacks like Vertex AI, TorchServe <br/><br/></li></ul><strong>Who You Are:<br/><br/></strong><ul><li>You have a Bachelor's degree or higher in a quantitative field including Computer Science, Physics, Applied Math, Statistics or other quantitative fields </li><li>You have 7+ years of professional experience as a Machine Learning Engineer or Software Engineer or 5+ years with an advanced degree </li><li>You have experience delivering large-scale, distributed machine learning systems </li><li>You have programming skills in Python and an understanding of software engineering principles, including writing clean, maintainable code </li><li>You have strong communication skills and the ability to work well cross-functionally </li><li>You approach problems with first principles. You are comfortable with ambiguity and get excited about working collaboratively to figure out solutions to complex problems, and then executing on them. You can take a high-level, ambiguous goal and achieve a shippable solution </li><li>You have a strong product sense, and you’re passionate about applications driven by user feedback and end user experiences <br/><br/></li></ul><strong>The US base salary range for this full-time position is ($204,000) to ($220,000) + equity + benefits. Our salary ranges are determined by role and level. Within the range, individual pay is determined by additional factors, including job-relate4d skills, experience, and relevant education or training. Please note that the compensation details listed in US role posting reflect the base salary only, and do not include equity, or benefits.<br/><br/></strong>Benefits and Perks<br/><br/><ul><li>Comprehensive medical insurance including Health, Dental and Vision (plus up to $20,000 for gender affirmation procedures)</li><li>Mental health resources and quarterly wellness stipends</li><li>14+ paid holidays, 4 weeks of PTO + use-what-you-need sick days </li><li>Paid parental leave (plus fertility, adoption and other family planning benefits)</li><li>Flexible long-term work options (remote and hybrid)</li><li>Volunteer time off</li><li>A diverse slate of Employee Resource Groups </li><li>Plus commuter contributions and other perks for office-based employees<br/><br/></li></ul><strong>About Us<br/><br/></strong>Discord is a voice, video and text app that helps friends and communities come together to hang out and explore their interests — from artists and activists, to study groups, sneakerheads, plant parents, and more. With 150 million monthly users across 19 million active communities, called servers, Discord has grown to become one of the most popular communications services in the world. Discord was built without selling ads or user data and instead, offers a premium subscription called Nitro that gives users special perks like higher quality streams and fun customizations.<br/><br/>We’re working toward an inclusive world where no one feels like an outsider, where genuine human connection is a click, text chat, or voice call away. A place where everyone can find belonging. Challenging? Heck yes. Rewarding? Double heck yes. It’s a mission that gives us the chance to positively impact millions of people all over the world. <strong>So if this strikes a chord with you, come build belonging with us!</strong>
</div>",$204000- $220000,Data and AI Engineer
"Applied ML Engineer (Ranking & Relevance), Search Science",Slickdeals,12/19/2023,https://www.linkedin.com/jobs/view/3731834262,0,https://media.licdn.com/dms/image/C4D0BAQHlRkpkUKwIhg/company-logo_100_100/0/1642112508173/slickdeals_logo?e=2147483647&v=beta&t=peb8Xtz0zncQ2Coo5a8skCxR8ZSFkiU9BsgQFOP7BX4,"San Mateo, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>THE PURPOSE:<br/><br/></strong>We are building a new search, discovery, and shopping graph platform that powers the suite of Slickdeals product lines. We're looking for top-notch search engineering talents in the area of information retrieval, search indexing, Elasticsearch, Lucene, algorithms, relevance &amp; ranking, data mining, machine learning, data analysis &amp; metrics, query processing, multi-lingual search and multi-modal search.<br/><br/>In this role, you will be part of our unique Search and Discovery team. We are looking for someone with expertise in information retrieval and a passion for creating exceptional search experiences. The ideal candidate will have a strong technical background and a deep understanding of search algorithms and systems. As an individual contributor to the Search and Discovery Team, you will play a crucial role in enhancing our search capabilities and driving the discovery of deals and content for our users. You will be building products using technologies such as AWS SageMaker, Tensforflow, Pytorch, LLM, Elastic Search, REST web services, SQS/Kafka, Vector Database, HBase, Machine Learning, and more.<br/><br/><strong>THE CANDIDATE:<br/><br/></strong><ul><li>5+ years of building, scaling and maintaining software systems in production environments</li><li>Solid fundamentals in algorithms, data structures, system design</li><li>Experience with machine learning frameworks and libraries (PyTorch, Tensorflow)</li><li>Experience designing fault-tolerant distributed systems</li><li>Strong architectural skills<br/><br/></li></ul><strong>BONUS POINTS:<br/><br/></strong><ul><li>Experience working with a cloud technology stack (AWS, GCP, Kubernetes)</li><li>Experience building machine learning training pipelines or inference services in a production setting</li><li>Experience with managing and maintaining open source machine learning libraries</li><li>Experience managing small teams in pursuit of an ambitious technical goal</li><li>Hands-on experience in building machine learning-based search and recommendation systems</li><li>Experience with implementing ML-based search systems such as query classification, learning to rank or machine-learned ranking (MLR) search is a plus<br/><br/></li></ul><strong>LOCATION</strong><strong>: Las Vegas, Los Angeles, or the Bay Area (San Mateo)<br/><br/></strong><em>Flexible hybrid schedule visiting our Las Vegas, Los Angeles or San Mateo office.<br/><br/></em><strong>Slickdeals Compensation, Benefits, Perks:<br/><br/></strong><ul><li>Competitive salary based on your experience</li><li>Equity, become a Slickdeals stakeholder</li><li>Platinum level medical benefits</li><li>Dental, Vision, &amp; Life Insurance</li><li>401K matching above the industry standard</li><li>10 vacation days, 10 paid holidays, &amp; 48 hours of sick leave</li><li>Professional Development Reimbursement Program, and LinkedIn Learning Membership<br/><br/></li></ul><strong>Work Authorization<br/><br/></strong>Candidates must be eligible to work in the United States.<br/><br/>Slickdeals is an Equal Opportunity Employer; employment is governed on the basis of merit, competence and qualifications and will not be influenced in any manner by race, color, religion, gender (including pregnancy, childbirth, or related medical conditions), national origin/ethnicity, veteran status, disability status, age, sexual orientation, gender identity, marital status, mental or physical disability or any other protected status. Slickdeals will consider qualified applicants with criminal histories consistent with the ""Ban the Box"" legislation. We may access publicly available information as part of your application.<br/><br/>Slickdeals participates in E-Verify. For more information, please refer to E-Verify Participation and Right to Work.<br/><br/><strong><em>Slickdeals does not accept unsolicited resumes from agencies and is not responsible for related fees.</em></strong>
</div>",No Salary Info Found,Data and AI Engineer
Software Engineer — Frontend,Snorkel AI,12/19/2023,https://www.linkedin.com/jobs/view/3790347582,0,https://media.licdn.com/dms/image/D560BAQH98PpVu85Wgw/company-logo_100_100/0/1689007725014/snorkel_ai_logo?e=2147483647&v=beta&t=rJi3LQPtVpA2UK2mxs2GYxfcKO6h2UyKG2Wu7cBXx6w,"Redwood City, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Snorkel AI, we’re redefining how people and organizations build AI applications. Snorkel started as a research project in the Stanford AI Lab in 2016, creating a higher-level interface to machine learning through programmatically labeled and managed training data. From deploying in some of the world’s largest and most sophisticated tech organizations, to empowering scientists, doctors, and journalists — we’ve seen firsthand how this approach democratizes and accelerates AI. Now, we’re building Snorkel Flow to bring our technology to everyone!<br/><br/>Excited to help us redefine how AI applications are built? Apply to be the newest Snorkeler!<br/><br/>As a UX/Front-end Engineer, you’ll build amazing interfaces that will empower developers and non-developers deploy models, monitor them, and analyze production data. Using a combination of strong programming skills and a creative, user-focused mindset, you will have full ownership and responsibility for building, shipping, and maintaining innovative new functionality across the stack.<br/><br/><strong>Main Responsibilities<br/><br/></strong><ul><li>Design and develop key interfaces of Snorkel Flow, including interfaces for managing deployments, automatically analyzing data, and visualizing key metrics</li><li>Work directly with world-class customers to help create intuitive interfaces for ML development</li><li>Advocate and help define standards for the best practices in performance, product quality, security and user experience across the entire application</li><li>Provide mentorship and foster a growth and collaborative mindset for all members of your team.</li><li>Collaborate with cross functional teams on developing large scale products</li><li> The salary range for this position based in the San Francisco Bay Area is $143,000.00 - $185,000.00. All offers include equity compensation in the form of employee stock options. <br/><br/></li></ul><strong>Be Your Best At Snorkel<br/><br/></strong>Snorkel AI is on a mission to make machine learning practical for everyone, and it starts with building a team that welcomes, represents and gives opportunity to all. We work at the frontier of AI and software engineering, and believe that underrepresented communities need to play a part in shaping the future of these fields. At Snorkel AI, we actively work to create an environment that values end-to-end ownership, diverse forms of impact, and opportunities for personal growth.<br/><br/>Snorkelers are supported by an amazing team and an amazing set of benefits. We offer comprehensive medical, dental, and vision plans for Snorkelers and their families, plus a yearly wellness stipend. Our 401k program lets Snorkelers plan for their future and our parental leave program lets new parents take up to 20 weeks of paid time off. Learn more about these benefits and more — like our workstation setup allowance — on our Careers page.<br/><br/>Snorkel AI is proud to be an Equal Employment Opportunity employer and is committed to building a team that represents a variety of backgrounds, perspectives, and skills. Snorkel AI embraces diversity and provides equal employment opportunities to all employees and applicants for employment. Snorkel AI prohibits discrimination and harassment of any type on the basis of race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by federal, state, or local law. All employment is decided on the basis of qualifications, performance, merit, and business need.<br/><br/>We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, to perform essential job functions, and to receive other benefits and privileges of employment. Please contact us to request accommodation.
      </div>",$143000.00- $185000.00,Data and AI Engineer
"Staff Data Scientist, AI",Asana,12/19/2023,https://www.linkedin.com/jobs/view/3736991568,0,https://media.licdn.com/dms/image/C560BAQGwaqVHYIXJiQ/company-logo_100_100/0/1679507865817/asana_logo?e=2147483647&v=beta&t=8Vk7iuTEtSON7XU5ffGKNClRbEhQEODJe_M2J-zW7xU,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>We are hiring a full-stack data scientist for the AI org located in San Francisco. The AI org has a mission to transform Asana by building innovative AI experiences that dramatically improve customers’ lives at work. We empower teams to pioneer the future of work through rapid prototyping and exploration, deliver amazing AI-first experiences that help customers achieve their missions and business objectives, and accelerate Asana’s ability to deliver AI experience through frameworks and tooling.</p><p><br/></p><p>The Data Science team at Asana is instrumental in enabling Asana's mission by instilling a data-influenced approach to building the product or business strategy, defining and measuring success metrics, and learning and iterating to deliver value to our users. Data Scientists closely partner with Product, Business, Design, Engineering, and other members of the Data team. We leverage experimentation, statistical modelling and machine learning techniques, causal inference, and data storytelling to deepen our understanding of Asana customers and make optimal decisions to drive more business value.</p><p><br/></p><p>This role is based in our San Francisco office with an office-centric hybrid schedule. Along with most Asanas, you’ll work from this office in person on Mondays, Tuesdays, and Thursdays. Most Asanas have the option to work from home on Wednesdays and Fridays. If you're interviewing for this role, your Talent Acquisition Partner will share more about the in-office requirements.</p><p><br/></p><p><strong>What You’ll Achieve</strong></p><ul><li>Thinking deeply about how to measure and track success for a set of products with a complex and nuanced customer value</li><li>Performing and evangelizing strategic analysis to help inform the future of work for the AI org</li><li>Developing ML models to align with AI org strategy and drive business impact</li><li>Designing and analyzing experiments to measure the impact of new LLM and ML features</li></ul><p><br/></p><p><strong>About You</strong></p><p><br/></p><ul><li>Bachelor's Degree in Computer Science, Math, Statistics, Engineering, a related quantitative field, or equivalent experience.</li><li>5+ years of experience in applying data science techniques to drive technical product development and decision-making</li><li>Strong technical background in computer science, statistics, math, information science, or another quantitative field</li><li>Strong ability in managing stakeholders, communicating complex concepts to diverse audiences, and crafting compelling stories.</li><li>Experience in scoping and planning projects with stakeholders, and driving technical execution.</li><li>Fluency in at least one modern language useful for data processing (e.g. Python, Scala)</li><li>Proficiency with relational data modelling and SQL</li><li>Expertise in machine learning (experience in recommendation, ranking, graph modeling) statistical methods and experimental design and analysis</li></ul><p><br/></p><p><strong>What We’ll Offer</strong></p><p><br/></p><p>Our comprehensive compensation package plays a big part in how we recognize you for the impact you have on our path to achieving our mission. We believe that compensation should be reflective of the value you create relative to the market value of your role. To ensure pay is fair and not impacted by biases, we're committed to looking at market value which is why we check ourselves and conduct a yearly pay equity audit.</p><p><br/></p><p>For this role, the estimated base salary range is between $202,000 - $316,000. The actual base salary will vary based on various factors, including market and individual qualifications objectively assessed during the interview process. The listed range above is a guideline, and the base salary range for this role may be modified.</p><p><br/></p><p>In addition to base salary, your compensation package may include additional components such as equity, sales incentive pay (for most sales roles), and benefits. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role.</p><p><br/></p><p>We strive to provide equitable and competitive benefits packages that support our employees worldwide and include:</p><p><br/></p><ul><li>Mental health, wellness &amp; fitness benefits</li><li>Career coaching &amp; support</li><li>Inclusive family building benefits</li><li>Long-term savings or retirement plans</li><li>In-office culinary options to cater to your dietary preferences</li><li><br/></li></ul><p>These are just some of the benefits we offer, and benefits may vary based on role, country, and local regulations. If you're interviewing for this role, speak with your Talent Acquisition Partner to learn more about the total compensation and benefits for this role.</p><p><br/></p><p><strong>About Us</strong></p><p>Asana helps teams orchestrate their work, from small projects to strategic initiatives. Millions of teams around the world rely on Asana to achieve their most important goals, faster. Asana has been named a Top 10 Best Workplace for 5 years in a row, is Fortune's #1 Best Workplace in the Bay Area, and one of Glassdoor’s and Inc.’s Best Places to Work. After spending more than a year physically distanced, Team Asana is safely and mindfully returning to in-person collaboration, incorporating flexibility that adds hybrid elements to our office-centric culture. </p><p><br/></p><p>With 11+ offices all over the world, we are always looking for individuals who care about building technology that drives positive change in the world and a culture where everyone feels that they belong.</p><p><br/></p><p>We believe in supporting people to do their best work and thrive, and building a diverse, equitable, and inclusive company is core to our mission. Our goal is to ensure that Asana upholds an inclusive environment where all people feel that they are equally respected and valued, whether they are applying for an open position or working at the company. We provide equal employment opportunities to all applicants without regard to race, color, religion, age, sex, national origin, disability status, genetics, protected veteran status, sexual orientation, gender identity or expression, or any other characteristic protected by law.</p>
</div>",$202000- $316000,Data and AI Engineer
Software Engineer (Backend / AI),Alphawatch.AI,12/19/2023,https://www.linkedin.com/jobs/view/3788142536,0,https://media.licdn.com/dms/image/D560BAQF0LKRfz0jh8g/company-logo_100_100/0/1686600168298?e=2147483647&v=beta&t=Su6VtCdT7tIJgAY-MqRDQgiVC-1YHbcQPKYUOTGvAy8,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Just as conversations spark action in other fields, financial decisions depend on accurate, timely insights gleaned from a vast network of experts. In the complex world of finance, sifting through data, identifying relevant expertise, and translating it into actionable decisions can be a herculean task. This is where AlphaWatch AI steps in.<br/><br/><strong>You'll Be Building<br/><br/></strong><ul><li>Cutting-edge search and discovery platform: Connect with a curated network of industry experts</li><li>AI-powered analytics and insights: Uncover hidden patterns and generate actionable recommendations from vast amounts of market data.</li><li>Next-generation user experience: Simplify complex data processing workflows and deliver actionable insights in a clear, intuitive interface.<br/><br/></li></ul><strong>More Than Just Code, You'll Be<br/><br/></strong><ul><li>A builder: Play a pivotal role in shaping the future of financial intelligence.</li><li>A collaborator: Work alongside a passionate team of experts and fellow enthusiasts.</li><li>An innovator: Push the boundaries of what's possible with technology and financial expertise.<br/><br/></li></ul><strong>We're Looking For<br/><br/></strong>Backend Engineer with interest in AI &amp; LLMs<br/><br/><strong>We're looking for a seasoned backend engineer who thrives in the intersection of data, AI, and finance.</strong> You'll play a pivotal role in building the infrastructure that powers AlphaWatch AI.<br/><br/><strong>Your Ideal Background Includes<br/><br/></strong><ul><li>3+ years of experience as a backend engineer, architecting and developing scalable systems.</li><li>Solid proficiency in Python, particularly web frameworks like FastAPI.</li><li>Experience with data pipelines and storage solutions like PostgreSQL, OpenSearch (ElasticSearch), and potentially Pinecone.</li><li>Familiarity with cloud platforms like AWS Bedrock is a strong plus.</li><li>AI/LLM awareness and enthusiasm for exploring their potential in financial insights.<br/><br/></li></ul><strong>Bonus Points For<br/><br/></strong><ul><li>Proven track record of building high-performance, data-driven APIs.</li><li>Experience with AI/LLM integration in backend systems.</li><li>Understanding of NLP and search algorithms.</li><li>Passion for finance and a desire to apply technology to its challenges.</li><li>Excellent communication and collaboration skills to work effectively with diverse teams.<br/><br/></li></ul><strong>You'll Be Responsible For<br/><br/></strong><ul><li>Designing and implementing robust backend components for our search, data pipelines, and analytics engine.</li><li>Integrating AI/LLM models into our infrastructure to enhance data processing and insights generation.</li><li>Optimizing data pipelines for efficiency and scalability, ensuring lightning-fast responses for users.</li><li>Collaborating with data scientists and frontend engineers to build a seamless user experience.</li><li>Contributing to the continuous improvement of our backend architecture and performance.<br/><br/></li></ul><strong>What We Offer<br/><br/></strong><ul><li>Competitive salary and equity package.</li><li>The chance to make a real impact in the world of finance.</li><li>A collaborative and supportive work environment.</li><li>Unlimited snacks and caffeine (because brilliant ideas need fuel).<br/><br/></li></ul><strong>Join us at AlphaWatch AI and help rewrite the future of financial decision-making.<br/><br/></strong>Apply today and let's unlock the power of financial expertise together!
      </div>",No Salary Info Found,Data and AI Engineer
2024 AI/ML Intern - Machine Learning Engineer,Adobe,12/19/2023,https://www.linkedin.com/jobs/view/3756141231,0,https://media.licdn.com/dms/image/C560BAQFrtK-ioO1rsQ/company-logo_100_100/0/1630645864762/adobe_logo?e=2147483647&v=beta&t=wxfArvhegDxZEB-gLnuqzm1Mqur7kWaVi1bCw9Yjw50,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Our Company<br/><br/></strong>Changing the world through digital experiences is what Adobe’s all about. We give everyone—from emerging artists to global brands—everything they need to design and deliver exceptional digital experiences! We’re passionate about empowering people to create beautiful and powerful images, videos, and apps, and transform how companies interact with customers across every screen.<br/><br/>We’re on a mission to hire the very best and are committed to creating exceptional employee experiences where everyone is respected and has access to equal opportunity. We realize that new ideas can come from everywhere in the organization, and we know the next big idea could be yours!<br/><br/><strong>The Opportunity<br/><br/></strong>Adobe is looking for a Machine Learning intern who will apply AI and machine learning techniques to big-data problems to help Adobe better understand, lead, and optimize the experience of its customers.<br/><br/>By using predictive models, experimental design, and optimization techniques, the candidate will be working on the research and development of exciting, computer-vision related projects like generative AI, segmentation, detection, classification, etc.<br/><br/>All 2024 Adobe interns will be ‘co-located hybrid. This means that interns will be assigned to an Adobe office location, but in-office schedules will be flexible and determined by team. All interns must live in the same state, country, and within commuting distance of their assigned Adobe office so they can be on-site as needed.<br/><br/><strong>What You’ll Do<br/><br/></strong><ul><li> Work closely with Research to develop and productize ML models and pipelines. </li><li> Develop and implement scalable and efficient ML-Ops tools and processes that can work with large-scale data in production systems. </li><li> Collaborate with product management and engineering groups to develop new products and features. <br/><br/></li></ul><strong>What You Need To Succeed<br/><br/></strong><ul><li> Currently enrolled full time and pursuing a Master’s or PhD degree in Computer Science, Computer Engineering; or equivalent experience required</li><li> Good understanding of statistical modeling, machine learning, deep learning, or data analytics concepts. </li><li> Proficient in one or more programming languages such as Python, Java and C</li><li> Familiar with the latest in ML-Ops techniques or API design and back end services desirable</li><li> Computer vision experience desirable</li><li> Strong analytical and quantitative problem-solving ability. </li><li> Excellent communication, relationship skills and a team player</li><li> Ability to participate in a full-time internship between May-September<br/><br/></li></ul>Our compensation reflects the cost of labor across several  U.S. geographic markets, and we pay differently based on those defined markets. The U.S. pay range for this position is $45.00 -- $55.00 hourly. Your recruiter can share more about the specific pay rate for your job location during the hiring process.<br/><br/>Adobe is proud to be an Equal Employment Opportunity and affirmative action employer. We do not discriminate based on gender, race or color, ethnicity or national origin, age, disability, religion, sexual orientation, gender identity or expression, veteran status, or any other applicable characteristics protected by law. Learn more.<br/><br/>Adobe aims to make Adobe.com accessible to any and all users. If you have a disability or special need that requires accommodation to navigate our website or complete the application process, email accommodations@adobe.com or call (408) 536-3015.<br/><br/>Adobe values a free and open marketplace for all employees and has policies in place to ensure that we do not enter into illegal agreements with other companies to not recruit or hire each other’s employees.
      </div>",$45.00- $55.00,Data and AI Engineer
AI Backend Developer,PETADATA,12/20/2023,https://www.linkedin.com/jobs/view/3789077415,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Machine Learning Engineer - Operations Research,Plaid,12/20/2023,https://www.linkedin.com/jobs/view/3790467462,0,https://media.licdn.com/dms/image/C560BAQHLwuXfJnPUKQ/company-logo_100_100/0/1657040795231/plaid__logo?e=2147483647&v=beta&t=JhmgMEoCTiz__kDXmZOkrpjtLYHPbCfWV-ix1g6o0qI,"San Francisco, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We believe that the way people interact with their finances will drastically improve in the next few years. We’re dedicated to empowering this transformation by building the tools and experiences that thousands of developers use to create their own products. Plaid powers the tools millions of people rely on to live a healthier financial life. We work with thousands of companies like Venmo, SoFi, several of the Fortune 500, and many of the largest banks to make it easy for people to connect their financial accounts to the apps and services they want to use. Plaid’s network covers 12,000 financial institutions across the US, Canada, UK and Europe. Founded in 2013, the company is headquartered in San Francisco with offices in New York, Washington D.C., London and Amsterdam.<br/><br/>Plaid’s Machine Learning team is building models that improve how millions of users understand and grow their financial lives. We're looking for machine learning engineers with experience applying state-of-the-art machine learning and modeling techniques -- including natural language processing, anomaly detection, optimization, and time series forecasting -- toward different product areas. We value not only technical know-how, but also creativity, user empathy, and teamwork.<br/><br/>The traffic team is responsible for building and maintaining machine learning and/or optimization models to optimize web/API traffic flow. You will leverage ML and optimization techniques to help Plaid automate and scale our current traffic schedule system, which will help deliver a superior product experience to our partners and clients. In addition, you will develop and deploy ML and optimization models to help automate the traffic scheduling system.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Building and improving ML infrastructure that powers the end-to-end ML development lifecycle. </li><li>Hands-on develop, productionize, and operate Machine Learning/optimization models and pipelines to optimize Plaid’s web and API traffic.</li><li>Continuously proposing and developing new features to improve the Traffic ML/optimization model performance.</li><li>Debugging ML production issues across services and multiple levels of the stack.</li><li>Work collaboratively with cross-functional partners to identify opportunities for business impact, understand, refine, and prioritize requirements for machine learning and optimization models, drive engineering decisions, and quantify impact.<br/><br/></li></ul><strong>Qualifications<br/><br/></strong><ul><li>Experience in building optimization models to solve real world problems.</li><li>Experience in developing end to end data systems/products and productionizing ML and/or optimization models.</li><li>Experience in well-known big data processing infrastructures, like Airflow, DBT, Hive, Presto, Spark, and etc.</li><li>Ability to architect software and ML and/or optimization systems at scale.</li><li>Solid software engineer skill in complex and multi-language systems. Code fluency in Python.</li><li>Experience in working with product, design, and backend engineering.</li><li>Nice to have - experience in building and deploying large scale optimization or reinforcement learning system in an industrial setting (traffic routing, two-sided software marketplace, logistics optimization etc.)<br/><br/></li></ul>$178,200 - $267,300 a year<br/><br/>Target base salary for this role is between $178,200 and $267300 per year. Additional compensation in the form(s) of equity and/or commission are dependent on the position offered. Plaid provides a comprehensive benefit plan, including medical, dental, vision, and 401(k). Pay is based on factors such as (but not limited to) scope and responsibilities of the position, candidate's work experience and skillset, and location. Pay and benefits are subject to change at any time, consistent with the terms of any applicable compensation or benefit plans.<br/><br/>Our mission at Plaid is to unlock financial freedom for everyone. To support that mission, we seek to build a diverse team of driven individuals who care deeply about making the financial ecosystem more equitable. We recognize that strong qualifications can come from both prior work experiences and lived experiences. We encourage you to apply to a role even if your experience doesn't fully match the job description. We are always looking for team members that will bring something unique to Plaid!<br/><br/>Plaid is proud to be an equal opportunity employer and values diversity at our company. We do not discriminate based on race, color, national origin, ethnicity, religion or religious belief, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, military or veteran status, disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state, and local laws. Plaid is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance with your application or interviews due to a disability, please let us know at accommodations@plaid.com.<br/><br/>Please review our Candidate Privacy Notice here .<br/><br/>
</div>",$178200- $267300,Data and AI Engineer
"Senior Software Engineer, AI Products",Instabase,12/25/2023,https://www.linkedin.com/jobs/view/3777299782,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Senior Machine Learning Engineer,FORDER I.T.,12/21/2023,https://www.linkedin.com/jobs/view/3772866152,0,https://media.licdn.com/dms/image/C4E0BAQGyuRJqK8tNhw/company-logo_100_100/0/1673698645493?e=2147483647&v=beta&t=RGnyvgkq5KzeNYUYhD7cDXS_s_edcJhjPMQYpRXM5vI,"Manhattan, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>** HYBRID ROLE (New York City, NY) **</p><p>** Native or Fluent Mandarin Speaker **</p><p><br/></p><p>We are partnered with the most exciting Artificial Intelligence risk protection start-up in New York! They are looking to add an experienced Senior Machine Learning Engineer to the team!</p><p><br/></p><p><strong>The Position </strong></p><p>The ideal candidate for this position is an experienced individual who has worked in the space of AI platform development. This also requires experience building abstract data schemas, mappings and models. With a complex understanding of machine learning concepts within Computer Vision or NLP projects.</p><p><br/></p><p><strong>You should have</strong></p><ul><li>Bachelor's or master's degree in Computer Science, Artificial Intelligence, or Applied Mathematics</li><li>Proficient programming skills in Python, coupled with familiarity with ML frameworks such as TensorFlow or PyTorch.</li><li>5+ years of experience in Natural Language Processing (NLP)</li><li>Acquired knowledge of machine learning techniques and algorithms.</li><li>Strong understanding of deep learning AI/ML frameworks or cloud services</li><li>Hands-on experience in ML Ops</li></ul><p><br/></p><p><strong>Benefits</strong></p><ul><li>Opportunity to own/ drive important and critical projects.</li><li>Competitive compensation including equity</li><li>Paid benefits for employees and dependents; including medical, dental, vision, disability and life insurance.</li><li>401(k) plan with company matching.</li><li>Flexible payback for out-of-pocket parking, transit and medical expenses.</li><li>Professional Learning and Development fund.</li><li>And more!</li></ul><p><br/></p><p>Salary: $160,000 - $200,000 + Equity</p><p><br/></p><p>Apply direct or email your application to oliver@forder-it.com</p><p><br/></p><p>www.forder-it.com</p>
</div>",$160000- $200000,Data and AI Engineer
Machine Learning Engineer,Talkspace,12/19/2023,https://www.linkedin.com/jobs/view/3762682837,0,https://media.licdn.com/dms/image/C4D0BAQFxdmtty5waaw/company-logo_100_100/0/1636986592615/talkspace_online_therapy_logo?e=2147483647&v=beta&t=96L8_5XF_FuU9DxFX-RUZ8-g11K3korVzMubxFDfsQ8,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Our mission at Talkspace is to help people heal. To get there, we need exceptionally passionate, bright, and motivated people. Want to help over one million people receive quality mental healthcare? Come join our mission of getting therapy in the hands of everyone!<br/><br/>We are looking for a seasoned Machine Learning Engineer to join our Technology team. This role will be responsible for pushing the boundaries of machine learning to deliver AI solutions that have a direct impact on Talkspace’s mission. We are seeking someone who has demonstrated expertise in AI for human-centered applications and the publication of academic research papers.<br/><br/>This position is hybrid and requires 2-3 days per week in our New York City office, near Grand Central.<br/><br/><strong>What You’ll Do<br/><br/></strong><ul><li>Work closely with our business stakeholders, the product team, and our data science department and our engineers to design and develop new algorithms and services. Examples include but are not limited to:</li><ul><li>Keyword and Topic Extraction</li><li>Emotion/Sentiment Identification</li><li>Text summarization</li><li>Text classification</li><li>Recommender systems</li><li>Intent detection and query parsing</li></ul><li>Guide the technical scoping and requirements-gathering of machine learning projects from research and development to production deployment.</li><li>Translate business needs into potential solutions and applications of machine learning that directly impact our business.</li><li>Lead the end-to-end execution of machine learning projects, collaborating with data scientists as necessary.</li><li>Build dataset creation, model training, and evaluation tools in an AWS environment.</li><li>Implement and maintain the build and deploy systems for production-critical data science services.<br/></li></ul><strong>About You<br/><br/></strong><ul><li>You hold an MA/MS or higher degree, preferably in Computer Science, Data Science, or an Engineering-related discipline.</li><li>5+ years of experience developing and deploying product-quality code.</li><li>4+ years of experience with NLP techniques and models for text analysis, sentiment analysis, language understanding, and generation.</li><li>Deep experience with Python and SQL.</li><li>You have a strong portfolio of published academic research papers.</li><li>You have proficiency in deep learning frameworks, and experience with deep neural networks for complex problem-solving.</li><li>You have a commitment to ethical AI practices and an understanding of the ethical considerations and potential biases in AI within healthcare.</li><li>You have experience with cloud-based machine learning services and platforms (e.g., AWS SageMaker, Google AI Platform) for model development and deployment.<br/><br/></li></ul><strong>Benefits<br/><br/></strong><ul><li>Comprehensive Medical, Dental, and Vision plans coverage since day one.</li><li>Pre-tax benefits: HSA/FSA.</li><li>401k Retirement Savings Program with matching up to 4%.</li><li>Voluntary benefits including disability, basic life, or pet insurance, etc.</li><li>Monthly Wellness Stipend to promote mental and physical self-care.</li><li>Flexible PTO and Remote First Environment.</li><li>Regular team events, including Wellness Workshops and Team Building Events.</li><li>Free access to Talkspace products for you and one household member, as well as access to a friends and family discount!<br/><br/></li></ul><strong>Compensation<br/><br/></strong>At Talkspace, we believe that pay transparency during the interview process is a critical part of diversity, equity, and inclusion. Our salary bands are based on internal and external compensation benchmarks, which we regularly evaluate to ensure we pay competitively.<br/><br/>The base salary range for this role is between $170,000 and $190,000 with a competitive bonus. Within the salary bands, leveling corresponds to each candidate’s relevant experience, skills as assessed during the interview process, education, and applicable certifications.<br/><br/>Why Talkspace?<br/><br/>Talkspace is the most comprehensive and convenient way to take care of your mental health and wellness, focused on providing quality mental health services on your own terms.<br/><br/>Our signature psychotherapy and psychiatry product connects individual users with a network of thousands of licensed mental health providers through an easy-to-use and HIPAA-compliant web and mobile platform. With Talkspace, users can connect their dedicated provider via live video, text, or phone.<br/><br/>Backed by over 10 years of industry-leading research and clinically proven results, our accessible care model continues to make huge strides in lowering the barriers to quality mental healthcare services nationwide. Talkspace is the top insurance-covered therapy service with over 112 million Americans covered and a leader within the Corporate Wellness Space, with more than 200 employer partnerships across several industries.<br/><br/>Our focus to help people feel better starts at Talkspace, where we connect and collaborate as a team to make the world a better place. Fun company-wide events, happy hours, wellness perks, flex PTO, access to Talkspace products, and competitive benefits are just some of the ways we make Talkspace a great place to work. Do you want to save the world? Come join us!<br/><br/>EQUAL OPPORTUNITY EMPLOYER<br/><br/>Talkspace welcomes and celebrates talent from all backgrounds, perspectives, and walks of life to foster an innovative and diverse workforce. We encourage you to apply, even if you don’t meet every qualification, if you believe you could make a great addition to this team. Come as you are and learn about the exciting opportunities on our team.<br/><br/>Individuals seeking employment at Talkspace are considered without regard to race, color, religious creed, sex, national origin, citizenship status, age, physical or mental disability, sexual orientation, marital, parental, veteran or military status, unfavorable military discharge, or any other status protected by applicable federal, state, or local law.<br/><br/><strong>How do we define Diversity, Equity, Inclusion, and Belonging at Talkspace?<br/><br/></strong><strong>Diversity<br/><br/></strong>Diversity encompasses the unique attributes of our employees as individuals. We value and embrace the richness arising from their varied backgrounds, perspectives, and experiences, which include, but are not limited to, age, ability, ethnicity, gender, race, and cultural background.<br/><br/><strong>Equity<br/><br/></strong>Equity refers to a fair and impartial workplace, aiming to ensure equal growth and advancement opportunities for all employees. This involves amplifying underrepresented voices, addressing unconscious biases, and providing inclusive, culturally competent mental health care.<br/><br/><strong>Inclusion<br/><br/></strong>Inclusion signifies the practice of granting equal access to opportunities and resources for all employees, particularly those who might otherwise be excluded or marginalized. It ensures that everyone feels a sense of belonging, value, support, and respect as an individual.<br/><br/><strong>Belonging<br/><br/></strong>Belonging reflects the affinity and positive relationships that develop among employees from diverse backgrounds when businesses actively promote diversity, equity, and inclusion in the workplace.
      </div>",$170000- $190000,Data and AI Engineer
"Machine Learning Engineer, Growth",Grammarly,12/19/2023,https://www.linkedin.com/jobs/view/3731821997,0,https://media.licdn.com/dms/image/C560BAQFroT18wpIblQ/company-logo_100_100/0/1669669290715/grammarly_logo?e=2147483647&v=beta&t=ztA7DBsCxjynNbw6oGlEHqtgqJneLWUJ1rfYbYVi91A,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>Grammarly is excited to offer a </em><em>remote-first hybrid working model</em><em>. Team members work primarily remotely in the United States, Canada, Ukraine, Germany, or Poland. Certain roles have specific location requirements to facilitate collaboration at a particular Grammarly hub.<br/><br/></em><em>All roles have an in-person component: Conditions permitting, teams meet 2–4 weeks every quarter at one of Grammarly’s hubs in San Francisco, Kyiv, New York, Vancouver, and Berlin, or in a workspace in Kraków. </em><em>This flexible approach gives team members the best of both worlds: plenty of focus time along with in-person collaboration that fosters trust and unlocks creativity.<br/><br/></em><em>Grammarly team members in this role must be based in the United States or Canada, and they must be able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub(s) where the team is based.<br/><br/></em><strong>The opportunity <br/><br/></strong>Grammarly is the world’s leading AI writing assistance company trusted by over 30 million people and 70,000 professional teams every day. From instantly creating a first draft to perfecting every message, Grammarly’s product offerings help people at 96% of the Fortune 500 get their point across—and get results. Grammarly has been profitable for over a decade because we’ve stayed true to our values and built an enterprise-grade product that’s secure, reliable, and helps people do their best work—without selling their data. We’re proud to be one of Inc.’s best workplaces, a Glassdoor Best Place to Work, one of TIME’s 100 Most Influential Companies, and one of Fast Company’s Most Innovative Companies in AI.<br/><br/>To achieve our ambitious goals, we’re looking for a Machine Learning Engineer to join our Marketing Technology team. This team is responsible for building systems that empower and enhance the company's marketing efforts and strategies. The person in this role will help shape marketing strategies, enhance customer experiences, and optimize marketing campaigns. They will be responsible for leveraging data and advanced algorithms to improve the performance and efficiency of advertising campaigns with the goal of maximizing the return on investment (ROI) for ad spend and delivering targeted ads to the right audience.<br/><br/>Grammarly’s engineers and researchers have the freedom to innovate and uncover breakthroughs—and, in turn, influence our product roadmap. The complexity of our technical challenges is growing rapidly as we scale our interfaces, algorithms, and infrastructure. Read more about our stack or hear from our team on our technical blog.<br/><br/><strong>Your impact<br/><br/></strong>As Machine Learning Engineer on the Marketing Technology team, you will transform the way marketing is done at Grammarly. You will improve data-driven decision-making, enhance customer experiences, and optimize marketing campaigns, ultimately leading to improved business outcomes and higher customer satisfaction.<br/><br/><strong>In This Role You Will<br/><br/></strong><ul><li>Drive business impact by building scalable end-to-end machine learning solutions for challenging marketing problems.</li><li>Help marketing teams make data-driven decisions.</li><li>Personalize marketing efforts, tailoring content and offers to individual customers.</li><li>Promote excellence and best practices across the Machine Learning team in research, implementation, tooling, and system design.</li><li>Work cross-functionally with various teams: Marketing, Marketing Analytics, Data Science, ML Infrastructure, and Product to name a few. </li><li>Effectively communicate technical machine learning results in a business context where most people are not machine learning experts.<br/><br/></li></ul><strong>We’re Looking For Someone Who<br/><br/></strong><ul><li>Embodies our EAGER values—is ethical, adaptable, gritty, empathetic, and remarkable.</li><li>Is inspired by our MOVE principles, which are the blueprint for how things get done at Grammarly: move fast and learn faster, obsess about creating customer value, value impact over activity, and embrace healthy disagreement rooted in trust.</li><li>Is able to collaborate in person 2 weeks per quarter, traveling if necessary to the hub where the team is based.</li><li>Has solid software engineering fundamentals, including knowledge of classical algorithms and data structures.</li><li>Has a solid understanding of the principles and best practices of developing software systems on a large scale.</li><li>Has the ability to apply machine learning algorithms to ad optimization tasks effectively.</li><li>Has strong knowledge of probability and statistics.</li><li>Has expertise in Python, its ecosystem, and Python-based ML tools and frameworks.</li><li>Has experience in Ad Optimisation domain: knowledge of different types of ad channels, multi-channel budget allocation, key marketing performance metrics. <br/><br/></li></ul><strong>Support for you, professionally and personally<br/><br/></strong><ul><li>Professional growth: We believe that autonomy and trust are key to empowering our team members to do their best, most innovative work in a way that aligns with their interests, talents, and well-being. We support professional development and advancement with training, coaching, and regular feedback.</li><li>A connected team: Grammarly builds a product that helps people connect, and we apply this mindset to our own team. Our remote-first hybrid model enables a highly collaborative culture supported by our EAGER (ethical, adaptable, gritty, empathetic, and remarkable) values. We work to foster belonging among team members in a variety of ways. This includes our employee resource groups, Grammarly Circles, which promote connection among those with shared identities, such as BIPOC and LGBTQIA+ team members, women, and parents. We also celebrate our colleagues and accomplishments with global, local, and team-specific programs. <br/><br/></li></ul><strong>Compensation And Benefits<br/><br/></strong>Grammarly offers all team members competitive pay along with a benefits package encompassing the following and more:<br/><br/><ul><li>Excellent health care (including a wide range of medical, dental, vision, mental health, and fertility benefits)</li><li>Disability and life insurance options</li><li>401(k) and RRSP matching </li><li>Paid parental leave</li><li>Twenty days of paid time off per year, eleven days of paid holidays per year, and unlimited sick days </li><li>Home office stipends</li><li>Caregiver and pet care stipends</li><li>Wellness stipends</li><li>Admission discounts</li><li>Learning and development opportunities<br/><br/></li></ul>Grammarly takes a market-based approach to compensation, which means base pay may vary depending on your location. Our US and Canada locations are categorized into compensation zones based on each geographic region’s cost of labor index. For more information about our compensation zones and locations where we currently support employment, please refer to this page. If a location of interest is not listed, please speak with a recruiter for additional information.<br/><br/>Base pay may vary considerably depending on job-related knowledge, skills, and experience. The expected salary ranges for this position are outlined below by compensation zone and may be modified in the future.<br/><br/><strong>United States<br/><br/></strong>Zone 1: $271,000 – $337,000 (USD)<br/><br/>Zone 2: $244,000 – $303,000 (USD)<br/><br/>Zone 3: $$230,000 – $286,000(USD)<br/><br/>Zone 4: $217,000 – $270,000 (USD)<br/><br/><strong>Canada<br/><br/></strong>Zone 1: $224,000 – $279,000 (CAD)<br/><br/>Zone 2: $190,000 – $237,000 (CAD)<br/><br/><strong>We encourage you to apply<br/><br/></strong>At Grammarly, we value our differences, and we encourage all—especially those whose identities are traditionally underrepresented in tech organizations—to apply. We do not discriminate on the basis of race, religion, color, gender expression or identity, sexual orientation, ancestry, national origin, citizenship, age, marital status, veteran status, disability status, political belief, or any other characteristic protected by law. Grammarly is an equal opportunity employer and a participant in the US federal E-Verify program (US). We also abide by the Employment Equity Act (Canada).<br/><br/><em>Please note that EEOC is optional and specific to US-based candidates.<br/><br/></em>#NA<br/><br/><em>All team members meeting in person for official Grammarly business or working from a hub location are strongly encouraged to be vaccinated against COVID-19.<br/><br/></em>
</div>",$271000- $337000,Data and AI Engineer
AI Engineer (Python),Open Systems Technologies,12/19/2023,https://www.linkedin.com/jobs/view/3772606379,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Sr. Machine Learning Engineer,Nielsen,12/19/2023,https://www.linkedin.com/jobs/view/3766327688,0,https://media.licdn.com/dms/image/C4E0BAQFKa_ObftR_8w/company-logo_100_100/0/1634555714141/nielsen_logo?e=2147483647&v=beta&t=nKy3CwaEkTSnMkh2Cb4XRoVFdPtiARFGoNvmxeqVMRs,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At Nielsen, we believe that career growth is a partnership. You ultimately own, fuel and set the journey. By joining our team of nearly 14,000 associates, you will become part of a community that will help you to succeed. We champion you because when you succeed, we do too. Embark on a new initiative, explore a fresh approach, and take license to think big, so we can all continuously improve. We enable your best to power our future.<br/><br/>This engineer will develop Machine Learning based solutions that aid in the curation and augmentation of one of the largest international entertainment data sets in the world.<br/><br/><strong>What We're Looking For<br/><br/></strong><ul><li>Proven track record of building modern Machine Learning, Deep Learning and Natural Language Processing based solutions</li><li>Proficiency with at least one common Deep Learning framework (e.g. PyTorch, TensorFlow)</li><li>Proficiency in Python and a data query language (e.g. SQL)</li><li>Proven track record of writing understandable, maintainable and testable code</li><li>Familiarity with software development practices such as unit testing, code reviews, and version control</li><li>Experience or strong interest working with cloud computing (preferably AWS)</li><li>Strong problem solving skills and the ability to work independently or collaboratively as required</li><li>A Bachelor’s degree in computer science, artificial intelligence, applied mathematics, statistics, machine learning or related field<br/><br/></li></ul><strong>Bonus Points<br/><br/></strong><ul><li>An advanced degree (MS or PhD) in computer science, artificial intelligence, applied mathematics, statistics, machine learning or related field</li><li>Experience working on LLM based Text Generation problems</li><li>Experience working on multilingual problems</li><li>Experience building internal review/labeling tools using Streamlit or equivalent</li><li>Proficiency in Spark using PySpark or Scala<br/><br/></li></ul><strong>Nielsen</strong>: Enabling your best to power a better media future. Our comprehensive benefits package (including health &amp; wellness plans, 401(k) retirement coupled with a Nielsen match, a generous paid time off policy, company provided car for those who qualify, and if eligible, a discretionary incentive/bonus) is designed to be inclusive for all employees and families, and we take pride in ensuring that employees are rewarded holistically for the role they are doing and their performance.<br/><br/>A reasonable estimate of salary range for a new employee to be offered this role would be $140,000 - $215,000 which would be adjusted based on each employee's geographic location. The position of each employee within a compensation range at Nielsen is dependent on several individual circumstances, such as experience, training, certifications and other business requirements/needs.<br/><br/>Nielsen is committed to hiring and retaining a diverse workforce. We are proud to be an Equal Opportunity/Affirmative Action-Employer, making decisions without regard to race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability status, age, marital status, protected veteran status or any other protected class.<br/><br/>
</div>",$140000- $215000,Data and AI Engineer
Senior Artificial Intelligence Algorithms Engineer,NVIDIA,12/19/2023,https://www.linkedin.com/jobs/view/3755933754,0,https://media.licdn.com/dms/image/C560BAQFDs6GbpvE3zA/company-logo_100_100/0/1630584931971/nvidia_logo?e=2147483647&v=beta&t=LoUj3FUN8Y9axtbhorghJZo6ep0wi4o5FxBaIXIm5b4,"New York, United States","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>We are now looking for a Senior Artificial Intelligence Algorithms Engineer:<br/><br/></strong>NVIDIA is seeking engineers to design, develop and optimize Artificial Intelligence solutions to diverse real-world problems.<br/><br/>If you have a strong understanding of AI /Deep-Learning(DL) and a deep algorithmic background, with exposure to computer architecture and performance, then this role may be a great fit for you! Collaborate and interact with internal partners, users, and members of the open source community to analyze, define and implement highly optimized AI algorithms. The scope of these efforts includes a combination of implementing new algorithms, performance/accuracy tuning and analysis, defining APIs, and analyzing functionality coverage to build larger, coherent toolsets and libraries. The ability to work in a multifaceted, product-centric environment with excellent interpersonal skills are required, to be successful in this role.<br/><br/><strong>What You’ll Be Doing<br/><br/></strong><ul><li>Develop algorithms for AI/DL, data analytics, machine learning, or scientific computing</li><li>Tackle large-scale distributed systems capable of performing end-to-end AI training and inference-deployment (data fetching, pre-processing, orchestrate and run model training and tuning, model serving)</li><li>Analyze, influence, and improve AI/DL libraries, frameworks and APIs according to good engineering practices</li><li>Research, prototype, and develop effective tools and infrastructure pipelines</li><li>Publish innovative results on Github and scientific publications<br/><br/></li></ul><strong>What We Need To See<br/><br/></strong><ul><li>A PhD or Master's Degree (or equivalent additional experience) and 5+ years of industry experience in Computer Science, AI, Applied Math, or related field</li><li>Strong Mathematical fundamentals and AI/DL algorithms skills or experience</li><li>Excellent programming, debugging, performance analysis, test design and documentation skills</li><li>Experience with AI/DL Frameworks (e.g. PyTorch, JAX)</li><li>Excellent C/C++ and Python programming skills<br/><br/></li></ul><strong>Ways To Stand Out From The Crowd<br/><br/></strong><ul><li>Knowledge of GPU/CPU architecture and related numerical software</li><li>Prior experience with Generative AI techniques applied to Large Language Modelsand multimodal learning (Image, Video, Speech etc.)</li><li>Exposure to large-scale AI training, understanding of the compute system concepts (latency/throughput bottlenecks, pipelining, multiprocessing etc) and related performance analysis and tuning</li><li>Hands-on experience with inference and deployment environments would be an asset (e.g. TRT, ONNX, Triton)<br/><br/></li></ul>NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people on the planet working with us. If you're creative and collaborative computer scientist with a passion for Artificial Intelligence / Deep Learning Algorithms, we want to hear from you!<br/><br/>The base salary range is 144,000 USD - 270,250 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.<br/><br/>You will also be eligible for equity and benefits . <em> NVIDIA accepts applications on an ongoing basis. <br/><br/></em>NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.<br/><br/>
</div>",No Salary Info Found,Data and AI Engineer
AI Engineer,Notion,12/19/2023,https://www.linkedin.com/jobs/view/3584600324,0,https://media.licdn.com/dms/image/D560BAQGSOTc29sEYDA/company-logo_100_100/0/1680539341112/notionhq_logo?e=2147483647&v=beta&t=JppE4EUsJlnAtNVNbdXyBJld1rP5X3qaAJUbC2tHgp0,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>We're on a mission to make it possible for every person, team, and company to be able to tailor their software to solve any problem and take on any challenge. Computers may be our most powerful tools, but most of us can't build or modify the software we use on them every day. At Notion, we want to change this with focus, design, and craft.<br/><br/>We've been working on this together since 2016, and have customers like Pixar, Mitsubishi, Figma, Plaid, Match Group, and thousands more on this journey with us. Today, we're growing fast and excited for new teammates to join us who are the best at what they do. We're passionate about building a company as diverse and creative as the millions of people Notion reaches worldwide.<br/><br/>Notion is an in person company, and currently requires its employees to come to the office for two Anchor Days (Mondays &amp; Thursdays) and requests that employees spend the majority of their week in the office (including a third day).<br/><br/><strong>About The Role<br/><br/></strong>We are looking for an AI Engineer to join our small but nimble AI team whose mission is to make Notion a product that gives empowers our users to tackle larger problems leveraging AI. As a more experienced member of the team, you will work on determining how best to incorporate large language models (LLMs), embeddings, and other AI technologies into Notion’s product. You’ll be exploring the boundaries of what’s possible with ML technology and finding innovative ways to apply new industry learnings to Notion’s product offering.<br/><br/><strong>What You’ll Achieve<br/><br/></strong><ul><li>Work with the team to prototype and experiment with new AI features</li><li>Productionize and launch new AI technology integrations into Notion’s core product</li><li>Collaborate with cross-functional teams to deliver product features on time</li><li>Stay up-to-date with the latest AI technologies and trends<br/><br/></li></ul><strong>Skills You'll Need To Bring<br/><br/></strong><ul><li>Domain Expert, Teacher and Learner: You have experience building AI products using LLMs, embeddings or other ML natural language technologies. 3+ years of experience in one or more of the following areas: machine learning, recommendation or ranking systems, natural language understanding/generation or artificial intelligence. You’re excited about bringing your pre-existing knowledge to the team, but you balance that with perpetual curiosity and understanding that there is always more to learn.</li><li>Pragmatic Problem-solver: You approach problems holistically, starting with a clear and accurate understanding of the context. You think critically about the implications of what you're building and how it will impact real people's lives. You can navigate ambiguity flawlessly, decompose complex problems into clean solutions, while also balancing the business impact of what you’re building. You are able to think on your feet, iterate efficiently on new ideas, and are enthusiastic about shifting your thinking as new information comes to light.</li><li>Empathetic communication and leadership: You communicate nuanced ideas clearly, whether you're explaining technical decisions in writing or brainstorming in real time. In disagreements, you engage thoughtfully with other perspectives and compromise when needed. You enjoy collaborating with and mentoring fellow engineers and work well with cross-functional partners. You are a lifelong learner and invest in both your own growth and the growth, learning, and development of your teammates.</li><li>Impact-orientation and user focus: You care about business impact and prioritize projects accordingly. You understand the balance between craft, speed, and the bottom line. You think critically about the implications of what you're building, and how it shapes real people's lives. You understand that reach comes with responsibility for our impact—good and bad. Work isn't a solo endeavor for you, and you enjoy collaborating cross-functionally to accomplish shared goals.<br/><br/></li></ul><strong>Nice To Haves<br/><br/></strong><ul><li>You understand how parts of a system fit together, from the user interface to the data model. You are familiar with relational database systems like Postgres or MySQL, and have experience building products from ground up.</li><li>You’re proficient with data pipeline technologies: Spark, DBT, etc</li><li>You're proficient with any part of our technology stack: React, TypeScript, Node.js, and Postgres.</li><li>You have experience driving teams toward shared goals and can balance business priorities with individuals’ strengths, areas of interest, and career development goals.</li><li>You've heard of computing pioneers like Ada Lovelace, Douglas Engelbart, Alan Kay, and others—and understand why we're big fans of their work.</li><li>You have interests outside of technology, such as in art, history, or social sciences.<br/><br/></li></ul>We hire talented and passionate people from a variety of backgrounds because we want our global employee base to represent the wide diversity of our customers. If you’re excited about a role but your past experience doesn’t align perfectly with every bullet point listed in the job description, we still encourage you to apply. If you’re a builder at heart, share our company values, and enthusiastic about making software toolmaking ubiquitous, we want to hear from you.<br/><br/>Notion is proud to be an equal opportunity employer. We do not discriminate in hiring or any employment decision based on race, color, religion, national origin, age, sex (including pregnancy, childbirth, or related medical conditions), marital status, ancestry, physical or mental disability, genetic information, veteran status, gender identity or expression, sexual orientation, or other applicable legally protected characteristic. Notion considers qualified applicants with criminal histories, consistent with applicable federal, state and local law. Notion is also committed to providing reasonable accommodations for qualified individuals with disabilities and disabled veterans in our job application procedures. If you need assistance or an accommodation due to a disability, please let your recruiter know.<br/><br/>Notion is committed to providing highly competitive cash compensation, equity, and benefits. The compensation offered for this role will be based on multiple factors such as location, the role’s scope and complexity, and the candidate’s experience and expertise, and may vary from the range provided below. For roles based in San Francisco or New York City, the estimated base salary range for this role is $160,000 - $280,000 per year.<br/><br/>
</div>",$160000- $280000,Data and AI Engineer
"Software Engineer, Bridging and Machine Learning, Jigsaw",Google,12/20/2023,https://www.linkedin.com/jobs/view/3788489180,0,https://media.licdn.com/dms/image/C4D0BAQHiNSL4Or29cg/company-logo_100_100/0/1631311446380?e=2147483647&v=beta&t=5bmvSDVt4i-ECxTU43yiS4iXUM4inJiG-e9PHOUlxx0,"New York, NY","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Minimum qualifications:<br/><br/></strong><ul><li>Bachelor's degree in Computer Science, related technical field, or equivalent practical experience.</li><li>5 years of experience with software development in one or more programming languages, and with data structures/algorithms.</li><li>3 years of experience testing, maintaining, or launching software products, and 1 year of experience with software design and architecture.<br/><br/></li></ul><strong>Preferred qualifications:<br/><br/></strong><ul><li>Experience working with the latest large language models.</li><li>Familiarity with academic research in AI, machine learning, and published papers.</li><li>Familiarity with social science academic research on subfields related to online discourse including conflict transformation, social norms, and polarization.<br/><br/></li></ul><strong>About The Job<br/><br/></strong>Google's software engineers develop the next-generation technologies that change how billions of users connect, explore, and interact with information and one another. Our products need to handle information at massive scale, and extend well beyond web search. We're looking for engineers who bring fresh ideas from all areas, including information retrieval, distributed computing, large-scale system design, networking and data storage, security, artificial intelligence, natural language processing, UI design and mobile; the list goes on and is growing every day. As a software engineer, you will work on a specific project critical to Google’s needs with opportunities to switch teams and projects as you and our fast-paced business grow and evolve. We need our engineers to be versatile, display leadership qualities and be enthusiastic to take on new problems across the full-stack as we continue to push technology forward.<br/><br/>We are evolving beyond identifying toxicity towards holistically supporting healthier online discourse by bridging diverse perspectives and fostering community connection. The team will work with content-based bridging algorithms to capture and predict “diverse appeal” based on content of a conversation and explore how to incorporate more traditional forms of bridging to a variety of online spaces.<br/><br/>In this role, you will bridge engineering and social science research, proficient enough in each to support the development of models with the Perspective team, work with Jigsaw's social science team to conduct research that advances the field of bridging algorithms, and understands their impact on people and conversations.<br/><br/>Jigsaw is a unit within Google that explores threats to open societies and builds technology that inspires scalable solutions. Our team addresses a range of global security issues. Jigsaw offers unique opportunities within the industry, mission-driven work within a team, strong connections to academia and civil society, and a quick path to making technology public. The Conversation-AI team's goal is to protect voices in online conversation. We design and build innovative user experiences to explore how our models can help humans have better conversations. We also publish original research to advance the state-of-the-art in using ML to support good online discussion.<br/><br/>The US base salary range for this full-time position is $157,000-$235,000 + bonus + equity + benefits. Our salary ranges are determined by role, level, and location. The range displayed on each job posting reflects the minimum and maximum target for new hire salaries for the position across all US locations. Within the range, individual pay is determined by work location and additional factors, including job-related skills, experience, and relevant education or training. Your recruiter can share more about the specific salary range for your preferred location during the hiring process.<br/><br/>Please note that the compensation details listed in US role postings reflect the base salary only, and do not include bonus, equity, or benefits. Learn more about benefits at Google .<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Build on the latest LLM technology to enable new Perspective API features and improvements, such as developing new bridging-focused models.</li><li>Work across the ML development lifecycle including leading data annotation processes, training models, evaluating, measuring and mitigating for bias, and meeting production latency and serving requirements.</li><li>Conduct independent research that is useful for society and Google, such as being integrated as part of a deployed product or service, resulting in co-authorship of a paper or patent.</li><li>Iterate on experimental approaches that apply mixed methods from computational and social sciences, in order to conduct and scale studies in collaboration with Google researchers, designers, engineers, and product managers.</li><li>Communicate research findings to diverse audiences.<br/><br/><br/></li></ul>Google is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. We also consider qualified applicants regardless of criminal histories, consistent with legal requirements. See also Google's EEO Policy and EEO is the Law. If you have a disability or special need that requires accommodation, please let us know by completing our Accommodations for Applicants form .
      </div>",$157000- $235000,Data and AI Engineer
Software Engineer (Backend / AI),Alphawatch.AI,12/20/2023,https://www.linkedin.com/jobs/view/3788497260,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Junior Data Scientist - US Residents Only,Team Remotely Incorporation,12/25/2023,https://www.linkedin.com/jobs/view/3793154087,0,https://media.licdn.com/dms/image/D4D0BAQFKPwUb2y1chw/company-logo_100_100/0/1702987730303?e=2147483647&v=beta&t=-X5LVvheBqm_7DpHnmichw7-gf09NLhB7Tq6GJJcKm8,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong> Junior Data Scientist - US Residents Only, 1 year experience, remote)<br/><br/></strong>Team Remotely Inc. is a staffing and recruitment agency that offers a comprehensive solution for talent acquisition, including sourcing, vetting, pay rolling, and managing talent. Whether you need contract staffing, direct hire, direct sourcing, talent pools, or diversity initiatives, our model can support your hiring strategy.<br/><br/><strong> Hiring Type:</strong> Full-Time<br/><br/><strong> Base Salary:</strong> $60K-$70K Per Annum.<br/><br/><strong> How to Apply:</strong> Please visit teamremotely.com to learn more &amp; apply.<br/><br/><strong>Responsibilities:<br/><br/></strong>Partner with engineers, product managers, and business partners to identify algorithmic problems, brainstorm possible approaches, and recommend the best path forward.<br/><br/>Develop algorithms iteratively, building in the right level of complexity to solve the business problem at hand and support future improvements.<br/><br/>Define success criteria for your models so that you can measure impact and changes over time. You'll be expected to communicate findings and drive continuous improvements.<br/><br/>Collaborate with Software Engineers to implement algorithms in production that scale gracefully.<br/><br/>Collaborate with stakeholders to prioritize projects and define requirements.<br/><br/>Carry out analysis of data produced by our hardware systems and create insightful visualizations to share your findings.<br/><br/>Contribute to internal libraries to help other teams with their data science needs including visualization, prediction, optimization, and inference.<br/><br/><strong>Requirements &amp; Experience:<br/><br/></strong>Advanced proficiency with Python and libraries commonly used for data analysis, e.g., Pandas, NumPy, SciPy, and Diplomatist.<br/><br/>Strong understanding of data modeling and statistical analysis.<br/><br/>Knowledge of optimization and predictive modeling techniques and experience applying them to real-world problems.<br/><br/>Skilled at translating a general question or problem into a clearly defined algorithmic solution.<br/><br/>Ability to communicate clearly with both technical and non-technical audiences.<br/><br/>Ability to work independently and manage multiple projects simultaneously.<br/><br/><strong>Nice to have:<br/><br/></strong>1-year Experience with Data Bricks or PySpark<br/><br/>1 year Experience with product ionizing data models<br/><br/><strong> Why work with Team Remotely?<br/><br/></strong>Team Remotely Inc. is a staffing platform offering a seamless experience for employers and candidates. Employers can post job openings and specify their requirements, while candidates can create profiles and upload resumes.<br/><br/>The team of Team Remotely continuously learns and adapts based on previous successful placements, constantly improving its matching capabilities. This ensures that the recommendations provided by Team Remotely are tailored and accurate, increasing the likelihood of a successful match between employers and candidates. By providing intelligent and data-driven solutions, they strive to enhance the efficiency and effectiveness of the hiring process, ultimately helping companies find the best talent and individuals find their dream jobs.<br/><br/>
</div>",$60- $70,Data and AI Engineer
AI Engineer,Motion Recruitment,12/22/2023,https://www.linkedin.com/jobs/view/3776484734,0,https://media.licdn.com/dms/image/C4E0BAQGBvaHLa2cjkg/company-logo_100_100/0/1657739070648/motion_recruitment_partners_logo?e=2147483647&v=beta&t=IOXFoJMyxUVpetwSC5tQM2Yn2QHnBd1ohX-wzpzkDn0,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        We are a pioneering technology company at the forefront of AI innovation, dedicated to developing groundbreaking solutions that revolutionize entire industries. Our team, composed of experienced professionals, consistently pushes the limits of AI capabilities. We are currently seeking a committed AI Engineer to join us full-time. As an AI Engineer, you will play a crucial role in creating and deploying state-of-the-art AI models and applications, actively contributing to the development of innovative products leveraging AI to address real-world challenges.<br/><br/><strong>Required Skills &amp; Experience<br/><br/></strong><ul><li>Bachelor's, Master's, or Ph.D. in Computer Science, Electrical Engineering, or a related field. </li><li>Minimum of 6 years hands-on experience in AI engineering, specializing in computer vision. </li><li>Proven expertise in training and deploying complex deep learning models using PyTorch and Python. </li><li>Strong understanding of image processing, object detection, image segmentation, and related computer vision techniques. </li><li>Familiarity with large language models (LLMs) and their integration into AI systems is advantageous. </li><li>Experience leading end-to-end AI projects, from ideation to deployment. </li><li>Exceptional problem-solving skills and adaptability to tackle new challenges in a dynamic environment. </li><li>Effective communication skills for seamless collaboration with cross-functional teams and conveying complex technical concepts. <br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li>Develop and implement cutting-edge computer vision algorithms for extracting meaningful insights from visual data. </li><li>Collaborate closely with multidisciplinary teams to integrate AI technologies seamlessly into our product suite. </li><li>Lead the research and development of deep learning models using PyTorch and Python, ensuring high performance and accuracy. </li><li>Fine-tune and optimize AI models for deployment across diverse platforms and environments. </li><li>Stay updated on AI advancements, particularly in computer vision, and propose innovative solutions proactively. <br/><br/></li></ul><strong>Offer<br/><br/></strong><ul><li>Competitive compensation package aligned with current market standards. </li><li>Unlimited PTO. </li><li>Comprehensive benefits, including medical, dental, vision, and more. </li><li>Stock options. </li><li>Opportunity to work with a highly talented team of AI experts on cutting-edge projects. </li><li>Ongoing professional development and training to stay at the forefront of AI breakthroughs. </li><li>Collaborative and inclusive work environment that values creativity and innovation. <br/><br/></li></ul>Applicants must be currently authorized to work in the US on a full-time basis now and in the future. No third-parties.<br/><br/><strong>Posted By:</strong> Megan Barno<br/><br/>
</div>",No Salary Info Found,Data and AI Engineer
Machine Learning Engineer Graduate (E-Commerce Recommendation/Search Alliance)- 2024 Start (MS),TikTok,12/19/2023,https://www.linkedin.com/jobs/view/3688641304,0,https://media.licdn.com/dms/image/C510BAQGCdThXIss7UQ/company-logo_100_100/0/1630606162248/tiktok_logo?e=2147483647&v=beta&t=139uJTX7-HNeX1_kJsHK-Ztmj2K9yb9XfIIGQoNOW3c,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong> TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, Mountain View, New York, Austin, London, Paris, Berlin, Dubai, Singapore, Jakarta, São Paulo, Seoul and Tokyo. <br/><br/>Why Join US<br/>At TikTok, our people are humble, intelligent, compassionate and creative. We create to inspire - for you, for us, and for more than 1 billion users on our platform. We lead with curiosity and aim for the highest, never shying away from taking calculated risks and embracing ambiguity as it comes. Here, the opportunities are limitless for those who dare to pursue bold ideas that exist just beyond the boundary of possibility. Join us and make impact happen with a career at TikTok.<br/><br/>Team Introduction:<br/>The e-commerce alliance team aims to serve merchants and creators in the e-commerce platform to meet merchants' business indicators and improve creators' creative efficiency. By cooperating with merchants and creators, we aim to provide high-quality content and a personalized shopping experience for TikTok users, create efficient shopping tools at seller centers, and promote cooperation between merchants and creators.<br/><br/>We are looking for talented individuals to join our team in 2024. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok.<br/><br/>Successful candidates must be able to commit to one of the following start dates below: <br/>1. January 15, 2024<br/>2. February 5, 2024<br/>3. March 4, 2024<br/>4. May 20, 2024<br/>5. June 10, 2024<br/>6. July 15, 2024<br/>7. August 12, 2024<br/>We will prioritize candidates who are able to commit to these start dates. Please state your availability and graduation date clearly in your resume.<br/><br/>Applications will be reviewed on a rolling basis. We encourage you to apply early.<br/><br/>Candidates can apply for a maximum of TWO positions and will be considered for jobs in the order you applied for. The application limit is applicable to TikTok and its affiliates globally.<br/><br/>Responsibilities:<br/>- Design and implement cutting-edge machine learning algorithms to enhance our recommendation systems.<br/>- Apply machine learning, natural language processing, and computer vision techniques to analyze e-commerce data and interactions.<br/>- Deploy and maintain scalable recommendation models for real-time query handling and product suggestions.<br/>- Analyze complex datasets to derive insights that guide strategic decisions.<br/>- Stay up-to-date with the latest machine learning developments, incorporating them into your work. <br/><br/><strong>Qualifications<br/><br/></strong> Qualifications:<br/>- Master degree in Computer Science, Engineering, Operations Research, or related fields.<br/>- Final year or graduate with a background in Software Development, Computer Science, Computer Engineering, or a related technical discipline<br/>- Thorough understanding understanding of data structures and algorithms, with excellent problem-solving ability.<br/>- Deep Understanding of machine learning, statistics, scaling distributed computing, and big  data engineering<br/>Preferred Qualifications:<br/>- Demonstrated software engineering experience from previous internship, work experience, coding competitions, or publications<br/>- Internship experience or research experience, especially in e-commerce, recommendation, search engine<br/>- Publications at conferences such as KDD, NeurIPS, WWW, SIGIR, WSDM, CIKM, ICLR, ICML, IJCAI, AAAI.<br/>- Curiosity toward new technologies and entrepreneurship<br/>- High levels of creativity and quick problem-solving capabilities<br/><br/>TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.<br/><br/>TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at dataecommerce.accommodations@tiktok.com. <br/><br/><strong>Job Information:<br/><br/></strong>【For Pay Transparency】Compensation Description (annually) <p>The base salary range for this position in the selected city is $104500 - $139650 annually.<span>​</span></p><p>Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.<span>​</span></p><p>Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: <span>​</span></p><p>We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&amp;D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. <span>​</span></p><p>Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. <span>​</span></p><p>We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.<span>​</span></p>
</div>",$104500- $139650,Data and AI Engineer
Machine Learning Engineer Graduate (Search E-commerce) - 2024 Start (BS/MS),TikTok,12/19/2023,https://www.linkedin.com/jobs/view/3691329962,0,https://media.licdn.com/dms/image/C510BAQGCdThXIss7UQ/company-logo_100_100/0/1630606162248/tiktok_logo?e=2147483647&v=beta&t=139uJTX7-HNeX1_kJsHK-Ztmj2K9yb9XfIIGQoNOW3c,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Responsibilities<br/><br/></strong> About TikTok:<br/>TikTok is the leading destination for short-form mobile video. Our mission is to inspire creativity and bring joy. TikTok has global offices including Los Angeles, New York, London, Paris, Berlin, Dubai, Singapore, Jakarta, Seoul and Tokyo.<br/><br/>Why Join Us<br/>Creation is the core of TikTok's purpose. Our platform is built to help imaginations thrive. This is doubly true of the teams that make TikTok possible. <br/>Together, we inspire creativity and bring joy - a mission we all believe in and aim towards achieving every day. <br/>To us, every challenge, no matter how difficult, is an opportunity; to learn, to innovate, and to grow as one team. Status quo? Never. Courage? Always. <br/>At TikTok, we create together and grow together. That's how we drive impact - for ourselves, our company, and the communities we serve. <br/>Join us.<br/><br/>Team Introduction<br/>The Search E-Commerce team is responsible for the search algorithm for TikTok's rapidly growing global e-commerce business. We use state-of-the-art large-scale machine learning technology, the cutting-edge NLP, CV and multi-modal technology to build the industry's top-class search engine to provide the best e-commerce search experience, for more than 1 billion monthly active TikTok users around the world. Our mission is to build a world where ""there is no hard-to-sell good-priced product in the world"".<br/><br/>We are looking for talented individuals to join our team in 2024. As a graduate, you will get unparalleled opportunities for you to kickstart your career, pursue bold ideas and explore limitless growth opportunities. Co-create a future driven by your inspiration with TikTok.<br/><br/>Successful candidates must be able to commit to one of the following start dates below: <br/>1. January 15, 2024<br/>2. February 5, 2024<br/>3. March 4, 2024<br/>4. May 20, 2024<br/>5. June 10, 2024<br/>6. July 15, 2024<br/>7. August 12, 2024<br/><br/>We will prioritize candidates who are able to commit to these start dates. Please state your availability and graduation date clearly in your resume.<br/><br/>Applications will be reviewed on a rolling basis. We encourage you to apply early.<br/><br/>Candidates can apply for a maximum of TWO positions and will be considered for jobs in the order you applied for. The application limit is applicable to TikTok and its affiliates' jobs globally. <br/><br/>Online Assessment<br/>Candidates who pass resume evaluation will be invited to participate in Tiktok's technical online assessment through HackerRank.<br/><br/>Responsibilities:<br/>-Improve the basic search quality and user experience: Optimize query analysis and text relevance matching. Understand e-commerce video content and implement multi-modal matching. Improve users' perception of product authority, and deeply participate in the design and implementation of core search products. Comprehensively improve the end-to-end shopping experience from browsing to after-sales.<br/>- Design and implement the end-to-end ranking system (recall, first stage ranking, final stage ranking and mixed row): Improve users' personalized shopping interests model. Improve the shopping conversion efficiency for merchandise, video and live stream to promote GMV growth. <br/>- Promote the healthy development of the ecosystem: From the perspective of the industry and businesses, solve challenging problems such as supply and demand matching, business cold start, and sustainable business growth, etc. Think, analyze and adjust the evolution of the system to achieve long-term and sustainable growth of GMV. <br/><br/><strong>Qualifications<br/><br/></strong> - Excellent coding skills. Solid knowledge of data structure and algorithms.<br/>- Excellent in analysis, modeling and problem-solving, and can see the essence of problems from complex data.<br/>- Publication records in top journals or conferences will be a plus. Experience winning ACM-ICPC medals will be a plus.<br/><br/>TikTok is committed to creating an inclusive space where employees are valued for their skills, experiences, and unique perspectives. Our platform connects people from across the globe and so does our workplace. At TikTok, our mission is to inspire creativity and bring joy. To achieve that goal, we are committed to celebrating our diverse voices and to creating an environment that reflects the many communities we reach. We are passionate about this and hope you are too.<br/><br/>TikTok is committed to providing reasonable accommodations in our recruitment processes for candidates with disabilities, pregnancy, sincerely held religious beliefs or other reasons protected by applicable laws. If you need assistance or a reasonable accommodation, please reach out to us at earlycareers.accommodations@tiktok.com<br/><br/>By submitting an application for this role, you accept and agree to our global applicant privacy policy, which may be accessed here: https://careers.tiktok.com/legal/privacy. <br/><br/><strong>Job Information:<br/><br/></strong>【For Pay Transparency】Compensation Description (annually) <p>The base salary range for this position in the selected city is $106590 - $139650 annually.<span>​</span></p><p>Compensation may vary outside of this range depending on a number of factors, including a candidate’s qualifications, skills, competencies and experience, and location. Base pay is one part of the Total Package that is provided to compensate and recognize employees for their work, and this role may be eligible for additional discretionary bonuses/incentives, and restricted stock units.<span>​</span></p><p>Our company benefits are designed to convey company culture and values, to create an efficient and inspiring work environment, and to support our employees to give their best in both work and life. We offer the following benefits to eligible employees: <span>​</span></p><p>We cover 100% premium coverage for employee medical insurance, approximately 75% premium coverage for dependents and offer a Health Savings Account(HSA) with a company match. As well as Dental, Vision, Short/Long term Disability, Basic Life, Voluntary Life and AD&amp;D insurance plans. In addition to Flexible Spending Account(FSA) Options like Health Care, Limited Purpose and Dependent Care. <span>​</span></p><p>Our time off and leave plans are: 10 paid holidays per year plus 17 days of Paid Personal Time Off (PPTO) (prorated upon hire and increased by tenure) and 10 paid sick days per year as well as 12 weeks of paid Parental leave and 8 weeks of paid Supplemental Disability. <span>​</span></p><p>We also provide generous benefits like mental and emotional health benefits through our EAP and Lyra. A 401K company match, gym and cellphone service reimbursements. The Company reserves the right to modify or change these benefits programs at any time, with or without notice.<span>​</span></p>
</div>",$106590- $139650,Data and AI Engineer
Machine Learning Engineer Graduate (E-Commerce Knowledge Graph - CV/Multimodal/NLP)- 2024 Start (MS),TikTok,12/19/2023,https://www.linkedin.com/jobs/view/3737229501,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Senior Consultant - Machine Learning / AI Engineer,Spur Reply,12/19/2023,https://www.linkedin.com/jobs/view/3728560397,0,https://media.licdn.com/dms/image/C4E0BAQHpLLWeIJ1uMQ/company-logo_100_100/0/1651604831744/thespurgroup_logo?e=2147483647&v=beta&t=q7W1aM9cRANhpUjrxfzfaNEiJE6vsfJRAve87JUJ-Vk,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Why Spur Reply <br/><br/></strong>At Spur Reply, our mission is to turn every interaction our clients have into a go-to-market advantage. We are a consultancy whose objective is to drive results that matter. As the leading authority on go-to-market solutions, we act as an extension of our client teams, providing the support, tools, and strategies to achieve important outcomes. If you tackle challenges with unmatched persistence and believe learning is critical to ongoing growth, we want you on our team.<br/><br/>Moreover, we focus on delighting our clients and creating the absolute best workplace for every person in the firm. We are a group of passionate, smart, and experienced consultants who strive to be their best selves every day and focus on driving value for our clients. Our size allows us to be large enough to scale but small enough to create a personalized journey and offer meaningful support as our consultants grow. The firm’s culture, which is built on teaming and teaching, empowers our professionals to support each other in their career development.<br/><br/>Our focus on our people is evident in the compelling benefits we offer<br/><br/><ul><li> Hybrid with a competitive salary and Total rewards package </li><li> Premium paid by company - 80% Health, 100% Dental, and Vision benefits for you and your family </li><li> Opportunity to participate in 401k with up to 4% company match </li><li> Generous paid vacation </li><li> Optional cell phone monthly plan </li><li> Commuter benefits </li><li> Monthly company lunches, company parties, and fully stocked kitchens </li><li> A world-class community experience with our Employee Resource Groups <br/><br/></li></ul>M ust be located in one of 3 areas (Irvine, Los Angeles or Seattle) due to being a hybrid role with an expectation of 3 days per week in office.<br/><br/><strong>About The Role &amp; What You'll Do<br/><br/></strong>Spur Reply is looking for a  <strong> Senior Consultant – Machine Learning / AI Engineer </strong> to join our  Ecosystem Engineering team . As a Machine Learning / AI Engineer, you are well-versed in developing and implementing large language models and have a solid understanding of the intersection between machine learning, software engineering, and product development.<br/><br/><strong>What You'll Do<br/><br/></strong><ul><li> Develop, implement, and maintain scalable and efficient machine learning and AI models, with a focus on large language models </li><li> Collaborate with cross-functional teams to understand requirements and identify opportunities for leveraging company data to drive business solutions </li><li> Be actively involved in the full model development lifecycle, including conception, creation, tuning, testing, and deployment </li><li> Utilize AWS SageMaker for building, tuning, and enhancing machine learning models to ensure optimal performance </li><li> Develop robust test datasets and validation frameworks to ensure the reliability and robustness of models </li><li> Work closely with the ML Ops and software engineering teams to productionize machine learning models and integrate them into company products and services </li><li> Proactively identify areas of improvement and innovation in our product portfolio and work closely with the product team to enhance our offerings </li><li> Maintain a current understanding of industry trends, advancements, and best practices in machine learning and artificial intelligence to drive organizational excellence <br/><br/></li></ul><strong>What You’d Bring To Spur<br/><br/></strong><ul><li> Solid experience with AWS SageMaker or equivalent platforms for building, tuning, and enhancing machine learning models </li><li> Proven experience in productionizing and deploying scalable machine learning models </li><li> Strong programming skills in Python, Java, or another programming language </li><li> Proficient in ML Ops practices and tools to deploy and monitor models in production </li><li> A strong understanding of machine learning algorithms, processes, tools, and platforms </li><li> Demonstrated ability to identify the intersection of ML and software engineering and possessing strong product intuition to contribute to product development </li><li> Excellent communication and collaboration skills, with the ability to work effectively with cross-functional teams </li><li> Solid experience with Natural Language Processing (NLP), Natural Language Understanding (NLU), and Natural Language Generation (NLG) <br/><br/></li></ul><strong>What You'll Need (Requirements)<br/><br/></strong><ul><li> Bachelor's degree in Computer Science , Engineering or a related field. Master’s degree or higher is a plus </li><li> 3 + years experience in machine learning and AI, with a focus on implementing large language models </li><li> Proficiency in requirements gathering techniques, process modeling tools, and data analysis </li><li> Strong analytical and problem-solving skills </li><li> Excellent communication and interpersonal abilities </li><li> Familiarity with ML frameworks like TensorFlow or PyTorch . (preferred) </li><li> Experience with Agile development methodologies </li><li> Team player with a collaborative mindset <br/><br/></li></ul><strong>Additional Information<br/><br/></strong>Spur Reply (Formerly The Spur Group) is a consulting firm based in Bellevue, WA. In our hybrid working environment, our general working hours are 8 a.m. to 5 p.m. PT, Monday through Friday. While we strive for work/life harmony, client work may extend beyond these hours and may require flexibility in work arrangements.<br/><br/>The base compensation range for this full-time position is between $130,000-$150,000 plus benefits. Compensation decisions are supported through market data, where regional variances may exist based on cost of labor. We also take into consideration prior experience, relevant skills, education and/or training, certifications, and, as applicable, other required qualifications. If you have questions regarding compensation, a Talent Acquisition Partner can provide relevant details during the interview process.<br/><br/>Spur Reply is committed to a diverse and inclusive workplace. Spur Reply is an equal opportunity employer and does not discriminate based on race, origin, gender, sexual orientation, protected veteran status, disability, age, or other legally protected status. If you need assistance and reasonable accommodation due to a disability during the application or the recruiting process, email us at talentacquisition.spur.us@reply.com . Visit our website to learn more about our open roles.<br/><br/>#IND1, ,<br/><br/>
</div>",$130000- $150000,Data and AI Engineer
"Partner Engineer, Gen AI",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3790489603,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Seattle, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Meta is seeking a Partner Engineer to join Meta’s Applied AI Partner Engineering team, a highly technical team that works with strategic partners, machine learning leaders across the industry and all major cloud service providers for building and launching new Generative AI product services and experience and taking Large Language Models (LLMs) from research to production. In this role, you will engage with some of the world's most influential companies and work closely with our Llama engineering and AI research teams. The ideal candidate will have industry experience working with PyTorch on a range of deep learning, machine learning, natural language processing, large language models, generative AI, conversational AI, reinforcement learning (RLHF) problems. You will also represent Meta at developer conferences and events. You will be required to develop technical accelerators, case studies, white papers, blogs, reference architectures, and/or presentations to evangelize Meta’s AI design patterns and best practices.<br/><br/>Partner Engineer, Gen AI Responsibilities:<br/><br/><ul><li>Apply relevant AI and machine learning techniques to build and launch generative AI solutions using Meta’s Llama and other state of the art LLMs</li><li>Understand Meta’s AI/Llama frameworks and products and their underlying implementation</li><li>Define and execute on a strategy to drive adoption of Llama and other Meta’s AI/ML platform offerings</li><li>Work closely with cloud providers (like Azure, AWS, GCP) and Meta’s strategic partners on deep learning &amp; LLM integrations</li><li>Be a subject matter technical expert, and have strategic influence on partners and internal teams at Meta</li><li>Provide thought leadership, evangelize Meta’s AI and Gen AI services and share best practices through forums such as medium blogs, whitepapers, reference architectures and public-speaking events</li><li>Develop reference architectures, samples and other materials to share with the broader Meta developer community</li><li>Work with key partners and LLM developer community to optimize existing generative AI models for improved performance, scalability, and efficiency.</li><li>Leads technical strategy and roadmap for long-term strategic partners with high level of autonomy / Able to own and navigate long term technical relationship with partners</li><li>Has good understanding of Responsible AI, proactively identifies risk to Meta and partners and drives involvement from the necessary XFNs</li><li>Effectively plan, lead and execute on projects with minimal direction &amp; oversight from leadership</li><li>Proactively communicate feedback, updates, status to direct team as well as relevant cross-functional teams</li><li>Write clear and concise documentation, including technical specifications, best practices guides, and presentations, to communicate complex AI concepts to both technical and non-technical stakeholders internally and externally.<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.</li><li>Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.</li><li>5+ years experience as software engineer, technical consultant or partner/sales engineer</li><li>5+ years of experience in one or more of the following areas: Deep Learning, LLMs, NLP, Speech, Conversational AI,AI-Infrastructure, Fine-tuning and optimizations of PyTorch models.</li><li>Software development experience in languages like Python, Java, Go, Rust, C/C++. (at least one)</li><li>Experience with at least one LLM such as Llama, GPT, Claude, Falcon, etc.</li><li>Experience with at least one deep learning framework such as PyTorch and/or JAX</li><li>Experience building cloud solutions on any cloud. Experience with Open Source cloud stacks like Kubernetes, Kubeflow, Docker containers.</li><li>Experience communicating and presenting to technical and business audiences<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>BS, MS or Ph.D. degree in Computer Science or related quantitative field</li><li>Solid understanding of at least one Deep Learning framework (PyTorch, Tensorflow or MXNet)</li><li>Experience building Deep Learning - Computer Vision or Natural Language Processing or Recommender Systems models using the frameworks.</li><li>Apply relevant AI and machine learning techniques to build</li><li>Experience influencing and building mindshare convincingly with any audience.</li><li>Experience working with internal and external partners</li><li>Data science background and experience manipulating/transforming data, model selection, model training, model optimization and deployment at scale.</li><li>Experience deploying production-grade machine learning solutions on public cloud platforms (like AWS)</li><li>(Nice to have) Experience of launching a product / service or application into market is a plus</li><li>(Nice to have) Knowledge of Mobile/IoT for deploying ML models at the edge is a plus</li><li>(Nice to have) Contributed to an Open Source project, submitted PRs for features/ fixed bugs and/or created sample applications in OSS or participated in Kaggle competitions<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data and AI Engineer
"Staff, Software Engineer - Gen AI",Walmart,12/20/2023,https://www.linkedin.com/jobs/view/3760950859,0,https://media.licdn.com/dms/image/C560BAQE4Th_qgWovfg/company-logo_100_100/0/1655487552700/walmart_logo?e=2147483647&v=beta&t=XYuU1vLHWna6Xoqkn8uJoMQUhrfZSWM0FKjQ900h4vE,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Position Summary...<br/><br/>What you'll do...<br/><br/>We are seeking an experienced Staff Engineer specializing in AI Systems to join our team and play a pivotal role in developing our Generative AI platform and its associated services. In this dynamic role, you will work on a variety of initiatives, such as designing secure and robust infrastructure, constructing large-scale distributed training clusters, managing LLMs for real-time applications, and supporting advanced AI research and development within our public and private cloud infrastructure.<br/><br/><strong>About Team<br/><br/></strong>Collaborating with a team of AI engineers and researchers, you will help shape the future of our platform and aid in designing and implementing essential services.<br/><br/><strong>What You'll Do<br/><br/></strong><ul><li>Designing and constructing fault-tolerant infrastructure to support long-running, large-scale training tasks, using containers and checkpointing libraries to maintain reliability despite individual node failures. </li><li>Developing infrastructure for serving extensive ML models in our public cloud. </li><li>Creating technical roadmaps, consulting on objectives and key results across teams, reviewing designs, engaging in and resolving technical discussions, and guiding engineering investments for Core ML. </li><li>Designing and implementing benchmarks to evaluate software system performance within a Generative AI Platform, and providing recommendations on technology selection. </li><li>Developing tools and applications that utilize LLMs and FMs for use cases such as testing, build tools, etc.</li><li>Designing and implementing platform capabilities to support MLOps for foundation models. </li><li>Optimizing AI algorithms and models to improve performance, efficiency, accuracy, and scalability.</li><li>Collaborating with cross-functional teams, working closely with researchers, data scientists, and other stakeholders to comprehend their needs, gather requirements, and develop AI-powered solutions. Ensuring AI models and systems align with regulatory and industry standards by partnering with domain experts. </li><li>Preparing and maintaining technical documentation, reports, and presentations to effectively communicate AI methodologies, results, and recommendations to diverse audiences. </li><li>Staying informed about the latest advancements in AI, machine learning, industry trends, regulatory guidelines, data privacy, and ethical considerations related to AI applications in the Retail domain. <br/><br/></li></ul><strong>What You'll Bring<br/><br/></strong><ul><li> Bachelor's degree in Computer Science, Computer Engineering, or a related technical field </li><li>6+ years of experience designing and building distributed systems at scale </li><li>4+ years of experience as a tech lead or an architect </li><li>1+ years of experience with the full ML development lifecycle using open-source AI/ML frameworks and public cloud <br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li> Master's degree in Engineering, Computer Science, a related technical field, or equivalent practical experience with a focus on contemporary AI techniques </li><li>Experience designing large-scale distributed platforms and/or systems in cloud environments such as Azure or GCP </li><li>Experience architecting cloud systems for security, availability, performance, scalability, and cost </li><li>Experience delivering very large models through the MLOps life cycle from exploration to serving </li><li>Experience building GPU clusters in the public cloud with tightly-coupled storage and networking </li><li>Proficiency with the complete stack for distributed training of large models, including ML compilers, distributed training frameworks, and ML development frameworks such as Pytorch, Tensorflow, Lightning, etc. </li><li>Familiarity with GenAI technology stack, including frameworks for prompt engineering, guardrails for GenAI applications, and LLM fine-tuning </li><li>Experience working with VectorDBs and other data infrastructure required to efficiently support Generative AI training pipelines and production applications </li><li>Experience training and maintaining large language models <br/><br/></li></ul><strong>About Walmart Global Tech<br/><br/></strong>Imagine working in an environment where one line of code can make life easier for hundreds of millions of people. That's what we do at Walmart Global Tech. We're a team of software engineers, data scientists, cybersecurity expert's and service professionals within the world's leading retailer who make an epic impact and are at the forefront of the next retail disruption. People are why we innovate, and people power our innovations. We are people-led and tech-empowered. We train our team in the skillsets of the future and bring in experts like you to help us grow. We have roles for those chasing their first opportunity as well as those looking for the opportunity that will define their career. Here, you can kickstart a great career in tech, gain new skills and experience for virtually every industry, or leverage your expertise to innovate at scale, impact millions and reimagine the future of retail.<br/><br/><strong>Flexible, Hybrid Work<br/><br/></strong>We use a hybrid way of working that is primarily in office coupled with virtual when not onsite. Our campuses serve as a hub to enhance collaboration, bring us together for purpose and deliver on business needs. This approach helps us make quicker decisions, remove location barriers across our global team and be more flexible in our personal lives.<br/><br/><strong>Benefits<br/><br/></strong>Benefits: Beyond our great compensation package, you can receive incentive awards for your performance. Other great perks include 401(k) match, stock purchase plan, paid maternity and parental leave, PTO, multiple health plans, and much more.<br/><br/><strong>Equal Opportunity Employer<br/><br/></strong>Walmart, Inc. is an Equal Opportunity Employer - By Choice. We believe we are best equipped to help our associates, customers and the communities we serve live better when we really know them. That means understanding, respecting and valuing diversity- unique styles, experiences, identities, ideas and opinions - while being inclusive of all people.<br/><br/>The above information has been designed to indicate the general nature and level of work performed in the role. It is not designed to contain or be interpreted as a comprehensive inventory of all responsibilities and qualifications required of employees assigned to this job. The full Job Description can be made available as part of the hiring process.<br/><br/>At Walmart, we offer competitive pay as well as performance-based incentive awards and other great benefits for a happier mind, body, and wallet. Health benefits include medical, vision and dental coverage. Financial benefits include 401(k), stock purchase and company-paid life insurance. Paid time off benefits include PTO (including sick leave), parental leave, family care leave, bereavement, jury duty, and voting. Other benefits include short-term and long-term disability, company discounts, Military Leave Pay, adoption and surrogacy expense reimbursement, and more.<br/><br/>You will also receive PTO and/or PPTO that can be used for vacation, sick leave, holidays, or other purposes. The amount you receive depends on your job classification and length of employment. It will meet or exceed the requirements of paid sick leave laws, where applicable. For information about PTO, see https://one.walmart.com/notices .<br/><br/>Live Better U is a Walmart-paid education benefit program for full-time and part-time associates in Walmart and Sam's Club facilities. Programs range from high school completion to bachelor's degrees, including English Language Learning and short-form certificates. Tuition, books, and fees are completely paid for by Walmart.<br/><br/>Eligibility requirements apply to some benefits and may depend on your job classification and length of employment. Benefits are subject to change and may be subject to a specific plan or program terms. For information about benefits and eligibility, see One.Walmart at https://bit.ly/3iOOb1J .<br/><br/>The annual salary range for this position is $132,000.00-$264,000.00<br/><br/><strong>Additional Compensation Includes Annual Or Quarterly Performance Incentives.<br/><br/></strong>Additional compensation for certain positions may also include:<br/><br/><ul><li> Regional Pay Zone (RPZ) (based on location)</li><li> Stock equity incentives<br/><br/></li></ul><strong>Minimum Qualifications...<br/><br/></strong>Outlined below are the required minimum qualifications for this position. If none are listed, there are no minimum qualifications.<br/><br/>Option 1: Bachelor's degree in computer science, computer engineering, computer information systems, software engineering, or related area and 4 years' experience in software engineering or related area.Option 2: 6 years' experience in software engineering or related area.<br/><br/><strong>Preferred Qualifications...<br/><br/></strong>Outlined below are the optional preferred qualifications for this position. If none are listed, there are no preferred qualifications.<br/><br/>Master's degree in Computer Science, Computer Engineering, Computer Information Systems, Software Engineering, or related area and 2 years' experience in software engineering or related area<br/><br/>Primary Location...<br/><br/>10500 Ne 8th St, Bellevue, WA 98004, United States of America
      </div>",$132000.00- $264000.00,Data and AI Engineer
ML Security Engineer,CyberSN,12/20/2023,https://www.linkedin.com/jobs/view/3784497234,0,https://media.licdn.com/dms/image/D560BAQHPnrPzz87txg/company-logo_100_100/0/1690494333818/cybersn_logo?e=2147483647&v=beta&t=lXyjJkL8-5_UgHVZQLNc6VdAy58kWMizrZc9YN_d3TE,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>Our client is looking to hire a Machine Learning Security Engineer to join their cybersecurity team. Join and support leading ML feature integration with a focus on security architecture, utilizing code, automation, and data-driven approaches. In this role, you will provide guidance on secure architecture, contribute to developer-friendly security tools, and collaborate effectively across teams. </p><p><br/></p><p>This role is a hybrid position that requires 2-3 days of onsite work in Bellevue, WA; San Mateo, CA; or Toronto, Canada.</p><p><br/></p><p>For a quicker response, please apply directly to this role here: https://cybersn.com/cards/2442/card.html </p><p><br/></p><p><strong>Responsibilities:</strong></p><p><strong>95% AI/ML Security Engineering</strong></p><ul><li>Design, Implement, And Maintain Machine Learning (ML) Security Processes And Solutions</li><li>Large Language Models (LLM); Machine Learning (ML); Natural Language Processing (NLP)</li><li>Provide Artificial Intelligence Operations (AI Ops) Security Architecture And Design</li><li>Training Data Preparation; Data Security And Anonymization; Model Security, Versioning, And Deployment; CI/CD; APIs; Scalability And Availability; Alerting And Notifications; Third-party Libraries And External Dependencies</li><li>Perform Threat Modeling, Security Design Reviews, And Security Testing</li><li>Influence And Enhance ML Security Practices Across Teams To Ensure Compliance With Industry Standards, Regulations, Best Practices, Ethical And Data Privacy Considerations</li><li>Stay Updated On AI &amp; and ML Security, Adversarial Machine Learning, And Privacy-preserving Techniques</li><li>Create Scripts And Programming To Supporting Automation</li></ul><p><strong>5% Cyber Data Science</strong></p><ul><li>Develop Custom Data Models And Algorithms To Apply To Data Sets</li></ul><p><br/></p><p><strong>Requirements:</strong></p><ol><li>6+ years of hands-on Machine Learning experience. Proficient in ML security with a deep understanding of best practices, capable of implementing and maintaining a strong security program. </li><li>Demonstrated ability to instill a security mindset early in the development lifecycle, enabling developer autonomy, and automating crucial security tasks for ML products.</li><li>Strong programming and security tooling skills, including automation and data analysis from diverse sources.</li><li>Experience in reviewing the design and implementation of ML and AI features.</li><li>Comfortable with onsite requirements in Bellevue, WA; San Mateo, CA; or Toronto, Canada.</li></ol><p><br/></p><p><strong>Why CyberSN?</strong></p><p>CyberSN is the Cybersecurity Jobs and Career Marketplace. From online matching to full-service recruitment, CyberSN provides professionals and hiring teams with the expertise, information, tools, connections, and services they need to maximize career success, job satisfaction, team performance, diversity, and retention.</p>
</div>",No Salary Info Found,Data and AI Engineer
"Software Engineer, Machine Learning",Meta,12/20/2023,https://www.linkedin.com/jobs/view/3726091288,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Bellevue, WA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Meta is embarking on the most transformative change to its business and technology in company history, and our Machine Learning Engineers are at the forefront of this evolution. By leading crucial projects and initiatives that have never been done before, you have an opportunity to help us advance the way people connect around the world. The ideal candidate will have industry experience working on a range of recommendation, classification, and optimization problems. You will bring the ability to own the whole ML life cycle, define projects and drive excellence across teams. You will work alongside the world’s leading engineers and researchers to solve some of the most exciting and massive social data and prediction problems that exist on the web.<br/><br/>Software Engineer, Machine Learning Responsibilities:<br/><br/><ul><li>Leading projects or small teams of people to help them unblock, advocating for ML excellence</li><li>Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)</li><li>Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based models</li><li>Suggest, collect and synthesize requirements and create effective feature roadmaps</li><li>Code deliverables in tandem with the engineering team<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>5+ years of experience in software engineering or a relevant field. 3+ years of experience if you have a PhD</li><li>1+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining, artificial intelligence, or a related technical field</li><li>Experience with developing machine learning models at scale from inception to business impact</li><li>Knowledge developing and debugging in C/C++ and Java, or experience with scripting languages such as Python, Perl, PHP, and/or shell scripts</li><li>Track record of setting technical direction for a team, driving consensus and successful cross-functional partnerships</li><li>Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience.<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Masters degree or PhD in Computer Science or a related technical field</li><li>Exposure to architectural patterns of large scale software applications<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data and AI Engineer
Senior Machine Learning Engineer,Jobot,12/25/2023,https://www.linkedin.com/jobs/view/3791629015,0,https://media.licdn.com/dms/image/C560BAQFSVDtroiTPVg/company-logo_100_100/0/1662729128612?e=2147483647&v=beta&t=ttQZOuL6r1DVH02dS8jE5nwXDw6T8nLCs8M4xlyILfU,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Want to learn more about this role and Jobot? Click our Jobot logo and follow our LinkedIn page!<br/><br/>Job details<br/><br/><strong>Exciting Senior Machine Learning Engineer role with rapidly growing Biotech on the cutting edge of protein design!<br/><br/></strong>This Jobot Job is hosted by Coalter Powers<br/><br/>Are you a fit? Easy Apply now by clicking the ""Easy Apply"" button and sending us your resume.<br/><br/>Salary $125,000 - $175,000 per year<br/><br/><strong>A Bit About Us<br/><br/></strong>****REMOTE OR HYBRID****<br/><br/>Our client, a cutting-edge biotech company recently announced a large partnership with Google Cloud to build a generative AI platform for engineering biology and for biosecurity.<br/><br/>We are exclusively partnering with them on the build-out of the newly created Digital Tech / AI Enablement team.<br/><br/>This is an excellent opportunity to get in early and be a part of it all.<br/><br/><strong><br/><br/><strong>Why join us?<br/><br/><br/></strong></strong>The AI Enablement team is responsible for delivering the ML expertise required to make this happen. With nearly limitless compute capacity CPU, GPU, or TPU; you will have the opportunity to partner with biologists, software and DevOps engineers, and data scientists to create the necessary ML infrastructure.<br/><br/>As one of the first members of this new team, you will have a large role in molding our approaches to creating foundation models for biology, as well as creating fine-tuned and derived models for specific applications in bioengineering.<br/><br/><ul><li> Work remotely, hybrid, or in-office</li><li> Competitive Compensation including industry leading equity program</li><li> Nearly limitless AI/ML resources and capacity</li><li> Unlimited opportunity for career development and growth<br/><br/></li></ul><strong>Job Details<br/><br/></strong>While the main focus of your work will be on building and evaluating new ML models for biology, many other types of work will come your way. You may need to do data archaeology, create and debug pipelines in tools like Kubeflow or Flyte, quickly learn the basics of protein folding or codon optimization, become the company’s expert on a new tool, debug odd results created by a production model for a project under a time crunch, contribute to brainstorming, planning and prioritization, make presentations, give feedback on others’ proposals and code, and more.<br/><br/>This is a new team, a significant company focus, and a rapidly evolving field. You will need to be able to handle ambiguity and uncertainty; on the flip side, you will be able to influence where things go and how they change.<br/><br/>You will identify what needs to happen, bring it to the team’s attention, and make it happen.<br/><br/>You will not be expected to be an expert in “All The Things”. You will be expected to have a high level of general technical competency, be a fast learner brimming with curiosity, and an expert in a few things - deep learning, in particular.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li> Build, manage, and evolve a GCP-based platform for large scale (up to 100B+ parameters) training, evaluation, and serving of Foundation Models for biology. </li><li> Develop, implement and maintain a system for creating smaller models that combine large FMs with additional experimental data to address specific needs and applications.</li><li> Own processes for data ingestion, data prep, data and model provenance tracking, and various other data engineering and ML Ops activities.</li><li> Contribute to model design and experimentation.</li><li> Identify opportunities for application of AI and ML across the company, create prototypes, and contribute to overall prioritization and roadmap development for AI.<br/><br/></li></ul><strong>Minimum Requirements<br/><br/></strong><ul><li> PhD in a scientific discipline and a minimum of 5 years related experience; may include post-doctoral experience; Masters and 7 years of related experience; Bachelors and 9 years of related experience in data engineering, systems engineering, machine learning and operations, MLOps, or similar roles; or equivalent industry experience.</li><li> Deep experience with Python.</li><li> Experience with ML and data orchestration and workflow engines like Airflow, Kubeflow, Flyte, or Dagster.</li><li> Familiarity with recent literature and state of the art for large model architectures and training approaches</li><li> Experience with building machine/deep learning models with at least one common framework such as PyTorch, Tensorflow, or JAX.<br/><br/></li></ul><strong>Preferred Capabilities And Experience<br/><br/></strong><ul><li> Practical experience iterating on LLM design </li><li> Familiarity with the ML ecosystem, including MLFlow and related tools</li><li> Experience with Terraform or Pulumi, Kubernetes</li><li> Experience operating non-trivial GCP deployments</li><li> Experience with Vertex AI services</li><li> Experience with “Cloud Life Sciences” / Google Batch<br/><br/></li></ul>Interested in hearing more? Easy Apply now by clicking the ""Easy Apply"" button.<br/><br/><strong>Want to learn more about this role and Jobot?<br/><br/></strong>Click our Jobot logo and follow our LinkedIn page!<br/><br/>
</div>",$125000- $175000,Data and AI Engineer
Data Scientist & AI: Bootcamp and Project Work (online – part-time) – Gain your first hands-on experience,Moyyn,12/24/2023,https://www.linkedin.com/jobs/view/3793083949,0,https://media.licdn.com/dms/image/C4E0BAQGvWM2Bhb5hrA/company-logo_100_100/0/1677587695409/moyyn_logo?e=2147483647&v=beta&t=zzJ9xfhFbYPgUtLbbwrggK2p6fVXl2L3u7q_gQRhILw,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        If you are a student, graduate or career change aspirant, and you are missing out on the skills to work in your dream job, this bootcamp is for you. Get trained and work on hands-on projects in our bootcamp to upskill yourself!<br/><br/>Program: Hands-on training and projects, training certification, and project work at our German AI startup – Moyyn (Program language – English)<br/><br/>What you will get from this program?<br/><br/>– Hands-on training and projects – in a German AI startup<br/><br/>– Learn and work – directly with founders and potential clients from Germany<br/><br/>– Do practical group Project work and build up experience in Data Science and AI<br/><br/><strong>Modules<br/><br/></strong><ul><li> Hands-on training and Project work<br/><br/></li></ul>Get trained directly from the founders and get hands-on training and projects<br/><br/>– Real-time data science/ML tasks<br/><br/>– Supervised matchmaking algorithm creation for Job-Candidate matchmaking<br/><br/>– Customer segmentation and analysis<br/><br/>– Data parsing of CV and Jobs using NLP and LLM<br/><br/>– Project work<br/><br/><ul><li> Data Science and AI Training<br/><br/></li></ul>8 hours training incl. guest speakers from Europe (self paced learning)<br/><br/>– Fundamentals of Data Science and Machine Learning<br/><br/>– Python libraries<br/><br/>– Supervised and Unsupervised learning<br/><br/>– Regression and Classification methods<br/><br/>– Clustering methods<br/><br/>– Deep Learning<br/><br/>– Matching algorithms<br/><br/>and many more<br/><br/><ul><li> Career Guidance:<br/><br/></li></ul>Get guidance on how to land a job<br/><br/>– Career sessions<br/><br/>– Job search platforms intro<br/><br/>– CV preparation<br/><br/>– Cover letter preparation<br/><br/>– Interview tips<br/><br/>Why join our Data Science Training Program?<br/><br/>– Skill development: Learn the fundamentals of Data Science and AI<br/><br/>– Career advancement: Get the confidence and training to switch your career to Data Scientist<br/><br/>– Job opportunities: Increase your job opportunities, get referred by us to our clients and partners<br/><br/>– Real startup projects: Work directly with our CPO on real startup projects<br/><br/>– Networking Join our GATE community and build your network<br/><br/>
</div>",No Salary Info Found,Data and AI Engineer
Machine Learning Engineer - Senior/Lead/Principal,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3707157031,0,https://media.licdn.com/dms/image/C560BAQHZ9xYomLW7zg/company-logo_100_100/0/1630658255326/salesforce_logo?e=2147483647&v=beta&t=GvAdJRB6d3hWoiMBjIAOP9tjZzbWxLNF84FnSTgWblE,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.<br/><br/></em>Job Category<br/><br/>Data, Software Engineering<br/><br/>Job Details<br/><br/><strong>About Salesforce<br/><br/></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/><strong>Machine Learning Engineer - Senior/Lead/Principal<br/><br/></strong>Note: By applying to the Machine Learning Engineer posting, recruiters and hiring managers across the organization hiring machine learning engineers will review your resume. Our goal is for you to apply once and have your resume reviewed by multiple hiring teams.<br/><br/>Salesforce is looking for an exceptional Machine Learning Engineer to help us take on one of the world’s most extensive data sets and transform it into amazing products that feel like magic. You will work on innovative AI applications and products. Brainstorming data product ideas with data scientists and engineers to build data products used by hundreds of millions people every day.<br/><br/>In your role as a Machine Learning Engineer, you will partner with analysts, engineers, designers, executives, product managers, marketers, customer success, and sales team members across all Cloud businesses to create ML-driven decision making data products that enable our partners to affect the bottom line and solve critical business problems.<br/><br/><strong>Your Impact<br/><br/></strong><ul><li>Work closely with a dedicated team of machine learning professionals on a wide range of problems including forecasting significant business metrics such as sales and capacity, churn and propensity modeling to retain and grow our customer base, clustering and classification using both structured and unstructured data, and more!</li><li>Help create high-visibility data products and decision-making tools for Salesforce’s leaders</li><li>Lead the charge on taking our core products to the next level in terms of engineering maturity and architecture</li><li>Refine and develop new data science products, workflows, tools, and automation</li><li>Build tools to monitor data pipeline performance, data quality and models in production</li><li>Establish best practices with coding standards, workflows, tools, and product automation</li><li>Review and maintain existing tool-set and codebase (pipelines, models, algorithms); continue to improve existing tools and build new ones</li><li>Scale the operations of the data science team by building automation and libraries<br/><br/></li></ul><strong>Required Skills<br/><br/></strong><ul><li>A related technical degree required</li><li>4+ years of industry experience and a passion for crafting, analyzing and deploying machine learning-based solutions</li><li>Experience working as part of a team with mature data science products</li><li>Consistent record in building software and data products using modern development lifecycle methodologies: CI/CD, QA, and Agile Methodologies</li><li>Applied experience designing, building and optimizing data pipelines, architectures and data sets</li><li>Experience deploying, monitoring and maintaining data science products in cloud environments such as AWS or Microsoft Azure</li><li>Good understanding of Machine Learning methods and Statistics, including ML project lifecycle and associated challenges at each stage of development</li><li>Proficient at writing good quality, well-documented and tested, scalable code - Python preferred. Experience with tools like mlFlow, Airflow, Docker and Cloud Platforms such as AWS/GCP is ideal</li><li>Solid understanding of data transformations and analytics functions using tools/languages like Pandas, Sklearn, SQL and Spark</li><li>Strong communication skills and ability to interface well with other engineers, data scientists and product managers</li><li>Passion, curiosity, solutions focus and independence<br/><br/></li></ul><strong>Benefits &amp; Perks<br/><br/></strong>Check out our benefits site which explains our various benefits, including wellbeing reimbursement, generous parental leave, adoption assistance, fertility benefits, and more.<br/><br/><strong>Salesforce Information<br/><br/></strong>Check out our Salesforce Engineering Site.<br/><br/><strong>*IN SCHOOL OR GRADUATED WITHIN THE LAST 12 MONTHS? PLEASE VISIT FUTURE FORCE FOR OPPORTUNITIES</strong>*<br/><br/>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.<br/><br/>﻿Salesforce welcomes all.<br/><br/>For Washington-based roles, the base salary hiring range for this position is $146,600 to $280,200.<br/><br/>For California-based roles, the base salary hiring range for this position is $160,000 to $305,600.<br/><br/>Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.
      </div>",$146600- $280200,Data and AI Engineer
Data Scientist/Junior-Level,SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3790310477,0,https://media.licdn.com/dms/image/C560BAQHPrA2XO9lh7g/company-logo_100_100/0/1663564885547/synergisticit_logo?e=2147483647&v=beta&t=biDnkXeeFcJXgnh87P53V9KGn6j1mqUOEQpisfcfR74,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        For more than 12+ years Synergisticit has helped Jobseekers differentiate themselves by providing candidates the requisite skills and experience to outperform at interviews and clients. Here at SynergisticIT We just don't focus on getting you a Job we make careers.<br/><br/>All Positions are open for all visas and US citizens<br/><br/>We are matchmakers we provide clients with candidates who can perform from day 1 of starting work. In this challenging economy every client wants to save $$$'s and they want the best value for their money. Jobseekers need to self-evaluate if they have the requisite skills to meet client requirements and needs as Clients now post covid can also hire remote workers which increases even more competition for jobseekers.<br/><br/>We at Synergisticit understand the problem of the mismatch between employer's requirements and Employee skills and that's why since 2010 we have helped 1000's of candidates get jobs at technology clients like apple, google, Paypal, western union, Client, visa, walmart labs etc to name a few.<br/><br/>We have an excellent reputation with the clients. Currently, We are looking for entry-level software programmers, Java Full stack developers, Python/Java developers, Data analysts/ Data Scientists, Machine Learning engineers for full time positions with clients.<br/><br/>Who Should Apply Recent Computer science/Engineering /Mathematics/Statistics or Science Graduates or People looking to switch careers or who have had gaps in employment and looking to make their careers in IT Industry<br/><br/>We assist in filing for STEM extension and also for H1b and Green card filing to Candidates<br/><br/>We also offer optionally Skill and technology enhancement programs for candidates who are either missing skills or are lacking Industry/Client experience with Projects and skills. Candidates having difficulty in finding jobs or cracking interviews or who wants to improve their skill portfolio. If they are qualified with enough skills and have hands on project work at clients then they should be good to be submitted to clients. Shortlisting and selection is totally based on clients discretion not ours.<br/><br/>please check the below links to see success outcomes of our candidates and our participation at different Tech industry events and how we are different from other organizations in helping Jobseekers secure Tech careers<br/><br/>We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2023/2022 and at Gartner Data Analytics Summit (Florida)-2023<br/><br/>(url removed)<br/><br/>(url removed)<br/><br/>(url removed)<br/><br/>(url removed)<br/><br/>For preparing for interviews please visit<br/><br/>We are looking for the right matching candidates for our clients<br/><br/>Please apply via the job posting<br/><br/><strong>REQUIRED SKILLS For Java /Full Stack/Software Programmer<br/><br/></strong>Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT<br/><br/>Highly motivated, self-learner, and technically inquisitive<br/><br/>Experience in programming language Java and understanding of the software development life cycle<br/><br/>Project work on the skills<br/><br/>Knowledge of Core Java , javascript , C++ or software programming<br/><br/>Spring boot, Microservices, Docker, Jenkins and REST API's experience<br/><br/>Excellent written and verbal communication skills<br/><br/>For data Science/Machine learning Positions<br/><br/><strong>Required Skills<br/><br/></strong>Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT<br/><br/>Project work on the technologies needed<br/><br/>Highly motivated, self-learner, and technically inquisitive<br/><br/>Experience in programming language Java and understanding of the software development life cycle<br/><br/>Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools<br/><br/>Excellent written and verbal communication skills<br/><br/>Preferred skills: NLP, Text mining, Tableau, PowerBI, SAS, Tensorflow<br/><br/>If you get emails from our skill enhancement team please email them or ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team who only connect with candidates who are matching client requirements.<br/><br/>No phone calls please. Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates
      </div>",No Salary Info Found,Data and AI Engineer
Senior Artificial Intelligence Engineer,CareerAddict,12/19/2023,https://www.linkedin.com/jobs/view/3788413679,0,https://media.licdn.com/dms/image/C4E0BAQHQUo3YFS080Q/company-logo_100_100/0/1630594573373/career_addict_logo?e=2147483647&v=beta&t=hlZnAyyIVBvbBfiOiJmKLhmpwyazTzU_0eCdWkhqD1E,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Salary: Open + Bonus<br/><br/>Location: Chicago, IL<br/><br/>Hybrid: 3 days on-site, 2 days remote<br/><br/>*We are unable to provide sponsorship for this role*<br/><br/><strong>Qualifications<br/><br/></strong><ul><li>Bachelor's Degree</li><li>5+ years of experience, with a focus on delivering value and outcomes in designing and deploying digital solutions.</li><li>5+ years of hands-on proficiency in Python, web backends, and relevant data science libraries.</li><li>3+ years of experience with the full ML development life cycle using AI and ML frameworks, in public and private clouds.</li><li>Experience with Pandas, Scikit-learn; familiarity with PyTorch preferred.<br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li>Advance AI initiatives through the development and delivery of machine learning models, data pipelines, and AI solutions.</li><li>Provides technical leadership and oversight to AI solutions, ensuring high-quality standards and scalability.</li><li>Design and build infrastructure for serving large ML models.</li><li>Designs, develops, and deploys machine learning models integrated with web backends and end-user UI.</li><li>Oversees the development and maintenance of data pipelines to support machine learning workflows.</li><li>Evaluates and adopts new technologies and frameworks to improve the performance and reliability of AI systems.</li></ul>
</div>",No Salary Info Found,Data and AI Engineer
Artificial Intelligence Engineer,CareerAddict,12/19/2023,https://www.linkedin.com/jobs/view/3788415484,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"Senior Lead Software Engineer, Back End (Remote)",Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788648217,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong><ul><li>Job Ad: Senior Lead Software Engineer, Back End (Remote)** **About Capital One**: Capital One is a technology company operating in a highly regulated business. We have built a large engineering organization, moved to the cloud, embraced machine learning, and developed innovative solutions like Eno (our AI/ML capabilities in banking). We have also open sourced software tools and formed partnerships with other digital leaders. **About Capital One Software**: Capital One Software is a new enterprise B2B software business focused on providing cloud and data management solutions to companies operating in the cloud. As a Capital One Software Engineer, you'll play a key role in driving a major transformation within Capital One. **What You'll Do:** - Utilize your strong engineering and technology background to learn and become proficient in our product and engineering solutions. - Help promote the adoption of best engineering practices and stay up-to-date with industry trends and innovations to drive incubated projects and create rapid product prototypes. - Foster a culture of engineering excellence and efficiently manage resources, reusing and sharing solutions whenever possible. - Lead the craftsmanship, availability, resilience, and scalability of your solutions. - Guide stakeholders in design and architecture discussions, helping engineering teams make key technology choices and staying involved through the development lifecycle. - Communicate effectively and build strong partnerships with stakeholders across the organization, from engineers to executives. **Basic Qualifications:** - Bachelor's Degree. - Minimum 8 years of experience in software engineering (internship experience does not apply). - At least 1 year of experience with cloud computing (AWS, Microsoft Azure, Google Cloud). - At least 1 year of experience with Big Data, Data Security, Governance, and Controls. - At least 1 year of experience with containerization technologies. **Preferred Qualifications:** - Master's Degree. - 9+ years of experience in software engineering, in at least one of the following technologies: GoLang, Java, Python, Rust, or C++. - 5+ years of experience with AWS, GCP, Azure, or another cloud service. - 2+ years of experience with containerization technologies such as Kubernetes. - 4+ years of experience in open source frameworks. - 2+ years of experience in Big Data, Data Security, Governance, and Controls. - 2+ years of experience in Agile practices. - 2+ years of experience working at a startup or in a startup environment. - 2+ years of experience building Multi-cloud COTS products. - 2+ years of DevOps or Site Reliability Engineering experience. **Salary Range:** - Remote (Regardless of Location): $195,000 - $222,600 for Sr. Lead Software Engineer. - Candidates hired to work in other locations will receive the pay range associated with that location. **Benefits:** Capital One offers a comprehensive, competitive, and inclusive set of health, financial, and other benefits that support your total well-being. Eligibility varies based on full or part-time status, exempt or non-exempt status, and management level. Learn more at the Capital One Careers website. **Equal Opportunity Employer:** Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We do not discriminate based on sex, race, color, age, national origin, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited under applicable federal, state, or local law. **Accommodations and Support:** If you require an accommodation during the application process, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. All information provided will be kept confidential and used only to provide the necessary accommodations. **Note for Third-Party Products and Services:** Capital One does not provide, endorse, guarantee, or assume liability for third-party products, services, educational tools, or other information available through this site. **Other Entities within Capital One Financial:** Please note that any positions posted in Canada, the United Kingdom, or the Philippines are for Capital One Canada, Capital One Europe, and Capital One Philippines Service Corp. (COPSSC), respectively.</li></ul>
</div>",$195000- $222600,Data and AI Engineer
Senior Machine Learning Engineer,Walker & Dunlop,12/20/2023,https://www.linkedin.com/jobs/view/3741586647,0,https://media.licdn.com/dms/image/C4D0BAQFWW6laE9VmIw/company-logo_100_100/0/1630533851109/walker__dunlop_logo?e=2147483647&v=beta&t=x-6bi63TLPpMexxZCSnJn0hPLOJgLPJcrlW62YqaT8g,"Chicago, IL","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Department<br/><br/></strong>WDTech - Engineering<br/><br/>We are Walker &amp; Dunlop. We are one of the largest providers of capital to the commercial real estate industry, enabling real estate owners and operators to bring their visions of communities — where people live, work, shop, and play — to life. We are committed to creating meaningful social, environmental, and economic change in our communities. We believe seeking diverse talent and promoting the inclusion of all perspectives are more than moral imperatives – they are critical to our success and ability to innovate and grow.<br/><br/><ul><li>Please note that for this position at this time we are not considering candidates who will require our company’s visa sponsorship, either now or in the future. The most common requests for sponsorship we receive are OPT Visas and H-1B Visas.*<br/><br/></li></ul><strong>About WDTech<br/><br/></strong>WDTech is on a mission to make the world of commercial real estate more transparent, efficient, and faster. Our multidisciplinary teams leverage data analytics and data science to unearth meaningful information from an extraordinary volume and variety of property, hyperlocal, and market data.<br/><br/><strong>The impact you will have<br/><br/></strong>We are looking for a Senior Machine Learning Engineer (MLE) to join our Data Science organization to help develop and productize Machine Learning (ML) solutions for automated property valuations, entity resolution, automated financial document ingestion, data mining, asset recommendations and market forecasting.<br/><br/>You will work alongside Data Scientists, Data Analysts and other MLEs on model research and development and join forces with Data and Software Engineers to embed those models in production-ready ML pipelines and APIs. You will orchestrate ML production loads in AWS, actively participate in the development of our Data Science computing platform and help us move towards a MLOps level 2 maturity level.<br/><br/><ul><li>Build scalable ML pipelines to deliver predictions in production</li><li>Collaborate with software and DevOps engineers to contribute designs and requirements for end-to-end solutions</li><li>Work on the development of the W&amp;D Data Science computing platform in AWS, our CD4ML tools and model monitoring mechanisms</li><li>Develop and productionized ML models to solve problems for a variety of data and domains, including entity resolution and linkage, deep learning for automated text processing, asset similarity models, etc.</li><li>Be a team player and constantly coordinate with other disciplines to deliver excellent products and clear documentation</li><li>Contribute to the Data Science/ML activities, supporting best practices, knowledge sharing and cross-functional initiatives<br/><br/></li></ul><strong>What We Look For<br/><br/></strong><ul><li>5 or more years experience in Python (Pandas, Numpy, Sklearn, etc.) and SQL</li><li>5 or more years experience in ML or software engineering and a strong academic background in ML or a related discipline</li><li>Experience with Git for version control, code collaboration, and managing repositories</li><li>Hands-on experience with developing CI/CD pipelines and best practices on MLOps</li><li>Hands-on experience with integrating machine learning models into APIs for deployment using tools such as MLFlow and FastAPI</li><li>Hands-on experience with orchestrating ML and big data services in AWS (Step Functions, Sagemaker Processing job and AutoML, S3, Amazon Redshift, EKS) or other cloud services</li><li>Hands-on experience with with containerization using Docker to package and deploy applications consistently across different environments</li><li>Deep Learning experience with PyTorch or TensorFlow</li><li>Amazing communicators who can convey the importance of their work to laypersons as well as peers</li><li>Demonstrable experience of influencing and driving Engineering strategy</li><li>Excellent communication skills in verbal and written English<br/><br/></li></ul><strong>Bonus points for <br/><br/></strong><ul><li>Experience with orchestrating production workflows in Apache Airflow</li><li>Experience in real-estate domain <br/><br/></li></ul><strong>What We Offer</strong> <br/><br/><ul><li>The opportunity to join one of Fortune Magazine’s Great Places to Work winners from 2015-2023 </li><li>Comprehensive benefit options* that have earned Walker &amp; Dunlop the silver level of the 2022 Cigna Healthy Workforce Designation™, some of which include:</li><li> Up to 83% subsidized medical payroll deductions</li><li> Competitive dental and vision benefits</li><li> 401(k) + match</li><li> Pre-tax transit and commuting benefits</li><li> A robust health and wellness program – earn cash rewards and gain access to resources that<br/><br/></li></ul>promote health, engagement, and balance<br/><br/><ul><li> Paid maternity and parental leave, as well as other family paid leave programs</li><li> Company-paid life, short and long-term disability insurance</li><li> Health Savings Account and Healthcare and Dependent Care Flexible Spending </li><li>Commitment to diversity, equity, and inclusion, with employee resource groups organizing activities and providing a space for open communication </li><li>Career development opportunities </li><li>Empowerment and encouragement to give back – volunteer hours and donation matching </li><li>Eligibility may vary based on average number of hours worked<br/><br/></li></ul><strong>EEO Statement<br/><br/></strong>We are committed to equity in all steps of the recruitment and employment experience. We believe in equal access to opportunities in our workplace. We do not tolerate discrimination, including harassment, based on any characteristic protected by applicable law, such as race, color, national origin, religion, gender identity, sexual orientation, sex, age, disability, veteran or military status, and genetic information. We strive to be a safe place to ask questions, build professional relationships, and develop careers.<br/><br/><strong>SPAM<br/><br/></strong>Please be wary of recruitment scams. An indication of a scam might be a request for sensitive or bank information at the time of application or emails coming from a non walkerdunlop.com email address. Please call us at 301.215.5500, if you have any concerns about information requested during or after the application process.<br/><br/>
</div>",No Salary Info Found,Data and AI Engineer
Senior Engineer (Artificial Intelligence),"Request Technology, LLC",12/20/2023,https://www.linkedin.com/jobs/view/3781195089,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"Staff Engineer, Machine Learning (AI)",Motorola Mobility (a Lenovo Company),12/20/2023,https://www.linkedin.com/jobs/view/3785086997,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"AI/ML Engineer, Therapeutic Protein Design",Jobot,12/24/2023,https://www.linkedin.com/jobs/view/3791333967,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"Senior Engineer, Machine Learning",Analog Devices,12/19/2023,https://www.linkedin.com/jobs/view/3724811692,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
AI Engineer,WilmerHale,12/19/2023,https://www.linkedin.com/jobs/view/3751100960,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
AI ML Developer,"Global Channel Management, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3788159319,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"Software Engineer, Machine Learning",Meta,12/19/2023,https://www.linkedin.com/jobs/view/3738373156,0,https://media.licdn.com/dms/image/C4E0BAQFdNatYGiBelg/company-logo_100_100/0/1636138754252/facebook_logo?e=2147483647&v=beta&t=ULaTUKRgzMzLCy5-pLoRMfMKpEI4OApXM5C9pEDZSDs,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Meta is embarking on the most transformative change to its business and technology in company history, and our Machine Learning Engineers are at the forefront of this evolution. By leading crucial projects and initiatives that have never been done before, you have an opportunity to help us advance the way people connect around the world.The ideal candidate will have industry experience working on a range of recommendation, classification, and optimization problems. You will bring the ability to own the whole ML life-cycle, define projects and drive excellence across teams. You will work alongside the world’s leading engineers and researchers to solve some of the most exciting and massive social data and prediction problems that exist on the web.<br/><br/>Software Engineer, Machine Learning Responsibilities:<br/><br/><ul><li>Develop highly scalable classifiers and tools leveraging machine learning, data regression, and rules based models</li><li>Suggest, collect and synthesize requirements and create effective feature roadmap</li><li>Code deliverables in tandem with the engineering team</li><li>Adapt standard machine learning methods to best exploit modern parallel environments (e.g. distributed clusters, multicore SMP, and GPU)<br/><br/></li></ul>Minimum Qualifications:<br/><br/><ul><li>2+ years of experience in one or more of the following areas: machine learning, recommendation systems, pattern recognition, data mining or artificial intelligence</li><li>Proven experience to translate insights into business recommendations</li><li>Experience with Hadoop/HBase/Pig or MapReduce/Sawzall/Bigtable</li><li>Knowledge developing and debugging in C/C++ and Java</li><li>Experience with scripting languages such as Perl, Python, PHP, and shell scripts</li><li>Currently has, or is in the process of obtaining a Bachelor's degree in Computer Science, Computer Engineering, relevant technical field, or equivalent practical experience. Degree must be completed prior to joining Meta.<br/><br/></li></ul>Preferred Qualifications:<br/><br/><ul><li>Exposure to architectural patterns of large scale software applications<br/><br/></li></ul>About Meta:<br/><br/>Meta builds technologies that help people connect, find communities, and grow businesses. When Facebook launched in 2004, it changed the way people connect. Apps like Messenger, Instagram and WhatsApp further empowered billions around the world. Now, Meta is moving beyond 2D screens toward immersive experiences like augmented and virtual reality to help build the next evolution in social technology. People who choose to build their careers by building with us at Meta help shape a future that will take us beyond what digital connection makes possible today—beyond the constraints of screens, the limits of distance, and even the rules of physics.<br/><br/>Meta is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, religion, color, national origin, sex (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender, gender identity, gender expression, transgender status, sexual stereotypes, age, status as a protected veteran, status as an individual with a disability, or other applicable legally protected characteristics. We also consider qualified applicants with criminal histories, consistent with applicable federal, state and local law. Meta participates in the E-Verify program in certain locations, as required by law. Please note that Meta may leverage artificial intelligence and machine learning technologies in connection with applications for employment.<br/><br/>Meta is committed to providing reasonable accommodations for candidates with disabilities in our recruiting process. If you need any assistance or accommodations due to a disability, please let us know at accommodations-ext@fb.com.
      </div>",No Salary Info Found,Data and AI Engineer
Machine Learning Engineer for Advanced Manufacturing Artificial Intelligence,Re:Build Manufacturing,12/19/2023,https://www.linkedin.com/jobs/view/3757378134,0,https://media.licdn.com/dms/image/C4E0BAQEyzFLWNPcr4Q/company-logo_100_100/0/1663607886389/re_build_manufacturing_logo?e=2147483647&v=beta&t=_5EMFkFcrWf4vXo0-jjzw19nlcD6vP3uX16tOmLXBFg,"Framingham, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        About Re:Build Manufacturing<br/><br/>Re:Build Manufacturing is a rapidly growing family of industrial businesses combining enabling technologies, operational superiority, and strategic M&amp;A to build America’s next generation industrial company. At Re:Build we deploy deep expertise in operations management and technology to supercharge performance of our subsidiaries by implementing core technologies across industrial platforms in diverse growth markets. Our goal is to help revitalize the U.S. manufacturing base over the coming decades, creating substantial opportunities for our employees and the communities where we operate.<br/><br/>We leverage deep professional expertise and a candid, principled operating culture to drive differentiated outcomes for our customers, our employees, our communities and our investors. Ours is a fast-paced environment where individuals can stretch and be challenged with a wide variety of opportunities and projects. We empower and support our employees to pursue their fullest potential and provide meaningful avenues for personal and professional growth.<br/><br/>Who We are Looking For:<br/><br/>The Machine Learning Engineer is responsible for proposing, planning, executing, and analyzing research and development machine learning projects related to the field of advanced manufacturing artificial intelligence. In this role, the Machine Learning Engineer will work with a variety of data-driven technologies, including traditional and deep learning paradigms. The work will require skill and technical competency working with large, high-dimensional datasets containing many different types of data including text-based data, 3D data, and time-series data. The Machine Learning Engineer should have a combination of generalist machine learning skills, engineering analysis skills, and the ability to quickly develop specialist capabilities where needed. The role will demand both creativity and scientific rigor to execute high-quality experiments in a fast-paced environment combining science, invention, commercial product research for new AI systems.<br/><br/><strong>What You’ll Get to Do: <br/><br/></strong><ul><li>Work with technology leadership to propose, plan, and execute experiments that drive technology development to strategic initiatives. </li><li>Design intelligent systems that make decisions related to advanced manufacturing problems. </li><li>Write code that implements intelligent constructs and facilitates rapid experimentation to study their performance. </li><li>Create automation systems that process large and rich datasets of complex and multimodal advanced manufacturing data. </li><li>Leverage cloud technologies to train machine learning constructs. </li><li>Write reports demonstrating the degree of performance of new systems as measured in designed experiments. </li><li>Prepare R&amp;D machine learning constructs for deployment in production cloud-based systems. <br/><br/></li></ul><strong>Minimum Qualifications: <br/><br/></strong><ul><li>Expert-level experience PyTorch, TensorFlow, or other major deep learning framework</li><li>Undergraduate Degree in a technical field (such as engineering, computer science, math, or general sciences)</li><li>Master’s degree or higher in a technical field (such as engineering, computer science, math, or science)</li><li>5+ years combined work experience beyond undergraduate studies and research (full-time employment in industry, co-op employment in industry, full-time graduate research, or post-graduate research positions, such as post-doctoral positions). </li><li>High proficiency and 5+ years hands-on experience programming Python</li><li>High proficiency and hands-on experience programming in C/C++</li><li>High proficiency and hands-on experience in at least one additional general-purpose programming language (such as C#, Java, etc.)</li><li>Experienced at using, analyzing, designing, and optimizing supervised, unsupervised, and reinforcement learning-based models</li><li>Demonstratable experience with a reinforcement learning-based project</li><li>Substantial experience in a substantial engineering or manufacturing position or project with a major physical component (such as design engineering, hands-on fabrication experience, process engineering, robotics</li><li>Substantial experience with at least one major category of 3D data, such as CAD, CAM, graphics, 3D scanning, simulation of 3D physical phenomena, mechanical-interacting control system design and modeling. </li><li>Proficiency using both Linux and Windows operating systems</li><li>Proficiency with git-based source code revision control</li><li>Experience in cloud computing technologies, such as elastic computing, serverless computing, relational and document-based databases, and remote GPU computing<br/><br/></li></ul><strong>Desirable Qualifications: <br/><br/></strong><ul><li>Mechanically-focused background (such as mechanical engineering, physics, design engineering, or experience in a machine-shop/factory)</li><li>Power-user-level experience with Computer-Aided Design (CAD) or Computer-Aided Manufacturing (CAM) software</li><li>Experience with simulation of complex physical phenomena, such as structural, fluidic, and electromagnetic phenomena</li><li>Experience with container-based technologies such as Docker</li><li>Experience with programming CUDA or similar platforms (such as OpenCL)</li><li>Experience proposing, executing, writing, and publishing long-form research projects with substantial deliverables, such as Masters/Ph.D. Thesis or industrial technical projects. </li><li>Experience executing experiments</li><li>Experiences with statistics</li><li>Strength in geometry and linear algebra</li><li>Experience with software, hardware, design, and/or analysis of machinery, such as automated industrial machines, robots, and vehicles. <br/><br/></li></ul><strong>Additional Details<br/><br/></strong>Location - Framingham, MA<br/><br/><strong>The BIG payoff<br/><br/></strong>We are a company who is going to make a difference in the industries and the communities in which we choose to operate.<br/><br/>Every employee of Re:Build will share ownership in the company and will share in the financial rewards of the success we achieve together, at all levels of the company!<br/><br/><strong>We want to work with people that reflect the communities in which we operate <br/><br/></strong>Re:Build Manufacturing is proud to be an Equal Employment Opportunity and Affirmative Action employer. We do not discriminate based upon race, color, religion, gender, gender identity or expression, sexual orientation, national origin, genetics, disability, age, veteran status, marital status, parental status, cultural background, organizational level, work styles, tenure and life experiences. Or for any other reason.<br/><br/>Re:Build is committed to providing reasonable accommodations for qualified individuals with disabilities in our job application procedures. If you need assistance or an accommodation due to a disability, you may contact us at accommodations.ta@ReBuildmanufacturing.com or you may call us at 617.909.6275.
      </div>",No Salary Info Found,Data and AI Engineer
"Machine Learning Engineer, Digital Transformation (64269BR)",Harvard Business School,12/19/2023,https://www.linkedin.com/jobs/view/3756726131,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Machine Learning Ops Engineer II,Klaviyo,12/19/2023,https://www.linkedin.com/jobs/view/3774253736,0,https://media.licdn.com/dms/image/D4E0BAQGC5AEqq6Fx4w/company-logo_100_100/0/1695215451585/klaviyo_logo?e=2147483647&v=beta&t=B7N2kpykzZZKNx29GaSJlK4JEyM9MHCd52fTYlKqxeg,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>At Klaviyo, we value the unique backgrounds, experiences and perspectives each Klaviyo (we call ourselves Klaviyos) brings to our workplace each and every day. We believe everyone deserves a fair shot at success and appreciate the experiences each person brings beyond the traditional job requirements. If you’re a close but not exact match with the description, we hope you’ll still consider applying. Want to learn more about life at Klaviyo? Visit careers.klaviyo.com to see how we empower creators to own their own destiny.<br/><br/></em><strong>About The Team<br/><br/></strong>Klaviyo operates a real-time data analytics platform coded primarily in Python that is built for massive scale and hosted on Amazon Web Services (AWS). Engineers come to Klaviyo with experience in a variety of languages and from a number of disciplines.<br/><br/>At Klaviyo, we love tackling tough engineering problems and look for employees who specialize in certain areas but are passionate about building, owning &amp; scaling features end to end from scratch and breaking through any obstacle or technical challenge in their way. We push each other to move out of our comfort zone, learn new technologies, and work hard to ensure each day is better than the last. Learn more about our engineering culture at https://klaviyo.tech<br/><br/><strong>About The Role<br/><br/></strong>As a Machine Learning Engineer II, you will be a key contributor to the DS Platform team’s efforts to build and improve the tools, systems, and software services that Data Scientists depend on to create cutting edge models that power Klaviyo’s most advanced features.<br/><br/>You will be responsible for developing tools to train and develop models, serve models in production, and monitor models’ long term performance. You’ll work with a modern software stack built on Kubernetes, Sagemaker, and Ray, helping to support models running on technologies such as PyTorch, SKLearn, Huggingface, and more.<br/><br/>You will learn from senior team members and level up your software engineering, dev ops, and DS/ML skills in a collaborative hybrid environment surrounded by engineers and data scientists passionate about producing high quality and high value models and features.<br/><br/><strong>How You'll Have An Impact<br/><br/></strong>30 days<br/><br/><ul><li>You will have set up your local environment and contributed your first PR.</li><li>You will be participating in team meetings and processes, and have met several members of the wider Data Science team.<br/><br/></li></ul>60 days<br/><br/><ul><li>You will have a firm understanding of at least one of the systems the team owns, and will be actively and consistently contributing code on a regular cadence.</li><li>You will be actively reviewing teammates’ code.<br/><br/></li></ul>90 days<br/><br/><ul><li>You will have developed at least one major feature.</li><li>You will be familiar with all of the team’s systems and have joined the team’s on-call rotation, demonstrating ownership and mastery.</li><li>You will be an active contributor to team discussions on technical decisions.<br/><br/></li></ul>Up to 1 year<br/><br/><ul><li>You will be a key member of the team’s technical and social fabric, shipping impactful code and systems, responding to incidents, monitoring and ensuring uptime, and collaborating with teammates effectively to solve problems.<br/><br/></li></ul><strong>What We're Looking For<br/><br/></strong><ul><li>Prior industry experience as software engineer or machine learning engineer</li><li>Python</li><li>AWS</li><li>Unix/Linux</li><li>Networking<br/><br/></li></ul><strong>Nice To Have<br/><br/></strong><ul><li>Kubernetes</li><li>Terraform</li><li>Go</li><li>Sagemaker</li><li>ML frameworks such as Huggingface, PyTorch, Tensorflow, Keras</li><li>Distributed training frameworks such as Spark, Ray, etc<br/><br/></li></ul>The pay range for this role is listed below. Sales roles are also eligible for variable compensation and hourly non-exempt roles are eligible for overtime in accordance with applicable law. This role is eligible for benefits, including: medical, dental and vision coverage, health savings accounts, flexible spending accounts, 401(k), flexible paid time off and company-paid holidays and a culture of learning that includes a learning allowance and access to a professional coaching service for all employees.<br/><br/>Pay Range For US Locations:<br/><br/>$123,200—$184,800 USD<br/><br/><strong>Get to Know Klaviyo<br/><br/></strong>We’re Klaviyo (pronounced clay-vee-oh). We empower creators to own their destiny by making first-party data accessible and actionable like never before. We see limitless potential for the technology we’re developing to nurture personalized experiences in ecommerce and beyond. To reach our goals, we need our own crew of remarkable creators—ambitious and collaborative teammates who stay focused on our north star: delighting our customers. If you’re ready to do the best work of your career, where you’ll be welcomed as your whole self from day one and supported with generous benefits, we hope you’ll join us.<br/><br/><em>Klaviyo is committed to a policy of equal opportunity and non-discrimination. We do not discriminate on the basis of race, ethnicity, citizenship, national origin, color, religion or religious creed, age, sex (including pregnancy), gender identity, sexual orientation, physical or mental disability, veteran or active military status, marital status, criminal record, genetics, retaliation, sexual harassment or any other characteristic protected by applicable law.<br/><br/></em><em>IMPORTANT NOTICE: Our company takes the security and privacy of job applicants very seriously. We will never ask for payment, bank details, or personal financial information as part of the application process. All our legitimate job postings can be found on our official career site. Please be cautious of job offers that come from non-company email addresses (@klaviyo.com), instant messaging platforms, or unsolicited calls. <br/><br/></em><em>You can find our Job Applicant Privacy Notice here.<br/><br/></em>
</div>",$123200- $184800,Data and AI Engineer
Machine Learning/Databricks Developer (Hybrid Onsite role W2 only),Xoriant,12/19/2023,https://www.linkedin.com/jobs/view/3785486633,0,https://media.licdn.com/dms/image/D4D0BAQGx2q3UbyFGTA/company-logo_100_100/0/1692680296902/xoriant_logo?e=2147483647&v=beta&t=VmegONTBYcHv4-9g8TQK2CZH4WgHtlfaKpM5gXZ562M,"Boston, MA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title : Machine Learning / Databricks Developer </strong></p><p><strong>Client Location: Boston, MA (Hybrid 2-3 days a week onsite)</strong></p><p><strong>Duration : Long term contract</strong></p><p><strong>Contract: W2 / C2C (Own corp) </strong></p><p><strong> </strong></p><p><strong> Job Description:</strong></p><p>• Design and implement data engineering solutions in big data space</p><p>• Design and implement batch and streaming solutions to support near real-time analytics</p><p>• Collaborate with architects, tech leads, QA, business stakeholders, and project managers to design and develop solutions in AWS Databricks.</p><p>• Develop end-to-end Enterprise grade solutions, facilitate discussions with business &amp; IT stakeholders and highlighting the outcomes that can be delivered through these solutions.</p><p>• Develop data models based on the source systems</p><p>• Part of 24x7 on-call roration process for production support</p><p>• Troubleshoot productions issues and bug fixes</p><p>• Translate business requirements into technical specs</p><p>• Hands-on developer as part of a global team and coach fellow developers</p><p><br/></p><p><strong>Qualifications:</strong></p><p>• 8+ years of IT experience in big data space like Hadoop, data lake, data engineering using Python &amp; Spark programming languages</p><p>• Minimum 3 year of experience in Databricks workspace, Databricks notebooks, Job cluster, Delta Lake, Databricks Lakehouse and Unity catalog</p><p>• Minimum 5 years' experience in PySpark and Python development</p><p>• 6+ year's design and/or implementation of data pipelines</p><p>• Experience on design and develop Data pipelines and ETL or ELT jobs to ingest and process data in data lake</p><p>• Strong working knowledge of SQL Server, No SQL, Spark SQL, Data Modeling, Identity &amp; Access Management, Query optimization, Parallel processing</p><p>• Must have experience in problem-solving, verbal and communication skills.</p><p>• Experience in processing streaming data using Kafka / Pub-Sub</p><p>• Experience in AGILE development, SCRUM and Application Lifecycle Management (ALM)</p><p>• Must have knowledge in Datawarehouse concepts</p><p>• Hands-on experience in full life-cycle of software development or methodology using Agile Scrum/Kanban etc; requirements analysis, design, development testing</p><p>and implementation</p><p>• Plus to have experience in IaaS using Terraform</p><p>• Plus to have experience in pandas and tensor flow</p><p>• Plus to have Java, JavaSparak experience.</p>
</div>",No Salary Info Found,Data and AI Engineer
"Staff Data Scientist, Machine Learning",Valo Health,12/19/2023,https://www.linkedin.com/jobs/view/3774250572,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Data Scientist III,Sam's Club,12/23/2023,https://www.linkedin.com/jobs/view/3792731390,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Staff Data Scientist,Fanatics,12/23/2023,https://www.linkedin.com/jobs/view/3744433103,0,https://media.licdn.com/dms/image/C4E0BAQHEcEUNWZeiNw/company-logo_100_100/0/1677183216422/fanatics_inc__logo?e=2147483647&v=beta&t=sHvet6efUAXXZqaBoGgNsL_c9ZmAwHCMM9u_kykKNw4,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Overview<br/><br/></strong>Fanatics is building a leading global digital sports platform. The company ignites the passions of global sports fans and maximizes the presence and reach for hundreds of sports partners globally by offering innovative products and services across Fanatics Commerce, Fanatics Collectibles, and Fanatics Betting &amp; Gaming, allowing sports fans to Buy, Collect and Bet. Through the Fanatics platform, sports fans can buy licensed fan gear, jerseys, lifestyle and streetwear products, headwear, and hardgoods; collect physical and digital trading cards, sports memorabilia, and other digital assets; and bet as the company builds its Sportsbook and iGaming platform. Fanatics has an established database of over 100 million global sports fans, a global partner network with over 900 sports properties, including major national and international professional sports leagues, teams, players associations, athletes, celebrities, colleges, and college conferences, and over 2,000 retail locations, including its Lids retail business stores.<br/><br/>As a market leader with more than 18,000 employees, and hundreds of partners, suppliers, and vendors worldwide, we take responsibility for driving toward more ethical and sustainable practices. We are committed to building an inclusive Fanatics community, reflecting and representing society at every level of the business, including our employees, vendors, partners and fans. Fanatics is also dedicated to making a positive impact in the communities where we all live, work, and play through strategic philanthropic initiatives.<br/><br/>We’re hiring a Staff Data Scientist for our Data Engineering, Science, and Analytics team. If you excel at using data science to tackle business issues, this role could be perfect for you. As part of our team, you’ll get the chance to apply your data science skills to generate business growth. You’ll extract vital insights from diverse data sources, employ machine learning algorithms, and apply advanced statistical models. Your findings will be translated into business actions. Expect a daily array of new challenges and captivating projects that will leverage your interests and strengths.<br/><br/><strong>Responsibilities<br/></strong><ul><li>Team up with colleagues from engineering, operations, marketing, and finance to understand business needs and scope data science projects.</li><li>Wrangle, process, cleanse, validate, and enrich data from different sources and prepare it for analysis.</li><li>Assist in crafting data-informed business strategy and roadmaps.</li><li>Convert data requirements into data product requirements, evaluate technologies, and identify opportunities to innovate and improve our data science capabilities.</li><li>Apply innovative problem-solving skills to dissect data and build machine learning / statistical models to solve business problems from different perspectives.</li><li>Work with engineers to create services that can ingest and supply data to and from both internal and external sources and ensure data quality and timeliness</li><li>Lead the development of data visualization and dashboards to help the organization monitor performance, generate insights, and continuously improve user experience</li><li>Establish playbooks to drive process and consistent outcomes</li><li>Participating in the full life cycle of model development, which spans from business problem discovery, data discovery to model deployment and monitoring.<br/></li></ul><strong>Qualifications<br/></strong><ul><li>Master’s or Doctoral degree in Computer Science (with a focus on AI, Machine Learning, Data Mining), Statistics, Econometrics, Physics, or other quantitative disciplines that require processing and modeling data at a large scale.</li><li>5+ years of professional experience as a data scientist.</li><li>Proficient in Python, SQL, Spark, the associated Python and Spark packages commonly used by data scientists, and Deep Learning libraries, such as PyTorch.</li><li>Proficient in wrangle and analyze data with complex relationships and time scale.</li><li>Strong understanding of and practical experience in a wide range of machine learning algorithms and statistical models.</li><li>Strong understanding of and practical experience in using generative AI models.</li><li>Experience in using data visualization and dashboard tools.</li><li>Working experience in cloud-native technology.</li><li>Experience working with large structured and unstructured datasets stored in relational and NOSQL databases.</li><li>Out-of-the-box thinker and problem solver who can turn ambiguous business problems into clear data-driven solutions that deliver meaningful business impacts.</li><li>Excellent organizational skills, verbal and written communication skills, and presentation skills.<br/></li></ul><strong>Pluses<br/></strong><ul><li>Doctoral degree in computer science with a strong focus on deep learning and AI.</li><li>Proficient in other languages, such as R, used in data science.</li><li>Knowledge of data engineering and MLOps.</li><li>Certificates earned in AI, data mining, machine learning, deep learning, statistical modeling, cloud computing, data engineering, and MLOps.<br/></li></ul>Ensure your Fanatics job offer is legitimate and don’t fall victim to fraud. Fanatics never seeks payment from job applicants. Feel free to ask your recruiter for a phone call or other type of communication for interview, and ensure your communication is coming from a Fanatics or Fanatics Brand email address. For added security, where possible, apply through our company website at www.fanaticsinc.com/careers<br/><br/><em>Tryouts are open at Fanatics! Our team is passionate, talented, unified, and charged with creating the fan experience of tomorrow. The ball is in your court now.<br/><br/></em>Fanatics is committed to responsible planning and purchasing (RPP) practices, working with its business partners across its global and multi-layered supply chain, to ensure that planning, sourcing, and purchasing decisions, along with other supporting processes, do not impede or conflict with the fulfillment of Fanatics’ fair labor practices.<br/><br/><strong>NOTICE TO CALIFORNIA RESIDENTS/APPLICANTS</strong>: In connection with your application, we collect information that identifies, reasonably relates to or describes you (“Personal Information”). The categories of Personal Information that we collect include your name, government issued identification number(s), email address, mailing address, other contact information, emergency contact information, employment history, educational history, criminal record, and demographic information. We collect and use those categories of Personal Information about you for human resources and other business management purposes, including identifying and evaluating you as a candidate for potential or future employment or other types of positions, recordkeeping in relation to recruiting and hiring, conducting criminal background checks as permitted by law, conducting analytics, and ensuring compliance with applicable legal requirements and Company policies. For additional information on how we collect and use personal information in connection with your job application, review our Candidate Privacy Policy-CA
      </div>",No Salary Info Found,Data and AI Engineer
Data Scientist,"Trinity Industries, Inc.",12/19/2023,https://www.linkedin.com/jobs/view/3784405970,0,https://media.licdn.com/dms/image/C4E0BAQEMU98sXpLjcA/company-logo_100_100/0/1631331847797?e=2147483647&v=beta&t=Yf21unZuq1HQYHBWJ07k_vRdVQL0piPh5pVdGE6eWyI,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>TrinityRail </strong>is searching for a <strong>Data Scientist </strong>in <strong>Dallas, TX!</strong></p><p><br/></p><p>The successful candidate will be innovation-minded with a blend of skills in data analytics, data engineering, and data science. This individual will dive deep into analytics, model workflows, and data pipelines for our manufacturing business, while concentrating on support for the entire enterprise. This includes production-line workforce modeling &amp; analytics and supporting our lease fleet operations. The role is a unique blend of various skill domains - we're seeking an individual who can navigate these priorities with ease while unlocking value for our integrated business platform.</p><p><br/></p><p>Join our team today and be a part of <strong>Delivering Goods for the Good of All!</strong></p><p><br/></p><p><strong>What you'll do:</strong></p><p><br/></p><ul><li>Lead development of end-to-end analytics projects for our manufacturing, leasing, and supply chain groups from conception through delivery, driving effective collaboration and alignment with business stakeholders</li><li>Work closely with business leaders, project stakeholders, and subject matter experts to understand and optimize key business processes. Apply your SQL, data transformation, and data modeling skills to turn data into actionable insights and optimized solutions</li><li>Partner with data engineers on technical design of complex data sourcing, transformation, and aggregation logic to meet business analytics needs and deliver value. Leverage generative AI in analytical work where applicable</li><li>Work with data analysts to translate business requirements into impactful data visualizations and data models in platforms like Qliksense, Tableau, PowerBI, and other analytics tools</li></ul><p><br/></p><p><strong>What you'll need:</strong></p><p><br/></p><ul><li>Bachelor’s Degree in quantitative field such as Mathematics, Economics, Computer Science, Information Management, Statistics, Finance or Accounting; Masters and/or PhD preferred</li><li>5+ years relevant experience in related analytics, data science, and business intelligence</li><li>Expert-level skills in Data Analytics with advanced analytical languages (Python, R, Spark, Scala, and/or Julia)</li><li>Must possess exceptional communication/presentation skills, both verbal and written</li><li>Familiarity with industrial manufacturing and supply chain processes highly preferred</li><li>Possess competencies with SQL, Generative AI prompting, and data transformation tools. Seamlessly leverage generative AI tools like GPT, Co-Pilot, and other technologies as core aspects of the development process</li><li>Advanced skills in Data Architecting, Visualization, SQL, Microsoft Excel, PowerPoint</li><li>Technical fluency regarding data mining, data models, database design/development, and other segmentation techniques, usage of Data Orchestration &amp; Modeling platforms (e,g. Azure Databrick &amp; Data Factory)</li><li>Experience with data visualization tools such as Qliksense and techniques in translating business analytics needs into data visualization and semantic data access requirements</li><li>Intermediate skills in Application development with Business Intelligence tools (e,g. Qliksense, Tableau, Power BI, etc.)</li><li>Strong organizational, time management and multi-tasking skills</li><li>Prior experience with Palantir Foundry, including developing integrated workflows, process improvement and automation highly preferred</li></ul><p><br/></p><p><br/></p><p>EEO/AA/Disabled/Veterans/Drug-Free Workplace</p>
</div>",No Salary Info Found,Data and AI Engineer
Machine Learning Engineer G5430,Nisum,12/19/2023,https://www.linkedin.com/jobs/view/3771751301,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"PEPI - Manager, Generative AI – AI Engineer (Open to All US locations)",Alvarez & Marsal,12/19/2023,https://www.linkedin.com/jobs/view/3771052378,0,https://media.licdn.com/dms/image/D4E0BAQGMC4Foh_foyA/company-logo_100_100/0/1688474876208/alvarez__marsal_logo?e=2147483647&v=beta&t=F6dB5veqYvDS3ctf_LHmJ9WYLX6C96zT9q2I3diUu1Y,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Description<br/><br/></strong>Alvarez &amp; Marsal is a leading independent global professional services firm, specializing in providing turnaround management, performance improvement and corporate advisory services, is seeking to expand its Private Equity Performance Improvement (PEPI) Generative AI team. With more than 7,000 professionals based in 40 locations across North America, Europe, Asia, and Latin America, our firm excels in problem solving and value creation. Drawing on a strong operational heritage and hands on approach, our professionals work closely with organizations and stakeholders to help tackle complex business issues and maximize value.<br/><br/>A&amp;M's Private Equity Performance Improvement Services (PEPI) practice, with offices throughout the US, focuses on serving upper middle market and large cap private equity firms who have engaged A&amp;M to help improve operating results at their portfolio companies. The companies we serve are upper middle market in the $50 million to $1 billion plus range.<br/><br/><strong>Our PEPI services include: <br/><br/></strong>Merger Integration &amp; Carveouts<br/><br/>IT pre acquisition diligence<br/><br/>IT post acquisition implementations and integration<br/><br/>Interim Management<br/><br/>CFO Services<br/><br/>Commercial Due Diligence/Strategy<br/><br/>Rapid Results<br/><br/>Supply Chain<br/><br/><strong>Private Equity Focused Professionals <br/><br/></strong>We're developing a cutting-edge Generative AI tool designed to streamline analysis and research by automating portions of data analysis, identifying opportunities, and facilitating interactive data search. Our platform aims to enhance private equity decision-making through advanced AI techniques, transforming complex use case scenarios into streamlined, insightful processes.<br/><br/>We provide private equity buyers with a broad continuum of knowledge and tools for due diligence (IT and operational), merger integration / carveout planning and execution, transition service agreement negotiation &amp; governance, ERP implementations, IT operations &amp; cost reduction, and enterprise architecture. We support full spectrum of the deal lifecycle from pre-deal technology, operational and synergy reviews, through 'Day1' planning, to post deal implementations.<br/><br/>By joining our Generative AI team, you will have the opportunity to be at the forefront of Generative AI technology and its application in the private equity industry, working closely with leaders in the field to shape the future of consulting.<br/><br/><strong>Manager:<br/><br/></strong>The AI Engineer will be a pivotal member of the Generative AI lab, a specialized cohort of engineers devoted to innovating core AI functionalities that propel value across the consulting lifecycle for our consultants. The key focus areas encompass information extraction, synthesis, and analytical processing of both structured and unstructured data to unearth quantitative insights. The AI Engineer will be instrumental in architecting, owning, and evolving AI functionalities throughout their lifecycle, transitioning from proof of concept to a production-grade pipeline. This role involves researching novel capabilities, conducting empirical experiments to quantitatively ascertain the functionality’s performance and suitability, and developing proofs of concept. The ensuing phase involves refining the pipeline to a production-grade module, ready for integration by the product team into a user-centric experience.<br/><br/><strong>Key Responsibilities:<br/><br/></strong><ul><li>Owning and steering individual pipelines for AI functionalities from conceptualization to production.</li><li>Investigating emerging capabilities, conducting rigorous experiments to quantitatively evaluate functionality's performance and relevance, and developing proofs of concept.</li><li>Transitioning pipelines to production-quality modules for seamless integration into user experiences by the product team.</li><li>Collaborating closely with other engineers in the Generative AI lab to drive innovative solutions and share knowledge and insights.</li><li>Ensuring the continual enhancement of AI functionalities by leveraging feedback and performance metrics to refine pipelines and modules.</li><li>Communicating effectively with stakeholders to report progress, challenges, and outcomes of AI initiatives.<br/><br/><br/></li></ul><strong>Qualifications:<br/><br/></strong><ul><li>5+ years of professional experience in data science, specifically in crafting and deploying AI/ML applications.</li><li>Proficiency in Python is mandatory, with substantial knowledge of ML libraries such as Scikit-Learn; SQL expertise is desirable, as is familiarity with cloud platforms like Azure or comparable platforms, and vector databases like Pinecone.</li><li>A robust understanding of the lifecycle of statistical and machine learning models encompassing data preparation, technique selection, model selection, hyperparameter tuning, and performance evaluation/improvement.</li><li>A seasoned background in handling unstructured natural language data, text extraction, and engineering.</li><li>Preferred experience in Natural Language Processing (NLP) including n-grams, bag of words representation, TF-IDF, semantic parsing, and sentiment analysis.</li><li>A penchant for Generative AI and large language models including text completion models, semantic embeddings, and familiarity with frameworks such as Langchain is desirable.</li><li>Sharp analytical and problem-solving abilities with a self-driven nature, capable of functioning autonomously under the guidance of the head of AI labs.</li><li>An advanced degree in a quantitative discipline like Statistics, Computer Science, Physics, or Mathematics is preferred.<br/><br/><br/></li></ul>Diversity &amp; Inclusion<br/><br/>A&amp;M’s entrepreneurial culture celebrates independent thinkers and doers who can positively impact our clients and shape our industry. The collaborative environment and engaging work—guided by A&amp;M’s core values of Integrity, Quality, Objectivity, Fun, Personal Reward, and Inclusive Diversity—are the main reasons our people love working at A&amp;M. Inclusive Diversity means we embrace diversity, and we foster inclusiveness, encouraging everyone to bring their whole self to work each day. It runs through how we recruit, develop employees, conduct business, support clients, and partner with vendors. It is the A&amp;M way.<br/><br/>Equal Opportunity Employer<br/><br/>It is Alvarez &amp; Marsal’s practice to provide and promote equal opportunity in employment, compensation, and other terms and conditions of employment without discrimination because of race, color, creed, religion, national origin, ancestry, citizenship status, sex or gender, gender identity or gender expression (including transgender status), sexual orientation, marital status, military service and veteran status, physical or mental disability, family medical history, genetic information or other protected medical condition, political affiliation, or any other characteristic protected by and in accordance with applicable laws. Employees and Applicants can find A&amp;M policy statements and additional information by region here.<br/><br/>Unsolicited Resumes from Third-Party Recruiters<br/><br/>Please note that as per A&amp;M policy, we do not accept unsolicited resumes from third-party recruiters unless such recruiters are engaged to provide candidates for a specified opening and in alignment with our Inclusive Diversity values. Any employment agency, person or entity that submits an unsolicited resume does so with the understanding that A&amp;M will have the right to hire that applicant at its discretion without any fee owed to the submitting employment agency, person or entity.<br/><br/>
</div>",$50- $1,Data and AI Engineer
"Staff, Data Scientist - Data Ventures",Walmart Luminate,12/19/2023,https://www.linkedin.com/jobs/view/3737759430,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Data Scientist,Consulting Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3784413239,0,https://media.licdn.com/dms/image/D560BAQGxtHRirtOmLA/company-logo_100_100/0/1688441674265/consultingsolutionsna_logo?e=2147483647&v=beta&t=nR28EuPPSutsgvdV9zRYJ7apZCfknTompUKreeqpcBU,Dallas-Fort Worth Metroplex,"<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>1 Year Contract Engagement. Hybrid schedule (2-3 days in office). Located in North Dallas. </strong></p><p><br/></p><p><strong>Requirements</strong>:</p><p>• A quantitative MS/PhD and minimum of 7 years of demonstrated success in Data Science</p><p>• 7+ years of experience in deploying data science in a business environment and fact-based evidence/anecdotes of implementation and impact from such deployments</p><p>• Expertise in Time Series modeling and the complexity of Time Series</p><p>• Deep expertise in Bayesian modeling and Bayesian inference</p><p>• An understanding of uncertainty principles in modeling and leverage distributional predictions to represent uncertainty and risk</p><p>• The ability to accurately scope modeling projects</p><p>• Collaboration skills and experience working with cross-functional teams and effectively communicate findings and recommendations to non-technical stakeholders</p><p>• An entrepreneurial mind-set</p><p>• A team-player and a team-first mentality</p><p>• Excellent oral and written communication skills</p><p>• Excellent Data Story telling skills</p><p>• A highly detail–oriented and organized working style—ensuring model documentation excellence</p><p>• Strong business, economic, and financial acumen</p><p><br/></p><p><em><u>Pluses included:</u></em></p><p>• The ability to quantify indirect effect of treatments utilizing Bayesian Networks or Halo Effects</p><p>• Experience incorporating expert qualitative business knowledge and A/B test results to adjust and tune model results</p><p>• Experience with Bayesian Belief Networks</p><p>• Familiarity and experience with conformal prediction, diffusion methods is a plus</p><p>• Demonstrated experience with applying integer and linear optimization methods to drive business goals/KPI outcomes</p><p>• Demonstrated success in Data Science within the Marketing Domain</p><p>• Experience working in CPG, Media, or Retail on the client or agency side</p><p>• Domain knowledge on marketing and/or Market Mix Models</p><p>• Up to date and passion for staying current with various modeling techniques and a demonstrated history of utilizing champion challenger principles to ensure model</p><p>• 3+ years of demonstrated experience working directly or indirectly with Python in a full-stack Data Science product environment</p><p>• Experience working with engineers to convert experimental code into production ready code</p><p>• Experience working with Bit Bucket, Git, Google Cloud Platform</p>
</div>",No Salary Info Found,Data and AI Engineer
"ML Infrastructure Engineer - Python, C++",CyberCoders,12/20/2023,https://www.linkedin.com/jobs/view/3789464418,0,https://media.licdn.com/dms/image/C560BAQF7t9X4k2P2hA/company-logo_100_100/0/1630672294143/cybercoders_logo?e=2147483647&v=beta&t=svLLpBE8gsgu2VaDigkqM3UEMeVyCIhMQEUzznif85w,"Dallas, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        If you are a ML Infrastructure Engineer with experience, please read on!<br/><br/>*** THIS ROLE IS ONSITE IN SAN JOSE, CA AND RELOCATION ASSISTANCE IS AVAILABLE***<br/><br/>What You Will Be Doing<br/><br/><strong>Day To Day<br/><br/></strong><ul><li> Design and develop systems to support Machine Learning algorithm development within the team.</li><li> Own the system design that will cater to multi-modal input, quick prototyping of algorithms, visualization tools, and state-of-the-art ML algorithm architecture development.</li><li> Build distributed systems and pipelines for data management, ensuring scalability, reliability, and performance.</li><li> Demonstrate a deep understanding of DevOps practices and apply them to ML operations.</li><li> Handle the complexities of designing and implementing ML infrastructure systems in a dynamic and fast-paced environment.</li><li> Contribute to the overall impact of the team by delivering robust and efficient ML infrastructure.<br/><br/></li></ul><strong>Requirements<br/><br/></strong><ul><li> Bachelor's degree in Computer Science or a related field.</li><li> Minimum 5+ years of experience in software engineering, focusing on infrastructure design.</li><li> 5+ years experience in Python and C++.</li><li> Proven experience in designing complex systems and strong software engineering skills.</li><li> Strong understanding and experience with distributed systems and infrastructure design.</li><li> Demonstrated expertise in DevOps practices, with a focus on ML.<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li> Experience with ML pipeline automation and data management in ML workflows.</li><li> Previous experience building ML systems and working on ML adjacent teams.<br/><br/></li></ul>What You Need for this Position<br/><br/><ul><li> Machine Learning</li><li> Infrastructure Engineer</li><li> Infrastructure Design</li><li> Python</li><li> C++</li><li> Devops</li><li> Machine Learning Infrastructure Engineer<br/><br/></li></ul>What's In It for You<br/><br/>Salary: $180K-$250K/yr DOE<br/><br/><ul><li> Vacation/PTO</li><li> Dental</li><li> Vision</li><li> 401k</li><li> Relocation</li><li> Medical<br/><br/></li></ul><strong>Benefits<br/><br/></strong><ul><li> Vacation/PTO</li><li> Medical</li><li> Dental</li><li> Vision</li><li> 401k</li><li> Relocation<br/><br/></li></ul>So, if you are a ML Infrastructure Engineer with experience, please apply today!<br/><br/>Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Anya Glover<br/><br/><strong>Email Your Resume In Word To<br/><br/></strong>Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:<br/><br/>Anya.Glover@CyberCoders.com<br/><br/><ul><li>Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : AG17-1779375L627 -- in the email subject line for your application to be considered.***<br/><br/></li></ul>Anya Glover - Executive Recruiter - CyberCoders<br/><br/>Applicants must be authorized to work in the U.S.<br/><br/><strong>CyberCoders is proud to be an Equal Opportunity Employer<br/><br/></strong>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br/><br/><strong>Your Right to Work</strong> – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br/><br/>CyberCoders will consider for Employment in the City of Los Angeles qualified Applicants with Criminal Histories in a manner consistent with the requirements of the Los Angeles Fair Chance Initiative for Hiring (Ban the Box) Ordinance.<br/><br/>
</div>",$180- $250,Data and AI Engineer
Senior Artificial Intelligence / Machine Learning Software Engineer,Raytheon,12/20/2023,https://www.linkedin.com/jobs/view/3785096266,0,https://media.licdn.com/dms/image/D560BAQEJrjIh_xsiKg/company-logo_100_100/0/1687168982390/raytheon_logo?e=2147483647&v=beta&t=Ql1WfWKBqCvpXs0PAfkMyKqumr9ZnI9rkiHcVS-qeOI,"Richardson, TX","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Date Posted:<br/><br/></strong>2023-12-14<br/><br/><strong>Country:<br/><br/></strong>United States of America<br/><br/><strong>Location:<br/><br/></strong>TX234: Richardson 1717 CityLine 1717 East CityLine Drive Building C17, Richardson, TX, 75082 USA<br/><br/><strong>Position Role Type:<br/><br/></strong>Onsite<br/><br/><strong>About Us:<br/><br/></strong>At Raytheon, the foundation of everything we do is rooted in our values and a higher calling – to help our nation and allies defend freedoms and deter aggression. We bring the strength of more than 100 years of experience and renowned engineering expertise to meet the needs of today’s mission and stay ahead of tomorrow’s threat. Our team solves tough, meaningful problems that create a safer, more secure world.<br/><br/><strong>Job Summary:<br/><br/></strong>Raytheon is looking for a candidate to join our world-class team as a <strong>Senior Artificial Intelligence / Machine Learning Software Engineer. </strong>In this role, you will develop, integrate, scale and test containerized microservices based on high performance algorithms and applied analytic techniques.<br/><br/>This position is located onsite in Richardson, Texas (Cityline)<br/><br/><strong>Responsibilities to Anticipate: <br/><br/></strong><ul><li>Opportunity to use your understanding of data science, software principles, theories, and concepts related to software engineering (including software development lifecycle and software development process), design patterns, and Object Oriented architecture. </li><li>Demonstrate critical thinking skills with the ability to communicate concepts and ideas well. </li><li>Ability to obtain and maintain SCI program access and complete polygraphs. <br/><br/></li></ul><strong>Basic Qualifications:<br/><br/></strong><ul><li>Typically requires Bachelor’s degree in Science, Technology, Engineering or Mathematics (STEM) and five (5) years of engineering experience. </li><li>3+ years’ software development experience. </li><li>3+ years' experience developing complex applications with Java. </li><li>1+ years' experience event driven architecture and microservices. </li><li>Experience with Data Science techniques such as classification analysis, anomaly detection, clustering analysis, segmentation, etc. </li><li>Experience with analytic frameworks such as Jupyter, Data Bricks, Spark, Esper, and Chronos. </li><li>Experience with Agile and DevSecOps toolsets such as Jira, Confluence, BitBucket, Jenkins, and Cucumber. </li><li>Active and transferable U.S. government issued Top Secret security clearance is required. U.S. citizenship is required, as only U.S. citizens are eligible for a security clearance. <br/><br/></li></ul><strong>Preferred Qualifications:<br/><br/></strong><ul><li>Active TS/SCI with CI polygraph. </li><li>Security+ Certification. </li><li>Experience with containerization technologies such as Docker and Kubernetes. </li><li>Experience with Agile development methodologies. </li><li>Experience with DevSecOps and Continuous Integration/Continuous Delivery. </li><li>Experience with AWS Cloud Technologies. </li><li>Proven problem solving and analytical abilities. <br/><br/></li></ul><strong>What We Offer</strong><strong>:<br/><br/></strong>Whether you’re just starting out on your career journey or are an experienced professional, we offer a total rewards package that goes above and beyond with compensation; healthcare, wellness, retirement and work/life benefits; career development and recognition programs. Some of the benefits we offer include parental (including paternal) leave, flexible work schedules, achievement awards, educational assistance and child/adult backup care.<br/><br/><strong>Location Information:<br/><br/></strong>In North Texas we have facilities in Dallas, McKinney and Richardson that delivers excellence every day in engineering, manufacturing and supply chain. As one of the fastest growing areas in America, North Texas is a destination for suburban seekers and urban explores. Offering farm-to-table food scene, festivals, nature trails, mountain biking, lakes and more. https://careers.rtx.com/global/en/raytheon-north-texas-location<br/><br/><strong><em>RTX is An Equal Opportunity/Affirmative Action Employer. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability or veteran status, age or any other federally protected class.<br/><br/></em></strong><strong>Privacy Policy and Terms:<br/><br/></strong>Click on this link to read the Policy and Terms<br/><br/><strong>01668010</strong>
</div>",No Salary Info Found,Data and AI Engineer
Principal Artificial Intelligence / Machine Learning Software Engineer,Raytheon,12/20/2023,https://www.linkedin.com/jobs/view/3785098094,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Data Scientist,Jobot,12/24/2023,https://www.linkedin.com/jobs/view/3791328967,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"Data Scientist, Pricing Analytics",The Home Depot,12/19/2023,https://www.linkedin.com/jobs/view/3789768606,0,https://media.licdn.com/dms/image/C4E0BAQHzR2llYqUBtg/company-logo_100_100/0/1630656428961/the_home_depot_logo?e=2147483647&v=beta&t=NH5wv1AXmlH4oUpVAOaSorm4nU1y-uttFDDEbY5Veps,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Home Depot is able to offer virtual employment of this position in the following states:<br/><br/>AK, AZ, CA, GA, HI, ID, IL, KS, KY, ME, MA, MI, MN, MT, NE, NV, NH, NJ, NM, NY, ND, OH, OR, RI, SD, TX, UT, VT, WA, WV, WI, WY<br/><br/><strong>Position Purpose<br/><br/></strong>The Data Scientist is responsible for supporting data science initiatives that drive business profitability, increased efficiencies and improved customer experience. This role applies industry-leading analytical methodologies for working with large datasets to extract meaningful business insight and creatively solve business problems. Data Scientists are also responsible for ensuring that developed codes are documented into a library of reusable algorithms. Based on the specific data science team, this role would need to be knowledgeable in one or more data science specializations, such as optimization, computer vision, recommendation, search or NLP.<br/><br/>As a Data Scientist, you will apply advanced analytics methods and algorithms for identifying trends and providing business solutions. This role is expected to present insights and recommendations to non-technical audiences and explain the benefits and impacts of the recommended solutions. In addition, Data Scientists collaborate with business partners and cross-functional teams, requiring effective communication skills, building relationships, and focus on understanding the overall business area being supported.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>55% Solution Development - Design and develop algorithms and models to use against large datasets to create business insights; Participates in large data analytics project teams by serving as a technical lead for analytics projects; May lead small projects and work independently on solution development; Execute tasks with high levels of efficiency and quality; Make appropriate selection, utilization and interpretation of advanced analytical methodologies</li><li>20% Communicating Results - Effectively communicate insights and recommendations to both technical and non-technical leaders and business customers/partners; Present recommendations in a confident manner in order to influence execution of recommendation; Prepare reports, updates and/or presentations related to progress made on a project or solution; Clearly communicate impacts of recommendations to drive alignment and appropriate implementation</li><li>10% Business Collaboration - Incorporate business knowledge into solution approach; Effectively develop trust and collaboration with internal customers and cross-functional teams; Work with project teams and business partners to determine project goals</li><li>15% Technical Exploration &amp; Development - Seek further knowledge on key developments within data science, technical skill sets, and additional data sources; Participate in the continuous improvement of data science and analytics by developing replicable solutions (for example, codified data products, project documentation, process flowcharts) to ensure solutions are leveraged for future projects; Build and maintain library of reusable algorithms for future use, ensuring developed codes are documented<br/><br/></li></ul><strong>Direct Manager/Direct Reports<br/><br/></strong><ul><li>This position typically reports to Manager or above</li><li>This position has 0 Direct Reports<br/><br/></li></ul><strong>Travel Requirements<br/><br/></strong><ul><li>Typically requires overnight travel less than 10% of the time.<br/><br/></li></ul><strong>Physical Requirements<br/><br/></strong><ul><li>Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.<br/><br/></li></ul><strong>Working Conditions<br/><br/></strong><ul><li>Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>Must be eighteen years of age or older.</li><li>Must be legally permitted to work in the United States.<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Masters in a quantitative field (Computer Science, Math, Statistics, etc.) or equivalent work experience</li><li>4+ years of experience in business intelligence and analytics</li><li>Working knowledge of Microsoft Excel and Power Point</li><li>Experience in a modern scripting language (preferably Python)</li><li>Proficient running queries against data (preferably with Google BigQuery or SQL)</li><li>Proficient with data visualization software (preferably Tableau)</li><li>Proficient utilizing statistical techniques to identify key insights that help solve business problems</li><li>Knowledgeable in Prescriptive Modeling like optimization, computer vision, recommendation, search or NLP</li><li>Demonstrated experience in predictive modeling, data mining and data analysis<br/><br/></li></ul><strong>Minimum Education<br/><br/></strong><ul><li>The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.<br/><br/></li></ul><strong>Preferred Education<br/><br/></strong><ul><li>No additional education<br/><br/></li></ul><strong>Minimum Years Of Work Experience<br/><br/></strong><ul><li>3<br/><br/></li></ul><strong>Preferred Years Of Work Experience<br/><br/></strong><ul><li>No additional years of experience<br/><br/></li></ul><strong>Minimum Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Preferred Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Certifications<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Competencies<br/><br/></strong><ul><li>Action Oriented: Taking on new opportunities and tough challenges with a sense of urgency, high energy, and enthusiasm</li><li>Business Insight: Applying knowledge of the business and the marketplace to advance the organization's goals</li><li>Collaborates: Building partnerships and working collaboratively with others to meet shared objectives</li><li>Communicates Effectively: Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences</li><li>Customer Focus: Building strong customer relationships and delivering customer-centric solutions</li><li>Drives Results: Consistently achieving results, even under tough circumstances</li><li>Nimble Learning: Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder</li><li>Optimizes Work Processes: Knowing the most efficient and effective processes to get things done, with a focus on continuous improvement</li><li>Plans and Aligns: Planning and prioritizing work to meet commitments aligned with organizational goals</li><li>Self-Development: Actively seeking new ways to grow and be challenged using both formal and informal development channels</li></ul>
</div>",No Salary Info Found,Data and AI Engineer
Machine Learning Engineer - Senior/Lead/Principal,Salesforce,12/19/2023,https://www.linkedin.com/jobs/view/3768852505,0,https://media.licdn.com/dms/image/C560BAQHZ9xYomLW7zg/company-logo_100_100/0/1630658255326/salesforce_logo?e=2147483647&v=beta&t=GvAdJRB6d3hWoiMBjIAOP9tjZzbWxLNF84FnSTgWblE,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<em>To get the best candidate experience, please consider applying for a maximum of 3 roles within 12 months to ensure you are not duplicating efforts.<br/><br/></em>Job Category<br/><br/>Data, Software Engineering<br/><br/>Job Details<br/><br/><strong>About Salesforce<br/><br/></strong>We’re Salesforce, the Customer Company, inspiring the future of business with AI+ Data +CRM. Leading with our core values, we help companies across every industry blaze new trails and connect with customers in a whole new way. And, we empower you to be a Trailblazer, too — driving your performance and career growth, charting new paths, and improving the state of the world. If you believe in business as the greatest platform for change and in companies doing well and doing good – you’ve come to the right place.<br/><br/><strong>Machine Learning Engineer - Senior/Lead/Principal<br/><br/></strong>Note: By applying to the Machine Learning Engineer posting, recruiters and hiring managers across the organization hiring machine learning engineers will review your resume. Our goal is for you to apply once and have your resume reviewed by multiple hiring teams.<br/><br/>Salesforce is looking for an exceptional Machine Learning Engineer to help us take on one of the world’s most extensive data sets and transform it into amazing products that feel like magic. You will work on innovative AI applications and products. Brainstorming data product ideas with data scientists and engineers to build data products used by hundreds of millions people every day.<br/><br/>In your role as a Machine Learning Engineer, you will partner with analysts, engineers, designers, executives, product managers, marketers, customer success, and sales team members across all Cloud businesses to create ML-driven decision making data products that enable our partners to affect the bottom line and solve critical business problems.<br/><br/><strong>Your Impact<br/><br/></strong><ul><li>Work closely with a dedicated team of machine learning professionals on a wide range of problems including forecasting significant business metrics such as sales and capacity, churn and propensity modeling to retain and grow our customer base, clustering and classification using both structured and unstructured data, and more!</li><li>Help create high-visibility data products and decision-making tools for Salesforce’s leaders</li><li>Lead the charge on taking our core products to the next level in terms of engineering maturity and architecture</li><li>Refine and develop new data science products, workflows, tools, and automation</li><li>Build tools to monitor data pipeline performance, data quality and models in production</li><li>Establish best practices with coding standards, workflows, tools, and product automation</li><li>Review and maintain existing tool-set and codebase (pipelines, models, algorithms); continue to improve existing tools and build new ones</li><li>Scale the operations of the data science team by building automation and libraries<br/><br/></li></ul><strong>Required Skills<br/><br/></strong><ul><li>A related technical degree required</li><li>4+ years of industry experience and a passion for crafting, analyzing and deploying machine learning-based solutions</li><li>Experience working as part of a team with mature data science products</li><li>Consistent record in building software and data products using modern development lifecycle methodologies: CI/CD, QA, and Agile Methodologies</li><li>Applied experience designing, building and optimizing data pipelines, architectures and data sets</li><li>Experience deploying, monitoring and maintaining data science products in cloud environments such as AWS or Microsoft Azure</li><li>Good understanding of Machine Learning methods and Statistics, including ML project lifecycle and associated challenges at each stage of development</li><li>Proficient at writing good quality, well-documented and tested, scalable code - Python preferred. Experience with tools like mlFlow, Airflow, Docker and Cloud Platforms such as AWS/GCP is ideal</li><li>Solid understanding of data transformations and analytics functions using tools/languages like Pandas, Sklearn, SQL and Spark</li><li>Strong communication skills and ability to interface well with other engineers, data scientists and product managers</li><li>Passion, curiosity, solutions focus and independence<br/><br/></li></ul><strong>Benefits &amp; Perks<br/><br/></strong>Check out our benefits site which explains our various benefits, including wellbeing reimbursement, generous parental leave, adoption assistance, fertility benefits, and more.<br/><br/><strong>Salesforce Information<br/><br/></strong>Check out our Salesforce Engineering Site.<br/><br/><strong>*IN SCHOOL OR GRADUATED WITHIN THE LAST 12 MONTHS? PLEASE VISIT FUTURE FORCE FOR OPPORTUNITIES</strong>*<br/><br/>Accommodations<br/><br/>If you require assistance due to a disability applying for open positions please submit a request via this Accommodations Request Form.<br/><br/>Posting Statement<br/><br/>At Salesforce we believe that the business of business is to improve the state of our world. Each of us has a responsibility to drive Equality in our communities and workplaces. We are committed to creating a workforce that reflects society through inclusive programs and initiatives such as equal pay, employee resource groups, inclusive benefits, and more. Learn more about Equality at www.equality.com and explore our company benefits at www.salesforcebenefits.com.<br/><br/>Salesforce is an Equal Employment Opportunity and Affirmative Action Employer. Qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender perception or identity, national origin, age, marital status, protected veteran status, or disability status. Salesforce does not accept unsolicited headhunter and agency resumes. Salesforce will not pay any third-party agency or company that does not have a signed agreement with Salesforce.<br/><br/>﻿Salesforce welcomes all.<br/><br/>For Washington-based roles, the base salary hiring range for this position is $146,600 to $280,200.<br/><br/>For California-based roles, the base salary hiring range for this position is $160,000 to $305,600.<br/><br/>Compensation offered will be determined by factors such as location, level, job-related knowledge, skills, and experience. Certain roles may be eligible for incentive compensation, equity, benefits. More details about our company benefits can be found at the following link: https://www.salesforcebenefits.com.
      </div>",$146600- $280200,Data and AI Engineer
"Systems Engineer, AI Infrastructure",Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3725159678,0,https://media.licdn.com/dms/image/C4D0BAQG16gpXzS14DQ/company-logo_100_100/0/1630499898593/cloudflare_logo?e=2147483647&v=beta&t=JnWbIHRMM7IEd6GKOBdDcOcAwe8GlG6X05cH_ptu3Rc,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world’s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine’s Top Company Cultures list and ranked among the World’s Most Innovative Companies by Fast Company.<br/><br/>We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!<br/><br/><strong>About The Role<br/><br/></strong>We're rekindling efforts to leverage acceleration and machine learning at Cloudflare in 2023, and the HW systems team is looking to hire senior technical engineers with a strong understanding of deep learning, ML end-to-end workloads and frameworks, and experience with hardware accelerator and processor architectures (GPUs, CPUs w/AI features, ASICs). This is an exciting opportunity with real world impact, where you'll get to build and deploy hardware accelerators on our data center platform.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Evaluate, design and deploy cutting edge acceleration solutions for our growing services</li><li>Lead the design of scalable AI infrastructure for Cloudflare's own internal machine learning platform and tune for optimal performance</li><li>Collaborate with product/data science teams to identify customer use-cases and translate workloads to technical design and hardware requirements (architecture definition, hardware selection, performance tuning)</li><li>Engage with hardware vendors to identify hardware solutions that best fit needs of the platform</li><li>Set the strategy and long term roadmap to demonstrate the value proposition of AI/ML workloads for the edge </li><li>Engage with AI leaders across the industry and influence design based on open industry standards <br/><br/><br/></li></ul><strong> <strong>Qualifications</strong> <br/><br/></strong><ul><li>Masters or equivalent experience in Computer Architecture, Computer Science, Electrical Engineering or related field with 12 years of relevant experience or equivalent</li><li>Has demonstrated technical leadership on critical company wide projects with experience in computer architecture (GPU, CPU w/AI. acceleration) and ML software ecosystem. Experience with programming models a plus</li><li>Strong technical foundation and deep understanding of cloud technologies, DL/ML workloads in the industry, frameworks (Tensorflow/Pytorch), and containers tools. </li><li>Ability to work in a constantly changing ambiguous environment and bridget the software/hardware divide </li><li>Industry-wide impact. Proactively creates formal networks involving coordination with internal and external technical leaders and has tangible proof points (patents, papers, conference contributions, open source SW or HW contributions, and/or sitting on a standards committee or board, etc.) demonstrating industry-wide influence as an influential spokesperson for the organization</li><li>Must be collaborative and has demonstrated ability to work effectively across cross functional teams, sound technical judgement and is capable of building positive working relationships</li><li>Seeks to mentor team members, offers technical advice and seeks to continuously learn<br/><br/><br/></li></ul><strong>Compensation<br/><br/></strong>Compensation may be adjusted depending on work location.<br/><br/><ul><li>For Colorado-based hires: Estimated annual salary of $168,000 - $248,000.</li><li>For New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $187,000 - $281,000.</li><li>For Bay Area-based hires: Estimated annual salary of $196,000 - $286,000.<br/><br/><br/></li></ul><strong>Equity<br/><br/></strong>This role is eligible to participate in Cloudflare’s equity plan.<br/><br/><strong>Benefits<br/><br/></strong>Cloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S.<br/><br/><strong>Health &amp; Welfare Benefits<br/><br/></strong><ul><li>Medical/Rx Insurance</li><li>Dental Insurance</li><li>Vision Insurance</li><li>Flexible Spending Accounts</li><li>Commuter Spending Accounts</li><li>Fertility &amp; Family Forming Benefits</li><li>On-demand mental health support and Employee Assistance Program</li><li>Global Travel Medical Insurance<br/><br/><br/></li></ul><strong>Financial Benefits<br/><br/></strong><ul><li>Short and Long Term Disability Insurance</li><li>Life &amp; Accident Insurance</li><li>401(k) Retirement Savings Plan</li><li>Employee Stock Participation Plan<br/><br/><br/></li></ul><strong>Time Off<br/><br/></strong><ul><li>Flexible paid time off covering vacation and sick leave</li><li>Leave programs, including parental, pregnancy health, medical, and bereavement leave<br/><br/><br/></li></ul><strong>What Makes Cloudflare Special?<br/><br/></strong>We’re not just a highly ambitious, large-scale technology company. We’re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.<br/><br/><strong>Project Galileo</strong> : We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare’s enterprise customers--at no cost.<br/><br/><strong> Athenian Project </strong> : We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.<br/><br/><strong>Path Forward Partnership</strong> : Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.<br/><br/><strong>1.1.1.1</strong> : We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here’s the deal - we don’t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.<br/><br/>Sound like something you’d like to be a part of? We’d love to hear from you!<br/><br/>This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.<br/><br/>Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.<br/><br/>Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.
      </div>",$168000- $248000,Data and AI Engineer
"Associate Data Scientist, Assortment and Space Planning",The Home Depot,12/19/2023,https://www.linkedin.com/jobs/view/3789772016,0,https://media.licdn.com/dms/image/C4E0BAQHzR2llYqUBtg/company-logo_100_100/0/1630656428961/the_home_depot_logo?e=2147483647&v=beta&t=NH5wv1AXmlH4oUpVAOaSorm4nU1y-uttFDDEbY5Veps,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        The Home Depot is able to offer virtual employment of this position in the following states:<br/><br/>AK, AZ, CA, GA, HI, ID, IL, KS, KY, ME, MA, MI, MN, MT, NE, NV, NH, NJ, NM, NY, ND, OH, OR, RI, SD, TX, UT, VT, WA, WV, WI, WY<br/><br/><strong>Position Purpose<br/><br/></strong>The Associate Data Scientist is responsible for supporting data science initiatives that drive business profitability, increased efficiencies and improved customer experience. This role works closely with Data Scientists and/or Sr. Data Scientists in their team to develop solutions by applying advanced analytics methods and algorithms for identifying trends and providing business solutions. Based on the specific data science team, this role may need to develop skills in one or more data science specializations, such as optimization, computer vision, recommendation, search or NLP.<br/><br/>As an Associate Data Scientist, you will develop skills that effectively leverage data science methodologies to creatively solve business problems and provide strategic insights. This requires effective communication skills as well as continuous learning and development at both the technical and business level.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>70% Solution Development - Design and develop algorithms and models to use against large datasets to create business insights; Supports data science projects by conducting effective analysis to solve business problems; Executes tasks with high levels of efficiency and quality; Consults with Data Scientist or Sr. Data Scientist on appropriate selection, utilization and interpretation of advanced analytical methodologies; Learn about the assigned business areas to provide better solutions by incorporating business-specific knowledge</li><li>20% Communicating Results - Effectively communicate insights and recommendations to both technical and non-technical audience; Support preparation of reports, updates and/or presentations related to progress made on a project or solution; Highlights potential impacts of recommendations to drive alignment and appropriate implementation</li><li>10% Technical Learning - Keep up to date on industry trends, best practices and emerging methodologies; Continually develop skills and expertise in data analytics concepts and methodologies; Identify opportunities to apply learnings<br/><br/></li></ul><strong>Direct Manager/Direct Reports<br/><br/></strong><ul><li>This position reports to manager or above</li><li>This position has 0 direct reports<br/><br/></li></ul><strong>Travel Requirements<br/><br/></strong><ul><li>No travel required.<br/><br/></li></ul><strong>Physical Requirements<br/><br/></strong><ul><li>Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.<br/><br/></li></ul><strong>Working Conditions<br/><br/></strong><ul><li>Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>Must be eighteen years of age or older.</li><li>Must be legally permitted to work in the United States.<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Master's degree in a quantitative field (Computer Science, Math, Statistics, etc.) or equivalent work experience</li><li>3+ years of experience in business intelligence and analytics</li><li>Working knowledge of Microsoft Excel and Power Point</li><li>Experience in a modern scripting language (preferably Python)</li><li>Experience running queries against data (preferably with Google BigQuery or SQL)</li><li>Experience in predictive modeling, data mining and data analysis</li><li>Experience with data visualization software (preferably Tableau)</li><li>Experience utilizing statistical techniques to identify key insights that help solve business problems</li><li>Basic knowledge or exposure to Prescriptive Modeling like optimization, computer vision, recommendation, search or NLP</li><li>Basic knowledge or exposure to predictive modeling, data mining and data analysis<br/><br/></li></ul><strong>Minimum Education<br/><br/></strong><ul><li>The knowledge, skills and abilities typically acquired through the completion of a bachelor's degree program or equivalent degree in a field of study related to the job.<br/><br/></li></ul><strong>Preferred Education<br/><br/></strong><ul><li>No additional education<br/><br/></li></ul><strong>Minimum Years Of Work Experience<br/><br/></strong><ul><li>0<br/><br/></li></ul><strong>Preferred Years Of Work Experience<br/><br/></strong><ul><li>No additional years of experience<br/><br/></li></ul><strong>Minimum Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Preferred Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Certifications<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Competencies<br/><br/></strong><ul><li>Action Oriented: Taking on new opportunities and tough challenges with a sense of urgency, high energy, and enthusiasm</li><li>Business Insight: Applying knowledge of the business and the marketplace to advance the organization's goals</li><li>Collaborates: Building partnerships and working collaboratively with others to meet shared objectives</li><li>Communicates Effectively: Developing and delivering multi-mode communications that convey a clear understanding of the unique needs of different audiences</li><li>Customer Focus: Building strong customer relationships and delivering customer-centric solutions</li><li>Drives Results: Consistently achieving results, even under tough circumstances</li><li>Nimble Learning: Actively learning through experimentation when tackling new problems, using both successes and failures as learning fodder</li><li>Optimizes Work Processes: Knowing the most efficient and effective processes to get things done, with a focus on continuous improvement</li><li>Plans and Aligns: Planning and prioritizing work to meet commitments aligned with organizational goals</li><li>Self-Development: Actively seeking new ways to grow and be challenged using both formal and informal development channels</li></ul>
</div>",No Salary Info Found,Data and AI Engineer
AI/ML Engineer - ICL - OPEN RANK,Georgia Tech Research Institute,12/19/2023,https://www.linkedin.com/jobs/view/3749310942,0,https://media.licdn.com/dms/image/C4E0BAQGa9Z_TlViCoQ/company-logo_100_100/0/1631899577072/georgia_tech_research_institute_logo?e=2147483647&v=beta&t=1pvq4VTKBlw02JmIlJufMxVNcOsBzoPqg9Tvsp9lo10,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Project/Unit Description<br/><br/></strong>The Advanced Computing and Artificial Intelligence Division (ACAID) within the ICL Lab is seeking a Senior Artificial Intelligence Scientist to join our team of passionate researchers. We seek an experienced Scientist who can support our research efforts by matching cutting-edge algorithms with advanced computing technologies to realize solutions for the Nation’s most challenging problems. The ideal candidate will have broad and deep expertise in the application of analytic tools and machine learning techniques. A strong candidate will have interest and practical experience in AI applications for a wind range of research domains to include DoD, DOE and Healthcare industry.<br/><br/>This position will focus on the design, development and deployment of AI pipeline designs. The candidate will work closely with staff members in a collaborative working environment. This is an excellent opportunity for a motivated, results-oriented professional. We are seeking people who get excited about working with data, developing evidence base data driven solutions.<br/><br/>The ACAID Division works with a diverse group of organizations and agencies in National Security and the public health space. The ideal candidate must be able to communicate complex technical material clearly to a wide variety of audiences including academia, conference proceedings, management, business development leads, prospective and existing customers.<br/><br/><strong>Job Purpose<br/><br/></strong>Develops AI/ML algorithms and the development of cloud computing or heterogeneous distributed computing infrastructure to support the deployment of AI/ML applications. Additionally, an AI/ML Engineer performs research in the mathematical foundations and frameworks for nonlinear systems characterized by time-varying and emerging dynamics of Evolving or Adaptive Systems. They work at the leading edge of Artificial Intelligence (AI), Machine Learning (ML), Genetic Programming (GP), Computer Vision (CV), and advanced data processing, filtering, and fusion techniques. Work in high-performance computing and distributed heterogeneous computing environments. Write parallel processing programs to deploy ML models developed by the data scientist into more complex systems. Familiarity with state-of-the-art, open-source software frameworks and high-performance computing accelerators for machine learning. Leverage the most recent advances in statistical analysis of large data sets (AI/ML) to advance state-of-the-art automated sensor and data processing for a broad range of smart and sensor enabled systems.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>Design complex system architectures (e.g. high performance computing clusters, networks, chipsets) based on available hardware (e.g. embedded systems, cloud, on-premise)</li><li>Lead a team of engineers responsible for deployment.</li><li>Develop novel algorithms and methodologies.</li><li>Engage with sponsors to meet system requirements.</li><li>Primary author on technical reports and proposals.<br/><br/></li></ul><strong>Additional Responsibilities<br/><br/></strong><ul><li>Applying the Cross Industry Standard Process for Data Mining (CRIPS-DM)</li><li>Data parsing, preparation and fusing of disparate data sources using fundamental data python libraries and established practices and procedures</li><li>Independently conducting exploratory data analysis, documenting and presenting findings to senior leadership and decision makers</li><li>Applying data collection techniques in support of ETL and ELT</li><li>Database modeling, data design and application of stored procedures, stored functions and triggers</li><li>Application of Machine Learning techniques such as supervised, unsupervised and semi-supervised learning</li><li>Application of Natural Language Processing techniques</li><li>Present research at conferences, contribute to business development, and meet with customers<br/><br/></li></ul><strong>Required Minimum Qualifications<br/><br/></strong><ul><li>Strong cloud experience (AWS)</li><li>Experience with Scala, Spark, SQL, MATLAB, Github, Probability &amp; Statistic and Machine Learning</li><li>Passion for working with data, can think in data structures</li><li>Ability to work well with a variety of teams with diverse skill sets<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Active Top Secret Clearance</li><li>Advanced degree in Data Science, Computer Science, Electrical Engineering, Aerospace Engineering, Civil Engineering or related Engineering field</li><li>Documented experience conducting advanced research in AI pipeline design using proven Data Science methodologies as well as System Engineering practices.</li><li>Fundamental programming skills in core data science languages such as Python, R, MATLAB and SQL</li><li>Experience modeling data in JSON, XML and Entity Relational Diagraming (ERD) design</li><li>Experience working with cloud-based analytics environment, such as Databricks, Azure ML and AWS</li><li>Conceptual development in RStudio, JupyterLab and/or Jupyter Notebooks</li><li>Experience working with databases (I.e. configuring, deploying, securing and maintaining)</li><li>Experience working with government systems</li><li>Experience writing research proposals and documenting results<br/><br/></li></ul><strong>Travel Requirements<br/><br/></strong>10% - 25% travel<br/><br/><strong>Education And Length Of Experience<br/><br/></strong>This position vacancy is an open-rank announcement. The final job offer will be dependent on candidate qualifications in alignment with Research Faculty Extension Professional ranks as outlined in section 3.2.1 of the Georgia Tech Faculty Handbook<br/><br/><ul><li>9 years of related experience with a Bachelor’s degree in Computer Engineering, Computer Science, Information Technology, High Performance Computing, Analytics, Artificial Intelligence, Electrical Engineering, Aerospace Engineering, Civil Engineering or related Engineering Field.</li><li>7 years of related experience with a Masters’ degree in Computer Engineering, Computer Science, Information Technology, High Performance Computing, Analytics, Artificial Intelligence, Electrical Engineering, Aerospace Engineering, Civil Engineering or related Engineering Field.</li><li>4 years of related experience with a Ph.D. in Computer Engineering, Computer Science, Information Technology, High Performance Computing, Analytics, Artificial Intelligence, Electrical Engineering, Aerospace Engineering, Civil Engineering or related Engineering Field.<br/><br/></li></ul><strong>U.S. Citizenship Requirements<br/><br/></strong>Not Applicable<br/><br/><strong>Clearance Type Required<br/><br/></strong>Candidates must be able to obtain and maintain an active security clearance.<br/><br/><strong>Benefits At GTRI<br/><br/></strong>Comprehensive information on currently offered GTRI benefits, including Health &amp; Welfare, Retirement Plans, Tuition Reimbursement, Time Off, and Professional Development, can be found through this link: https://hr.gatech.edu/benefits<br/><br/><strong>Diversity &amp; Inclusion<br/><br/></strong>Diversity &amp; Inclusion (D&amp;I) at Georgia Tech Research Institute aims to enhance the Institute’s mission of solving the world’s most complex technical problems by creating a workforce with a shared appreciation for diversity, raising awareness around inclusiveness, and fostering a sense of belonging and appreciation for all members of our community.<br/><br/><strong>Equal Employment Opportunity<br/><br/></strong>Georgia Tech Research Institute is an Equal Opportunity Employer of individuals with disabilities and protected veterans and actively seeks diversity among its employees. Equal Employment Opportunity is the Law .
      </div>",No Salary Info Found,Data and AI Engineer
Sr.+ Machine Learning Engineer (ML Ops focus),LeaseQuery,12/19/2023,https://www.linkedin.com/jobs/view/3676799377,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Senior Machine Learning Engineer,FanDuel,12/19/2023,https://www.linkedin.com/jobs/view/3787625397,0,https://media.licdn.com/dms/image/D4E0BAQFmXQroJ-4OFQ/company-logo_100_100/0/1689147682137/fanduel_logo?e=2147483647&v=beta&t=EPZngTV6z2gdQUbi0nFNcYqLLQ-tia5vQrhZBFRiaB4,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Fanduel<br/><br/></strong>FanDuel Group (“FanDuel"") is an innovative sports-tech entertainment company that is changing the way consumers engage with their favorite sports, teams, and leagues. The premier gaming destination in the United States, FanDuel consists of a portfolio of leading brands across gaming, sports betting, daily fantasy sports, advance-deposit wagering, and TV/media.<br/><br/>FanDuel has a presence across all 50 states with approximately 17 million customers and 28 retail locations. FanDuel is based in New York with offices in New Jersey, Georgia, California, Oregon, Canada and Scotland.<br/><br/>Its networks FanDuel TV and FanDuel+ are broadly distributed on linear cable television and through its relationships with leading direct-to-consumer over-the-top platforms.<br/><br/>FanDuel is a subsidiary of Flutter Entertainment plc, the world's largest sports betting and gaming operator with a portfolio of globally recognized brands and a constituent of the FTSE 100 index of the London Stock Exchange.<br/><br/><strong>THE ROSTER…<br/><br/></strong>At FanDuel, we give fans a new and innovative way to interact with their favorite games, sports and teams. We’re dedicated to building a winning team and we pride ourselves on being able to make every moment mean more, especially when it comes to your career. So, what does “winning” look like at FanDuel? It’s recognition for your hard-earned results, a culture that brings out your best work—and a roster full of talented coworkers. Make no mistake, we are here to win, but we believe in winning right. That means we’ll never compromise when it comes to looking out for our teammates. From creatives professionals to cutting edge technology innovators, FanDuel offers a wide range of career opportunities, best in class benefits, and the tools to explore and grow into your best selves. At FanDuel, our principle of “We Are One Team” runs through all our offices across the globe, and you can expect to be a part of an exciting company with many opportunities to grow and be successful.<br/><br/><strong>THE POSITION<br/><br/></strong>Our roster has an opening with your name on it<br/><br/>At FanDuel, data is the heartbeat of our organization. As an ML Engineer at FanDuel, you will help us unlock the full potential of our vast amounts of real-time and relational data. You will be asked to provide our business with insight and our customers with world-class personalized experiences. Every click our users make, every bet, every touchdown, every fumble, and every play is fair game for us to turn into a stream of knowledge. Your expertise will be used here to make better and faster decisions – outpacing our competition.<br/><br/>Collaboration is at the core of your role. You’ll be the linchpin between engineering teams working downstream to build out our online application and upstream to land necessary data for feature engineering. You’ll also be working with Data Scientists and Analysts to productionize, analyze, and validate AI powered insights. You will be asked to help organize, model, and present our data as a coherent product and offer it to our stakeholders, providing a common information framework that allows FanDuel to intelligently react to what is happening on the field and in the marketplace.<br/><br/>We are looking for ML Engineers of all skill levels or experienced engineers from other disciplines who may be looking to make the move to a big data environment. If this describes you, read on – we want to hear from you!<br/><br/><strong>THE GAME PLAN<br/><br/></strong>Everyone on our team has a part to play<br/><br/><ul><li>Building multi-layer serving architectures for ML models</li><li>Business intelligence tools (e.g., Tableau, Knime, Looker)</li><li>Data security and privacy (e.g. GDPR, CPP)</li><li>Data governance and data testing frameworks.</li><li>Continuous integration and delivery of production data products</li><li>An inclusive culture that expects excellence and priorities your growth as an engineer and your well-being as a person</li><li>Advance your career within well-defined, skill-based tracks, either as an individual contributor or as a manager – both providing equal opportunities for compensation and advancement</li><li>Apply your experience and intellect as part of an autonomous team with end-to-end ownership of key components of our data architecture.</li><li>Serve as a mentor to more junior engineers not only in cultivating craftsmanship but also in achieving operational excellence – system reliability, automation, data quality, and cost-efficiency.<br/><br/></li></ul>ML engineering is a rapidly changing field – most of all, we’re looking for someone who enjoys experimenting, keeping their finger on the pulse of current data engineering tools, and always thinking about how to do something better.<br/><br/><strong>THE STATS<br/><br/></strong>What we’re looking for in our next teammate  <br/><br/><ul><li>5+ years of relevant experience developing code in one or more core programming languages (Python, Java, etc.)</li><li>1+ Years of experience in deploying ML models under the constraints of scalability, correctness, and maintainability.</li><ul><li>Hands on experience with ML frameworks and libraries (Scikit-learn, Pytorch, Tensorflow, LightGBM, Keras, etc.)</li></ul><li>3+ Years of experience designing and building various software architecture.</li><ul><li>Deep understanding and knowledge of data structures and software engineering principles</li></ul><li>2+ Years of experience demonstrating technical leadership working with teams, owning projects, defining, and setting technical direction for projects.</li><li>Experience with one or more relevant tools (Flink, Spark, Sqoop, Flume, Kafka, Amazon Kinesis)</li><li>Ability to share findings in easy to consume formats, whether that is through dashboards or data modeling.</li><li>Conduct regular design process reviews and ensure development standards within the team.</li><li>Working with leadership to drive adoption of ML solutions to product engineering teams.</li><li>Experience working in a cloud environment such as AWS, GCP, Azure.</li><li>Experience with Databricks is a plus, their unity catalog, another plus.</li><li>Designing and building data pipelines for production level ML infrastructure.</li><li>Motivate junior engineers on best practices and latest industry design patterns.<br/><br/></li></ul><strong>Player Benefits<br/><br/></strong>We treat our team right<br/><br/>From our many opportunities for professional development to our generous insurance and paid leave policies, we’re committed to making sure our employees get as much out of FanDuel as we ask them to give. Competitive compensation is just the beginning. As part of our team, you can expect:<br/><br/><ul><li>An exciting and fun environment committed to driving real growth</li><li>Opportunities to build really cool products that fans love</li><li>Mentorship and professional development resources to help you refine your game</li><li>Be well, save well and live well - with FanDuel Total Rewards your benefits are one highlight reel after another<br/><br/></li></ul>FanDuel is an equal opportunities employer and we believe, as one of our principal states, “We Are One Team!” We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, Veteran status, or another other characteristic protected by state, local or federal law. We believe FanDuel is strongest and best able to compete if all employees feel valued, respected, and included. We want our team to include diverse individuals because diversity of thought, diversity of perspectives, and diversity of experiences leads to better performance. Having a diverse and inclusive workforce is a core value that we believe makes FanDuel stronger and more competitive as One Team!<br/><br/>
</div>",No Salary Info Found,Data and AI Engineer
Distinguished Data Scientist (Search & Personalization),The Home Depot,12/19/2023,https://www.linkedin.com/jobs/view/3789769207,0,https://media.licdn.com/dms/image/C4E0BAQHzR2llYqUBtg/company-logo_100_100/0/1630656428961/the_home_depot_logo?e=2147483647&v=beta&t=NH5wv1AXmlH4oUpVAOaSorm4nU1y-uttFDDEbY5Veps,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Position Purpose<br/><br/></strong>The Distinguished Data Scientist is responsible for leading cutting-edge research for developing advanced analytics modeling techniques and complex algorithms. This role promotes the innovative application of data science techniques and methodologies across the company and leads large portfolios of data science projects. Distinguished Data Scientists focus on seeking out business opportunities to leverage data science as a competitive advantage for Home Depot.<br/><br/>As a Distinguished Data Scientist, you will provide thought leadership and establish a technical strategy for advanced analytics. This role is expected to contribute to Home Depot's intellectual property by developing cutting-edge, innovative algorithms. Distinguished Data Scientists support the building of skilled and talented data science teams by attracting top talent and developing skills of team members. In addition, this role network with experts, both academic and industry, to further the application of data science to business problems.<br/><br/><strong>Key Responsibilities<br/><br/></strong><ul><li>20% Business Collaboration - Leverage extensive business knowledge into solution approach; Effectively develop trust and collaboration with internal customers and cross-functional teams; Actively seek out new business opportunities to leverage data science as a competitive advantage; Deep understanding of IT needs for the team to be successful in tackling business problems; Provide general education on advanced analytics to technical and non-technical business partners</li><li>15% Project Management &amp; Team Support - Support recruiting and hiring efforts for the team; Collaborate with managers and team in the distribution of workload and resources; Provide mentoring and coaching to more junior roles to support their technical competencies; Provide direction on prioritization of work and ensure quality of work; Serve as a technical subject matter expert (SME) for one or more data science methods, both predictive and prescriptive; Work with project teams and business partners to determine project goals</li><li>15% Solution Development - Effectively communicate insights and recommendations to both technical and non-technical leaders and business customers/partners; Test alternative methodology and cutting-edge algorithms on business problems to deliver even better solutions and recommendations; Clearly communicate impacts of recommendations to drive alignment and appropriate implementation; Provide thought leadership when designing and developing algorithms and models to use against large datasets to create business insights; Make appropriate selection, utilization and interpretation of advance analytical methodologies</li><li>50% Technical Exploration &amp; Development - Be a thought leader within Home Depot in one or more Prescriptive Modeling techniques like optimization, computer vision, recommendation, search or NLP; Demonstrate and share technical expertise by attending conferences, speaking events and publishing papers; Lead networks of both academic and industry experts to further the application of data science to business problems; Develop cutting-edge, innovative algorithms that would serve as Intellectual Property for Home Depot; Lead the continuous improvement of data science and analytics by developing replicable solutions (for example, codified data products, project documentation, process flowcharts) to ensure solutions are leveraged for future projects; Define best practices and develop clear vision for data analysis and model productionalization; Seek further knowledge on key developments within data science, technical skill sets, and additional data sources<br/><br/></li></ul><strong>Direct Manager/Direct Reports<br/><br/></strong><ul><li>This position typically reports to the Director or above</li><li>This position has 0 Direct Reports<br/><br/></li></ul><strong>Travel Requirements<br/><br/></strong><ul><li>Typically requires overnight travel 5% to 20% of the time.<br/><br/></li></ul><strong>Physical Requirements<br/><br/></strong><ul><li>Most of the time is spent sitting in a comfortable position and there is frequent opportunity to move about. On rare occasions there may be a need to move or lift light articles.<br/><br/></li></ul><strong>Working Conditions<br/><br/></strong><ul><li>Located in a comfortable indoor area. Any unpleasant conditions would be infrequent and not objectionable.<br/><br/></li></ul><strong>Minimum Qualifications<br/><br/></strong><ul><li>Must be eighteen years of age or older.</li><li>Must be legally permitted to work in the United States.</li><li>Thought leadership in predictive modeling, data mining and data</li><li>Mastery utilizing statistical techniques to identify key insights that help solve business problems<br/><br/></li></ul><strong>Preferred Qualifications<br/><br/></strong><ul><li>Working knowledge of Microsoft Office Suite</li><li>Working knowledge of Tableau</li><li>Working knowledge of presentation software (e.g., Microsoft PowerPoint)</li><li>PhD in a quantitative field (Computer Science, Math, Statistics, etc.) or equivalent work experience.</li><li>10+ years of experience in business intelligence and analytics</li><li>Expertise in a modern scripting language (preferably Python)</li><li>Expertise running queries against data (preferably with Google BigQuery or SQL)</li><li>Advanced knowledge of Microsoft Office Suite</li><li>Expertise with data visualization software (preferably Tableau)</li><li>Thought leadership in Prescriptive Modeling like optimization, computer vision, recommendation, search or NLP</li><li>Track record of teaching, mentoring, growing and advising other data science experts inside and outside of the organization</li><li>Professionally recognized by peers and leaders in the organization for significant expertise within Data Science<br/><br/></li></ul><strong>Minimum Education<br/><br/></strong><ul><li>The knowledge, skills and abilities typically acquired through the completion of a doctoral program in a field related to the job.<br/><br/></li></ul><strong>Preferred Education<br/><br/></strong><ul><li>No additional education<br/><br/></li></ul><strong>Minimum Years Of Work Experience<br/><br/></strong><ul><li>10<br/><br/></li></ul><strong>Preferred Years Of Work Experience<br/><br/></strong><ul><li>No additional years of experience<br/><br/></li></ul><strong>Minimum Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Preferred Leadership Experience<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Certifications<br/><br/></strong><ul><li>None<br/><br/></li></ul><strong>Competencies<br/><br/></strong><ul><li>Business Insights</li><li>Drives Vision and Purpose</li><li>Persuades</li><li>Self-Development</li><li>Tech Savvy</li><li>Attracts Top Talent</li><li>Cultivates Innovation</li><li>Instills Trust</li><li>Optimizes Work Processes</li><li>Builds Network</li><li>Communicates Effectively</li><li>Develops Talent</li><li>Strategic Mindset</li></ul>
</div>",No Salary Info Found,Data and AI Engineer
AI Chatbot Developer  Atlanta GA (Hybrid),Tek Hire Solutions,12/19/2023,https://www.linkedin.com/jobs/view/3788170152,0,https://media.licdn.com/dms/image/D560BAQEBr1_4ACtFkw/company-logo_100_100/0/1665561740867?e=2147483647&v=beta&t=_hcD-f0ZST209sXxXXr_TE4sbvq_p124soR6UKW7dUE,"Atlanta, GA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Title: AI Chatbot Developer <br/><br/></strong><strong>Location: Atlanta GA (Hybrid)<br/><br/></strong><strong>Responsibilities<br/><br/></strong><ul><li>Develop, train, and fine-tune generative AI models using appropriate algorithms for natural language processing.</li><li>Implement preprocessing of data with Large Language Models (LLMs) to understand contexts and patterns, enhancing the accuracy and relevance of generated content.</li><li>Design prompts for LLM models, ensuring clear and effective instructions to generate contextually relevant and coherent text.</li><li>Collaborate with cross-functional teams to understand business requirements and integrate AI chatbot solutions into various applications and platforms.</li><li>Stay updated on the latest advancements in AI and machine learning technologies, applying this knowledge to enhance chatbot capabilities.</li><li>Troubleshoot and optimize chatbot performance, addressing issues related to model outputs, response accuracy, and user interactions.</li><li>Work closely with stakeholders to gather feedback, iterate on models, and continuously improve the overall user experience.</li><li>Ensure the security and privacy of user data by implementing robust data protection measures within the chatbot architecture.</li><li>Collaborate with UX/UI designers to enhance the user interface and overall user experience of the AI chatbot.</li><li>Document development processes, model architectures, and codebase to maintain clear and comprehensive records.<br/><br/></li></ul><strong>Primary Skill Set<br/><br/></strong><ul><li>Proficiency in developing and fine-tuning generative AI models, utilizing algorithms for natural language processing.</li><li>Experience with preprocessing data using Large Language Models (LLMs) to enhance contextual understanding.</li><li>Strong knowledge of prompt design for LLM models to guide the generation of coherent and relevant text.</li><li>Programming proficiency in languages such as Python, Java, or similar for AI model development.</li><li>Familiarity with chatbot frameworks and platforms, such as Dialogflow, Rasa, or similar.</li><li>Understanding of UX/UI principles for designing effective and user-friendly chatbot interfaces.</li><li>Problem-solving skills and the ability to troubleshoot and optimize AI chatbot performance.</li><li>Excellent communication and collaboration skills for working with cross-functional teams and stakeholders.</li><li>Continuous learning mindset to stay updated on advancements in AI and machine learning technologies.<br/><br/></li></ul>This role offers an exciting opportunity for a skilled AI Chatbot Developer to contribute to the development and enhancement of cutting-edge conversational AI solutions.<br/><br/>Tekhire Solutions is a world-class technology focused on customer-driven solutions and has a deep dive knowledge of client requirements. Tekhire is best in connecting a bridge between highly skilled workers and the Fortune 500. Always thrives to be up with the technology trends, Innovation and transforms our trusted clients with certified and enterprise solutions that makes difference in the business.
      </div>",No Salary Info Found,Data and AI Engineer
Mid level Data Scientist,HireMeFast LLC - Career Accelerator - Land A Job,12/25/2023,https://www.linkedin.com/jobs/view/3793404157,0,https://media.licdn.com/dms/image/D4E0BAQEyjD-Ph-TGQQ/company-logo_100_100/0/1701610059693?e=2147483647&v=beta&t=mhsnt1Z9NISRb3qPPvbOzdCHt8afRrLALubmCPZGOSs,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong> Job Title:</strong> Mid level Data Scientist<br/><br/><strong> Employment Type:</strong> Full-Time<br/><br/><strong> Salary:</strong> $90,000 - $100,000 per annum<br/><br/><strong> Experience Required: </strong> Minimum 2-3 years of project experience<br/><br/><strong>About us: </strong>HireMeFast is a leading staffing and recruitment agency specializing in connecting businesses with top-tier talent across various industries. Our mission is to bridge the gap between exceptional candidates and organizations needing their skills, expertise, and unique qualities. Our team of experienced and dedicated recruitment specialists utilizes innovative sourcing strategies, and a vast network to identify and attract top talent. We conduct comprehensive procedures to ensure that only the most qualified candidates are presented to our clients.<br/><br/><strong>Position Summary<br/><br/></strong>You will collaborate with team members leveraging the agile methodology to work on innovative and complex solutions with the use of Machine Learning and statistical analysis. Under general direction, you will develop models using Machine Learning, Deep Learning, and other similar technologies to predict and analyze data on hardware and software systems within a large server infrastructure to prevent outages and pinpoint errors. Independently support processes related to the implementation of systems into production, including integration of purchased solutions. Responsible for design, coding, testing, debugging, and documentation.<br/><br/><ul><li>Team Player: Willing to teach, share knowledge, and work with others to make the team successful. </li><li>Communication: Exceptional verbal, written, organizational, presentation, and communication skills. </li><li>Creativity: Ability to take written and verbal requirements and come up with other innovative ideas. </li><li>Attention to detail: Systematically and accurately research future solutions and current problems. </li><li>Strong work ethic: The innate drive to do work extremely well. </li><li>Passion: A drive to deliver better products and services than expected to customers. <br/><br/></li></ul><strong>Essential Qualifications<br/><br/></strong><ul><li>2+ years of experience in machine learning with domain knowledge and experience in the following areas: data-driven statistical modeling, discrimination methods, feature extraction and analysis, supervised learning. </li><li>2+ years of experience with a programming language such as Python, R, SQL, etc. </li><li>2+ years of experience with data extraction, wrangling, visualization, and analysis. </li><li>Experience processing data from various sources and via big data platforms (such as GCP, AWS, etc.) </li><li>Experience creating scalable machine learning models and solutions. </li><li>Experience researching and implementing statistical models, machine learning algorithms or other customized solutions that show significant impact on solving complex business problems. </li><li>Experience enhancing existing data pipelines by exploring unstructured data sources and engineering new features. </li><li>Can provide technical support and expertise to the broader team. </li><li>Master’s degree or greater in Statistics, Mathematics, Computer Science or other quantitative field; or equivalent working experience </li><li>Knowledge of Machine Learning, Data Mining, Statistics, Applied Mathematics, or a related field. <br/><br/></li></ul><strong>Education<br/><br/></strong>Bachelor's degree in Data Science, Statistics, Mathematics, Computer Science or other quantitative field.<br/><br/><strong>Benefits<br/><br/></strong><ul><li>401(k) </li><li>Dental insurance </li><li>Disability insurance </li><li>Employee discount </li><li>Employee stock purchase plan </li><li>Health insurance </li><li>Life insurance </li><li>Paid time off </li><li>Store discount </li><li>Tuition reimbursement </li><li>Vision insurance <br/><br/></li></ul><strong>Why HireMeFast LLC?<br/><br/></strong>At HireMeFast, we understand that finding the right individuals to join your team is crucial for success and growth of your organization. We are committed to streamlining the hiring process for our clients, ensuring they have access to a diverse pool of highly qualified candidates who are a perfect fit for their specific needs.<br/><br/>
</div>",$90000- $100000,Data and AI Engineer
Entry-Level Data Scientist Engineer  (US),Patterned Learning Career,12/23/2023,https://www.linkedin.com/jobs/view/3792710569,0,https://media.licdn.com/dms/image/D4D0BAQGaHaR8NJdTNA/company-logo_100_100/0/1702321277719/patterned_learning_ai_career_logo?e=2147483647&v=beta&t=O1x4uQGAgo3QG6K7tOhb6yIeEJo4nKewDo8Dd6krT3I,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        This is a remote position.<br/><br/><strong><strong>Entry-Level Data Scientist Engineer </strong>(US) - Remote Job, 1+ Year Experience<br/><br/></strong><strong>Annual Income:</strong> $65K - $77K<br/><br/><strong>About us:</strong> Patterned Learning is a platform that aims to help developers code faster and more efficiently. It offers features such as collaborative coding, real-time multiplayer editing, and the ability to build, test, and deploy directly from the browser. The platform also provides tightly integrated code generation, editing, and output capabilities.<br/><br/>Skills and Abilities:<br/><br/><ul><li>Strong knowledge of R or Python for data analysis and modeling. </li><li>Proficiency in statistical programs such as R, SAS, MATLAB, or Python. </li><li>Familiarity with spreadsheets (VBA) and database applications (Access, Oracle, SQL, or equivalent technology). </li><li>Basic understanding of SQL, Javascript, XML, JSON, and HTML. </li><li>Ability to learn new methods quickly and work under deadlines. </li><li>Excellent teamwork and communication skills. </li><li>Strong analytical and problem-solving abilities. </li><li>Basic understanding of SQL, Javascript, XML, JSON, and HTML. <br/><br/></li></ul>Preferred:<br/><br/><ul><li>Knowledge of actuarial concepts and life, health, and/or annuity products. </li><li>Experience with statistical modeling techniques such as GLM, Decision Trees, Time Series, Regression, etc. </li><li>Familiarity with Microsoft DeployR. </li><li>Exposure to insurance risk analysis. </li><li>Basic experience in computational finance, econometrics, statistics, and math. </li><li>Knowledge of SQL and VBA. </li><li>Familiarity with R or Python for predictive modeling <br/><br/></li></ul><strong>Why Patterned Learning LLC?<br/><br/></strong>Patterned Learning can provide intelligent suggestions, automate repetitive tasks, and assist developers in writing code more effectively. This can help reduce coding errors, improve productivity, and accelerate the development process.<br/><br/>The pattern recognition is particularly relevant in the context of coding. Neural networks, especially deep learning models, are commonly employed for pattern detection and classification tasks. These models simulate human decision-making and can identify patterns in data, making them well-suited for tasks like code analysis and generation.<br/><br/>
</div>",$65- $77,Data and AI Engineer
"AI Prompt Engineer, gt.school (Remote) - $100,000/year USD",Crossover,12/22/2023,https://www.linkedin.com/jobs/view/3788456152,0,https://media.licdn.com/dms/image/C4E0BAQG8bdX5sQ24KQ/company-logo_100_100/0/1630619679689/crossover__logo?e=2147483647&v=beta&t=AJ9DucsHoIHoUUgwhW_19OT-eD9gGHi87WYzH7bHcnU,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Crossover is the world's #1 source of full-time remote jobs. Our clients offer top-tier pay for top-tier talent. We're recruiting this role for our client, gt.school. Have you got what it takes?<br/><br/>At gt.school, we're not just reimagining education; we're actively reinventing it. Leveraging state-of-the-art AI technology, we're on a mission to redefine the learning experience, making it faster, more fun, and highly personalized. Our platform is designed to push the boundaries of traditional education, offering a digital, self-paced learning environment that's both engaging and effective. As a member of our vibrant team, you'll contribute to the development of revolutionary AI-driven products and services that are transforming how students learn and grow on a global scale.<br/><br/>We're currently on the lookout for an innovative AI Engineer to enhance our core AI Engineering team. Collaborating closely with our Academic Engineers, AI Operations, and Program Operations teams, you'll be at the forefront of AI research and development, prompt engineering, and a mix of strategic technical and non-technical initiatives. Your role is crucial in advancing the academic impact of our AI tools, which are central to the learning journey of thousands of students enrolled in our programs worldwide.<br/><br/>In this role, you'll not only contribute to our groundbreaking work but also grow and develop your skills. You'll receive mentorship and coaching from the Vice President of AI Engineering &amp; Operations at gt.school, and work alongside three supportive sister teams. This environment is ripe with opportunities for professional growth and learning.<br/><br/>To succeed in this role, you’ll need to be ownership-minded, consistently make good data-backed decisions, be attentive to detail, always have a high quality bar for work, and be an extremely strong communicator).<br/><br/>If you're eager to take on a challenging and fulfilling role that's at the cutting edge of reshaping education, gt.school is your destination. Join us in our quest to create a future where the potential for learning is limitless!<br/><br/><strong>What You Will Be Doing<br/><br/></strong><ul><li>Designing, developing, and refining prompts that are used to either produce educational content or build our core data models.</li><li>Building scalable, automated workflows that produce AI educational content.</li><li>Building prototypes weekly that the team’s VP will present to executive leadership.</li><li>Actively engaging in thought leadership about how we could innovate in terms of work processes, AI content, and more.</li><li>Staying up to date with respect to the latest advancements with AI.</li><li>Owning the timely delivery of AI content generators and respective backing documentation, partially by delegating work to supporting sister teams.</li><li>Actively collaborating with our AI Operations &amp; Academic Engineering teams to ensure AI-generated content aligns with our core data structures and curriculum standards.<br/><br/></li></ul><strong>Basic Requirements<br/><br/></strong><strong>AI Prompt Engineer key responsibilities<br/><br/></strong><ul><li>Substantial experience working with generative AI models, like GPT-4, meaning you understand many of the nuances, limitations, pitfalls, and best practices of working with AI.</li><li>Scored 5s on APs (Advanced Placement Exams) &amp; 1500+/2300+ on SAT or 34+ on ACT exams in high school</li><li>Bachelors in Computer Science in Computer Science, AI, Machine Learning, or a related field</li><li>Able to, Mon-Fri, attend a daily Stand-Up Zoom meeting at 9AM CST daily and commit to an 8 hour shift anytime of the worker’s choice between 5 AM and 5 PM CST.<br/><br/></li></ul><strong>About Gt.school<br/><br/></strong>GT School is an EdTech Startup that leverages technology, AI, and subject matter experts to cultivate a new way of learning. Our unique approach leverages 50+ years of learning science, cutting-edge data analytics and high-performance coaching. In doing so, we can help students learn more, learn faster, and learn better - and have fun while doing it. We are a remote-first company that hires globally via Crossover.<br/><br/>There is so much to cover for this exciting role, and space here is limited. Hit the Apply button if you found this interesting and want to learn more. We look forward to meeting you!<br/><br/><strong>Working with Crossover<br/><br/></strong>This is a full-time (40 hours per week), long-term position. The position is immediately available and requires entering into an independent contractor agreement with Crossover. The compensation level for this role is $50 USD/hour, which equates to $100,000 USD/year assuming 40 hours per week and 50 weeks per year. The payment period is weekly. Consult www.crossover.com/help-and-faqs for more details on this topic.<br/><br/><strong>What to expect next:<br/><br/></strong><ul><li>You will receive an email with a link to start your self-paced, online job application.</li><li>Our hiring platform will guide you through a series of online “screening” assessments to check for basic job fit, job-related skills, and finally a few real-world job-specific assignments.<br/><br/></li></ul><strong>Important!</strong> If you do not receive an email from us:<br/><br/><ul><li>First, emails may take up to 15 minutes to send, refresh and check again.</li><li>Second, check your spam and junk folders for an email from Crossover.com, mark as “Not Spam” since you will receive other emails as well.</li><li>Third, we will send to whatever email account you indicated on the Apply form - by default, that is the email address you use as your LinkedIn username and it might be different than the one you have already checked.</li><li>If all else fails, just reset your password by visiting https://www.crossover.com/auth/password-recovery if you already applied using LinkedIn EasyApply.<br/><br/></li></ul>Crossover Job Code: LJ-5070-US-Phoenix-AIPromptEngine.019<br/><br/>
</div>",$50- $100000,Data and AI Engineer
Solutions Architect AI/ML - Remote - USA,FullStack Labs,12/22/2023,https://www.linkedin.com/jobs/view/3761317667,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"Principal Software Engineer/Architect - Golang, AWS, Docker",CyberCoders,12/22/2023,https://www.linkedin.com/jobs/view/3759538869,0,https://media.licdn.com/dms/image/C560BAQF7t9X4k2P2hA/company-logo_100_100/0/1630672294143/cybercoders_logo?e=2147483647&v=beta&t=svLLpBE8gsgu2VaDigkqM3UEMeVyCIhMQEUzznif85w,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Are you a Principal/Staff level Software Engineer with hands on experience working with Golang microservices? Are you excited when you're building highly scaled and distributed cloud-based architecture? If so you may want to look at this....<br/><br/>We are a well-established SaaS software company working to build the next generation of video surveillance solutions with an AI-driven engine working to provide analytics to our customer's security needs. Our solutions help ensure that our customers have a simplified method to understanding their needs when it comes to protecting their company's assets and having the ability to scale to their growing business needs. As we continue to build and expand on our AI-driven solutions, we are looking to bring on a Principal Golang Engineer/Architect to help design and scale our back end microservices.<br/><br/>Top Reasons to Work with Us<br/><br/><ul><li> Fully established company with the backing of a Fortune 500 parent company</li><li> WORK FULLY REMOTE! (We are based on West Coast so mostly Pacific hours)</li><li> We keep a startup mentality with our software development process<br/><br/></li></ul>What You Will Be Doing<br/><br/><ul><li> Collaborate with cross-functional product and engineering teams to determine the scope and direction of new feature releases</li><li> Create innovative data structure solutions to improve on the platform's ability to process and organize data</li><li> Oversee junior and senior engineers on development process to ensure timely delivery of sprint releases</li><li> Work closely with DevOps/SRE teams to determine best design for cloud-based microservices<br/><br/></li></ul>What You Need for this Position<br/><br/>The Principal Software Architect/Engineer must have at least 10+ years of software development experience and be familiar with:<br/><br/><ul><li> 8+ Years of proven experience working hands on with microservices architecture</li><li> Hands on experience working with Golang architecture (we also use Python, but Golang is our primary stack)</li><li> Solid background working with AWS or GCP Cloud environments</li><li> Knowledge of bucket and container services such as Docker</li><li> Experience with modern CI/CD principles and working with REST API integrations</li><li> Bachelor's Degree in Computer Science or related field<br/><br/></li></ul><strong>Nice To Have<br/><br/></strong><ul><li> Industry background working with AI or ML models</li><li> Master's Degree<br/><br/></li></ul>What's In It for You<br/><br/><ul><li> Competitive Compensation Package ($160,000 - $220,000/year)</li><li> Vacation/PTO</li><li> Medical/Dental/Vision</li><li> BONUS OPPORTUNITIES (5-10+%)</li><li> FULLY REMOTE WORK (we are based on Pacific Time)<br/><br/></li></ul><strong>Benefits<br/><br/></strong><ul><li> Vacation/PTO</li><li> Medical</li><li> Dental</li><li> Vision</li><li> Bonus: 5-12%<br/><br/></li></ul>So, if you are a Principal Software Engineer/Architect with experience, please apply today!<br/><br/>Colorado employees will receive paid sick leave. For additional information about available benefits, please contact Daniel OKeefe<br/><br/><strong>Email Your Resume In Word To<br/><br/></strong>Looking forward to receiving your resume through our website and going over the position with you. Clicking apply is the best way to apply, but you may also:<br/><br/>Daniel.OKeefe@cybercoders.com<br/><br/><ul><li>Please do NOT change the email subject line in any way. You must keep the JobID: linkedin : DO2-1773149L731 -- in the email subject line for your application to be considered.***<br/><br/></li></ul>Daniel OKeefe - Sr. Executive Recruiter - CyberCoders<br/><br/>Applicants must be authorized to work in the U.S.<br/><br/><strong>CyberCoders is proud to be an Equal Opportunity Employer<br/><br/></strong>All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, national origin, disability, protected veteran status, or any other characteristic protected by law.<br/><br/><strong>Your Right to Work</strong> – In compliance with federal law, all persons hired will be required to verify identity and eligibility to work in the United States and to complete the required employment eligibility verification document form upon hire.<br/><br/>
</div>",$160000- $220000,Data and AI Engineer
"Sr. Product Marketing Manager, Machine Learning & Developer GTM",Elastic,12/21/2023,https://www.linkedin.com/jobs/view/3758752398,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Data Science Gen AI - Solution Specialist,Deloitte,12/20/2023,https://www.linkedin.com/jobs/view/3743050912,0,https://media.licdn.com/dms/image/C560BAQGNtpblgQpJoQ/company-logo_100_100/0/1662120928214/deloitte_logo?e=2147483647&v=beta&t=KhIfaHWyu1aAgyyImEhYDprMjFP3LaMR0E7NF2MPxMY,"Gilbert, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Are you an experienced, passionate pioneer in technology - a solutions builder, a roll-up-your-sleeves technologist who wants a daily collaborative environment, think-tank feel and share new ideas with your colleagues - without the extensive demands of travel? If so, consider an opportunity with our US Delivery Center - we are breaking the mold of a typical Delivery Center.<br/><br/>Our US Delivery Centers have been growing since 2014 with significant, continued growth on the horizon. Interested? Read more about our opportunity below ...<br/><br/><strong>Work you'll do<br/><br/></strong>The Generative AI Engineer will, as part of several client delivery teams, be responsible for developing, designing, and maintaining cutting-edge AI-based systems, ensuring smooth and engaging user experiences. Additionally, the Generative AI Engineer will participate in a wide variety of Natural Language Processing activities, including refining and optimizing prompts to improve the outcome of Large Language Models (LLMs), and code and design review. The kinds of activities performed by the Prompt Engineer will also include, but not be limited to:<br/><br/><ul><li>Working across client teams to develop and architect Generative AI solutions using ML and GenAI</li><li>Developing and promoting standards across the community</li><li>Evaluating and selecting appropriate AI tools and machine learning models for tasks, as well as building and training working versions of those models using Python and other open-source technologies</li><li>Working with leadership and stakeholders to identify AI opportunities and promote strategy</li><li>Developing and conducting trainings for users across the Government &amp; Public Services landscape on principles used to develop models and how to interact with models to facilitate their business processes</li><li>Building and prioritizing backlog for future machine-learning enabled features to support client business processes<br/><br/></li></ul><strong>The Team</strong>Artificial Intelligence &amp; Data Engineering<br/><br/>In this age of disruption, organizations need to navigate the future with confidence, embracing decision making with clear, data-driven choices that deliver enterprise value in a dynamic business environment.<br/><br/>The Artificial Intelligence &amp; Data Engineering team leverages the power of data, analytics, robotics, science and cognitive technologies to uncover hidden relationships from vast troves of data, generate insights, and inform decision-making. Together with the Strategy practice, our Strategy &amp; Analytics portfolio helps clients transform their business by architecting organizational intelligence programs and differentiated strategies to win in their chosen markets.<br/><br/>Artificial Intelligence &amp; Data Engineering will work with our clients to:<br/><br/><ul><li>Implement large-scale data ecosystems including data management, governance and the integration of structured and unstructured data to generate insights leveraging cloud-based platforms</li><li>Leverage automation, cognitive and science-based techniques to manage data, predict scenarios and prescribe actions</li><li>Drive operational efficiency by maintaining their data ecosystems, sourcing analytics expertise and providing As-a-Service offerings for continuous insights and improvements<br/><br/></li></ul><strong>Qualifications<br/><br/></strong>Required:<br/><br/><ul><li>3+ years of experience programming in Python or R</li><li>2+ years of experience with Natural Language Processing (NLP) and Large Language Models (LLM) 2+ years of experience building and maintaining scalable API solutions</li><li>2+ years of experience designing solutions to address client requirements</li><li>3+ years of experience with the design and implementation (building, containerizing, and deploying end to end automated data and ML pipelines) of automated cloud solutions</li><li>3+ years of experience in developing algorithms using data science technologies to build analytical models</li><li>3+ years of data extraction/manipulation experience using scripts specific to AI/ML</li><li>3+ years of modeling experience using a variety of regression and supervised and unsupervised learning techniques.</li><li>3+ years of experience in data wrangling/cleansing, statistical modeling, and programming</li><li>3+ years of extensive experience working in an Agile development environment</li><li>3+ years of experience for fluency in both structured and unstructured data (SQL, NOSQL)</li><li>3+ years of production experience with Apache Spark</li><li>3+ years of hands-on experience with web APIs, CI/CD for ML, and Serverless Deployment</li><li>2+ years of experience with presentation and data analysis software such as: SAS, R, SPSS, MATLAB, QlikView, Excel and Access</li><li>1+ years of experience to have familiarity with Linux OS and Windows servers</li><li>1+ years of experience to have knowledge of Docker, Jenkins, Kubernetes, and other DevOps tools</li><li>Must be legally authorized to work in the United States without the need for employer sponsorship, now or at any time in the future</li><li>Must live near, or relocate to, the Lake Mary, FL; Gilbert, AZ; or Mechanicsburg, PA areas</li><li>Must be in your designated office location 10%-30% throughout the year</li><li>Ability to travel up to 10%, on average, based on the work you do and the clients and industries/sectors you serve</li><li>Bachelor's degree, preferably in Computer Sciences, Information Technology, Computer Engineering, or related IT discipline; or equivalent experience<br/><br/></li></ul>Preferred:<br/><br/><ul><li>Previous Government Consulting and/or professional services experience</li><li>In depth understanding of AI protocols and standards</li><li>Understanding of technology risks and the ability to assess and mitigate them</li><li>Deep knowledge of a specific domain or industry, with a focus on applying NLP/LLM solutions in that context</li><li>Experience with debugging and troubleshooting software or solutions design issues</li><li>Proven ability to stay current with best practices and new technology solutions in the field</li><li>Ability to display both breadth and depth of knowledge regarding functional and technical issues</li><li>Experience presenting to clients or other decision makers to present and sell ideas to various audiences (technical and non-technical)</li><li>Certification from any of the three major cloud platforms (AWS / Azure / GCP) in Cloud Architecture / Engineering / DevOps / ML.</li><li>Familiarity with Kubeflow or MLflow</li><li>Experience with machine learning pipelines (Azure ML)</li><li>Familiarity with the latest Natural Language Processing or Computer Vision related algorithms</li></ul>
</div>",No Salary Info Found,Data and AI Engineer
"PEPI Lead Developer – Back End, Generative AI – Customer Success (Open to All US Locations)",Alvarez & Marsal,12/20/2023,https://www.linkedin.com/jobs/view/3771051798,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Data Scientist/Engineer - Junior,SynergisticIT,12/19/2023,https://www.linkedin.com/jobs/view/3784400083,0,https://media.licdn.com/dms/image/C560BAQHPrA2XO9lh7g/company-logo_100_100/0/1663564885547/synergisticit_logo?e=2147483647&v=beta&t=biDnkXeeFcJXgnh87P53V9KGn6j1mqUOEQpisfcfR74,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        At SynergisticIT, we're all about making connections. Whatever IT goals you have, our software programmers can help achieve those. Our Software development teams can take up turnkey projects and execute them in an effective and efficient manner. If you are looking to source talent our recruiters will find the ideal IT talent for your company. What's the secret to our success? Well, it all starts with taking quality time to listen to each client's specific needs. After we have a thorough grasp of your IT goals, we can better customize our Developments as per your specific needs. We can also tailor make recruiting programs to exceed your expectations. Since our founding in 2010, SynergisticIT's strategies have earned the company an enviable position in the software development, IT staffing and IT skill enhancement fields. SynergisticIT continues to work with hundreds of satisfied American clients with our software programmers working on our projects and after gaining hands on experience on cutting edge technologies moving to contribute their skills to great clients like Apple, Google, Client, Ebay, Paypal, Kroger, the Walt Disney Company and hundreds more. If you are tired of working with inefficient programmers who take a lot of time to ramp up we want you to try us. Our software programmers can hit the ground running and get you the maximum return on your investment. You have already tried the rest its time you tried the best. SynergisticIT - Home of the Best Data Scientists and Software Programmers in the Bay Area.<br/><br/><strong> Why Us ? <br/><br/></strong>SynergisticIT has a proven track record of successfully skill enhancement and staffing IT employees for some of the world's most iconic brands. Our team takes the time to fully understand every client's needs so we could best meet your IT staffing requirements. The knowledgeable staff at SynergisticIT is always more than happy to work with clients to ensure they reach their software development goals. Besides staffing, SynergisticIT is also committed to helping young IT professionals advance their career with a robust upskill program . Everyone who goes through SynergisticIT's program learns all the skills necessary to succeed in many IT fields ranging from Java to Machine Learning. Additionally, everyone trained at SynergisticIT has been through extensive mock and technical interview screenings to bolster their career prospects. Last, but certainly not least, SynergisticIT takes great care to respect the privacy considerations for every client. All companies who work with SynergisticIT can rest assured their confidential data is protected using the most up-to-date encryption technologies. SynergisticIT also complies with all the latest NDA agreements.<br/><br/><strong> REQUIRED SKILLS For Java /Software Programmers <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, Time series analysis <br/><br/></strong><strong> We regularly interact with the Top Tech companies to give our candidates a competitive advantage-Please see us exhibiting at Oracle Cloud world /Oracle Java one (Las vegas) -2022 and at Gartner Data Analytics Summit (Florida)-2023 <br/><br/></strong>Oracle CloudWorld Event (OCW) Las Vegas 2022 | SynergisticIT - YouTube<br/><br/><strong> https://www.youtube.com/watch?v=OAFOhcGy9Z8 <br/><br/></strong><strong> https://www.youtube.com/watch?v=EmO7NrWHkLM <br/><br/></strong><strong> https://www.youtube.com/watch?v=NVBU9RYZ6UI <br/><br/></strong><strong> https://www.youtube.com/watch?v=Yy74yvjatVg <br/><br/></strong>SynergisticIT at Gartner Data and Analytics Summit 2023 - YouTube<br/><br/>For preparing for interviews please visit <strong> https://www.synergisticit.com/interview-questions/ <br/><br/></strong><strong> We are looking for the right matching candidates for our clients <br/><br/></strong><strong> Please apply via the job posting <br/><br/></strong><strong> REQUIRED SKILLS For Java /Full Stack/Software Programmer <br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Project work on the skills </li><li> Knowledge of Core Java , javascript , C++ or software programming </li><li> Spring boot, Microservices, Docker, Jenkins and REST API's experience </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> For data Science/Machine learning Positions <br/><br/></strong><strong>Required Skills<br/><br/></strong><ul><li> Bachelors degree or Masters degree in Computer Science, Computer Engineering, Electrical Engineering, Information Systems, IT </li><li> Project work on the technologies needed </li><li> Highly motivated, self-learner, and technically inquisitive </li><li> Experience in programming language Java and understanding of the software development life cycle </li><li> Knowledge of Statistics, SAS, Python, Computer Vision, data visualization tools </li><li> Excellent written and verbal communication skills <br/><br/></li></ul><strong> Preferred skills: NLP, Text mining, Tableau, PowerBI, Tensorflow <br/><br/></strong><strong> If you get emails from our skill enhancement team please ask them to take you off their distribution list and make you unavailable as they share the same database with the client servicing team. <br/><br/></strong><strong> No phone calls please. </strong> Shortlisted candidates would be reached out. No third party or agency candidates or c2c candidates
      </div>",No Salary Info Found,Data and AI Engineer
"Systems Engineer, AI Infrastructure",Cloudflare,12/19/2023,https://www.linkedin.com/jobs/view/3725162370,0,https://media.licdn.com/dms/image/C4D0BAQG16gpXzS14DQ/company-logo_100_100/0/1630499898593/cloudflare_logo?e=2147483647&v=beta&t=JnWbIHRMM7IEd6GKOBdDcOcAwe8GlG6X05cH_ptu3Rc,"Phoenix, AZ","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Us<br/><br/></strong>At Cloudflare, we have our eyes set on an ambitious goal: to help build a better Internet. Today the company runs one of the world’s largest networks that powers approximately 25 million Internet properties, for customers ranging from individual bloggers to SMBs to Fortune 500 companies. Cloudflare protects and accelerates any Internet application online without adding hardware, installing software, or changing a line of code. Internet properties powered by Cloudflare all have web traffic routed through its intelligent global network, which gets smarter with every request. As a result, they see significant improvement in performance and a decrease in spam and other attacks. Cloudflare was named to Entrepreneur Magazine’s Top Company Cultures list and ranked among the World’s Most Innovative Companies by Fast Company.<br/><br/>We realize people do not fit into neat boxes. We are looking for curious and empathetic individuals who are committed to developing themselves and learning new skills, and we are ready to help you do that. We cannot complete our mission without building a diverse and inclusive team. We hire the best people based on an evaluation of their potential and support them throughout their time at Cloudflare. Come join us!<br/><br/><strong>About The Role<br/><br/></strong>We're rekindling efforts to leverage acceleration and machine learning at Cloudflare in 2023, and the HW systems team is looking to hire senior technical engineers with a strong understanding of deep learning, ML end-to-end workloads and frameworks, and experience with hardware accelerator and processor architectures (GPUs, CPUs w/AI features, ASICs). This is an exciting opportunity with real world impact, where you'll get to build and deploy hardware accelerators on our data center platform.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Evaluate, design and deploy cutting edge acceleration solutions for our growing services</li><li>Lead the design of scalable AI infrastructure for Cloudflare's own internal machine learning platform and tune for optimal performance</li><li>Collaborate with product/data science teams to identify customer use-cases and translate workloads to technical design and hardware requirements (architecture definition, hardware selection, performance tuning)</li><li>Engage with hardware vendors to identify hardware solutions that best fit needs of the platform</li><li>Set the strategy and long term roadmap to demonstrate the value proposition of AI/ML workloads for the edge </li><li>Engage with AI leaders across the industry and influence design based on open industry standards <br/><br/><br/></li></ul><strong> <strong>Qualifications</strong> <br/><br/></strong><ul><li>Masters or equivalent experience in Computer Architecture, Computer Science, Electrical Engineering or related field with 12 years of relevant experience or equivalent</li><li>Has demonstrated technical leadership on critical company wide projects with experience in computer architecture (GPU, CPU w/AI. acceleration) and ML software ecosystem. Experience with programming models a plus</li><li>Strong technical foundation and deep understanding of cloud technologies, DL/ML workloads in the industry, frameworks (Tensorflow/Pytorch), and containers tools. </li><li>Ability to work in a constantly changing ambiguous environment and bridget the software/hardware divide </li><li>Industry-wide impact. Proactively creates formal networks involving coordination with internal and external technical leaders and has tangible proof points (patents, papers, conference contributions, open source SW or HW contributions, and/or sitting on a standards committee or board, etc.) demonstrating industry-wide influence as an influential spokesperson for the organization</li><li>Must be collaborative and has demonstrated ability to work effectively across cross functional teams, sound technical judgement and is capable of building positive working relationships</li><li>Seeks to mentor team members, offers technical advice and seeks to continuously learn<br/><br/><br/></li></ul><strong>Compensation<br/><br/></strong>Compensation may be adjusted depending on work location.<br/><br/><ul><li>For Colorado-based hires: Estimated annual salary of $168,000 - $248,000.</li><li>For New York City, Washington, and California (excluding Bay Area) based hires: Estimated annual salary of $187,000 - $281,000.</li><li>For Bay Area-based hires: Estimated annual salary of $196,000 - $286,000.<br/><br/><br/></li></ul><strong>Equity<br/><br/></strong>This role is eligible to participate in Cloudflare’s equity plan.<br/><br/><strong>Benefits<br/><br/></strong>Cloudflare offers a complete package of benefits and programs to support you and your family. Our benefits programs can help you pay health care expenses, support caregiving, build capital for the future and make life a little easier and fun! The below is a description of our benefits for employees in the United States, and benefits may vary for employees based outside the U.S.<br/><br/><strong>Health &amp; Welfare Benefits<br/><br/></strong><ul><li>Medical/Rx Insurance</li><li>Dental Insurance</li><li>Vision Insurance</li><li>Flexible Spending Accounts</li><li>Commuter Spending Accounts</li><li>Fertility &amp; Family Forming Benefits</li><li>On-demand mental health support and Employee Assistance Program</li><li>Global Travel Medical Insurance<br/><br/><br/></li></ul><strong>Financial Benefits<br/><br/></strong><ul><li>Short and Long Term Disability Insurance</li><li>Life &amp; Accident Insurance</li><li>401(k) Retirement Savings Plan</li><li>Employee Stock Participation Plan<br/><br/><br/></li></ul><strong>Time Off<br/><br/></strong><ul><li>Flexible paid time off covering vacation and sick leave</li><li>Leave programs, including parental, pregnancy health, medical, and bereavement leave<br/><br/><br/></li></ul><strong>What Makes Cloudflare Special?<br/><br/></strong>We’re not just a highly ambitious, large-scale technology company. We’re a highly ambitious, large-scale technology company with a soul. Fundamental to our mission to help build a better Internet is protecting the free and open Internet.<br/><br/><strong>Project Galileo</strong> : We equip politically and artistically important organizations and journalists with powerful tools to defend themselves against attacks that would otherwise censor their work, technology already used by Cloudflare’s enterprise customers--at no cost.<br/><br/><strong> Athenian Project </strong> : We created Athenian Project to ensure that state and local governments have the highest level of protection and reliability for free, so that their constituents have access to election information and voter registration.<br/><br/><strong>Path Forward Partnership</strong> : Since 2016, we have partnered with Path Forward, a nonprofit organization, to create 16-week positions for mid-career professionals who want to get back to the workplace after taking time off to care for a child, parent, or loved one.<br/><br/><strong>1.1.1.1</strong> : We released 1.1.1.1 to help fix the foundation of the Internet by building a faster, more secure and privacy-centric public DNS resolver. This is available publicly for everyone to use - it is the first consumer-focused service Cloudflare has ever released. Here’s the deal - we don’t store client IP addresses never, ever. We will continue to abide by our privacy commitment and ensure that no user data is sold to advertisers or used to target consumers.<br/><br/>Sound like something you’d like to be a part of? We’d love to hear from you!<br/><br/>This position may require access to information protected under U.S. export control laws, including the U.S. Export Administration Regulations. Please note that any offer of employment may be conditioned on your authorization to receive software or technology controlled under these U.S. export laws without sponsorship for an export license.<br/><br/>Cloudflare is proud to be an equal opportunity employer. We are committed to providing equal employment opportunity for all people and place great value in both diversity and inclusiveness. All qualified applicants will be considered for employment without regard to their, or any other person's, perceived or actual race, color, religion, sex, gender, gender identity, gender expression, sexual orientation, national origin, ancestry, citizenship, age, physical or mental disability, medical condition, family care status, or any other basis protected by law. We are an AA/Veterans/Disabled Employer.<br/><br/>Cloudflare provides reasonable accommodations to qualified individuals with disabilities. Please tell us if you require a reasonable accommodation to apply for a job. Examples of reasonable accommodations include, but are not limited to, changing the application process, providing documents in an alternate format, using a sign language interpreter, or using specialized equipment. If you require a reasonable accommodation to apply for a job, please contact us via e-mail at hr@cloudflare.com or via mail at 101 Townsend St. San Francisco, CA 94107.
      </div>",$168000- $248000,Data and AI Engineer
Staff Machine Learning Operations Engineer,Agoda,12/25/2023,https://www.linkedin.com/jobs/view/3791645998,0,https://media.licdn.com/dms/image/C4D0BAQGBa_7QNZNwpw/company-logo_100_100/0/1656643826660/agoda_logo?e=2147483647&v=beta&t=5V7q9sl3YFGW99Fa_-fGJ8jjK_dhtppZ8mxz8836vy4,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>About Agoda<br/><br/></strong>Agoda is an online travel booking platform for accommodations, flights, and more. We build and deploy cutting-edge technology that connects travelers with more than 3.6 million accommodations globally. Based in Asia and part of Booking Holdings, our 6,000+ employees representing 90+ nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enhancing the ability for our customers to experience the world.<br/><br/>Agoda is an online travel booking platform for accommodation, flights, and more. We build and deploy cutting edge technology that connects travelers with more than 2.5 million accommodations globally. Based in Asia and part of Booking Holdings, our 4,000+ talents coming from 90+ different nationalities foster a work environment rich in diversity, creativity, and collaboration. We innovate through a culture of experimentation and ownership, enabling our customers to experience the world.<br/><br/><strong>Get to Know Our Team<br/><br/></strong>The Engineering department oversees all Agoda’s ML and software related requirements. Our goal is to enable and increase Agoda’s business through creative approaches and the implementation of powerful resources such as operational and analytical databases, ML driven solutions, queue systems and data monitoring tools. We hire the brightest minds from around the world to take on this challenge and equip them with the knowledge and tools that contribute to their personal growth and success while supporting our company’s culture of diversity and experimentation. The role the engineering team plays at Agoda is critical as business users, product managers, and many others rely on us to empower their decision making. We are equally dedicated to our customers by improving their search experience with faster results and protecting them from any fraudulent activities. Data is interesting only when you have enough of it, and we have plenty. This is what drives up the challenge as part of the ML engineering squad, but also the reward. We work across structured and non-structured data at scale. For example, our current ML models process millions of images every day to try and enhance the experience that our users get from our app.<br/><br/><strong> ML Platform in Agoda <br/><br/></strong>Agoda ML Platform is built on self-managed Kubernetes and powered by Kubeflow, an open-source solution that enables efficient machine learning workflows.<br/><br/>Our MLOps team combines the best practices of software engineering with data science to help Machine Learning Engineers and Data Scientists work more effectively, meaning we aim to incorporate data/model versioning, collaboration, monitoring etc. in an intuitive way that allows our users to prosper within the field.<br/><br/><strong> In This Role, You’ll Get to: <br/><br/></strong><ul><li> Lead the design, development, and implementation of on-premises MLOps solutions that support the delivery of machine learning models </li><li> Collaborate with data scientists and software engineers to build scalable and efficient data pipelines and model training and deployment systems </li><li> Develop and maintain monitoring and management tools to ensure the reliability and performance of our on-premises MLOps infrastructure </li><li> Work with stakeholders across the organization to understand their machine learning needs and requirements, and to develop MLOps solutions that meet those needs </li><li> Stay up-to-date with the latest trends and technologies in MLOps, LLMOps, machine learning, and artificial intelligence, and share your knowledge with the team to help us stay at the forefront of the field </li><li> Mentor junior members of the team and help them grow their skills and expertise in MLOps </li><li> Troubleshooting and debugging user issues <br/><br/></li></ul><strong>What You’ll Need To Succeed<br/><br/></strong><ul><li> 5+ years of experience in MLOps, Software engineering, Data engineering, or a related field </li><li> Strong programming skills in a modern programming language (Java, Scala, Python, Kotlin) </li><li> Excellent communication and collaboration skills, and the ability to work effectively in a team environment </li><li> Value code simplicity and performance <br/><br/></li></ul><strong> It’s Great if you have: <br/><br/></strong><ul><li> Understanding of ML Projects lifecycle </li><li> Experience with MLOps platforms, such as Kubeflow or MLFlow </li><li> Experience with ML frameworks – like scikit-learn, LGBM, Tensorflow, PyTorch etc. </li><li> Experience with Big Data tools – Spark, S3, Hadoop </li><li> Strong knowledge of containerization and container orchestration technologies, such as Docker and Kubernetes </li><li> Experience with DevOps and CI/CD practices </li><li> Has experience building and scaling model serving tools, i.e building APIs with tight SLAs </li><li> Passion for the engineering behind machine learning, and scaling it </li><li> Experience designing and building MLOps infrastructure, including data pipelines, model training and deployment systems, and monitoring and management tools. <br/><br/></li></ul>#telaviv #jerusalem #IT #ENG #4 #sanfrancisco #sanjose #losangeles #sandiego #oakland #denver #miami #orlando #atlanta #chicago #boston #detroit #newyork #portland #philadelphia #dallas #houston #austin #seattle #sydney #melbourne #perth #toronto #vancouver #montreal #prague #Brno #Ostrava #cairo #alexandria #giza #estonia #paris #berlin #munich #hamburg #stuttgart #cologne #frankfurt #budapest #bali #dublin #telaviv #milan #rome #venice #florence #naples #turin #palermo #bologna #osaka #malta #amsterdam #oslo #warsaw #krakow #alrayyan #riyadh #jeddah #mecca #medina #singapore #seoul #barcelona #madrid #stockholm #zurich #taipei #tainan #taichung #kaohsiung #bangkok #Phuket #istanbul #london #manchester  #edinburgh #hcmc #hanoi #lodz #wroclaw #poznan #katowice #rio #salvador #newdelhi #bangalore #bandung #yokohama #nagoya #okinawa #fukuoka #jerusalem #IT #4 #bangalore #delhi #hyderabad #pune #singapore #beijing #shanghai #shenzhen #tokyo #seoul #hongkong #taipei #kualalumpur #jakarta #hochiminh #hochiminhcity #manila #instanbul #makati #dubai #riyadh #gurgaon #noida<br/><br/><strong>Equal Opportunity Employer <br/><br/></strong>At Agoda, we pride ourselves on being a company represented by people of all different backgrounds and orientations. We prioritize attracting diverse talent and cultivating an inclusive environment that encourages collaboration and innovation. Employment at Agoda is based solely on a person’s merit and qualifications. We are committed to providing equal employment opportunity regardless of sex, age, race, color, national origin, religion, marital status, pregnancy, sexual orientation, gender identity, disability, citizenship, veteran or military status, and other legally protected characteristics.<br/><br/>We will keep your application on file so that we can consider you for future vacancies and you can always ask to have your details removed from the file. For more details please read our privacy policy .<br/><br/>To all recruitment agencies: Agoda does not accept third party resumes. Please do not send resumes to our jobs alias, Agoda employees or any other organization location. Agoda is not responsible for any fees related to unsolicited resumes.<br/><br/>
</div>",No Salary Info Found,Data and AI Engineer
"Intern, AI Software Engineer",Samsung Semiconductor,12/23/2023,https://www.linkedin.com/jobs/view/3761294259,0,https://media.licdn.com/dms/image/D560BAQF2y3Yx7-VJGQ/company-logo_100_100/0/1665363849767/samsungsemiconductor_logo?e=2147483647&v=beta&t=xWSWXuBs6U_RU6wBQv-pTAYlGdOAqPAivDxOtXKz4GE,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Advancing the World’s Technology Together<br/><br/></strong>Our technology solutions power the tools you use every day--including smartphones, electric vehicles, hyperscale data centers, IoT devices, and so much more. Here, you’ll have an opportunity to be part of a global leader whose innovative designs are pushing the boundaries of what’s possible and powering the future.<br/><br/>We believe that innovation and growth are driven by an inclusive culture and a diverse workforce. We’re dedicated to empowering people to be their true selves. Together, we’re building a better tomorrow for our employees, customers, partners, and communities.<br/><br/><strong> </strong><strong>What You’ll Learn<br/><br/></strong><strong>Project<br/><br/></strong><ul><li>NPU SW<br/><br/></li></ul><strong>Skills You’ll Learn<br/><br/></strong><ul><li>Model converting between different framework, like Pytorch/ONNX/TFlite/Caffe;</li><li>Model quantization;</li><li>AI compiler, like TVM, Halide</li><li>Experience on deploying AI model on edge devices.</li><li>Complete other responsibilities as assigned.<br/><br/></li></ul><strong>What You’ll Do<br/><br/></strong><ul><li>Develop NPU Compiler front end to support more operators, including floating or quantized PyTorch quantized model, and converted it to Exynos NN compiler’s IR</li><li>Conduct Research and Experiments: Investigate how to better illustrate the graph of AI model with Intermediate Representative</li><li>Create Comprehensive Documentation: Generate clear and comprehensive documentation to facilitate knowledge transfer within the team, including best practices and implementation guidelines.</li><li>Test and Validate newly introduced AI operators: Conduct thorough testing and validation on Exynos Device.</li><li>Stay Informed about Industry Trends: Keep up to date with the latest advancements in AI compiler and deployment</li><li>Complete other responsibilities as assigned.<br/><br/></li></ul>Location: Hybrid, working onsite at our San Diego, CA office 3 days per week with the flexibility to work remotely the remainder of your time<br/><br/><strong>What You Bring<br/><br/></strong><ul><li>Educational Background: A graduate student pursuing a Ph.D. or Master's degree in Engineering, Computer Science or Applied Math from a reputable university with a strong academic standing is preferred.</li><li>Problem-Solving Skills: Strong problem-solving abilities and the capacity to innovate, with a proven history of addressing complex challenges effectively.</li><li>Collaboration Skills: Demonstrated ability to collaborate effectively with cross-functional teams, fostering a culture of teamwork and knowledge sharing.</li><li>Documentation and Communication: Excellent documentation and communication skills, including the</li><li>capability to clearly convey complex technical concepts.</li><li>Performance Optimization: Experience in optimizing the performance of applications for edge devices, including TPU/NPU/GPU acceleration and resource efficiency.</li><li>Knowledge Sharing: Willingness to actively share knowledge and support the growth and development of the team, contributing to a culture of continuous learning.</li><li>Tech Trend Awareness: A commitment to staying updated with the latest advancements and trends in AI development and deployment, and the ability to integrate new insights into projects. Innovation: A proven track record of bringing fresh and innovative ideas to the team, which have positively impacted projects and the organization</li><li>You’re inclusive, adapting your style to the situation and diverse global norms of our people.</li><li>An avid learner, you approach challenges with curiosity and resilience, seeking data to help build understanding.</li><li>You’re collaborative, building relationships, humbly offering support and openly welcoming approaches.</li><li>Innovative and creative, you proactively explore new ideas and adapt quickly to change.<br/><br/></li></ul><strong>What We Offer<br/><br/></strong>The pay range below is for all roles at this level across all US locations and functions. Individual pay rates depend on a number of factors—including the role’s function and location, as well as the individual’s knowledge, skills, experience, education, and training.<br/><br/>This is in addition to our diverse package of benefits centered around the wellbeing of our employees and their loved ones. In addition to the usual Medical/Dental/Vision, our inclusive rewards plan empowers our people to care for their whole selves. An investment in your future is an investment in ours.<br/><br/><strong>Relocation Support </strong>Live 50+ miles away from your new office? No worries! We'll provide a stipend to help support your move.<br/><br/><strong>Housing Stipend </strong>Signing a lease on a new place for your summer internship? We'll help you pay your way with a monthly stipend.<br/><br/><strong>Give Back </strong>With a charitable giving match and frequent opportunities to get involved, we take an active role in supporting the community.<br/><br/><strong>Prioritize Emotional Wellness </strong>With on-demand apps and paid therapy sessions, you’ll have support no matter where you are.<br/><br/><strong>Stay Fit </strong>Eating well and being active are important parts of a healthy life. Our onsite Café and gym, plus virtual classes, make it easier.<br/><br/><strong>Embrace Flexibility </strong>Benefits are best when you have the space to use them. That’s why we facilitate a flexible environment so you can find the right balance for you.<br/><br/>Hourly Base Pay Rate<br/><br/>$27—$57 USD<br/><br/><strong>Equal Opportunity Employment Policy<br/><br/></strong>Samsung Semiconductor is proud to be an equal opportunity workplace and affirmative action employer. We’re committed to fostering an inclusive environment where everyone feels welcomed and empowered to do their best work. We hire the best talent for our teams, regardless of race, religion, color, age, disability, sex, gender identity, sexual orientation, ancestry, genetic information, marital status, national origin, political affiliation, or veteran status. Our focus is on hiring teammates with humble expertise, kindness, dedication and a willingness to embrace challenges and learn together every day.<br/><br/><strong>Covid-19 Policy<br/><br/></strong>To help keep our employees, customers, and communities safe, we’ve developed guidelines for our teams. Currently, we encourage vaccination for all employees, and may require it depending on job functions (e.g., traveling for business, meeting with customers). While visiting our offices or attending team events, we ask employees to complete a daily health questionnaire and complete a weekly COVID test. Our COVID policies are subject to change depending on public health, regulatory and business circumstances.<br/><br/><strong>Applicant Privacy Policy<br/><br/></strong>https://semiconductor.samsung.com/us/careers/privacy
      </div>",$27- $57,Data and AI Engineer
Machine Learning Engineer,General Atomics,12/19/2023,https://www.linkedin.com/jobs/view/3659867485,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
"Computational Scientist, Omics Data Analysis and Integration",Altos Labs,12/19/2023,https://www.linkedin.com/jobs/view/3642218564,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
CoStar Group - Senior Machine Learning Engineer,CoStar Group,12/19/2023,https://www.linkedin.com/jobs/view/3790343983,0,https://media.licdn.com/dms/image/C4E0BAQG3aaai8L_lEA/company-logo_100_100/0/1630644550246/costar_group_logo?e=2147483647&v=beta&t=zd1w8rSUJehBCWm2xn00s6DSnoJt8fApF0uDXcJfkAc,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Description<br/><br/></strong>CoStar Group (NASDAQ: CSGP) is a leading global provider of commercial and residential real estate information, analytics, and online marketplaces. Included in the S&amp;P 500 Index and the NASDAQ 100, CoStar Group is on a mission to digitize the world’s real estate, empowering all people to discover properties, insights and connections that improve their businesses and lives.<br/><br/>We have been living and breathing the world of real estate information and online marketplaces for over 35 years, giving us the perspective to create truly unique and valuable offerings to our customers. We’ve continually refined, transformed and perfected our approach to our business, creating a language that has become standard in our industry, for our customers, and even our competitors. We continue that effort today and are always working to improve and drive innovation. This is how we deliver for our customers, our employees, and investors. By equipping the brightest minds with the best resources available, we provide an invaluable edge in real estate.<br/><br/>Homes.com is already one of the fastest growing real estate portals in the industry, we are driven to be #1. Just ask Brad Bellflower, Chief Change Officer at Apartments.com. After its acquisition in 2014, Apartments.com quickly turned into the most popular place to find a place. Proven success at the highest level – and we’re doing it again with the new Homes.com. Homes.com is a CoStar Group company with 20+ years' experience in leading and growing digital marketplaces. We pride ourselves on continually improving, innovating, and setting the standard for property search and marketing experiences. With Homes.com we’re building a brand on the cusp of defining the industry. We’re looking for big thinkers, brave leaders, and creative advertising wizards ready to influence a new age of homebuying within a tried-and-true, award-winning company.<br/><br/>Learn more about Homes.com<br/><br/>Machine Learning Engineers at CoStar play an important role in this process, by mining data from sources including billions of pageviews, millions of images, vast geographic data, deep property content, and much more. We enhance our extensive property database, personalize our customers’ experience on our product websites, and create innovative datasets and forecasts that are the industry standards in our market leading products.<br/><br/>We are searching for a Senior Machine Learning Engineer to join our collaborative group that includes a mix of big data, API, and full stack development teams. We are growing rapidly to help invent the future of Real Estate, with Data Science playing a critical role in that growth.<br/><br/>This position is located in San Diego, CA (UTC Area), and offers the following hybrid schedule option:<br/><br/><ul><li> 3 days onsite, 2 days remote<br/><br/></li></ul><strong>Responsibilities<br/><br/></strong><ul><li>Collaborate on the continued improvement of CoStar’s cloud-based machine learning environment.</li><li>Design, build, test and deploy scalable, reusable, and maintainable models that handle large amounts of data.</li><li>Collaborate with other engineers, product owners, and leadership to create ML solutions that solve practical problems and improve our customer’s experience.</li><li>Gain an understanding of the CoStar business and how ML can improve things.<br/><br/></li></ul><strong>Basic Qualifications<br/><br/></strong><ul><li>Bachelor’s Degree required from an accredited, not for profit university or college. MSc or PhD is a plus. </li><li>A track record of commitment to prior employers</li><li>5+ years of professional development experience as Machine Learning Engineer, Data Scientist or related role</li><li>5+ years of programming experience with modern languages such as Python, C#, Java, or Scala.</li><li>Work experience with Image Classification, Object Detection, NER, or Recommendation Systems.</li><li>Experience building data pipelines to collect data, train and test models, measure model performance, run inference on large datasets, and output results.</li><li>Experience with ML libraries such as TensorFlow, Keras, and Scikit-learn.</li><li>Experience with data manipulation and visualization libraries such as pandas, matplotlib, seaborn, or Plotly.</li><li>Strong math and analytical skills.<br/><br/></li></ul><strong>Preferred Qualifications And Skills<br/><br/></strong><ul><li>Experience with databases, such as SQL Server, AWS RDS, DynamoDB.</li><li>Experience solving streaming and batch data processing problems at scale.</li><li>Experience with ML cloud tools such as Databricks, Amazon Personalize, Comprehend, SageMaker, and Rekognition.</li><li>Experience with integration of input data from a variety of sources.<br/><br/></li></ul><strong>What’s In It For You<br/><br/></strong>When you join CoStar Group, you’ll experience a collaborative and innovative culture working alongside the best and brightest to empower our people and customers to succeed.<br/><br/>We offer you generous compensation and performance-based incentives. CoStar Group also invests in your professional and academic growth with internal training, tuition reimbursement, and an inter-office exchange program.<br/><br/><strong>Our Benefits Package Includes (but Is Not Limited To)<br/><br/></strong><ul><li>Comprehensive healthcare coverage: Medical / Vision / Dental / Prescription Drug</li><li>Life, legal, and supplementary insurance</li><li>Virtual and in person mental health counseling services for individuals and family</li><li>Commuter and parking benefits</li><li>401(K) retirement plan with matching contributions</li><li>Employee stock purchase plan</li><li>Paid time off</li><li>Tuition reimbursement</li><li>On-site fitness center and/or reimbursed fitness center membership costs (location dependent), with yoga studio, Pelotons, personal training, group exercise classes</li><li>Access to CoStar Group’s Diversity, Equity, &amp; Inclusion Employee Resource Groups</li><li>Complimentary gourmet coffee, tea, hot chocolate, fresh fruit, and other healthy snacks<br/><br/></li></ul>We welcome all qualified candidates who are currently eligible to work full-time in the United States to apply. However, please note that CoStar Group is not able to provide visa sponsorship for this position.<br/><br/>This position offers a base salary range of <strong>$143,000 - </strong><strong>$231,000</strong>, based on relevant skills and experience and includes a generous benefits plan.<br/><br/>CoStar Group is an Equal Employment Opportunity Employer; we maintain a drug-free workplace and perform pre-employment substance abuse testing<br/><br/>
</div>",$143000- $231000,Data and AI Engineer
Principal Data Scientist,Intuit,12/19/2023,https://www.linkedin.com/jobs/view/3739158009,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Machine Learning Software Engineer,Sony Interactive Entertainment,12/19/2023,https://www.linkedin.com/jobs/view/3766979811,0,https://media.licdn.com/dms/image/C4D0BAQFJO00VqEb3Vg/company-logo_100_100/0/1630540194089/sony_interactive_entertainment_llc_logo?e=2147483647&v=beta&t=jfycjFelGW7uhdwCfVpNWJM5i608eZ6RciYz-9xMHRA,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Why PlayStation?<br/><br/></strong>PlayStation isn’t just the Best Place to Play — it’s also the Best Place to Work. Today, we’re recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation®5, PlayStation®4, PlayStation®VR, PlayStation®Plus, acclaimed PlayStation software titles from PlayStation Studios, and more.<br/><br/>PlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team.<br/><br/>The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.<br/><br/><strong>ML Software Engineer<br/><br/></strong>Sony Interactive Entertainment’s (SIE) Global Payment, Fraud Management and Decision Science (GPFD) teams are the guardians of both customer trust and purchase success for PlayStation and the PlayStation Network (PSN). We provide innovative solutions to support every element of the network, various platform services, customer service teams, a diverse developer community, and more.<br/><br/>GPFD runs a next generation risk platform and machine learning framework that support the global, fast growing PlayStation Network customer base, world class PlayStation consoles, and network entertainment services such as PlayStation Plus and PlayStation Now. In doing so, the ability to extract information from data and drive action that help achieve business goals is essential. GPFD’s data science team is responsible for evaluating online user activity data for potential fraud and revenue optimization across this platform, and the engineering team empowers them. We are looking for an engineer to join our GPFD team to support this data science platform.<br/><br/>The position is a hands-on engineering role with a wide range of responsibilities to evolve and support a machine learning pipeline. You should be intimately familiar with running applications at scale on modern cloud architectures using containerized and serverless workflows. You must be a self-motivated individual and take pride in delivering high-quality work within a fast-paced, dynamic environment.<br/><br/><strong>Responsibilities<br/><br/></strong><ul><li>Create, deploy, and maintain cloud solutions using AWS</li><li>Build core infrastructure around data streaming and enhancement</li><li>Build and enhance our machine learning pipeline to support development, experimentation, continuous integration, continuous delivery, verification/validation, and monitoring of ML models</li><li>Ensure all work is deployed in an automated, repeatable fashion</li><li>Ensure highest levels of service availability<br/><br/></li></ul>Qualifications and Education Requirements:<br/><br/><ul><li>Bachelor’s degree and 2-5 years of related experience</li><li>Demonstrated experience with Java and Python</li><li>Competency with most common AWS Services - EKS/ECS, Kinesis, Lambda, DynamoDB, SNS, SQS, and more</li><li>Knowledge in systems monitoring, alerting and analytics including using tools such as DataDog, Splunk, New Relic, AWS CloudTrail, etc.</li><li>General knowledge in Linux</li><li>Strong communication abilities to work with cross functional teams</li><li>Experience with orchestration and management of containers using Kubernetes or similar.<br/><br/></li></ul>Preferred Skills:<br/><br/><ul><li>AWS certification</li><li>Basic knowledge of data science and data science workflows</li><li>Experience with streams/queues at internet scale – Kinesis/Kafka/ActiveMQ/SQS</li><li>Experience successfully implementing data pipelines<br/><br/></li></ul><strong> Please refer to our Candidate Privacy Notice for more information about how we process your personal information, and your data protection rights. <br/><br/></strong>At SIE, we consider several factors when setting each role’s base pay range, including the competitive benchmarking data for the market and geographic location.<br/><br/>Please note that the base pay range may vary in line with our hybrid working policy and individual base pay will be determined based on job-related factors which may include knowledge, skills, experience, and location.<br/><br/>In addition, this role is eligible for SIE’s top-tier benefits package that includes medical, dental, vision, matching 401(k), paid time off, wellness program and coveted employee discounts for Sony products. This role also may be eligible for a bonus package. Click <strong>here</strong> to learn more.<br/><br/>The estimated base pay range for this role is listed below.<br/><br/>$127,400 — $191,000 USD<br/><br/><strong>Equal Opportunity Statement:<br/><br/></strong>Sony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to gender (including gender identity, gender expression and gender reassignment), race (including colour, nationality, ethnic or national origin), religion or belief, marital or civil partnership status, disability, age, sexual orientation, pregnancy or maternity, trade union membership or membership in any other legally protected category.<br/><br/>We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.<br/><br/>PlayStation is a Fair Chance employer and qualified applicants with arrest and conviction records will be considered for employment.<br/><br/>
</div>",$127400- $191000,Data and AI Engineer
Machine Learning Engineer,EVONA,12/20/2023,https://www.linkedin.com/jobs/view/3788696794,0,https://media.licdn.com/dms/image/D4E0BAQEtPq5iCK5bhQ/company-logo_100_100/0/1688640059802/evona_space_logo?e=2147483647&v=beta&t=LbszcASTe_YbsNgsBCdifaRRLbbbNEIIqiYYQAzFdhQ,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p>We have an exciting opportunity for a <strong>Machine Learning Engineer</strong> in the San Diego area. </p><p><br/></p><p>The company are looking to develop and deploy end-to-end autonomous systems that enable unmanned aerial systems to execute autonomous missions.</p><p><br/></p><p><strong><u>DUTIES AND RESPONSIBILITIES:</u></strong></p><p><br/></p><ul><li>Develops and communicates descriptive, diagnostic, predictive and prescriptive insights/algorithms of limited scope.</li><li>In product/systems improvement projects, uses machine language and statistical modelling techniques to include but not limited to decision trees, logistic regression, Bayesian analysis and others to develop and evaluate algorithms to improve product/system performance, quality, data management and accuracy.</li><li>In both theoretical development environments and specific product design, implementation and improvement environments, uses programming language and technologies to translate algorithms and technical specifications into code.</li><li>Completes programming and implements efficiencies, performs testing and debugging.</li><li>Completes documentation and procedures for installation and maintenance.</li><li>Applies deep learning technologies to give computers the capability to visualize, learn and respond to situations of limited scope.</li><li>Lead technical teams and scope challenging projects into executable sprints.</li><li>Drive code reviews to help team adhere to general DevSecOps and MLOps best practices.</li><li>Have a growth mindset and be comfortable in a setting where milestones shift often due to customer preferences or technology evolution.</li><li>Adapts machine learning to areas such as virtual reality, augmented reality, artificial intelligence, robotics and other products that allow users to have an interactive experience.</li><li>Interface with external vendors and partners to integrate their technology into the team’s autonomy stack.</li><li>Maintains the strict confidentiality of sensitive information.</li><li>Responsible for observing all laws, regulations and other applicable obligations wherever and whenever business is conducted on behalf of the Company. Expected to work in a safe manner in accordance with established operating procedures and practices.</li></ul><p><br/></p><p><strong><u>JOB QUALIFICATIONS:</u></strong></p><p><br/></p><ul><li>Bachelors, Masters Degree or PhD in Computer Science, Engineering, Mathematics, or a related technical discipline from an accredited institution</li><li>Must have an advanced understanding of machine learning concepts, principles, and theory.</li><li>Demonstrates the ability to follow and apply advanced machine learning knowledge, adapt cutting edge standard techniques, and utilize the required diagnostics, tools and equipment, while ensuring safety and regulatory compliance.</li><li>Experience in developing and leading scalable software architectures from scratch.</li><li>Experience in optimizing AI models to meet edge processing requirements.</li><li>Strong coding skills in Java, Java Script, C/C++, Python</li><li>Experience in AI frameworks such as Tensorflow and pyTorch.</li><li>Must be able to architect, design, and develop complex software.</li><li>Technical expertise in the application of engineering principles, concepts, theory, and practice as well as project management and leadership skills including organizing, planning, scheduling, and coordinating workloads to meet established deadlines or milestones.</li><li>Active membership and participation in relevant conference and professional society organizations.</li><li>Demonstrated recent history of academic quality publications in the area of AI/ML and autonomy.</li><li>Must be able to understand new concepts quickly and apply them accurately throughout an evolving environment.</li><li>Strong communication, computer, and interpersonal skills are required to enable an effective interface with other professionals, to produce appropriate documentation, and to present results to a limited internal audience.</li><li>Must be able to work both independently and on a team.</li><li>Ability to obtain and maintain a DoD security clearance is required.</li></ul><p><br/></p><p>If you would like more information regarding this position, please contact Yasmin Hamdy - y.hamdy@evona.com</p>
</div>",No Salary Info Found,Data and AI Engineer
Unity Game Developer - Remote | WFH,Get It Recruit - Information Technology,12/20/2023,https://www.linkedin.com/jobs/view/3785600031,0,https://media.licdn.com/dms/image/C560BAQEtBFYCMxEHXg/company-logo_100_100/0/1674747061472?e=2147483647&v=beta&t=RvKEHy-U00_WSFMenHx6rXutOA7bpg49MtBMrE5ZdY4,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        Join a passionate team on a mission to spark a love of coding in millions of children around the world. We're a small, agile crew building multi-platform Unity games used by over 30 million kids in over 50% of US schools and 190 countries. Less meetings, more coding! Sounds exciting, right? Read on...<br/><br/><strong>Here's What You'll Do<br/><br/></strong>Work hand-in-hand with top-notch artists, designers, and educators to craft games that make learning computer science a blast for kids.<br/><br/>Own every aspect of the Kodable game development process, from building code to seeing it used by millions.<br/><br/>Partner directly with the CEO and product team to ensure your work makes a real impact on Kodable's success.<br/><br/><strong>Who You Are<br/><br/></strong>Passionate about early childhood education and empowering the next generation of programmers.<br/><br/>A seasoned Unity developer (3+ years) with a proven track record in production environments.<br/><br/>Comfortable coding in multiple languages (3+ years), including JavaScript, Python, and C#.<br/><br/>A team player with a public game release under your belt (even a small one with a few thousand users counts!).<br/><br/><strong>Bonus Points If You Have<br/><br/></strong>Experience with 2D game development.<br/><br/>Networking and server-side code chops (saving/loading data, etc.).<br/><br/>Multi-platform deployment expertise (Web and iOS, for example).<br/><br/><strong>Extra Bonus Points (because We Love Tech Geeks)<br/><br/></strong>REST API experience (creating or consuming).<br/><br/>Firebase know-how.<br/><br/>Game design skills.<br/><br/>Ready to make a difference? We're excited to hear from you!<br/><br/>Employment Type: Full-Time
      </div>",No Salary Info Found,Data and AI Engineer
"Data Scientist, Mid",Booz Allen Hamilton,12/20/2023,https://www.linkedin.com/jobs/view/3789000813,0,https://media.licdn.com/dms/image/D560BAQFONzmexEjnKQ/company-logo_100_100/0/1688152881727/booz_allen_hamilton_logo?e=2147483647&v=beta&t=WObdLZdWUtVerjHd32dAqEjay9aR9sBz2AI2Y4tN_44,"San Diego, CA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Job Number: R0187217<br/><br/></strong>Data Scientist, Mid<br/><br/><strong>The Opportunity: <br/><br/></strong>As a data scientist, you’re excited at the prospect of unlocking the secrets held by a data set, and you’re fascinated by the possibilities presented by IoT, machine learning, and artificial intelligence. In an increasingly connected world, massive amounts of structured and unstructured data open new opportunities. As a data scientist at Booz Allen, you can help turn these complex data sets into useful information to solve global challenges. Across private and public sectors—from fraud detection to cancer research to national intelligence—we need you to help find the answers in the data.<br/><br/>On our team, you’ll use your leadership skills and data science expertise to create real-world impact. You’ll work closely with clients to understand their questions and needs, and then dig into their data-rich environments to find the pieces of their information puzzle. You’ll guide teammates and lead the development of algorithms and systems. You’ll use the right combination of tools and frameworks to turn sets of disparate data points into objective answers to advise your clients as they make informed decisions. Ultimately, you’ll provide a deep understanding of the data, what it all means, and how it can be used. Work with us as we use data science for good.<br/><br/>Join us. The world can’t wait.<br/><br/><strong>You Have:<br/><br/></strong><ul><li>3+ years of experience with data science, data analytics, machine learning, or statistics, including in a management or advisory role</li><li>Experience with object-oriented programming languages, including Python, C++, Java, or R</li><li>Experience with identifying and analyzing data sets to meet customer requirements</li><li>Experience with preparing customer data for models, including merging and aggregating data, handling anomalies, balancing, and feature selection</li><li>Knowledge of Cloud services, including AWS, Azure, or Google Cloud</li><li>Ability to help interpret model results and communicate them clearly through compelling data visualizations</li><li>Ability to obtain a security clearance</li><li>Bachelor’s degree<br/><br/><br/></li></ul><strong>Nice If You Have:<br/><br/></strong><ul><li>Experience with supervised and unsupervised machine learning techniques, including neural networks, decision trees, logistic regressions, or dimension reduction</li><li>Experience with data engineering and data science tools, including Databricks, ElasticSearch, Apache NiFi, or StreamSets</li><li>Experience with enterprise DataOps, DevSecOps, and MLOps processes to operationalize and monitor data science models</li><li>Experience with Agile development</li><li>Experience with CI/CD, including Git, Jenkins, and Docker</li><li>Knowledge of procedural SQL language, including PL/pgSQL</li><li>Ability to explain analytic and model findings to non-technical audiences<br/><br/><br/></li></ul><strong>Clearance:<br/><br/></strong>Applicants selected will be subject to a security investigation and may need to meet eligibility requirements for access to classified information.<br/><br/><strong>Create Your Career: <br/><br/></strong><strong>Grow With Us <br/><br/></strong>Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms.<br/><br/><strong>A Place Where You Belong <br/><br/></strong>Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time.<br/><br/><strong>Support Your Well-Being<br/><br/></strong>Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home.<br/><br/><strong>Your Candidate Journey<br/><br/></strong>At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us.<br/><br/><strong>Compensation<br/><br/></strong>At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page.<br/><br/>Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $73,100.00 to $166,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees.<br/><br/><strong>Work Model<br/><br/></strong>Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely.<br/><br/><ul><li>If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility.</li><li>If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role.<br/><br/><br/></li></ul><strong>EEO Commitment<br/><br/></strong>We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.
      </div>",$73100.00- $166000.00,Data and AI Engineer
Senior Machine Learning Engineer,ClickJobs.io,12/25/2023,https://www.linkedin.com/jobs/view/3793196359,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Data Scientist with GenAI,New York Technology Partners,12/20/2023,https://www.linkedin.com/jobs/view/3790026586,0,https://media.licdn.com/dms/image/C4D0BAQHDKWHx36SB2Q/company-logo_100_100/0/1630569042627/new_york_technology_partners_logo?e=2147483647&v=beta&t=OPcExY5jVOikWIdqsxEFCwjmBxvlXHcbjxS5hP2tthM,"Malvern, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<p><strong>Job Title: Data Scientist with GenAI</strong></p><p><strong>Location: Malvern, PA / Charlotte, NC (Hybrid)</strong></p><p><strong>Position Type: Contract</strong> </p><p> </p><p><strong>Job Description:</strong></p><p><strong>Core Skills:</strong></p><p>· Strong Python skills including libraries like LangChain, LangIndex, PyTorch, SageMaker SDK, psycopg2</p><p>· Experience with Docker and AWS ECR</p><p>· Strong AWS experience with with the following services: </p><p>o Bedrock</p><p>o SageMaker</p><p>o IAM</p><p>o Glue</p><p>o S3</p><p>o Lambda</p><p>o CodeCommit and CodePipeline</p><p>· Experience creating quick apps using Streamlit, NodeJS, or some other app framework</p><p>· Education and or experience in developing NLP models for text classification, completion, summarization, generation</p><p>· Experience using embeddings models to create vector embeddings and working with vector databases</p><p>· Understanding of RAG architecture, retrieval optimization, and tradeoffs of splitting methods</p><p>· Familiarity with benchmarks for model evaluation and methods of determining vector similarity</p><p>· Experience with scaling ML training workloads using distributed training techniques on GPU and/or developing microservices for AI/ML/GenAI products</p><p>· Data Preprocessing and Analysis: Work with large-scale datasets, preprocess the data, and perform in-depth analysis to derive meaningful insights, patterns, and trends for AI model training.</p><p><strong> </strong></p><p><strong>Preferred candidates will have:</strong></p><p>· Real world experience fine-tuning models, methods of fine-tuning, and data preprocessing for fine-tuning</p><p>· AWS Solutions Architect and or AWS Machine Learning Specialty certifications</p><p><strong> </strong></p><p>If you believe you are qualified for this position and are currently in the job market or interested in making a change, please email me the resume along with contact details at roshni@nytpcorp.com</p>
</div>",No Salary Info Found,Data and AI Engineer
Generative AI Engineer,BeaconFire Inc.,12/19/2023,https://www.linkedin.com/jobs/view/3788145588,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Senior Data Engineer,Comcast,12/19/2023,https://www.linkedin.com/jobs/view/3765726099,0,https://media.licdn.com/dms/image/C560BAQGT4d_JDjXclg/company-logo_100_100/0/1630612186529/comcast_logo?e=2147483647&v=beta&t=ATBNl1bzlNEh1TNo0dGTKyOPUrmKUCyylo4VBuMch6k,"Philadelphia, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
        R375144<br/><br/>Make your mark at Comcast -- a Fortune 30 global media and technology company. From the connectivity and platforms we provide, to the content and experiences we create, we reach hundreds of millions of customers, viewers, and guests worldwide. Become part of our award-winning technology team that turns big ideas into cutting-edge products, platforms, and solutions that our customers love. We create space to innovate, and we recognize, reward, and invest in your ideas, while ensuring you can proudly bring your authentic self to the workplace. Join us. You’ll do the best work of your career right here at Comcast. (In most cases, Comcast prefers to have employees on-site collaborating unless the team has been designated as virtual due to the nature of their work. If a position is listed with both office locations and virtual offerings, Comcast may be willing to consider candidates who live greater than 100 miles from the office for the remote option.)<br/><br/><strong>Job Summary<br/><br/></strong>We are looking for a Senior Data Engineer to join our Philadelphia-based WiFi Engineer team. Be part of the team that manages and operates world’s largest public Wi-Fi network. The work involves analysis and performance improvement of our Xfinity Wi-Fi networks hyperscale , using state of the art optimization techniques, machine learning, specification and use of wireless measurements, and analysis of network performance, building business insights that could help create future deployment strategy. The solutions are all implemented in the cloud, using an agile development process.<br/><br/><strong>Job Description<br/><br/></strong><strong>Core Responsibilities:<br/><br/><br/></strong><ul><li>Create, maintain, redesign data pipelines</li><li>Create ETL from a variety of data sources using SQL and big data technologies</li><li>Perform data analysis to discover opportunities and address gaps</li><li>Automate any manual processes</li><li>Create scalable big data solutions</li><li>Build reports to provide actionable insights from the data</li><li>Perform analysis for query optimization</li><li>Work with data Scientists/Wireless Engineers on WiFi CX optimization using AI/ML techniques</li><li>Work with stakeholders and executives to create the requirement for data related needs</li><li>Build business insights that could help create future deployment strategy<br/><br/><br/></li></ul><strong>Qualifications:<br/><br/><br/></strong><ul><li>This is a Senior Engineer (Engineer 4) role, which requires 7-10 years of relevant experience</li><li>This team is based in our cutting-edge Comcast Technology Center in downtown Philadelphia, and collaborates in-person on a hybrid basis.</li><li>7+ years of experience in Python</li><li>7+ years of experience in custom ETL design, implementation and maintenance</li><li>7+ Experience in Database technologies, SQL, MySQL, Elastic search, ETLs and framework development.</li><li>7+ year of experience with Data Modeling</li><li>7+ Experience working on Big Data</li><li>7+ Experience with data analysis and visualization, particularly Tableau, Splunk</li><li>Experience processing large data sets</li><li>Strong experience with Spark, Hive, Pig, Flume, Sqoop, Kafka, Amazon RDS, Amazon Redshift, GCP</li><li>Experience with data quality and validation<br/><br/><br/></li></ul><strong>Additional responsibilities:<br/><br/><br/></strong><ul><li>Develops data structures and pipelines aligned to established standards and guidelines to organize, collect, standardize and transform data that helps generate insights and address reporting needs.</li><li>Focuses on ensuring data quality during ingest, processing as well as final load to the target tables.</li><li>Creates standard ingestion frameworks for structured and unstructured data as well as checking and reporting on the quality of the data being processed.</li><li>Creates standard methods for end users / downstream applications to consume data including but not limited to database views, extracts and Application Programming Interfaces.</li><li>Develops and maintains information systems (e.g., data warehouses, data lakes) including data access Application Programming Interfaces.</li><li>Participates in the implementation of solutions via data architecture, data engineering, or data manipulation on both on-prem platforms like Kubernetes and Teradata as well as Cloud platforms like Databricks.</li><li>Determines the appropriate storage platform across different on-prem (minIO and Teradata) and Cloud (AWS S3, Redshift) depending on the privacy, access and sensitivity requirements.</li><li>Understands the data lineage from source to the final semantic layer along with the transformation rules applied to enable faster troubleshooting and impact analysis during changes.</li><li>Collaborates with technology and platform management partners to optimize data sourcing and processing rules to ensure appropriate data quality as well as process optimization.</li><li>Creates and establishes design standards and assurance processes for software, systems and applications development to ensure compatibility and operability of data connections, flows and storage requirements. Reviews internal and external business and product requirements for data operations and activity and suggests changes and upgrades to systems and storage to accommodate ongoing needs.</li><li>Develops strategies for data acquisition, archive recovery, and database implementation.</li><li>Manages data migrations/conversions and troubleshooting data processing issues.</li><li>Understands the data sensitivity, customer data privacy rules and regulations and applies them consistently in all Information Lifecycle Management activities.</li><li>Identifies and reacts to system notification and log to ensure quality standards for databases and applications. Solves abstract problems beyond single development language or situation by reusing data file and flags already set.</li><li>Solves critical issues and shares knowledge such as trends, aggregate, quantity volume regarding specific data sources.</li><li>Consistent exercise of independent judgment and discretion in matters of significance.<br/><br/><br/></li></ul>Employees at all levels are expected to:<br/><br/><br/><ul><li>Understand our Operating Principles; make them the guidelines for how you do your job.</li><li>Own the customer experience - think and act in ways that put our customers first, give them seamless digital options at every touchpoint, and make them promoters of our products and services.</li><li>Know your stuff - be enthusiastic learners, users and advocates of our game-changing technology, products and services, especially our digital tools and experiences.</li><li>Win as a team - make big things happen by working together and being open to new ideas.</li><li>Be an active part of the Net Promoter System - a way of working that brings more employee and customer feedback into the company - by joining huddles, making call backs and helping us elevate opportunities to do better for our customers.</li><li>Drive results and growth.</li><li>Respect and promote inclusion &amp; diversity.</li><li>Do what's right for each other, our customers, investors and our communities.<br/><br/><br/></li></ul>Disclaimer:This information has been designed to indicate the general nature and level of work performed by employees in this role. It is not designed to contain or be interpreted as a comprehensive inventory of all duties, responsibilities and qualifications.<br/><br/>Comcast is proud to be an equal opportunity workplace. We will consider all qualified applicants for employment without regard to race, color, religion, age, sex, sexual orientation, gender identity, national origin, disability, veteran status, genetic information, or any other basis protected by applicable law.<br/><br/><strong>Education<br/><br/></strong>Bachelor's Degree<br/><br/>While possessing the stated degree is preferred, Comcast also may consider applicants who hold some combination of coursework and experience, or who have extensive related professional experience.<br/><br/><strong>Relevant Work Experience<br/><br/></strong>7-10 Years<br/><br/>Base pay is one part of the Total Rewards that Comcast provides to compensate and recognize employees for their work. Most sales positions are eligible for a Commission under the terms of an applicable plan, while most non-sales positions are eligible for a Bonus. Additionally, Comcast provides best-in-class Benefits. We believe that benefits should connect you to the support you need when it matters most, and should help you care for those who matter most. That’s why we provide an array of options, expert guidance and always-on tools, that are personalized to meet the needs of your reality – to help support you physically, financially and emotionally through the big milestones and in your everyday life. Please visit the compensation and benefits summary on our careers site for more details.
      </div>",No Salary Info Found,Data and AI Engineer
"PEPI - Manager, Generative AI – AI Engineer (Open to All US locations)",Alvarez & Marsal,12/19/2023,https://www.linkedin.com/jobs/view/3771050931,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Temp Remote Machine Learning Engineer,Phaxis,12/19/2023,https://www.linkedin.com/jobs/view/3784098309,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
Data Engineer,Hyperloop Recruitment,12/20/2023,https://www.linkedin.com/jobs/view/3788678577,0,https://media.licdn.com/dms/image/D4E0BAQE5-wtGV9fWBQ/company-logo_100_100/0/1683619007636/hyperlooprecruitment_logo?e=2147483647&v=beta&t=4GRFib2T7ZuyTWESWmNt0g2NBzu40ZTgn23wPDBKEO8,"North Wales, PA","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Data Engineer/Science<br/><br/></strong><strong>Circa 70k<br/><br/></strong><strong>North Wales<br/><br/></strong><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>The Client<br/><br/></strong>We’re representing a multi-billion pound Data Analytics and Software house who’re experience a period of high growth. They’re revolutionising their channel bringing new insights to their tracking software and work with the main players in global performance.<br/><br/>The role sits in the R&amp;D channel and at the crossover of software, hardware, data science and AI. You’ll help come up with new solutions to hard problems, create novel products and support the dev team in building and maintaining core software.<br/><br/>We’re looking for a hybrid Data Science/Engineer to join the team as their first specialist Data employee to leverage the extensive data volume we harvest<br/><br/><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>The Role<br/><br/></strong>As the companies first Data Specialist you’ll be confident working autonomously and help shape the companies Data profile. The role offers the chance to really shape the long term direction of the Data Dept with your decision making influential to the companies plans to scale<br/><br/><strong>Requirements<br/><br/></strong><ul><li>Strong coding skills, Python, Java </li><li>AWS experience</li><li>Ability to create data pipelines and storage in AWS</li><li>Ability to analyse large data sets and present findings</li><li>(nice to have) AI skills<br/><br/></li></ul><strong>AWS - Python - AI - CICD<br/><br/></strong><strong>Benefits<br/><br/></strong><ul><li>Competitive salary, contributory pension scheme</li><li>Hybrid working.</li><li>International travel available</li><li>20% bonus scheme</li><li>Electric Vehicle Salary Sacrifice scheme (after 6 months of joining)<br/><br/></li></ul><strong>AWS - Python - AI - CICD</strong>
</div>",No Salary Info Found,Data and AI Engineer
Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788644512,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Wilmington, DE","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Job Title: Senior Lead Engineer - Generative AI Product Engineering (Remote-Eligible) Location: Remote (Work from Anywhere) Company: Capital One About Us: At Capital One, our mission is to create trustworthy, reliable, and inclusive AI systems that make banking simple and accessible for everyone. We have been at the forefront of using machine learning to deliver intelligent and personalized customer experiences, from detecting fraudulent charges to providing instant customer support. With our investment in cloud infrastructure and machine learning platforms, we are uniquely positioned to harness the power of AI. We are dedicated to building top-notch applied science and engineering teams to continue developing breakthrough products and scalable AI infrastructure. Join us in reimagining how we serve our customers and businesses and make a positive impact with emerging AI technologies. Job Description: We are seeking an experienced Senior Lead Engineer to join our Enterprise AI team. In this role, you will be responsible for developing and maintaining APIs and SDKs that allow users to train, fine-tune, and access AI models at scale. Working alongside world-class AI engineers and researchers, you will design and implement key API products and services, ensuring real-time customer-facing applications are empowered by our AI capabilities. Your projects may include architecting and deploying core APIs for large-language models, designing high-performance and secure APIs, and developing application-specific interfaces to enhance the customer experience. Responsibilities: - Architect, build, and deploy well-managed core APIs and SDKs for accessing large-language models and proprietary models, including training, fine-tuning, and prompting tasks. - Design APIs for performance, real-time applications, scalability, ease of use, and governance automation. - Develop application-specific interfaces utilizing language models to improve the customer and associate experience. - Enable users to build new AI capabilities. - Develop tools and processes to monitor API access patterns and operational health. - Implement AI safety measures in the API layer in collaboration with researchers. Requirements: - Bachelor's degree in Computer Science, Computer Engineering, or a related technical field. - Minimum 8 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. - Minimum 4 years of programming experience with Python, Go, Scala, or Java. - Minimum 3 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks. Preferred Qualifications: - Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. - Ability to work in a fast-paced environment with ambiguity and competing priorities. - Experience collaborating with researchers and engineers to improve product experiences while building foundational capabilities. - Experience deploying large neural network models in demanding production environments. - Knowledge of API security, observability, cloud access control, and privacy best practices. Salary: - New York City (Hybrid On-Site): $230,100 - $262,700 per year - San Francisco, California (Hybrid On-Site): $243,800 - $278,200 per year - Remote (Work from Anywhere): $195,000 - $222,600 per year Benefits: Capital One offers a comprehensive and inclusive set of health, financial, and other benefits to support your well-being. Learn more about our benefits on the Capital One Careers website. Application Process: Please apply through our website. Applications will be accepted for a minimum of 5 business days. Equal Opportunity Employer: Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We provide equal employment opportunities to all qualified individuals without regard to sex, race, age, religion, disability, genetic information, marital status, sexual orientation, gender identity, gender reassignment, citizenship, immigration status, protected veteran status, or any other basis prohibited by applicable federal, state, or local law. Accommodations: If you require accommodations during the application process, please contact Capital One Recruiting at 1-800-304-9102 or email RecruitingAccommodation@capitalone.com. All the information you provide will be kept confidential and used only to provide necessary reasonable accommodations. Technical Support: For technical support or questions about our recruiting process, please email Careers@capitalone.com. Note: Capital One does not endorse or guarantee third-party products, services, educational tools, or information available through external sites. Please note that positions posted in Canada are for Capital One Canada, those in the United Kingdom are for Capital One Europe, and positions in the Philippines are for Capital One Philippines Service Corp. (COPSSC).
      </div>",$230100- $262700,Data and AI Engineer
Lead Engineer - Generative AI Product Engineering (Remote-Eligible),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788649255,0,https://media.licdn.com/dms/image/C560BAQFq3vOeLNal8w/company-logo_100_100/0/1646204220376/jobs_for_humanity_global_logo?e=2147483647&v=beta&t=bht4ZHYQ_d6ZNBMXAu7oraOMxQJv81SadVMZ4nVGp88,"Wilmington, DE","<div class=""show-more-less-html__markup show-more-less-html__markup--clamp-after-5 relative overflow-hidden"">
<strong>Company Description<br/><br/></strong>Jobs for Humanity is partnering with Capital One to build an inclusive and just employment ecosystem. Therefore, we prioritize individuals coming from the following communities: Refugee, Neurodivergent, Single Parent, Blind or Low Vision, Deaf or Hard of Hearing, Black, Hispanic, Asian, Military Veterans, the Elderly, the LGBTQ, and Justice Impacted individuals. This position is open to candidates who reside in and have the legal right to work in the country where the job is located.<br/><br/>Company Name: Capital One<br/><br/><strong>Job Description<br/><br/></strong>Lead Engineer - Generative AI Product Engineering (Remote-Eligible) Our mission at Capital One is to create trustworthy, reliable, and inclusive AI systems that improve banking for everyone. We have been pioneers in using machine learning to enhance customer experiences, from detecting unusual charges to providing real-time assistance. We are now seeking an experienced Lead Generative AI Engineer to join our Enterprise AI team and help build and maintain APIs and SDKs that enable users to access and train AI models at scale. Examples of projects you will work on: - Architect, build, and deploy core APIs and SDKs for accessing Large-Language Models (LLMs) and Foundation Models (FMs), including training, fine-tuning, and prompting tasks. - Design APIs that prioritize performance, real-time applications, scalability, ease of use, and governance automation. - Develop application-specific interfaces that leverage LLMs and FMs to enhance the customer experience. - Enable users to develop new Generative AI capabilities. - Create tools and processes to monitor API access patterns and ensure operational health. - Implement AI safety and guardrails in the API layer, in collaboration with researchers. Basic Qualifications: - Bachelor's degree in Computer Science, Computer Engineering, or a related technical field. - At least 6 years of experience designing and building data-intensive solutions using distributed computing and cache optimization techniques. - At least 4 years of programming experience with Python, Go, Scala, or Java. - At least 2 years of experience building, scaling, and optimizing training and inferencing APIs for deep neural networks. Preferred Qualifications: - Familiarity with building large-scale AI products or platforms for NLP, speech, computer vision, or recommendation systems serving millions of users. - Ability to work in a fast-paced, ambiguous environment with competing priorities and deadlines. - Experience collaborating with researchers and engineers to improve product experiences. - Familiarity with deploying large neural network models in demanding production environments. - Knowledge of API security, observability, cloud access control, and privacy best practices. At this time, Capital One is unable to sponsor new applicants for employment authorization for this position. Salary Range: - New York City (Hybrid On-Site): $197,400 - $225,300 for Lead Machine Learning Engineer. - San Francisco, California (Hybrid On-Site): $209,200 - $238,700 for Lead Machine Learning Engineer. - Remote (Regardless of Location): $167,400 - $191,000 for Lead Machine Learning Engineer. Capital One offers comprehensive benefits that support your well-being. Learn more at the Capital One Careers website. Eligibility varies based on employment status. This role is open for a minimum of 5 business days. No agencies, please. Capital One is an equal opportunity employer committed to diversity and inclusion in the workplace. We value candidates from all backgrounds. If you require an accommodation during the application process, please contact Capital One Recruiting at 1-800-304-9102 or via email at RecruitingAccommodation@capitalone.com. For technical support or questions about our recruiting process, please email Careers@capitalone.com. Note: This position is specific to Capital One in the United States. For opportunities in other countries, please visit the appropriate Capital One entity's website.
      </div>",$197400- $225300,Data and AI Engineer
Senior Lead Engineer - Generative AI Infrastructure (Remote-Eligible),Jobs for Humanity,12/20/2023,https://www.linkedin.com/jobs/view/3788645436,0,Unable to scrape,Unable to scrape,Unable to scrape,Unable to scrape,Data and AI Engineer
